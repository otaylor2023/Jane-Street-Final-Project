{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q seaborn\n",
        "!pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "id": "gFKd0wXYAQMP",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00046e5-9553-4976-c539-19b997798f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.0.3)\n",
            "Collecting tensorflow==2.16.2 (from tensorflow_decision_forests)\n",
            "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.43.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting tf-keras~=2.16 (from tensorflow_decision_forests)\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ydf (from tensorflow_decision_forests)\n",
            "  Downloading ydf-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (71.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.0.0 (from tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (0.37.1)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras~=2.16 (from tensorflow_decision_forests)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (0.1.2)\n",
            "Downloading tensorflow_decision_forests-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, ydf, wurlitzer, optree, ml-dtypes, tensorboard, keras, tensorflow, tf-keras, tensorflow_decision_forests\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.15.1\n",
            "    Uninstalling tf_keras-2.15.1:\n",
            "      Successfully uninstalled tf_keras-2.15.1\n",
            "Successfully installed keras-3.4.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.12.1 tensorboard-2.16.2 tensorflow-2.16.2 tensorflow_decision_forests-1.9.2 tf-keras-2.16.0 wurlitzer-3.1.1 ydf-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-fe0umOr5n3I",
        "outputId": "16f368b3-3265-417e-bd6a-3301c82e1ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.1.4)\n",
            "Collecting tensorflow==2.16.2 (from tensorflow_decision_forests)\n",
            "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.43.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tf-keras~=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.17.0)\n",
            "Collecting ydf (from tensorflow_decision_forests)\n",
            "  Downloading ydf-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (71.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow_decision_forests)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2->tensorflow_decision_forests) (0.37.1)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras~=2.16 (from tensorflow_decision_forests)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow_decision_forests) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow_decision_forests) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow_decision_forests) (0.1.2)\n",
            "Downloading tensorflow_decision_forests-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m583.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ydf, wurlitzer, ml-dtypes, tensorboard, tensorflow, tf-keras, tensorflow_decision_forests\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.0\n",
            "    Uninstalling ml-dtypes-0.4.0:\n",
            "      Successfully uninstalled ml-dtypes-0.4.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "Successfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.2 tensorflow_decision_forests-1.9.2 tf-keras-2.16.0 wurlitzer-3.1.1 ydf-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ml_dtypes",
                  "tensorflow"
                ]
              },
              "id": "95f309dc8f8c4fd6b9c110f648a2248e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.utils import class_weight\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "# Make NumPy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "metadata": {
        "id": "OgDXxl6yASZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "7HfzZYeNOcOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjuQ3s0He0Jo",
        "outputId": "e03f338a-aeac-4002-e560-8043e072aeb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a6sZuiP7ISO",
        "outputId": "7e5c2007-57cb-4285-9e40-52ef8ddd0c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd = \"/content/drive/MyDrive/JSIP Final Project/dbs\"\n",
        "model_save_pwd = \"/content/drive/MyDrive/JSIP Final Project/models\"\n",
        "pwd_parent = \"/content/drive/MyDrive/JSIP Final Project\"\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "WMM3RGA85t2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_FeO-aZx-Lo3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##process datasets##"
      ],
      "metadata": {
        "id": "z7mgze3El4mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset():\n",
        "  dataset = pd.read_excel(f\"{pwd}/db_exp_1.xlsx\")\n",
        "  del dataset[\"Unnamed: 0\"]\n",
        "  del dataset[\"result\"]\n",
        "  del dataset[\"date\"]\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "eSKSeGDQe-AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_with_result():\n",
        "  dataset = pd.read_excel(f\"{pwd}/db_exp_1.xlsx\")\n",
        "  del dataset[\"Unnamed: 0\"]\n",
        "  del dataset[\"date\"]\n",
        "  return dataset\n",
        "\n",
        "def get_dataset_with_date():\n",
        "  dataset = pd.read_excel(f\"{pwd}/db_exp_1.xlsx\")\n",
        "  del dataset[\"Unnamed: 0\"]\n",
        "  del dataset[\"result\"]\n",
        "  return dataset\n",
        "\n",
        "def get_dataset_with_season():\n",
        "  dataset = pd.read_excel(f\"{pwd}/db_exp_2.xlsx\")\n",
        "  del dataset[\"Unnamed: 0\"]\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
        "  cm = tf.math.confusion_matrix(actual, predicted)\n",
        "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
        "  sns.set(rc={'figure.figsize':(4, 4)})\n",
        "  sns.set(font_scale=1.4)\n",
        "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
        "  ax.set_xlabel('Predicted Action')\n",
        "  ax.set_ylabel('Actual Action')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "msa07StWJ9pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset_splits(train_dataset, test_dataset, convert_to_float):\n",
        "  train_target = train_dataset[['CP1_AVG', 'CPX_AVG', 'CP2_AVG']]\n",
        "  test_target = test_dataset[['CP1_AVG', 'CPX_AVG', 'CP2_AVG']]\n",
        "  train_features = train_dataset.drop(columns=['CP1_AVG', 'CPX_AVG', 'CP2_AVG'])\n",
        "  test_features = test_dataset.drop(columns=['CP1_AVG', 'CPX_AVG', 'CP2_AVG'])\n",
        "  if convert_to_float:\n",
        "    train_target = np.array(train_target).astype('float32')\n",
        "    test_target = np.array(test_target).astype('float32')\n",
        "\n",
        "    train_features = np.array(train_features).astype('float32')\n",
        "    test_features = np.array(test_features).astype('float32')\n",
        "  return (train_features, train_target), (test_features, test_target)\n",
        "\n",
        "def split_dataset(dataset, convert_to_float):\n",
        "  # dropping last 2 seasons\n",
        "  test_size = 760\n",
        "  train_dataset = dataset.iloc[:-test_size]\n",
        "  test_dataset = dataset.tail(test_size)\n",
        "  return train_dataset, test_dataset\n",
        "  # dataset\n",
        "\n",
        "def get_dataset_splits(dataset, convert_to_float):\n",
        "  train_dataset, test_dataset = split_dataset(dataset, convert_to_float)\n",
        "  return process_dataset_splits(train_dataset, test_dataset, convert_to_float)\n",
        "\n",
        "def get_diffs(openings, closings):\n",
        "  op1, opx, op2 = openings\n",
        "  cp1, cpx, cp2 = closings\n",
        "  diff1 = cp1 - op1\n",
        "  diffx = cpx - opx\n",
        "  diff2 = cp2 - op2\n",
        "  return diff1, diffx, diff2\n",
        "\n",
        "def min_diff(diffs):\n",
        "  diff1, diffx, diff2 = diffs\n",
        "  min_diff = min(diff1, diffx, diff2)\n",
        "  if min_diff == diff1:\n",
        "      return \"H\"\n",
        "  elif min_diff == diffx:\n",
        "    return \"D\"\n",
        "  elif min_diff == diff2:\n",
        "    return \"A\"\n",
        "  else:\n",
        "    return \"aaa\"\n",
        "\n",
        "def get_diff_database(database):\n",
        "  op1x2 = database[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]]\n",
        "  op1x2 = np.array(op1x2).astype('float32')\n",
        "  cp1x2 = database[[\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"]]\n",
        "  cp1x2 = np.array(cp1x2).astype('float32')\n",
        "  diff1_list = []\n",
        "  diffx_list = []\n",
        "  diff2_list = []\n",
        "  for op, cp in zip(op1x2, cp1x2):\n",
        "    op1, opx, op2 = op\n",
        "    diff1, diffx, diff2 = get_diffs(op, cp)\n",
        "    # print(f\"{diff1}, {diffx}, {diff2}\")\n",
        "    # print(cp)\n",
        "    diff1_list.append(diff1)\n",
        "    diffx_list.append(diffx)\n",
        "    diff2_list.append(diff2)\n",
        "  database[\"DIFF1\"] = diff1_list\n",
        "  database[\"DIFFX\"] = diffx_list\n",
        "  database[\"DIFF2\"] = diff2_list\n",
        "  return database\n",
        "\n",
        "def get_max_diff(dataset, as_letter = True):\n",
        "  op1x2 = dataset[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]]\n",
        "  cp1x2 = dataset[[\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"]]\n",
        "  op1x2 = np.array(op1x2).astype('float32')\n",
        "  cp1x2 = np.array(cp1x2).astype('float32')\n",
        "\n",
        "  max_diffs = []\n",
        "  for cp1x2_val, op1x2_val in zip(cp1x2, op1x2):\n",
        "    real_diffs = get_diffs(op1x2_val, cp1x2_val)\n",
        "    next_letter = min_diff(real_diffs)\n",
        "    if (as_letter):\n",
        "      max_diffs += next_letter\n",
        "    else:\n",
        "      if next_letter == \"H\":\n",
        "        max_diffs.append(0)\n",
        "      elif next_letter == \"D\":\n",
        "        max_diffs.append(1)\n",
        "      else:\n",
        "        max_diffs.append(2)\n",
        "\n",
        "  return max_diffs\n",
        "\n",
        "def get_dir_database(database):\n",
        "  op1x2 = database[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]]\n",
        "  op1x2 = np.array(op1x2).astype('float32')\n",
        "  cp1x2 = database[[\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"]]\n",
        "  cp1x2 = np.array(cp1x2).astype('float32')\n",
        "  diff1_list = []\n",
        "  diffx_list = []\n",
        "  diff2_list = []\n",
        "  for op, cp in zip(op1x2, cp1x2):\n",
        "    op1, opx, op2 = op\n",
        "    diff1, diffx, diff2 = get_diffs(op, cp)\n",
        "    # print(f\"{diff1}, {diffx}, {diff2}\")\n",
        "    # print(cp)\n",
        "    diff1_list.append(1 if diff1 > 0 else 0)\n",
        "    diffx_list.append(1 if diffx > 0 else 0)\n",
        "    diff2_list.append(1 if diff2 > 0 else 0)\n",
        "  database[\"DIR1\"] = diff1_list\n",
        "  database[\"DIRX\"] = diffx_list\n",
        "  database[\"DIR2\"] = diff2_list\n",
        "  return database\n",
        "\n",
        "def get_dir_dataset_stats(dataset, label):\n",
        "  num_up = (dataset[label].value_counts()[1])\n",
        "  num_down = (dataset[label].value_counts()[0])\n",
        "  total = len(dataset)\n",
        "  print(f\"U% : {format((num_up/total) * 100, '.3f')}%, {num_up}/{total}; D% : {format((num_down/total) * 100, '.3f')}%, {num_down}/{total}\")"
      ],
      "metadata": {
        "id": "YBdYlHgVbPhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_odds_percent_database(dataset):\n",
        "  total_odds = dataset[\"OP1_AVG\"] + dataset[\"OPX_AVG\"] + dataset[\"OP2_AVG\"]\n",
        "  dataset[\"OP1_RATE\"] = dataset[\"OP1_AVG\"] / total_odds\n",
        "  dataset[\"OPX_RATE\"] = dataset[\"OPX_AVG\"] / total_odds\n",
        "  dataset[\"OP2_RATE\"] = dataset[\"OP2_AVG\"] / total_odds\n",
        "  return dataset\n",
        "\n",
        "def get_odds_percent_database_closing(dataset):\n",
        "  total_odds = dataset[\"CP1_AVG\"] + dataset[\"CPX_AVG\"] + dataset[\"CP2_AVG\"]\n",
        "  dataset[\"CP1_RATE\"] = dataset[\"CP1_AVG\"] / total_odds\n",
        "  dataset[\"CPX_RATE\"] = dataset[\"CPX_AVG\"] / total_odds\n",
        "  dataset[\"CP2_RATE\"] = dataset[\"CP2_AVG\"] / total_odds\n",
        "  return dataset\n",
        "\n",
        "def get_max_diff_database(dataset):\n",
        "  dataset[\"MAX_DIFF\"] = get_max_diff(dataset)\n",
        "  return dataset\n",
        "\n",
        "def calculate_winnings(dataset, odds_label, pred_result):\n",
        "  winnings = dataset[dataset[\"result\"] == pred_result][odds_label].sum()\n",
        "  costs = len(dataset)\n",
        "  return winnings - costs\n",
        "\n",
        "def calculate_ev(dataset, odds_label, pred_result):\n",
        "  if (len(dataset) == 0):\n",
        "    return 0\n",
        "  winnings = calculate_winnings(dataset, odds_label, pred_result)\n",
        "  # print(len(dataset))\n",
        "  return winnings / len(dataset)\n",
        "\n",
        "def calculate_ev_math(p, odds):\n",
        "  return (p * (odds - 1) + (1 - p) * -1)\n",
        "\n",
        "def get_power_database(dataset):\n",
        "  dataset[\"HOME_POWER\"] = (dataset[\"home_wins_rate\"] * 2 + dataset[\"home_tie_rate\"]) / (dataset[\"away_wins_rate\"] * 2 + dataset[\"away_tie_rate\"])\n",
        "  dataset[\"HOME_POWER\"] = [10 if x > 10 else x for x in dataset[\"HOME_POWER\"]]\n",
        "  return dataset\n",
        "\n",
        "def get_odds_rankings(dataset, is_opening):\n",
        "  p1_label = \"OP1_AVG\" if is_opening else \"CP1_AVG\"\n",
        "  px_label = \"OPX_AVG\" if is_opening else \"CPX_AVG\"\n",
        "  p2_label = \"OP2_AVG\" if is_opening else \"CP2_AVG\"\n",
        "  append_label = \"OP\" if is_opening else \"CP\"\n",
        "  max_odds = []\n",
        "  mid_odds = []\n",
        "  min_odds = []\n",
        "  for index, row in dataset.iterrows():\n",
        "    op1 = {\"odd\": row[p1_label], \"symbol\": \"H\"}\n",
        "    opx = {\"odd\": row[px_label], \"symbol\": \"D\"}\n",
        "    op2 = {\"odd\": row[p2_label], \"symbol\": \"A\"}\n",
        "    max_odd = max(op1, opx, op2, key=lambda x:x[\"odd\"])\n",
        "    min_odd = min(op1, opx, op2, key=lambda x:x[\"odd\"])\n",
        "    mid_odd = [x for x in [op1, opx, op2] if (x != max_odd and x != min_odd)][0]\n",
        "    # print(mid_odd)\n",
        "    max_odds.append(max_odd[\"symbol\"])\n",
        "    min_odds.append(min_odd[\"symbol\"])\n",
        "    mid_odds.append(mid_odd[\"symbol\"])\n",
        "  dataset[f\"{append_label}_MAX_ODD\"] = max_odds\n",
        "  dataset[f\"{append_label}_MID_ODD\"] = mid_odds\n",
        "  dataset[f\"{append_label}_MIN_ODD\"] = min_odds\n",
        "  return dataset\n"
      ],
      "metadata": {
        "id": "ApUqRnTjgXIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stat_percent_database(dataset):\n",
        "  dataset[\"home_wins_rate\"] = [(0 if num == 0 else x / num) for x, num in zip(dataset[\"home_wins\"], dataset[\"games\"])]\n",
        "  dataset[\"home_tie_rate\"] = [(0 if num == 0 else x / num) for x, num in zip(dataset[\"home_tie\"], dataset[\"games\"])]\n",
        "  dataset[\"home_loss_rate\"] = [(0 if num == 0 else x / num) for x, num in zip(dataset[\"home_loss\"], dataset[\"games\"])]\n",
        "  dataset[\"away_wins_rate\"] = [(0 if num == 0 else x / num) for x, num in zip(dataset[\"away_wins\"], dataset[\"games\"])]\n",
        "  dataset[\"away_tie_rate\"] = [(0 if num == 0 else x / num) for x, num in zip(dataset[\"away_tie\"], dataset[\"games\"])]\n",
        "  dataset[\"away_loss_rate\"] = [(0 if num == 0 else x / num) for x, num in zip(dataset[\"away_loss\"], dataset[\"games\"])]\n",
        "  dataset = dataset.drop(columns=[\"home_wins\", \"home_tie\", \"home_loss\", \"away_wins\", \"away_tie\", \"away_loss\"])\n",
        "  return dataset\n",
        "\n",
        "def get_features_and_labels(dataset, labels):\n",
        "  dataset_target = dataset[labels]\n",
        "  dataset_features = dataset.drop(columns=labels)\n",
        "\n",
        "  dataset_target = np.array(dataset_target).astype('float32')\n",
        "  dataset_features = np.array(dataset_features).astype('float32')\n",
        "  return dataset_target, dataset_features\n",
        "\n",
        "def get_extreme_stats_dataset(dataset, label):\n",
        "  for index, row in stats_dataset.iterrows():\n",
        "    diff = row[\"home_wins_rate\"] - row[\"away_wins_rate\"]\n",
        "    if abs(diff) < .5:\n",
        "      stats_dataset = stats_dataset.drop(index=index)"
      ],
      "metadata": {
        "id": "mZUn7DpKBgXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maybe make it 1 if away, 2 if home\n",
        "def get_OHE_dataset(dataset):\n",
        "  home_one_hot = pd.get_dummies(dataset[\"home_team\"], prefix=\"home\")\n",
        "  away_one_hot = pd.get_dummies(dataset[\"away_team\"], prefix=\"away\")\n",
        "  dataset_hot = dataset.drop(\"home_team\", axis = 1)\n",
        "  dataset_hot = dataset_hot.drop(\"away_team\", axis = 1)\n",
        "  dataset_hot = dataset_hot.join(home_one_hot)\n",
        "  dataset_hot = dataset_hot.join(away_one_hot)\n",
        "  return dataset_hot"
      ],
      "metadata": {
        "id": "841RHeK58Vqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_small_OHE_dataset(dataset):\n",
        "  home_one_hot = pd.get_dummies(dataset[\"home_team\"])\n",
        "  away_one_hot = pd.get_dummies(dataset[\"away_team\"])\n",
        "  result_df = home_one_hot.copy()\n",
        "  for col_name in result_df.columns.tolist():\n",
        "    result_df[col_name] = result_df[col_name] + away_one_hot[col_name]\n",
        "    result_df = result_df.ge(1).astype(int)\n",
        "\n",
        "  dataset_hot = dataset.drop(\"home_team\", axis = 1)\n",
        "  dataset_hot = dataset_hot.drop(\"away_team\", axis = 1)\n",
        "  dataset_hot = dataset_hot.join(result_df)\n",
        "  return dataset_hot\n",
        "\n",
        "def get_weighted_OHE_dataset(dataset):\n",
        "  home_one_hot = pd.get_dummies(dataset[\"home_team\"])\n",
        "  away_one_hot = pd.get_dummies(dataset[\"away_team\"])\n",
        "  result_df = home_one_hot.copy()\n",
        "  for col_name in result_df.columns.tolist():\n",
        "    result_df[col_name] = (result_df[col_name]) * 2 + away_one_hot[col_name]\n",
        "    # result_df = result_df.ge(1).astype(int)\n",
        "\n",
        "  dataset_hot = dataset.drop(\"home_team\", axis = 1)\n",
        "  dataset_hot = dataset_hot.drop(\"away_team\", axis = 1)\n",
        "  dataset_hot = dataset_hot.join(result_df)\n",
        "  return dataset_hot"
      ],
      "metadata": {
        "id": "p3Xhdvy2U42G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_factorized_dataset(dataset):\n",
        "  dataset_encoded = dataset.copy()\n",
        "  encoded_home = pd.factorize(dataset[\"home_team\"])[0]\n",
        "  encoded_away= pd.factorize(dataset[\"away_team\"])[0]\n",
        "  dataset_encoded[\"home_team\"] = encoded_home\n",
        "  dataset_encoded[\"away_team\"] = encoded_away\n",
        "  return dataset_encoded"
      ],
      "metadata": {
        "id": "zgggKTijclmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_dataset.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N805sqX_OnSw",
        "outputId": "6bd36259-95c5-410a-b1df-e7f44a4d67ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_target = np.array(train_target).astype('float32')\n",
        "# test_target = np.array(test_target).astype('float32')\n",
        "\n",
        "# train_features = np.array(train_features).astype('float32')\n",
        "# test_features = np.array(test_features).astype('float32')\n",
        "\n"
      ],
      "metadata": {
        "id": "Lu4rpcqQ8MPE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_factorized_data_splits():\n",
        "  dataset = get_dataset()\n",
        "  factorized_dataset = get_factorized_dataset(dataset)\n",
        "  return get_dataset_splits(factorized_dataset, True)\n",
        "\n",
        "def get_OHE_data_splits():\n",
        "  dataset = get_dataset()\n",
        "  ohe_dataset = get_OHE_dataset(dataset)\n",
        "  return get_dataset_splits(ohe_dataset, True)\n",
        "\n",
        "def get_MDO_data_splits():\n",
        "  dataset = get_dataset()\n"
      ],
      "metadata": {
        "id": "OaBrmUxNRiVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZyOgnKImAfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_features, train_target), (test_features, test_target) = get_factorized_data_splits()\n"
      ],
      "metadata": {
        "id": "tHpkpY4ghCSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBiQTalYkssR",
        "outputId": "81298a08-82c5-4111-a9f6-d8d3a1e28565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.217, 3.414, 2.237],\n",
              "       [1.994, 3.245, 4.134],\n",
              "       [2.386, 3.239, 3.098],\n",
              "       ...,\n",
              "       [3.13 , 2.933, 2.603],\n",
              "       [1.445, 4.722, 7.145],\n",
              "       [1.98 , 3.922, 3.546]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_features, train_target), (test_features, test_target) = get_OHE_data_splits()"
      ],
      "metadata": {
        "id": "BUxFIZ1RhNy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2derAB5-KYcI",
        "outputId": "da56b56c-0bab-4002-f6f6-ab4ba52ecf13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.217, 3.414, 2.237],\n",
              "       [1.994, 3.245, 4.134],\n",
              "       [2.386, 3.239, 3.098],\n",
              "       ...,\n",
              "       [3.13 , 2.933, 2.603],\n",
              "       [1.445, 4.722, 7.145],\n",
              "       [1.98 , 3.922, 3.546]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##run model##"
      ],
      "metadata": {
        "id": "ukA3R9N7mFmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "metadata": {
        "id": "ArL3PiXRh4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xvuITWrvfg5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(train_features)\n",
        "\n",
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(3)\n",
        "])\n",
        "\n",
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.05),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "eglqtcf9hT52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5IUBfdg0hb3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c2aa89-e497-4e6d-ed3a-53ee00eda09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 177ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.083],\n",
              "       [ 1.737],\n",
              "       [-1.585],\n",
              "       [-1.248],\n",
              "       [-0.221],\n",
              "       [-0.737],\n",
              "       [-2.319],\n",
              "       [-1.839],\n",
              "       [-0.75 ],\n",
              "       [-0.234]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_1zmbCEhce1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features.dtype)\n",
        "print(train_target.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCEMc853PQjU",
        "outputId": "11124660-242f-40b8-e2c2-49cef4715741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=30,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")"
      ],
      "metadata": {
        "id": "CtUvqAY3X_w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features,\n",
        "    train_target,\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping],\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "Vqp6v74ghiCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "05b7d91c-b7c5-4b10-b1d0-ea1d43190859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "67/67 [==============================] - 1s 7ms/step - loss: 1.0925 - val_loss: 0.6936\n",
            "Epoch 2/200\n",
            "43/67 [==================>...........] - ETA: 0s - loss: 0.7193"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mAn\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mon\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mdevice_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;34m\"\"\"Returns the device name for the current thread.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##evaluate model##"
      ],
      "metadata": {
        "id": "X6K_F4HtEHsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "feGWozYmhqNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "928d8401-558f-4853-d38e-33cce808c99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAG2CAYAAABlBWwKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/GklEQVR4nO3deZwU9Z3/8Xf13T33AXPAAANyDAiIIIi4iQgEUfGIcdeVJKgbjYoHGo2aeBFjMMcSEnUx5rdidgOSNQnGqKCIotGgXAIityIgMDPMfff0Ub8/amgZh2MYZugufT0f1KPpOj/d35qud3+rutswTdMUAACADTniXQAAAEBHEWQAAIBtEWQAAIBtEWQAAIBtEWQAAIBtEWQAAIBtEWQAAIBtEWQAAIBtEWQAAIBtEWQAAIBtxTXIvP3225o6dary8/NlGIZeeOGFVtNN09SDDz6ovLw8+f1+TZw4UTt27IhPsQAAIOHENcjU19dr+PDhevLJJ484/Re/+IV++9vf6qmnntL777+vpKQkTZ48WU1NTae4UgAAkIiMRPnRSMMwtHjxYl122WWSrN6Y/Px8/eAHP9Bdd90lSaqurlZOTo6effZZXXXVVXGsFgAAJAJXvAs4ml27dqm4uFgTJ06MjUtLS9OYMWO0cuXKowaZYDCoYDAYux+NRlVRUaGsrCwZhtHldQMAgJNnmqZqa2uVn58vh+PoJ5ASNsgUFxdLknJyclqNz8nJiU07ktmzZ2vWrFldWhsAADg19u7dq549ex51esIGmY667777dOedd8buV1dXq1evXtq1a5dSUlI6bTuhUEhvvvmmxo8fL7fb3WnrRdei3eyJdrMn2s2eEqXdamtrVVhYeNxjd8IGmdzcXElSSUmJ8vLyYuNLSkp0xhlnHHU5r9crr9fbZnxmZqZSU1M7rb5QKKRAIKCsrCz+QG2EdrMn2s2eaDd7SpR2O7Tt410WkrDfI1NYWKjc3FwtX748Nq6mpkbvv/++xo4dG8fKAABAoohrj0xdXZ127twZu79r1y6tX79emZmZ6tWrl2bOnKmf/vSn6t+/vwoLC/XAAw8oPz8/9skmAADw1RbXILNmzRqNHz8+dv/QtS3Tp0/Xs88+qx/+8Ieqr6/XDTfcoKqqKp177rlaunSpfD5fvEoGAAAJJK5B5rzzztOxvsbGMAz95Cc/0U9+8pNTWBUA4MsmGo2qubk53mXYQigUksvlUlNTkyKRSJdtx+12y+l0nvR6EvZiXwAAOkNzc7N27dqlaDQa71JswTRN5ebmau/evV3+/Wvp6enKzc09qe0QZAAAX1qmaerAgQNyOp0qKCg45herwRKNRlVXV6fk5OQue75M01RDQ4NKS0slqdWnk08UQQYA8KUVDofV0NCg/Px8BQKBeJdjC4dOw/l8vi4Nfn6/X5JUWlqq7t27d/g0E9EUAPCldegaD4/HE+dKcCSHwmUoFOrwOggyAIAvPX5rLzF1RrsQZAAAgG0RZAAASDDnnXeeZs6cGe8ybIEgAwAAbIsgAwAAbIsgAwBAAqusrNR3v/tdZWRkKBAIaMqUKdqxY0ds+u7duzV16lRlZGQoKSlJQ4YM0SuvvBJbdtq0aerWrZv8fr/69++v+fPnx+uhdAm+RwYA8JVhmqYaQ133tfvH4nc7O/QpnWuuuUY7duzQiy++qNTUVN1zzz268MILtXnzZrndbs2YMUPNzc16++23lZSUpM2bNys5OVmS9MADD2jz5s1asmSJsrOztXPnTjU2Nnb2Q4srggwA4CujMRTR4Adfjcu2N/9ksgKeEzvsHgow7777rs455xxJ0oIFC1RQUKAXXnhBV155pfbs2aMrrrhCQ4cOlST17ds3tvyePXs0YsQIjRo1SpLUp0+fznkwCYRTSwAAJKgtW7bI5XJpzJgxsXFZWVkaOHCgtmzZIkm67bbb9NOf/lTjxo3TQw89pI0bN8bmvemmm7Ro0SKdccYZ+uEPf6h//vOfp/wxdDV6ZAAAXxl+t1ObfzI5btvuCt/73vc0efJkvfzyy3rttdc0e/Zs/ed//qduvfVWTZkyRbt379Yrr7yiZcuWacKECZoxY4Z+9atfdUkt8UCPDADgK8MwDAU8rrgMHbk+pqioSOFwWO+//35sXHl5ubZt26bBgwfHxhUUFOjGG2/UX//6V/3gBz/Q73//+9i0bt26afr06frjH/+ouXPn6umnnz65JzHB0CMDAECC6t+/vy699FJdf/31+t3vfqeUlBTde++96tGjhy699FJJ0syZMzVlyhQNGDBAlZWVevPNN1VUVCRJevDBBzVy5EgNGTJEwWBQL730UmzalwU9MgAAJLD58+dr5MiRuvjiizV27FiZpqlXXnlFbrdbkvXDmDNmzFBRUZEuuOACDRgwQP/1X/8lyfqxzPvuu0/Dhg3T1772NTmdTi1atCieD6fT0SMDAECCWbFiRez/GRkZ+p//+Z+jzvv4448fddr999+v+++/vzNLSzj0yAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAA8CXTp08fzZ07t13zGoahF154oUvr6UoEGQAAYFsEGQAAYFsEGQAAEsjTTz+t/Px8RaPRVuMvvfRSXXfddfr444916aWXKicnR8nJyTrrrLP0+uuvd9r2P/zwQ11yySVKSkpSVlaWbrjhBtXV1cWmr1ixQqNHj1ZSUpLS09M1btw47d69W5K0YcMGjR8/XikpKUpNTdXIkSO1Zs2aTqvtSAgyAICvDtOUmuvjM5hmu0q88sorVV5erjfffDM2rqKiQkuXLtW0adNUV1enCy+8UMuXL9cHH3ygCy64QFOnTtWePXtO+umpr6/XlClTlJ6ervfff1/PP/+8Xn/9dd1yyy2SpHA4rMsuu0xf//rXtXHjRq1cuVI33HCDDMOQJE2bNk09e/bU6tWrtXbtWt17771yu90nXdexuLp07QAAJJJQg/Sz/Phs+0f7JU/ScWfLyMjQlClTtHDhQk2YMEGS9Oc//1nZ2dkaP368HA6Hhg8fHpv/kUce0eLFi/Xiiy/GAkdHLVy4UE1NTZo3b57y8vLkcDj0xBNPaOrUqfr5z38ut9ut6upqXXzxxerXr58kqaioKLb8nj17dPfdd2vQoEGSpP79+59UPe1BjwwAAAlm2rRp+stf/qJgMChJWrBgga666io5HA7V1dXprrvuUlFRkdLT05WcnKwtW7Z0So/Mli1bNHz4cCUlfR64xo0bp2g0qm3btikzM1PXXHONJk+erKlTp+o3v/mNDhw4EJv3zjvv1Pe+9z1NnDhRjz32mD7++OOTrul46JEBAHx1uANWz0i8tt1OU6dOlWmaevnll3XWWWfpH//4h379619Lku666y4tW7ZMv/rVr3TaaafJ7/frW9/6lpqbm7uq8lbmz5+v2267TUuXLtWf/vQn3X///Vq2bJnOPvtsPfzww7r66qv18ssva8mSJXrooYe0aNEiXX755V1WD0EGAPDVYRjtOr0Tbz6fT9/85je1YMEC7dy5UwMHDtSZZ54pSXr33Xd1zTXXxMJBXV2dPv30007ZblFRkZ599lnV19crNTU1tj2Hw6GBAwfG5hsxYoRGjBih++67T2PHjtXChQt19tlnS5IGDBigAQMG6I477tC///u/a/78+V0aZDi1BABAApo2bZpefvllPfPMM5o2bVpsfP/+/fXXv/5V69ev14YNG3T11Ve3+YTTyWzT5/Pp5ptv1qZNm/Tmm2/q1ltv1Xe+8x3l5ORo165duu+++7Ry5Urt3r1br732mnbs2KGioiI1Njbqlltu0YoVK7R79269++67Wr16datraLoCPTIAACSg888/X5mZmdq2bZuuvvrq2Pg5c+bouuuu0znnnKPs7Gzdc889qqmp6ZRtBgIBLVmyRLfeeqvGjBmjQCCgK664QnPmzIlN37p1q/7whz+ovLxceXl5mjFjhr7//e8rHA6rvLxc3/3ud1VSUqLs7Gx985vf1KxZszqltqMhyAAAkIAcDof27297PU+fPn30xhtvtBo3Y8aMVvdP5FST+YWPhQ8dOlQvvviiUlNT5XC0PnGTk5OjxYsXH3E9Ho9Hzz33XLu321k4tQQAAGyLIAMAwJfUggULlJycfMRhyJAh8S6vU3BqCQCAL6lLLrlEY8aMOeK0rv7G3VOFIAMAwJdUSkqKUlJS4l1Gl+LUEgDgS++LF7QiMXRGuxBkAABfWk6nU5JO2bfe4sQ0NDRIOrnTXJxaAgB8ablcLgUCAR08eFBut7vNx4nRVjQaVXNzs5qamrrs+TJNUw0NDSotLVV6enoscHYEQQYA8KVlGIby8vK0a9cu7d69O97l2IJpmmpsbJTf75dhGF26rfT0dOXm5p7UOggyAIAvNY/Ho/79+3N6qZ1CoZDefvttfe1rX+vSTza53e6T6ok5hCADAPjSczgc8vl88S7DFpxOp8LhsHw+ny0+os3JQgAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsEGQAAYFsJHWQikYgeeOABFRYWyu/3q1+/fnrkkUdkmma8SwMAAAnAFe8CjuXnP/+55s2bpz/84Q8aMmSI1qxZo2uvvVZpaWm67bbb4l0eAACIs4QOMv/85z916aWX6qKLLpIk9enTR88995xWrVoV58oAAEAiSOggc8455+jpp5/W9u3bNWDAAG3YsEHvvPOO5syZc9RlgsGggsFg7H5NTY0kKRQKKRQKdVpth9bVmetE16Pd7Il2syfazZ4Spd3au33DTOALTqLRqH70ox/pF7/4hZxOpyKRiB599FHdd999R13m4Ycf1qxZs9qMX7hwoQKBQFeWCwAAOklDQ4OuvvpqVVdXKzU19ajzJXSQWbRoke6++2798pe/1JAhQ7R+/XrNnDlTc+bM0fTp04+4zJF6ZAoKClRWVnbMJ+JEhUIhLVu2TJMmTZLb7e609aJr0W72RLvZE+1mT4nSbjU1NcrOzj5ukEnoU0t333237r33Xl111VWSpKFDh2r37t2aPXv2UYOM1+uV1+ttM97tdndJg3TVetG1aDd7ot3siXazp3i3W3u3ndAfv25oaJDD0bpEp9OpaDQap4oAAEAiSegemalTp+rRRx9Vr169NGTIEH3wwQeaM2eOrrvuuniXBgAAEkBCB5nHH39cDzzwgG6++WaVlpYqPz9f3//+9/Xggw/GuzQAAJAAEjrIpKSkaO7cuZo7d268SwEAAAkooa+RAQAAOBaCDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsK2EDzL79u3Tt7/9bWVlZcnv92vo0KFas2ZNvMsCAAAJwBXvAo6lsrJS48aN0/jx47VkyRJ169ZNO3bsUEZGRrxLAwAACSChg8zPf/5zFRQUaP78+bFxhYWFcawIAAAkkoQOMi+++KImT56sK6+8Um+99ZZ69Oihm2++Wddff/1RlwkGgwoGg7H7NTU1kqRQKKRQKNRptR1aV2euE12PdrMn2s2eaDd7SpR2a+/2DdM0zS6upcN8Pp8k6c4779SVV16p1atX6/bbb9dTTz2l6dOnH3GZhx9+WLNmzWozfuHChQoEAl1aLwAA6BwNDQ26+uqrVV1drdTU1KPOl9BBxuPxaNSoUfrnP/8ZG3fbbbdp9erVWrly5RGXOVKPTEFBgcrKyo75RJyoUCikZcuWadKkSXK73Z22XnQt2s2eaDd7ot3sKVHaraamRtnZ2ccNMgl9aikvL0+DBw9uNa6oqEh/+ctfjrqM1+uV1+ttM97tdndJg3TVetG1aDd7ot3siXazp3i3W3u3ndAfvx43bpy2bdvWatz27dvVu3fvOFUEAAASSUIHmTvuuEPvvfeefvazn2nnzp1auHChnn76ac2YMSPepQEAgASQ0EHmrLPO0uLFi/Xcc8/p9NNP1yOPPKK5c+dq2rRp8S4NAAAkgIS+RkaSLr74Yl188cXxLgMAACSghO6RAQAAOBaCDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsK0TDjKhUEgul0ubNm3qinoAAADa7YSDjNvtVq9evRSJRLqiHgAAgHbr0KmlH//4x/rRj36kioqKzq4HAACg3VwdWeiJJ57Qzp07lZ+fr969eyspKanV9HXr1nVKcQAAAMfSoSBz2WWXdXIZAAAAJ65DQeahhx7q7DoAAABOWIeCzCFr167Vli1bJElDhgzRiBEjOqUoAACA9uhQkCktLdVVV12lFStWKD09XZJUVVWl8ePHa9GiRerWrVtn1ggAAHBEHfrU0q233qra2lp99NFHqqioUEVFhTZt2qSamhrddtttnV0jAADAEXWoR2bp0qV6/fXXVVRUFBs3ePBgPfnkk/rGN77RacUBAAAcS4d6ZKLRqNxud5vxbrdb0Wj0pIsCAABojw4FmfPPP1+333679u/fHxu3b98+3XHHHZowYUKnFQcAAHAsHQoyTzzxhGpqatSnTx/169dP/fr1U2FhoWpqavT44493do0AAABH1KFrZAoKCrRu3Tq9/vrr2rp1qySpqKhIEydO7NTiAAAAjuWEg0woFJLf79f69es1adIkTZo0qSvqAgAAOC5+/RoAANgWv34NAABsi1+/BgAAtsWvXwMAANs64SATDodlGIauu+469ezZsytqAgAAaJcTvkbG5XLpl7/8pcLhcFfUAwAA0G4d/mbft956q7NrAQAAOCEdukZmypQpuvfee/Xhhx9q5MiRbS72veSSSzqlOAAAgGPpUJC5+eabJUlz5sxpM80wDL5jBgAAnBIdCjL8wjUAAEgEJ3SNzIUXXqjq6urY/ccee0xVVVWx++Xl5Ro8eHCnFQcAAHAsJxRkXn31VQWDwdj9n/3sZ62+3TccDmvbtm2dVx0AAMAxnFCQMU3zmPcBAABOpQ59/BoAACARnFCQMQxDhmG0GQcAABAPJ/SpJdM0dc0118jr9UqSmpqadOONN8a+R+bw62cAAAC62gkFmenTp7e6/+1vf7vNPN/97ndPriIAAIB2OqEgM3/+/K6qAwAA4IRxsS8AALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtWwWZxx57TIZhaObMmfEuBQAAJADbBJnVq1frd7/7nYYNGxbvUgAAQIKwRZCpq6vTtGnT9Pvf/14ZGRnxLgcAACQIV7wLaI8ZM2booosu0sSJE/XTn/70mPMGg0EFg8HY/ZqaGklSKBRSKBTqtJoOrasz14muR7vZE+1mT7SbPSVKu7V3+wkfZBYtWqR169Zp9erV7Zp/9uzZmjVrVpvxr732mgKBQGeXp2XLlnX6OtH1aDd7ot3siXazp3i3W0NDQ7vmM0zTNLu4lg7bu3evRo0apWXLlsWujTnvvPN0xhlnaO7cuUdc5kg9MgUFBSorK1Nqamqn1RYKhbRs2TJNmjRJbre709aLrkW72RPtZk+0mz0lSrvV1NQoOztb1dXVxzx+J3SPzNq1a1VaWqozzzwzNi4Siejtt9/WE088oWAwKKfT2WoZr9crr9fbZl1ut7tLGqSr1ouuRbvZE+1mT7SbPcW73dq77YQOMhMmTNCHH37Yaty1116rQYMG6Z577mkTYgAAwFdLQgeZlJQUnX766a3GJSUlKSsrq814AADw1WOLj18DAAAcSUL3yBzJihUr4l0CAABIEPTIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA20roIDN79mydddZZSklJUffu3XXZZZdp27Zt8S4LAAAkiIQOMm+99ZZmzJih9957T8uWLVMoFNI3vvEN1dfXx7s0AACQAFzxLuBYli5d2ur+s88+q+7du2vt2rX62te+FqeqAABAokjoIPNF1dXVkqTMzMyjzhMMBhUMBmP3a2pqJEmhUEihUKjTajm0rs5cJ7oe7WZPtJs90W72lCjt1t7tG6Zpml1cS6eIRqO65JJLVFVVpXfeeeeo8z388MOaNWtWm/ELFy5UIBDoyhIBAEAnaWho0NVXX63q6mqlpqYedT7bBJmbbrpJS5Ys0TvvvKOePXsedb4j9cgUFBSorKzsmE/EiQqFQlq2bJkmTZokt9vdaetF16Ld7Il2syfazZ4Spd1qamqUnZ193CBji1NLt9xyi1566SW9/fbbxwwxkuT1euX1etuMd7vdXdIgXbVedC3azZ5oN3ui3ewp3u3W3m0ndJAxTVO33nqrFi9erBUrVqiwsDDeJQEAgASS0EFmxowZWrhwof72t78pJSVFxcXFkqS0tDT5/f44VwcAAOItob9HZt68eaqurtZ5552nvLy82PCnP/0p3qUBAIAEkNA9Mja5DhkAAMRJQvfIAAAAHAtBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZBBgAA2BZB5iRUBSXTNONdBgAAX1kEmQ56bOk2/eQDp17fcjDepQAA8JVFkOkgj9OhiGno8Tc/plcGAIA4Ich00LXjesvrNLWluFavflQS73IAAPhKIsh0UEbAo6/nWj0xv1m+Q9EovTIAAJxqBJmTcF5eVElep7YcqNFrm4vjXQ4AAF85BJmTkOSWpp/dW5I093V6ZQAAONUIMifp2nN6K8Xr0tbiWnplAAA4xQgyJyk94Na14/pIolcGAIBTjSDTCf7j3L6xXplXP6JXBgCAU4Ug0wnSAm5de26hJHplAAA4lQgyneQ/zi1Uis+lbSW1WtqOXpm1uyv0/f9do+/9YbX+vPYz1TSFTkGVAAB8ubjiXcCXRZrfrevGFeo3y3fowb99pJ2ldbp8RA8VZAZazbdpX7X+87VtenPb5z9t8PqWUnn+6tB5A7tp6vB8TSjqroCHpgEA4Hg4Wnai684t1OIP9mlPRYPmLNuuOcu2a3SfTF1+Zg8NyU/V7976RC9/eECS5HQYunJkT+Wl+fX3jfu1s7ROr20u0WubS+RzO3RWn0yN7ZelsX2zNLRHmlzOruk8aw5H5XIYcjiMLlk/AABdiSBzMsyoVL5TKt8mlWxSWslHWuH5SFV5afqb+XX9umSYVn0qrfq0IraIYUiXDM/XzIkDVJidJEm6bcJp2lZSq79v2K+/bzigPRUN+seOMv1jR5kkKdnr0ujCTBVk+NUUiioYjrS6bQpH1NgcUVMoosaQ9X+X06Fkr0spPlfLrVs+l6HqprCqGkKqqG9WVUOz6psjSvG6dGbvDI0uzNRZfTI1rGeafG5nrOZgOKLyumaV1zUrze9WQaZfhnFiwacuGNbWAzXaV9Wonhl+9c1OVkaS56Se/tKaJq36tEKrdlXo0/IGndEzTV8f2E3De6a3CX6hSFQf7KnSiq0lWrklqg+0VUX5aRqYm6r+3ZOV5G3fn0JlfbM+2FupUMRUfppfeek+ZSV5Tvj5AAB0DoJMBzle+5Eu2visXOubW4+XlCnpWm3UNQGftmdP0NN14/SX8t6aNDhXP/jGAA3KTW21jGEYGpSbqkG5qbrrGwO1raRWKz8u18qPy/XeJ+XKCH6ms3f+QSE5tSA8UfuV3a4aK+qt2rJVrXvdz+lCx/taEh2teeGp2mf2jM1XGwzrre0H9dZ263SXx+nQgNxkNQQjOlgXVG1TuNV6s5M9GtErQyN7Z+jMXhkakp+q5nBU1Y2hVsOusnptOVCjzQdqtLu8oU19mUke9euWpH7dkpXicykYjirYEtCC4ahCEVN+j1NJHqcCHpeSvE753E7tLq+PhZfDvb39oH77xk6l+lz6l/7d9LUB2QqGo3p7e5lWflymjNABPej6X93lWKc315yh+ZELdE/0dEmGCjKtcNUzw6+CzIB6ZvjVMyOgZK9LGz+r0upPK7Xm0wrtKK1r8zg8Lofy0nzqke5X/+7JGpibqoG5KRqYm6LkloBkmqaqGkI6UN2kA9WNqqhvVrLXpVS/W2l+t1J91m19c1j7qxq1v7rJuq1qVHVjSANyUjSsZ5qG9UhXWsDdpobqxpB2l9eruLpJLqchj9Mpt9OQx+WQ2+mQx+WQy2HI7XTI6TDkchryOp1K9rnkPEZvXDAcUUV9s2oawwp4nEr2upTsc8n9haBomqaC4aiaQlbbOQxDLochp7Pl1mEoGrV6AJsjLUM4qkjUVIrPpVSfWz63o8OBMBo1VVLbpD3lDdpb2ajS2iZ5nA55XdZj97qc8roc8rmd8nucCrQMPrdTHpdDDcGI6oJh1QfDqmsZ3E6H0r7QPik+1yntvTRNU7XBsMpqgzpYG1RZXbPqgiGrnoBbGQGPMgIepQfcrd58dMZ2o6YUiZoyDMnlMLosrFfWN2vnwTrtLK1TcXWTspM96pbiU06qVzmpPnVL8bbZ306EaZpqjkQlSYYMGYbkMAwZ0jHb0jRNVTZYf1d7KhoUNU0FPNYbwySvS8lep1J9bmUne7t0n4hETZXUNGlfVaNC4ag8h+3THpdDTsNQYyii+uawGpsjqg+G1dAckdvpUKrf+ttK9buV6rPe0Lqd7W/LYDiqzcVV2rivWhv3Vumj/TVK9bs0ujBLYwozNaJXekJcBmGYX/Kfbq6pqVFaWpqqq6uVmpp6/AXaKbL0x3K+94RMl19G9yIpZ4iUO1TqXiQVb5LW/Y90cEtsfjOtQEZaT8kdkDwB69YdkDILpb7jpZzTJccX/lhLPlL07f+UsXmxDNP6Q4wYTn2Sc4G29r1GjZlF8rocCnhc8rkd8rutF2af26moaaq2oUkpm/5XhRvnyB2qbbXqql7fUMPo2xToO0afVTZq9acVWv1phVbtqlRZXbDN43U5DGUmeVTZ0KxQ5Pi7jFMROWQqdFhWzkn1qldmQPurmtRYVaKzHNs02rFVIxw7tN/M1pzwt/SJmd/uNjAMqSg3VaMLM1WYnaTVn1boHzvKVN3Y+sJpr5p1g/MlzXC/KJ9aB89P1FP/HfqG/ho5V43yHX+bimpkVkgOX6p21UhldUEd6y+oZ4ZfHqdD+6sb1RSKtvuxHcvwzJCuSvlQpsOl10JDtbHSGwutJ8owrB6/9IA7dtAOhU2V1QVVVhdUzRdC7CE+t0PJXitQNTaH1RiK6GQ/rOdyGEptCQv+loDhdjrkbglDFWUHld2tm0wZipqmIlFT0ajVBp9VNsYOVl3N7TTkaQmHh0KiFZicsf97XQ55DguNTodDTkNyOhzyuq3e0oDHqSSPSwGvUy6HobK6ZpXWNKmkJqiS2iaV1gR1sC6o5nD7Hley16VuKV51S/aqW6p1m+pzqbIhFGvPsrpmldUGFYxEdehQZhjWAV6SIqapaNRU+AiN6Wp5LG6HQ07n5wfCw/d/r8th9QL7rANnksepitID6tmzpwzDIVOmWv5pf1WjPj5Yp7K64++7h8Juis/VMrjl9zgViZgKR6NqjpgKR6IKRaJqDEXUELQO7Iduj7Zvelyfh9X0llu306G9lQ3aU96g2uCR9//DeV0OFWQG1OuwQbL2y/K65thzX90YkinJkPXm1ZB1x+uy3qwlea03a0kelxyGof3Vjdpb0WAFmHa85raX02HI53LI73HK67KCvesL+6nDkIrLKlXS5Djmtl0OQ6f3SNOYwkxdNCxPw3qmd1qdUvuP3wSZDgqVfaK3l7+mr112jdzeIxwATVPat9YKNJv+IjW3fSffSlI3K9D0Gy+l9pDemydtX/L59P7fkMJN0q63Px/Xb4I09mYpZ6gUyJKchyXjvaull++Uijda9/OGS+Nulz5aLG15SdZLiaQ+/yKNulbqMUpK7yVT0qflDdpeUqs0v/VuIzvZozS/W0a4SU0RaVNxo9btqdS63VVau6dSB2ut4JPmNTTes0UX6R2NC7+ngNmgJleaoknd5U7LlTstT3J6pM9WS2Xb2jwFEcOpD3tcpY19vy8jkC6Xw1BTKKKGlncZjcGQUqu3qpsvon59T9PgAQOU9oU2jURNbfisSm9vP6h3d5ZpVGitbqx/SmlNn0mSor3P1XuuczQms0rODc9JzVbAC3tSdSBztKqifpWHvDrY7NaBJrdqm6VhyTUa6C1TfrRYSQ2fyQg3SU6vdNpEhQdNVXHueO1rdGtvZaO2l9Rqy4EabSuu1cHaRuWqUi4jrFozoDr5lZYUUG6aT5lJHjU2R1TTFFJNY1jVjSE1hiJyOQzlpfuUl+ZXj3S/8tN9Cnhc2rm/TCl7lutfGl7XeY4NchsR6/GYhj4wT9PrkZFa5x+jpvQBMnVYz0fYGsJRU6FIVOGWF/4TeWF0OQyl+FxqDEXaFcacDkOR46Qaj8shr9Mhw5DqmyPHnb+9dean+1WQ6VdOqk/RqNVL1ByOxnqLDp2GbWyOqKFl3wpFogq4nS3vsq0epySPS+Fo617GzgqiHZHsdSk72aOsZK9SfC7VNoVV2dCsqoaQqhqaTzpExlt+mk+n5aQoP82nivpmlbb0QJXWNnXqQbwjclK96p2ZJK/bEeu1q28JSLVN4U7Zd4/n0OuC3+2M7c/dQ/t0dmSdepjFWu8aqg3eM+XyJCngtXobQxFTNY0h1TaFrdt2hLIjSQ+4Naxnuob1SNPpPdJUUd+sVbvK9f6uCh2oborN9/DUwbpmXGFnPWRJBJmYLgsyoZBeeeUVXXjhhXK723b1txKsk/a+b4WZ5gYpVC+FGq3xB9ZLu/5hjWvDkIZcJp17p5Q3zBq1/wPp3d9Km1+wrtE5fN5AlpTcXfKmWNuTJG+aNOEBadR1kqOl6/ngNund30gb/yRFD9u5A1lS/ggp/0wpe4BUu18q/1iq+MS6rd0vOVxSVn8pZ7DUfbDM7kVqcCTLv/NlOT5aLNWXtv9J7D5Y6jVW6jlK+ugFacern9dx/gPSmd+VgjXSx29IO16Xdi6T6g+2XocvXUrJtYKgYVgB0jSt56a57vMgl5wrTX5UoYGX6JUlS6x2izRK6xdI7/9OqtzV/rplKBYEJSuc9TvfGupKW66b2imz/GMZ4cbWi7oDVvv40iR/xueDL11hb7ocbq8caqnfNK3tVO+VNv9NaqqOraY0ZbBkmupet6X1+tMKrCB8+Lr9GdZ+kdbTmp7WQ6Y7YL3QNYVU1RBSdX2jGmoq1FhbIafTpdSMbGVkZCk7xadUn9vqOo9GFar6TMGS7Wou2SGzfKeMcJNcHp+cHp9cHr9cXr+cniQpuZuiSTkKJ+UqEuiukMsvp2HI4zTkijbJaK6XgrVSU5XMulI1VxWruWq/IjUlMutKFHQlqzp9iCrSTldFcn81RBxat36Dhg8bJo/bOh3mMKxTVul+t3qlSLkN2+Q6sE76bI1UtVvqNqhlfx5h9Za6/Z8/T9Go1FAu1e6X2VAhw+WVXL6WnlK/NTjd1v5uOCWHS8GoVFvfoGj5J1LFJ3JUfCxH5SdyV3+qiMOjupS+qk3qo+qkPqr091a1M0sRKdbDEWm5DYaiqm8Ox04B1AfDao5E1S3JrT6BRvVyVSvfUaFss0LJqRlKKhgmX+5AyeVtuyuGGhU9uF1NB7aorrFZ5UpVaTRVB8LJ2tsUUHWzqUy/U/neZuV4mtTN1ahMV6M8DlOmHDINl0yHU6bhlBGNyN1QLHfdPrnq9stZt1/O2n0yHR5FkvMUTs5TKClPzUl5avZlW8/NoX4dhyFTDgUdflUZaaqMJqu2OarqhqDWbfxIAwcMVFqkTJn1nyiz4RNl1O9SWrRSKUaj/NF6OYM1UrBaikas14UeZ0r5ZyqaN0JVgV6qrA8qePATqeQjucs2y1e5Td7GEjX6uqsx0ENNST3VlFyg5pQCOZKz5fMnyedPUpLfpySPU1630/p7CjVJzTVSU63UXKum5rBqwi7Vhh2qbnaqMuRUg+lWTmaGemcnqVdmoO0pu2CtVLlbqvxUkdpiVTeGVd4Q1cGGsMrqwzpYH5FTUWV4o0pzW0OyK6IkR0jOUL0c4Xo5m2vlCNXLEapX0JulytQilSQN1P7AQJUpXZGoqbw0X+w0d26KV65Io7T3PWnHMmuo+Lh1XZ5kacBkafCl0mmTrJ7/w4QjUdUHrTDf1NSk5voqhRqqFK6vlNFUJUdTlZxBa3A0VqqidJ/6DjtHmX2Gyeg2UErt2eqsgWmasd78Vbsq9B/j+qh/bucdYyWCTExCBJnjCTdLn62yDtgfv2GFhqKp0rl3SNn9j7xMxS7pvf+yDnB1pWp1YD1k+NXSpJ9Iyd2OvI6qvdKq31m9PCUftQ41HeXPkIZcLg39VysM1ZdKdSVWjXUl1otA3nArwAQyWy+743Xp1fuksu3W/ZR8qa64dWDzpFjL1ZVYPVTHYzils2+SzrtX8qYcud2iUemTN63AFqyxajw0hINWAMgslDIKrdu0AisMbv6bFSgP1XskDpcVdEJtrxE6Yak9pGH/Jg2/Suo20BpXs1/avlTatkT65C0p0va04BH5M6Sk7lJzvRWQmmvbzmM4WwJXuvUYKndLXwxm7eVJsYJ0sFYyIye2rMMlM3uQPgulqkdBHzkMtewTpnXgK99hnc491noNp3WAdPukmgPWftUZ+/uxuPxW+HC4DhucktFyMIhdp2BIkZBVU+Qop1kMp5R1mvUGIrWHta8e3CpVfvqFNzRf4A50zr53ogyHFMiSGchSdV2T0iJlMo7XK3003lTr+enIvudwWe3gdFlvHKPt/L4uh/vzfd+XZg1N1dbz3VB+4nWciORc63U/1GBt89DwxX3D4ZIKzpayT7OCTc2+z6e5A1J6b+tvwoxafydmRIqErde4jrSFO2DV5U6y3ng3N1g1NtdbtxfPlUZMO6mH/kUEmRa2CDInKxqx/rjqSq3gUF9mhYj8M9q/jlCTFWb2r5P2rbNeKNN6SJn9pKx+1m1mX2uHLd1sDSUtt7XFUt+vW+Gl3/mS6yQ+jRQJSav/n7Ri9uc9EN2KpP6TrKHgbGv9pmlNry2Wag98/uJiGC0HCsP6f+5Qq+5DD7Mr2q10qxVq9q21nrOs0z4f0ntbL6KRUEs4qpGaalpenKqkxsrWQyT0hcfgsHoHBky2TgM6nEev41APX0N563U2VFjBr/ozK7weKbQc4k6yXvCOFhIdLivQZZ1m7RfeFCvshYPWMpGg9cJWV2q1S23x0Q+knhRr+eTuUnKOdXuod62u1Hos+z9o/4EjOcc6RdpzpNXmpVut5feva9uTJ0kyrG0lZVsHiVCTVWuo8dgHTW+alNXXeg4O/X2EGq1AW77Tuj1ewDiWpO5Sar6UkmftIyWbrd6Ko/FnWL1PTo/1t19/UGooa7t9T7LVg+lLs/bJaMQKc4duDcN685DWwwrvqS23kZAVmGv2tQz7rfY5FCYP9RyaUWsfb6w8cp0Ol/WcdRto1ZvaQ/KlWkHFl2bdmlGrF3XfWut1qHjj5/uiy2ctlzPECqXpBdb+Vbnb6oGr2i1V7jn2cyXJujClZd+TYa0/HLTavL3h1p8pZfSx2kk67LlsGRwuq16Xx7p1ttx6k6128KZYt54k6+/ywAZrKNuuI74pPSQlX+o/0epx6Xue9fxJ1pux/eusN1ab/yZV7Wnf4/Akf6F3OF3yZyjiTdPHn3yq0zIMOcp3WPv18ULghb+SRl/fvu22E0GmxVciyHwZ1ZdbvVQ5Q6T0Xp22WtpNVoiq/sw66HkPHdzSrRdFZ8tzEmqUGqtawlaV9SKf3vvzYNZepmkd3OpKrP97W17E3UltL24/2vLVnym8d622rXxZgwYOlNPpsgKe4bAOvqn5VoBJ63lYL8cX1lGz3wpG0UhLSMi1go/zKPuAaR52YGo5SJlRa/2+9CNv53DhoLXNQ+uIhD7//6ED/6HtSFZATcm13o1/8Y3AofoPvYGoOWD1DHYbZA3J3dvWE41agSJYbQWvw9u2q0VCVvisP6hwTYnWrnxbZ076V7m7DzjxNzmRkHVwd3qtx3ysIH9INGoF6lCjFVJCLQHl8ABxtH0vErbCbLDlzUZj1edvOjxJVojP6G0d/LtCc731hrLy089DRmxoCX3H2/dM01pHQ/nnPYCG0/q/o6WX1Zduresof8ttXicjYaumsu1W6D/8QyueJOs2kNXmdNbJau/xO/6fmwKOJClLGjgl3lV8OR16YTyWQ9eJpOad3LYMw3oB9nXwTYRhSOkFMpNytfMTQwPOuVDOEw2ghtHSy9DjxJZxujt+8He1HHg7w+H195/UvmUcDutvKCmrc2o4EU63FcpScmVmDVLxlnqrF8bVgefS6bbezJwIh0Ny+FtfE9Xu7bkkZ8v+mtbz+PN3Nk+SVDDaGjrKMKTc0zuvJsl6XrJPs4YExG8tAQAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA27JFkHnyySfVp08f+Xw+jRkzRqtWrYp3SQAAIAEkfJD505/+pDvvvFMPPfSQ1q1bp+HDh2vy5MkqLS2Nd2kAACDOEj7IzJkzR9dff72uvfZaDR48WE899ZQCgYCeeeaZeJcGAADiLKF/NLK5uVlr167VfffdFxvncDg0ceJErVy58ojLBINBBYPB2P3qausn3SsqKhQKHednyE9AKBRSQ0ODysvLv7q/omxDtJs90W72RLvZU6K0W21trSTJPPQr8UeR0EGmrKxMkUhEOTk5rcbn5ORo69atR1xm9uzZmjVrVpvxhYWd9Eu0AADglKmtrVVaWtpRpyd0kOmI++67T3feeWfsfjQaVUVFhbKysmQYRqdtp6amRgUFBdq7d69SU1M7bb3oWrSbPdFu9kS72VOitJtpmqqtrVV+fv4x50voIJOdnS2n06mSkpJW40tKSpSbm3vEZbxer7xeb6tx6enpXVWiUlNT+QO1IdrNnmg3e6Ld7CkR2u1YPTGHJPTFvh6PRyNHjtTy5ctj46LRqJYvX66xY8fGsTIAAJAIErpHRpLuvPNOTZ8+XaNGjdLo0aM1d+5c1dfX69prr413aQAAIM4SPsj827/9mw4ePKgHH3xQxcXFOuOMM7R06dI2FwCfal6vVw899FCb01hIbLSbPdFu9kS72ZPd2s0wj/e5JgAAgASV0NfIAAAAHAtBBgAA2BZBBgAA2BZBBgAA2BZBpoOefPJJ9enTRz6fT2PGjNGqVaviXRIOM3v2bJ111llKSUlR9+7dddlll2nbtm2t5mlqatKMGTOUlZWl5ORkXXHFFW2+fBHx89hjj8kwDM2cOTM2jjZLXPv27dO3v/1tZWVlye/3a+jQoVqzZk1summaevDBB5WXlye/36+JEydqx44dcawYkUhEDzzwgAoLC+X3+9WvXz898sgjrX7byBbtZuKELVq0yPR4POYzzzxjfvTRR+b1119vpqenmyUlJfEuDS0mT55szp8/39y0aZO5fv1688ILLzR79epl1tXVxea58cYbzYKCAnP58uXmmjVrzLPPPts855xz4lg1Dlm1apXZp08fc9iwYebtt98eG0+bJaaKigqzd+/e5jXXXGO+//775ieffGK++uqr5s6dO2PzPPbYY2ZaWpr5wgsvmBs2bDAvueQSs7Cw0GxsbIxj5V9tjz76qJmVlWW+9NJL5q5du8znn3/eTE5ONn/zm9/E5rFDuxFkOmD06NHmjBkzYvcjkYiZn59vzp49O45V4VhKS0tNSeZbb71lmqZpVlVVmW6323z++edj82zZssWUZK5cuTJeZcI0zdraWrN///7msmXLzK9//euxIEObJa577rnHPPfcc486PRqNmrm5ueYvf/nL2LiqqirT6/Wazz333KkoEUdw0UUXmdddd12rcd/85jfNadOmmaZpn3bj1NIJam5u1tq1azVx4sTYOIfDoYkTJ2rlypVxrAzHUl1dLUnKzMyUJK1du1ahUKhVOw4aNEi9evWiHeNsxowZuuiii1q1jUSbJbIXX3xRo0aN0pVXXqnu3btrxIgR+v3vfx+bvmvXLhUXF7dqu7S0NI0ZM4a2i6NzzjlHy5cv1/bt2yVJGzZs0DvvvKMpU6ZIsk+7Jfw3+yaasrIyRSKRNt8snJOTo61bt8apKhxLNBrVzJkzNW7cOJ1++umSpOLiYnk8njY/KJqTk6Pi4uI4VAlJWrRokdatW6fVq1e3mUabJa5PPvlE8+bN05133qkf/ehHWr16tW677TZ5PB5Nnz491j5Het2k7eLn3nvvVU1NjQYNGiSn06lIJKJHH31U06ZNkyTbtBtBBl96M2bM0KZNm/TOO+/EuxQcw969e3X77bdr2bJl8vl88S4HJyAajWrUqFH62c9+JkkaMWKENm3apKeeekrTp0+Pc3U4mv/7v//TggULtHDhQg0ZMkTr16/XzJkzlZ+fb6t249TSCcrOzpbT6WzzSYmSkhLl5ubGqSoczS233KKXXnpJb775pnr27Bkbn5ubq+bmZlVVVbWan3aMn7Vr16q0tFRnnnmmXC6XXC6X3nrrLf32t7+Vy+VSTk4ObZag8vLyNHjw4FbjioqKtGfPHkmKtQ+vm4nl7rvv1r333qurrrpKQ4cO1Xe+8x3dcccdmj17tiT7tBtB5gR5PB6NHDlSy5cvj42LRqNavny5xo4dG8fKcDjTNHXLLbdo8eLFeuONN1RYWNhq+siRI+V2u1u147Zt27Rnzx7aMU4mTJigDz/8UOvXr48No0aN0rRp02L/p80S07hx49p8vcH27dvVu3dvSVJhYaFyc3NbtV1NTY3ef/992i6OGhoa5HC0jgFOp1PRaFSSjdot3lcb29GiRYtMr9drPvvss+bmzZvNG264wUxPTzeLi4vjXRpa3HTTTWZaWpq5YsUK88CBA7GhoaEhNs+NN95o9urVy3zjjTfMNWvWmGPHjjXHjh0bx6rxRYd/ask0abNEtWrVKtPlcpmPPvqouWPHDnPBggVmIBAw//jHP8bmeeyxx8z09HTzb3/7m7lx40bz0ksvTbiP8X7VTJ8+3ezRo0fs49d//etfzezsbPOHP/xhbB47tBtBpoMef/xxs1evXqbH4zFHjx5tvvfee/EuCYeRdMRh/vz5sXkaGxvNm2++2czIyDADgYB5+eWXmwcOHIhf0Wjji0GGNktcf//7383TTz/d9Hq95qBBg8ynn3661fRoNGo+8MADZk5Ojun1es0JEyaY27Zti1O1ME3TrKmpMW+//XazV69eps/nM/v27Wv++Mc/NoPBYGweO7SbYZqHfYUfAACAjXCNDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDAAAsC2CDICvHMMw9MILL8S7DACdgCAD4JS65pprZBhGm+GCCy6Id2kAbMgV7wIAfPVccMEFmj9/fqtxXq83TtUAsDN6ZACccl6vV7m5ua2GjIwMSdZpn3nz5mnKlCny+/3q27ev/vznP7da/sMPP9T5558vv9+vrKws3XDDDaqrq2s1zzPPPKMhQ4bI6/UqLy9Pt9xyS6vpZWVluvzyyxUIBNS/f3+9+OKLXfugAXQJggyAhPPAAw/oiiuu0IYNGzRt2jRdddVV2rJliySpvr5ekydPVkZGhlavXq3nn39er7/+equgMm/ePM2YMUM33HCDPvzwQ7344os67bTTWm1j1qxZ+td//Vdt3LhRF154oaZNm6aKiopT+jgBdIJ4/2olgK+W6dOnm06n00xKSmo1PProo6ZpWr9cfuONN7ZaZsyYMeZNN91kmqZpPv3002ZGRoZZV1cXm/7yyy+bDofDLC4uNk3TNPPz880f//jHR61Bknn//ffH7tfV1ZmSzCVLlnTa4wRwanCNDIBTbvz48Zo3b16rcZmZmbH/jx07ttW0sWPHav369ZKkLVu2aPjw4UpKSopNHzdunKLRqLZt2ybDMLR//35NmDDhmDUMGzYs9v+kpCSlpqaqtLS0ow8JQJwQZACccklJSW1O9XQWv9/frvncbner+4ZhKBqNdkVJALoQ18gASDjvvfdem/tFRUWSpKKiIm3YsEH19fWx6e+++64cDocGDhyolJQU9enTR8uXLz+lNQOID3pkAJxywWBQxcXFrca5XC5lZ2dLkp5//nmNGjVK5557rhYsWKBVq1bpv//7vyVJ06ZN00MPPaTp06fr4Ycf1sGDB3XrrbfqO9/5jnJyciRJDz/8sG688UZ1795dU6ZMUW1trd59913deuutp/aBAuhyBBkAp9zSpUuVl5fXatzAgQO1detWSdYnihYtWqSbb75ZeXl5eu655zR48GBJUiAQ0Kuvvqrbb79dZ511lgKBgK644grNmTMntq7p06erqalJv/71r3XXXXcpOztb3/rWt07dAwRwyhimaZrxLgIADjEMQ4sXL9Zll10W71IA2ADXyAAAANsiyAAAANviGhkACYWz3QBOBD0yAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtggyAADAtv4/tGJHAFa1lssAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"linear_regression_model\"\n",
        "linear_model.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "id": "gb-mjXCIh_zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0i2DDmGQtL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = linear_model.predict(test_features[:10])\n",
        "op1x2 = test_dataset[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]]\n",
        "op1x2 = np.array(op1x2).astype('float32')\n",
        "for prediction, cp1x2_val, op1x2_val in zip(predictions, test_target[:10], op1x2[:10]):\n",
        "  print(f\"OP1X2: {op1x2_val} pred: {prediction}, CP1X2: {cp1x2_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKZ9SjzSKR5p",
        "outputId": "54f884c2-06c0-4e2d-85ff-699341fd1c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "OP1X2: [3.307 3.145 2.246] pred: [2.765 3.28  2.361], CP1X2: [3.187 3.029 2.513]\n",
            "OP1X2: [3.737 3.314 2.013] pred: [3.313 3.371 2.205], CP1X2: [3.484 3.374 2.179]\n",
            "OP1X2: [ 1.214  6.37  12.577] pred: [ 1.35   6.496 13.59 ], CP1X2: [ 1.217  6.787 13.65 ]\n",
            "OP1X2: [2.037 3.349 3.627] pred: [1.915 3.294 3.991], CP1X2: [1.767 3.574 5.043]\n",
            "OP1X2: [3.066 3.153 2.359] pred: [2.475 3.185 2.474], CP1X2: [3.771 3.052 2.212]\n",
            "OP1X2: [1.692 3.713 4.901] pred: [1.603 3.736 5.59 ], CP1X2: [1.9   3.503 4.292]\n",
            "OP1X2: [7.987 4.694 1.374] pred: [7.085 4.726 1.423], CP1X2: [7.05  4.945 1.428]\n",
            "OP1X2: [1.604 3.725 5.859] pred: [1.533 3.555 6.758], CP1X2: [1.57  3.913 6.634]\n",
            "OP1X2: [4.707 3.371 1.807] pred: [4.218 3.397 2.014], CP1X2: [5.557 3.096 1.847]\n",
            "OP1X2: [1.484 4.163 6.611] pred: [1.506 4.13  7.652], CP1X2: [1.579 4.043 6.111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tOm0quyMWBuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check direction\n",
        "# dataset = test_dataset\n",
        "# features = test_features\n",
        "# target = test_target\n",
        "# num = 50\n",
        "# predictions = linear_model.predict(features[:num])\n",
        "def compare_predictions(predictions, dataset, target, num):\n",
        "  op1x2 = dataset[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]][:num]\n",
        "  op1x2 = np.array(op1x2).astype('float32')\n",
        "  direction_right = 0\n",
        "  for prediction, cp1x2_val, op1x2_val in zip(predictions, target[:num], op1x2):\n",
        "    print(f\"OP1X2: {op1x2_val} CP1X2: {cp1x2_val} pred: {prediction}\")\n",
        "    real_diffs = get_diffs(op1x2_val, cp1x2_val)\n",
        "    pred_diffs = get_diffs(op1x2_val, prediction)\n",
        "    real_lowest = min_diff(real_diffs)\n",
        "    pred_lowest = min_diff(pred_diffs)\n",
        "    print(f\"real_diffs: {real_diffs}, pred_diffs: {pred_diffs}\")\n",
        "    print(f\"real low: {real_lowest}, pred_low: {pred_lowest}\")\n",
        "    if real_lowest == pred_lowest:\n",
        "      direction_right += 1\n",
        "\n",
        "  print(f\"correct_dir: {direction_right/num}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DzuT0ofMS1Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features = test_features\n",
        "target = test_target\n",
        "num = 50\n",
        "predictions = linear_model.predict(features[:num])\n",
        "compare_predictions(features, target, predictions, num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Ma5qpT1EEnsu",
        "outputId": "f75ee5ad-33e0-4135-9d90-30a6363de8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_target' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-8069ec54a29c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# features = test_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcompare_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_target' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Regression with random forest**\n"
      ],
      "metadata": {
        "id": "TWfr5rlMjj7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow_decision_forests as tfdf"
      ],
      "metadata": {
        "id": "5Ww8zdjpn1Ax",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset()\n",
        "train_dataset_rfo, test_dataset_rfo = split_dataset(dataset, False)"
      ],
      "metadata": {
        "id": "1O-bCQFtjvqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rIRqgQs7fMqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_tf_dataset(pd_dataset, label_keys):\n",
        "  feature_keys = [x for x in pd_dataset.columns.tolist() if x not in label_keys]\n",
        "  labels = dict(pd_dataset[label_keys])\n",
        "  features = dict(pd_dataset[feature_keys])\n",
        "\n",
        "  pd_dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(100)\n",
        "  return pd_dataset"
      ],
      "metadata": {
        "id": "fNKhCPtepqMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_keys = [\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"]\n",
        "multitask_items = [\n",
        "    tfdf.keras.MultiTaskItem(label=lbl, task=tfdf.keras.Task.REGRESSION, primary=True, output=None) for lbl in label_keys\n",
        "]\n",
        "multitask_items\n",
        "tf_train_data_rfo = get_tf_dataset(train_dataset, label_keys)"
      ],
      "metadata": {
        "id": "Ib4w049BuQYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tfdf.keras.RandomForestModel(multitask = multitask_items)\n",
        "model_1.compile(loss=\"mean_absolute_error\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bUh2G6mnvNU",
        "outputId": "69500c22-7e37-436d-b36f-a425f1d7f55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpt6f25not as temporary training directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit(tf_train_data_rfo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uce-ZUOOtNto",
        "outputId": "bb7d5323-4565-4da0-f356-60ac002d44fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.444624. Found 2660 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:11.038345\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7a2f9dfb9960>"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "_dHJXlNvFSGR",
        "outputId": "06bfdae4-1293-4d73-d951-73463692ed1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_3' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0238086cd86b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z1Vltzcet0JX",
        "outputId": "33fbd678-d5b8-497c-9a15-43d66c67d511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_4706a53e9d68419eb5fb212f28cd3f89\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7154345512390137, \"num_examples\": 2660.0, \"standard_deviation\": 1.9726564586856756}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Madrid\", \"Barcelona\", \"Atl. Madrid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.9050517082214355, \"num_examples\": 386.0, \"standard_deviation\": 3.302724687355556}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 5.072500228881836}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 11.495696067810059, \"num_examples\": 56.0, \"standard_deviation\": 4.112446012952551}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 1.2020000219345093}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 9.748767852783203, \"num_examples\": 43.0, \"standard_deviation\": 1.91865354092752}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 5.830499649047852}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 10.911894798278809, \"num_examples\": 19.0, \"standard_deviation\": 1.371532709399371}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Levante\", \"Espanyol\", \"Girona\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 12.479399681091309, \"num_examples\": 5.0, \"standard_deviation\": 1.0262152696795606}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 10.352071762084961, \"num_examples\": 14.0, \"standard_deviation\": 0.9929160792872622}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 10.024142265319824, \"num_examples\": 7.0, \"standard_deviation\": 0.6579196709323182}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 10.680000305175781, \"num_examples\": 7.0, \"standard_deviation\": 1.1505789630270602}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 8.827958106994629, \"num_examples\": 24.0, \"standard_deviation\": 1.7853365227860936}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Getafe\", \"Alaves\", \"Granada CF\", \"Valladolid\", \"Dep. La Coruna\", \"Huesca\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 9.838000297546387, \"num_examples\": 13.0, \"standard_deviation\": 1.4768129761550897}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 9.307833671569824, \"num_examples\": 6.0, \"standard_deviation\": 0.363780208088635}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 10.292428970336914, \"num_examples\": 7.0, \"standard_deviation\": 1.868027302116092}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 7.634272575378418, \"num_examples\": 11.0, \"standard_deviation\": 1.321480039833835}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 14.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.82883358001709, \"num_examples\": 6.0, \"standard_deviation\": 0.7535433002121297}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 8.600799560546875, \"num_examples\": 5.0, \"standard_deviation\": 1.203259622091393}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 17.27400016784668, \"num_examples\": 13.0, \"standard_deviation\": 4.146462160851275}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 11.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 19.006799697875977, \"num_examples\": 5.0, \"standard_deviation\": 3.9378367831786174}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 16.19099998474121, \"num_examples\": 8.0, \"standard_deviation\": 3.898430021327733}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.956336498260498, \"num_examples\": 330.0, \"standard_deviation\": 1.9196614735149045}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 4.832499980926514}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.397604942321777, \"num_examples\": 167.0, \"standard_deviation\": 1.411004429477916}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.468999862670898}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.219305992126465, \"num_examples\": 49.0, \"standard_deviation\": 1.467400119666075}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.599499702453613}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.9268999099731445, \"num_examples\": 40.0, \"standard_deviation\": 1.0057207834679902}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 6.923999786376953}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.451882362365723, \"num_examples\": 17.0, \"standard_deviation\": 1.186647286630036}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Celta Vigo\", \"Espanyol\", \"Alaves\", \"Huesca\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 8.266799926757812, \"num_examples\": 10.0, \"standard_deviation\": 0.7833490513957407}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Espanyol\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 8.68280029296875, \"num_examples\": 5.0, \"standard_deviation\": 0.18440589279718503}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 7.850799560546875, \"num_examples\": 5.0, \"standard_deviation\": 0.9204095860246568}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.28771448135376, \"num_examples\": 7.0, \"standard_deviation\": 0.48901798769553567}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.538869380950928, \"num_examples\": 23.0, \"standard_deviation\": 0.6033373481543245}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.700500011444092}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.155545234680176, \"num_examples\": 11.0, \"standard_deviation\": 0.5265643741675008}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 14.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.802833557128906, \"num_examples\": 6.0, \"standard_deviation\": 0.4109061098108719}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.578800201416016, \"num_examples\": 5.0, \"standard_deviation\": 0.28098051677887825}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.890250205993652, \"num_examples\": 12.0, \"standard_deviation\": 0.43054872783846676}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.150000095367432, \"num_examples\": 6.0, \"standard_deviation\": 0.05300503818380741}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.630499839782715, \"num_examples\": 6.0, \"standard_deviation\": 0.4826952504529397}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 8.518888473510742, \"num_examples\": 9.0, \"standard_deviation\": 2.2713341327652525}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.056389808654785, \"num_examples\": 118.0, \"standard_deviation\": 1.2356055268372002}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 5.647500038146973}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.850057601928711, \"num_examples\": 52.0, \"standard_deviation\": 1.2402154146849445}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Celta Vigo\", \"Eibar\", \"Alaves\", \"Granada CF\", \"Leganes\", \"Valladolid\", \"Rayo Vallecano\", \"Las Palmas\", \"Elche\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.3404998779296875, \"num_examples\": 38.0, \"standard_deviation\": 0.8686381320750157}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 1.4630000591278076}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.1306562423706055, \"num_examples\": 32.0, \"standard_deviation\": 0.7822221738447739}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Barcelona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 8.052666664123535, \"num_examples\": 6.0, \"standard_deviation\": 0.7335777561204228}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.917884826660156, \"num_examples\": 26.0, \"standard_deviation\": 0.6224451675316809}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.499666690826416, \"num_examples\": 6.0, \"standard_deviation\": 0.24873981799524783}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 7.0433502197265625, \"num_examples\": 20.0, \"standard_deviation\": 0.6456736990238006}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 6.866499900817871}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.7129998207092285, \"num_examples\": 10.0, \"standard_deviation\": 0.5187885618873878}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.03879976272583, \"num_examples\": 5.0, \"standard_deviation\": 0.45759976027222193}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.387199878692627, \"num_examples\": 5.0, \"standard_deviation\": 0.34145903790981486}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 7.373700141906738, \"num_examples\": 10.0, \"standard_deviation\": 0.5885449414278355}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.19849967956543}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 7.271200180053711, \"num_examples\": 5.0, \"standard_deviation\": 0.07692420834391264}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 7.476200103759766, \"num_examples\": 5.0, \"standard_deviation\": 0.815990488897691}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 8.45966625213623, \"num_examples\": 6.0, \"standard_deviation\": 0.1673473842137092}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.518857002258301, \"num_examples\": 14.0, \"standard_deviation\": 1.1135899421418967}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.095555782318115, \"num_examples\": 9.0, \"standard_deviation\": 0.9138869843055679}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.480800151824951, \"num_examples\": 5.0, \"standard_deviation\": 0.5410007816251011}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.431075572967529, \"num_examples\": 66.0, \"standard_deviation\": 0.7939895679590352}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 29.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.460625171661377, \"num_examples\": 8.0, \"standard_deviation\": 1.0717759337264328}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.5649309158325195, \"num_examples\": 58.0, \"standard_deviation\": 0.6411823137329176}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 5.229000091552734}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.037809371948242, \"num_examples\": 21.0, \"standard_deviation\": 0.568274633124157}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 3.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.444857120513916, \"num_examples\": 7.0, \"standard_deviation\": 0.38698224613894155}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 6.334285736083984, \"num_examples\": 14.0, \"standard_deviation\": 0.38187966458724726}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Celta Vigo\", \"Eibar\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 6.624625205993652, \"num_examples\": 8.0, \"standard_deviation\": 0.19696303326364284}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.947166442871094, \"num_examples\": 6.0, \"standard_deviation\": 0.16214772273930772}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.2965407371521, \"num_examples\": 37.0, \"standard_deviation\": 0.5120670389403416}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Getafe\", \"Alaves\", \"Rayo Vallecano\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.832444667816162, \"num_examples\": 9.0, \"standard_deviation\": 0.5634199284406043}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.124285697937012, \"num_examples\": 28.0, \"standard_deviation\": 0.34996655138630123}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.090000152587891}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.9268999099731445, \"num_examples\": 10.0, \"standard_deviation\": 0.42848380046538254}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Levante\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.28439998626709, \"num_examples\": 5.0, \"standard_deviation\": 0.07480203782820488}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.569400310516357, \"num_examples\": 5.0, \"standard_deviation\": 0.3255592860703358}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.233944416046143, \"num_examples\": 18.0, \"standard_deviation\": 0.2342006832024177}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Betis\", \"Granada CF\", \"Osasuna\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.460143089294434, \"num_examples\": 7.0, \"standard_deviation\": 0.15839126464564474}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.090000152587891, \"num_examples\": 11.0, \"standard_deviation\": 0.1432114661981377}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.207600116729736, \"num_examples\": 5.0, \"standard_deviation\": 0.13469595228881162}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.992000102996826, \"num_examples\": 6.0, \"standard_deviation\": 0.03678102487262529}}]}]}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4796993732452393, \"num_examples\": 163.0, \"standard_deviation\": 1.0545873192553994}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.2059998512268066}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.628432512283325, \"num_examples\": 74.0, \"standard_deviation\": 0.6553994012154274}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Sevilla\", \"Real Sociedad\", \"Betis\", \"Ath Bilbao\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1384999752044678, \"num_examples\": 36.0, \"standard_deviation\": 0.4664581747137418}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Real Sociedad\", \"Betis\", \"Ath Bilbao\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4961998462677, \"num_examples\": 15.0, \"standard_deviation\": 0.2818909721458017}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.366374969482422, \"num_examples\": 8.0, \"standard_deviation\": 0.24557989938665595}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.644571304321289, \"num_examples\": 7.0, \"standard_deviation\": 0.24510260726948158}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.883000135421753, \"num_examples\": 21.0, \"standard_deviation\": 0.3994600238204275}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.628333330154419, \"num_examples\": 6.0, \"standard_deviation\": 0.21566217813925984}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9848666191101074, \"num_examples\": 15.0, \"standard_deviation\": 0.41045425503783967}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.2723751068115234, \"num_examples\": 8.0, \"standard_deviation\": 0.3700196940288259}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6562857627868652, \"num_examples\": 7.0, \"standard_deviation\": 0.045868684793972686}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1452105045318604, \"num_examples\": 38.0, \"standard_deviation\": 0.38778632424021997}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9729583263397217, \"num_examples\": 24.0, \"standard_deviation\": 0.3325285497511417}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.808500051498413}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6384999752044678, \"num_examples\": 6.0, \"standard_deviation\": 0.08639797081904149}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.084444522857666, \"num_examples\": 18.0, \"standard_deviation\": 0.30859168530128234}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8559999465942383, \"num_examples\": 6.0, \"standard_deviation\": 0.1981674598162507}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.198666572570801, \"num_examples\": 12.0, \"standard_deviation\": 0.28994469408789225}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.3404998779296875}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.288285732269287, \"num_examples\": 7.0, \"standard_deviation\": 0.3373498764575518}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.073199987411499, \"num_examples\": 5.0, \"standard_deviation\": 0.12429813331620453}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.440500020980835, \"num_examples\": 14.0, \"standard_deviation\": 0.2838164865132962}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6096668243408203, \"num_examples\": 6.0, \"standard_deviation\": 0.166359819414041}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3136250972747803, \"num_examples\": 8.0, \"standard_deviation\": 0.28748679341703126}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.187494277954102, \"num_examples\": 89.0, \"standard_deviation\": 0.7590904041611222}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 3.8420000076293945}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.453296661376953, \"num_examples\": 64.0, \"standard_deviation\": 0.6796532307694999}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Ath Bilbao\", \"Levante\", \"Espanyol\", \"Eibar\", \"Rayo Vallecano\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.993444442749023, \"num_examples\": 18.0, \"standard_deviation\": 0.6509092020554664}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Madrid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.678666591644287, \"num_examples\": 6.0, \"standard_deviation\": 0.21731509149673411}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.6508331298828125, \"num_examples\": 12.0, \"standard_deviation\": 0.5096705853480172}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.93316650390625, \"num_examples\": 6.0, \"standard_deviation\": 0.40144579824354054}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.368499755859375, \"num_examples\": 6.0, \"standard_deviation\": 0.446032749958645}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.241934776306152, \"num_examples\": 46.0, \"standard_deviation\": 0.5639623611549899}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 4.128000259399414}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.364656925201416, \"num_examples\": 35.0, \"standard_deviation\": 0.4403186886286865}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.319999933242798}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.284200191497803, \"num_examples\": 30.0, \"standard_deviation\": 0.41034381134267484}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Sevilla\", \"Betis\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.4141764640808105, \"num_examples\": 17.0, \"standard_deviation\": 0.278163459353512}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 4.522000312805176}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.211166858673096, \"num_examples\": 6.0, \"standard_deviation\": 0.2911779117809201}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.524909019470215, \"num_examples\": 11.0, \"standard_deviation\": 0.19644787506284775}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.8565001487731934}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.695199966430664, \"num_examples\": 5.0, \"standard_deviation\": 0.043560385249515776}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.382999897003174, \"num_examples\": 6.0, \"standard_deviation\": 0.15769045661714765}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.114230632781982, \"num_examples\": 13.0, \"standard_deviation\": 0.4862199686269375}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 1.840499997138977}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.547999858856201, \"num_examples\": 5.0, \"standard_deviation\": 0.36497380293803616}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.843125104904175, \"num_examples\": 8.0, \"standard_deviation\": 0.3313860777241999}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.847399711608887, \"num_examples\": 5.0, \"standard_deviation\": 0.273844617219099}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.851454496383667, \"num_examples\": 11.0, \"standard_deviation\": 0.7160684134965392}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 17.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.5366666316986084, \"num_examples\": 6.0, \"standard_deviation\": 0.7376691419246966}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.2291998863220215, \"num_examples\": 5.0, \"standard_deviation\": 0.4620285285305902}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.507040023803711, \"num_examples\": 25.0, \"standard_deviation\": 0.47425239424544346}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.3550000190734863}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1912500858306885, \"num_examples\": 12.0, \"standard_deviation\": 0.45941788406843187}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Sevilla\", \"Real Sociedad\", \"Leganes\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4422857761383057, \"num_examples\": 7.0, \"standard_deviation\": 0.42666527426275147}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8398001194000244, \"num_examples\": 5.0, \"standard_deviation\": 0.19987830194757583}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.7985384464263916, \"num_examples\": 13.0, \"standard_deviation\": 0.24632663193991436}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Sevilla\", \"Betis\", \"Ath Bilbao\", \"Eibar\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.911600112915039, \"num_examples\": 5.0, \"standard_deviation\": 0.09661872282061697}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.727874994277954, \"num_examples\": 8.0, \"standard_deviation\": 0.2824582833715239}}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.174013137817383, \"num_examples\": 2274.0, \"standard_deviation\": 0.824787328687804}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.5824999809265137}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.550668716430664, \"num_examples\": 836.0, \"standard_deviation\": 0.5902076432242057}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 9.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1577932834625244, \"num_examples\": 121.0, \"standard_deviation\": 1.2839669463438401}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.5799999237060547}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.693615436553955, \"num_examples\": 104.0, \"standard_deviation\": 0.31674443680541176}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Sevilla\", \"Betis\", \"Espanyol\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0261499881744385, \"num_examples\": 20.0, \"standard_deviation\": 0.47193840003051907}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 9.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6029999256134033, \"num_examples\": 5.0, \"standard_deviation\": 0.44580731976824645}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8338667154312134, \"num_examples\": 15.0, \"standard_deviation\": 0.28779897125227494}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 12.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.059999942779541, \"num_examples\": 8.0, \"standard_deviation\": 0.10684894645751655}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5754286050796509, \"num_examples\": 7.0, \"standard_deviation\": 0.1980143690704677}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6144404411315918, \"num_examples\": 84.0, \"standard_deviation\": 0.19643675082386944}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 6.496500015258789}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3145833015441895, \"num_examples\": 12.0, \"standard_deviation\": 0.08847637494619104}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 8.510499954223633}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2356666326522827, \"num_examples\": 6.0, \"standard_deviation\": 0.03652225217150011}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3934999704360962, \"num_examples\": 6.0, \"standard_deviation\": 0.043203918221646695}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6644166707992554, \"num_examples\": 72.0, \"standard_deviation\": 0.16195868150466844}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Levante\", \"Granada CF\", \"Rayo Vallecano\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7974348068237305, \"num_examples\": 23.0, \"standard_deviation\": 0.1440838273748789}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Rayo Vallecano\", \"Dep. La Coruna\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.937833309173584, \"num_examples\": 6.0, \"standard_deviation\": 0.09263044690321202}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.74788236618042, \"num_examples\": 17.0, \"standard_deviation\": 0.12508536630032244}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.7304999828338623}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7002726793289185, \"num_examples\": 11.0, \"standard_deviation\": 0.10173595301481013}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 9.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6368333101272583, \"num_examples\": 6.0, \"standard_deviation\": 0.09244333520789241}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7763999700546265, \"num_examples\": 5.0, \"standard_deviation\": 0.04348209434567687}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8351666927337646, \"num_examples\": 6.0, \"standard_deviation\": 0.11654107556802767}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6019796133041382, \"num_examples\": 49.0, \"standard_deviation\": 0.12882055088375513}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.672999858856201}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5691463947296143, \"num_examples\": 41.0, \"standard_deviation\": 0.11142624405873171}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Betis\", \"Levante\", \"Getafe\", \"Eibar\", \"Alaves\", \"Granada CF\", \"Leganes\", \"Rayo Vallecano\", \"Malaga\", \"Las Palmas\", \"Dep. La Coruna\", \"Huesca\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5926944017410278, \"num_examples\": 36.0, \"standard_deviation\": 0.09661641108611582}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Celta Vigo\", \"Malaga\", \"Girona\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6265000104904175, \"num_examples\": 22.0, \"standard_deviation\": 0.06840779032537922}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Eibar\", \"Leganes\", \"Rayo Vallecano\", \"Dep. La Coruna\", \"Huesca\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6605384349822998, \"num_examples\": 13.0, \"standard_deviation\": 0.06151991732091892}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6251428127288818, \"num_examples\": 7.0, \"standard_deviation\": 0.030015768777783173}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7018332481384277, \"num_examples\": 6.0, \"standard_deviation\": 0.06310433897261053}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5773333311080933, \"num_examples\": 9.0, \"standard_deviation\": 0.04337487759075408}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5395714044570923, \"num_examples\": 14.0, \"standard_deviation\": 0.10969042738379246}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Betis\", \"Getafe\", \"Alaves\", \"Rayo Vallecano\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5981249809265137, \"num_examples\": 8.0, \"standard_deviation\": 0.10329636560206636}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4614999294281006, \"num_examples\": 6.0, \"standard_deviation\": 0.056402802832772506}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3996000289916992, \"num_examples\": 5.0, \"standard_deviation\": 0.043140550459672945}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7702499628067017, \"num_examples\": 8.0, \"standard_deviation\": 0.0645905609072585}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.997470378875732, \"num_examples\": 17.0, \"standard_deviation\": 1.3184459001361872}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.343249797821045, \"num_examples\": 12.0, \"standard_deviation\": 1.3488809745673818}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 5.08650016784668}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.468400001525879, \"num_examples\": 5.0, \"standard_deviation\": 1.1815760305056457}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.968142986297607, \"num_examples\": 7.0, \"standard_deviation\": 1.0884391777574374}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.167600154876709, \"num_examples\": 5.0, \"standard_deviation\": 0.7535447155859083}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4479244947433472, \"num_examples\": 715.0, \"standard_deviation\": 0.23531235364099315}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.762499809265137}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2341424226760864, \"num_examples\": 288.0, \"standard_deviation\": 0.11450637669513068}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 7.124500274658203}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1331623792648315, \"num_examples\": 117.0, \"standard_deviation\": 0.062082266422877994}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 10.051000595092773}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0731794834136963, \"num_examples\": 39.0, \"standard_deviation\": 0.025018905812160354}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 13.506000518798828}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.045699954032898, \"num_examples\": 10.0, \"standard_deviation\": 0.007911623684774848}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 1.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.041599988937378, \"num_examples\": 5.0, \"standard_deviation\": 0.007142952408064618}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0498000383377075, \"num_examples\": 5.0, \"standard_deviation\": 0.006367573398243761}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0826551914215088, \"num_examples\": 29.0, \"standard_deviation\": 0.02168016300250691}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Levante\", \"Espanyol\", \"Malaga\", \"Las Palmas\", \"Dep. La Coruna\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1014167070388794, \"num_examples\": 12.0, \"standard_deviation\": 0.014974975830891574}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1133333444595337, \"num_examples\": 6.0, \"standard_deviation\": 0.010193484139540722}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0894999504089355, \"num_examples\": 6.0, \"standard_deviation\": 0.007783205922758593}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0694117546081543, \"num_examples\": 17.0, \"standard_deviation\": 0.014821156399979706}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Madrid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0796250104904175, \"num_examples\": 8.0, \"standard_deviation\": 0.0033904184770724433}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.0603333711624146, \"num_examples\": 9.0, \"standard_deviation\": 0.015151566136567696}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.163153886795044, \"num_examples\": 78.0, \"standard_deviation\": 0.05262961684730493}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Sevilla\", \"Real Sociedad\", \"Ath Bilbao\", \"Getafe\", \"Espanyol\", \"Alaves\", \"Leganes\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2033333778381348, \"num_examples\": 27.0, \"standard_deviation\": 0.06232413015047897}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 19.724498748779297}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.149999976158142, \"num_examples\": 5.0, \"standard_deviation\": 0.031918658108912853}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2154545783996582, \"num_examples\": 22.0, \"standard_deviation\": 0.061173180030239506}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 29.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2649999856948853, \"num_examples\": 5.0, \"standard_deviation\": 0.09550702290900369}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2008823156356812, \"num_examples\": 17.0, \"standard_deviation\": 0.035009080269477674}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.1464999914169312}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.215416669845581, \"num_examples\": 12.0, \"standard_deviation\": 0.027059889434023463}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Sevilla\", \"Ath Bilbao\", \"Espanyol\", \"Alaves\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2438000440597534, \"num_examples\": 5.0, \"standard_deviation\": 0.013760282016557955}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1951428651809692, \"num_examples\": 7.0, \"standard_deviation\": 0.011556395509163672}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1660000085830688, \"num_examples\": 5.0, \"standard_deviation\": 0.026192000773918582}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1418824195861816, \"num_examples\": 51.0, \"standard_deviation\": 0.029542095377336982}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Celta Vigo\", \"Betis\", \"Levante\", \"Osasuna\", \"Valladolid\", \"Mallorca\", \"Girona\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1502368450164795, \"num_examples\": 38.0, \"standard_deviation\": 0.029133485424630668}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 8.72249984741211}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1371333599090576, \"num_examples\": 15.0, \"standard_deviation\": 0.031225698333118876}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 9.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1241250038146973, \"num_examples\": 8.0, \"standard_deviation\": 0.012663212011617679}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1519999504089355, \"num_examples\": 7.0, \"standard_deviation\": 0.038622637390309834}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1587826013565063, \"num_examples\": 23.0, \"standard_deviation\": 0.024112051170771025}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1502940654754639, \"num_examples\": 17.0, \"standard_deviation\": 0.019259371102361013}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Madrid\", \"Atl. Madrid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1651110649108887, \"num_examples\": 9.0, \"standard_deviation\": 0.015133210689668948}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1336250305175781, \"num_examples\": 8.0, \"standard_deviation\": 0.002392792473358261}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1828333139419556, \"num_examples\": 6.0, \"standard_deviation\": 0.019877737070084334}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1174615621566772, \"num_examples\": 13.0, \"standard_deviation\": 0.0119339356431489}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.159999966621399}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1268000602722168, \"num_examples\": 5.0, \"standard_deviation\": 0.011267928618931965}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1116249561309814, \"num_examples\": 8.0, \"standard_deviation\": 0.007969126995353607}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3032339811325073, \"num_examples\": 171.0, \"standard_deviation\": 0.08772276853223664}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 5.479000091552734}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2597368955612183, \"num_examples\": 95.0, \"standard_deviation\": 0.06571969132754717}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 10.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3052500486373901, \"num_examples\": 12.0, \"standard_deviation\": 0.08834232749351209}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 12.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2188000679016113, \"num_examples\": 5.0, \"standard_deviation\": 0.027867567456052084}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3669999837875366, \"num_examples\": 7.0, \"standard_deviation\": 0.060604039697290925}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2531566619873047, \"num_examples\": 83.0, \"standard_deviation\": 0.05892702879229622}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 13.407499313354492}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.212399959564209, \"num_examples\": 20.0, \"standard_deviation\": 0.049715565086221325}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Levante\", \"Getafe\", \"Espanyol\", \"Alaves\", \"Leganes\", \"Dep. La Coruna\", \"Mallorca\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2342857122421265, \"num_examples\": 14.0, \"standard_deviation\": 0.03791978611775294}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.2114999294281006}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2574000358581543, \"num_examples\": 5.0, \"standard_deviation\": 0.029648044456075835}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2214444875717163, \"num_examples\": 9.0, \"standard_deviation\": 0.03587057207176284}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.1613333225250244, \"num_examples\": 6.0, \"standard_deviation\": 0.03403279206645327}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2660952806472778, \"num_examples\": 63.0, \"standard_deviation\": 0.05563590327486094}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Levante\", \"Getafe\", \"Espanyol\", \"Osasuna\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3241666555404663, \"num_examples\": 12.0, \"standard_deviation\": 0.05259873466646672}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3011428117752075, \"num_examples\": 7.0, \"standard_deviation\": 0.007916384291489935}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3564000129699707, \"num_examples\": 5.0, \"standard_deviation\": 0.06907274936870988}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2524313926696777, \"num_examples\": 51.0, \"standard_deviation\": 0.046824357194789744}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2144999504089355, \"num_examples\": 6.0, \"standard_deviation\": 0.05248400300493929}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2574888467788696, \"num_examples\": 45.0, \"standard_deviation\": 0.043590864844848864}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Celta Vigo\", \"Alaves\", \"Granada CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2892941236495972, \"num_examples\": 17.0, \"standard_deviation\": 0.023775695701924917}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3118000030517578, \"num_examples\": 5.0, \"standard_deviation\": 0.02302568300043812}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2799166440963745, \"num_examples\": 12.0, \"standard_deviation\": 0.016760802745602762}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 1.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2706665992736816, \"num_examples\": 6.0, \"standard_deviation\": 0.019703580405525205}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2891666889190674, \"num_examples\": 6.0, \"standard_deviation\": 0.0015790767837628732}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2381786108016968, \"num_examples\": 28.0, \"standard_deviation\": 0.04151589760918227}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Barcelona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2521666288375854, \"num_examples\": 12.0, \"standard_deviation\": 0.044672279409451884}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.245500087738037}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.26419997215271, \"num_examples\": 5.0, \"standard_deviation\": 0.022399064419133884}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.243571400642395, \"num_examples\": 7.0, \"standard_deviation\": 0.05371566159905148}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2276874780654907, \"num_examples\": 16.0, \"standard_deviation\": 0.03553484050765106}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 10.969499588012695}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2436250448226929, \"num_examples\": 8.0, \"standard_deviation\": 0.0420445233920362}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2117500305175781, \"num_examples\": 8.0, \"standard_deviation\": 0.015801914884541423}}]}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.357605218887329, \"num_examples\": 76.0, \"standard_deviation\": 0.08120531522020231}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3377288579940796, \"num_examples\": 59.0, \"standard_deviation\": 0.06960765560724731}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 11.538999557495117}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2705556154251099, \"num_examples\": 9.0, \"standard_deviation\": 0.03635052396037182}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3498200178146362, \"num_examples\": 50.0, \"standard_deviation\": 0.06723928030126512}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Ath Bilbao\", \"Getafe\", \"Espanyol\", \"Alaves\", \"Granada CF\", \"Valladolid\", \"Dep. La Coruna\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.37893545627594, \"num_examples\": 31.0, \"standard_deviation\": 0.06633790802867717}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Sevilla\", \"Real Madrid\", \"Atl. Madrid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3928333520889282, \"num_examples\": 24.0, \"standard_deviation\": 0.05602300317760595}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 5.109999656677246}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.448714256286621, \"num_examples\": 7.0, \"standard_deviation\": 0.06735785960437579}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3698235750198364, \"num_examples\": 17.0, \"standard_deviation\": 0.027339743684928367}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.343500018119812}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3477500677108765, \"num_examples\": 8.0, \"standard_deviation\": 0.013027143533454624}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3894444704055786, \"num_examples\": 9.0, \"standard_deviation\": 0.02104612695571801}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3312857151031494, \"num_examples\": 7.0, \"standard_deviation\": 0.0761270764371461}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3023158311843872, \"num_examples\": 19.0, \"standard_deviation\": 0.03282999150845115}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Sevilla\", \"Girona\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3344000577926636, \"num_examples\": 5.0, \"standard_deviation\": 0.0031343511456899172}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.290857195854187, \"num_examples\": 14.0, \"standard_deviation\": 0.03098852796032189}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 9.64050006866455}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.2717777490615845, \"num_examples\": 9.0, \"standard_deviation\": 0.018468733537289058}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.325200080871582, \"num_examples\": 5.0, \"standard_deviation\": 0.015497235914279636}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4265881776809692, \"num_examples\": 17.0, \"standard_deviation\": 0.08083839534314334}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 5.115499973297119}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3875555992126465, \"num_examples\": 9.0, \"standard_deviation\": 0.06392895257327638}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4704999923706055, \"num_examples\": 8.0, \"standard_deviation\": 0.07514342857884895}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.592114806175232, \"num_examples\": 427.0, \"standard_deviation\": 0.17960826062512789}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 4.910499572753906}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5374411344528198, \"num_examples\": 331.0, \"standard_deviation\": 0.1230933122401763}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.105500221252441}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4717777967453003, \"num_examples\": 162.0, \"standard_deviation\": 0.09426662776415408}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Sevilla\", \"Celta Vigo\", \"Betis\", \"Ath Bilbao\", \"Levante\", \"Osasuna\", \"Leganes\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5241578817367554, \"num_examples\": 57.0, \"standard_deviation\": 0.09862350459769004}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5351346731185913, \"num_examples\": 52.0, \"standard_deviation\": 0.09465671639771643}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.548500061035156}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4619091749191284, \"num_examples\": 11.0, \"standard_deviation\": 0.09368150344738714}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Celta Vigo\", \"Betis\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5288000106811523, \"num_examples\": 5.0, \"standard_deviation\": 0.03472969907708219}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.406166672706604, \"num_examples\": 6.0, \"standard_deviation\": 0.09082257130413102}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5547804832458496, \"num_examples\": 41.0, \"standard_deviation\": 0.08476221481779787}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Real Sociedad\", \"Real Madrid\", \"Celta Vigo\", \"Alaves\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.653333306312561, \"num_examples\": 9.0, \"standard_deviation\": 0.06174846344896539}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5270625352859497, \"num_examples\": 32.0, \"standard_deviation\": 0.06806589913935811}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 12.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4856923818588257, \"num_examples\": 13.0, \"standard_deviation\": 0.059996651625451265}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Leganes\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5274286270141602, \"num_examples\": 7.0, \"standard_deviation\": 0.019955255741135398}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.437000036239624, \"num_examples\": 6.0, \"standard_deviation\": 0.054142147942241585}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.555368423461914, \"num_examples\": 19.0, \"standard_deviation\": 0.058032432911707434}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 4.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5891249179840088, \"num_examples\": 8.0, \"standard_deviation\": 0.04742376426565321}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.530818223953247, \"num_examples\": 11.0, \"standard_deviation\": 0.05244000602100301}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 1.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5637999773025513, \"num_examples\": 5.0, \"standard_deviation\": 0.05246862430741435}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.503333330154419, \"num_examples\": 6.0, \"standard_deviation\": 0.03294745667102364}}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4100000858306885, \"num_examples\": 5.0, \"standard_deviation\": 0.05843967046122471}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4433428049087524, \"num_examples\": 105.0, \"standard_deviation\": 0.07830715655237788}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.450500011444092}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4116863012313843, \"num_examples\": 51.0, \"standard_deviation\": 0.060245105530016045}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Getafe\", \"Espanyol\", \"Granada CF\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4683572053909302, \"num_examples\": 14.0, \"standard_deviation\": 0.06457068720173453}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.667500019073486}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5, \"num_examples\": 6.0, \"standard_deviation\": 0.03188567537545522}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4446250200271606, \"num_examples\": 8.0, \"standard_deviation\": 0.07224759649449732}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3902432918548584, \"num_examples\": 37.0, \"standard_deviation\": 0.041835232052098305}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3332221508026123, \"num_examples\": 9.0, \"standard_deviation\": 0.030814076363422552}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.408571481704712, \"num_examples\": 28.0, \"standard_deviation\": 0.025030635863620882}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Eibar\", \"Rayo Vallecano\", \"Girona\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4236153364181519, \"num_examples\": 13.0, \"standard_deviation\": 0.02822021963466997}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Sevilla\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4427143335342407, \"num_examples\": 7.0, \"standard_deviation\": 0.023106585765647662}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4013333320617676, \"num_examples\": 6.0, \"standard_deviation\": 0.013436462661959674}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3955333232879639, \"num_examples\": 15.0, \"standard_deviation\": 0.01063929468383558}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 7.363500118255615}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3901000022888184, \"num_examples\": 10.0, \"standard_deviation\": 0.00834940185345594}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3969999551773071, \"num_examples\": 5.0, \"standard_deviation\": 0.00014659500345108847}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3832000494003296, \"num_examples\": 5.0, \"standard_deviation\": 0.006647142527696963}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4064000844955444, \"num_examples\": 5.0, \"standard_deviation\": 0.004799070268094321}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4732407331466675, \"num_examples\": 54.0, \"standard_deviation\": 0.08157923159639045}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Dep. La Coruna\", \"Mallorca\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5545713901519775, \"num_examples\": 7.0, \"standard_deviation\": 0.06539969657696981}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4611276388168335, \"num_examples\": 47.0, \"standard_deviation\": 0.07666457066013023}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 4.323999881744385}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5031428337097168, \"num_examples\": 14.0, \"standard_deviation\": 0.08920525449042015}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 6.540499687194824}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5391249656677246, \"num_examples\": 8.0, \"standard_deviation\": 0.09678266827375905}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4551666975021362, \"num_examples\": 6.0, \"standard_deviation\": 0.04528244576558341}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4433029890060425, \"num_examples\": 33.0, \"standard_deviation\": 0.06267660851023588}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Celta Vigo\", \"Betis\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.480647087097168, \"num_examples\": 17.0, \"standard_deviation\": 0.05551525707338209}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 10.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5125000476837158, \"num_examples\": 6.0, \"standard_deviation\": 0.025595865434684454}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4632726907730103, \"num_examples\": 11.0, \"standard_deviation\": 0.05958489481255278}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.422800064086914, \"num_examples\": 5.0, \"standard_deviation\": 0.05135114846435455}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.496999979019165, \"num_examples\": 6.0, \"standard_deviation\": 0.04253212052312542}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4036250114440918, \"num_examples\": 16.0, \"standard_deviation\": 0.0420902254863479}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Eibar\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4241111278533936, \"num_examples\": 9.0, \"standard_deviation\": 0.04588929233470919}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.3772857189178467, \"num_examples\": 7.0, \"standard_deviation\": 0.010416396063948929}}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6003845930099487, \"num_examples\": 169.0, \"standard_deviation\": 0.11429450302748588}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Celta Vigo\", \"Dep. La Coruna\", \"Huesca\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7232500314712524, \"num_examples\": 16.0, \"standard_deviation\": 0.15350711495571373}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8564000129699707, \"num_examples\": 5.0, \"standard_deviation\": 0.07827023446833196}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6627272367477417, \"num_examples\": 11.0, \"standard_deviation\": 0.14060328303736883}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 1.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.625166654586792, \"num_examples\": 6.0, \"standard_deviation\": 0.04785147989514202}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.707800030708313, \"num_examples\": 5.0, \"standard_deviation\": 0.19240633262058743}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5875359773635864, \"num_examples\": 153.0, \"standard_deviation\": 0.10110056321429092}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Betis\", \"Getafe\", \"Espanyol\", \"Eibar\", \"Osasuna\", \"Rayo Vallecano\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6287811994552612, \"num_examples\": 64.0, \"standard_deviation\": 0.0749484428596451}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Levante\", \"Getafe\", \"Osasuna\", \"Rayo Vallecano\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7163846492767334, \"num_examples\": 13.0, \"standard_deviation\": 0.06247109755620597}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7599999904632568, \"num_examples\": 6.0, \"standard_deviation\": 0.04653998391647471}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6790000200271606, \"num_examples\": 7.0, \"standard_deviation\": 0.048611317368519695}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6064510345458984, \"num_examples\": 51.0, \"standard_deviation\": 0.059995696717313265}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 5.559000015258789}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.572428584098816, \"num_examples\": 28.0, \"standard_deviation\": 0.04013664685555735}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5400909185409546, \"num_examples\": 11.0, \"standard_deviation\": 0.01354785416498887}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 6.477499961853027}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5464999675750732, \"num_examples\": 6.0, \"standard_deviation\": 0.005594438407413049}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5324000120162964, \"num_examples\": 5.0, \"standard_deviation\": 0.016056096496680834}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5933529138565063, \"num_examples\": 17.0, \"standard_deviation\": 0.03768411050056644}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.621999979019165, \"num_examples\": 9.0, \"standard_deviation\": 0.022286152513577535}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5611250400543213, \"num_examples\": 8.0, \"standard_deviation\": 0.02229492341090198}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.64786958694458, \"num_examples\": 23.0, \"standard_deviation\": 0.05381123749345438}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Betis\", \"Malaga\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6957999467849731, \"num_examples\": 5.0, \"standard_deviation\": 0.07105881630024591}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6345555782318115, \"num_examples\": 18.0, \"standard_deviation\": 0.0384966121037406}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 4.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6627142429351807, \"num_examples\": 7.0, \"standard_deviation\": 0.0435181730690353}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6166363954544067, \"num_examples\": 11.0, \"standard_deviation\": 0.019855197663830097}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Espanyol\", \"Osasuna\", \"Rayo Vallecano\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.625999927520752, \"num_examples\": 6.0, \"standard_deviation\": 0.021430633676083555}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6053999662399292, \"num_examples\": 5.0, \"standard_deviation\": 0.009203725495859435}}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5578763484954834, \"num_examples\": 89.0, \"standard_deviation\": 0.10690696529090435}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Real Sociedad\", \"Ath Bilbao\", \"Getafe\", \"Espanyol\", \"Eibar\", \"Alaves\", \"Leganes\", \"Valladolid\", \"Rayo Vallecano\", \"Malaga\", \"Mallorca\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.577492594718933, \"num_examples\": 67.0, \"standard_deviation\": 0.10611137191048575}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6340000629425049, \"num_examples\": 16.0, \"standard_deviation\": 0.1164270059900933}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5526666641235352, \"num_examples\": 6.0, \"standard_deviation\": 0.08322009913799715}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.682800054550171, \"num_examples\": 10.0, \"standard_deviation\": 0.10574751744090753}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Ath Bilbao\", \"Alaves\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7411999702453613, \"num_examples\": 5.0, \"standard_deviation\": 0.12195472498424641}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.624400019645691, \"num_examples\": 5.0, \"standard_deviation\": 0.025903724231764298}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5597647428512573, \"num_examples\": 51.0, \"standard_deviation\": 0.09603850987962602}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.6200000047683716}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6331875324249268, \"num_examples\": 16.0, \"standard_deviation\": 0.08333684986146536}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.684749960899353, \"num_examples\": 8.0, \"standard_deviation\": 0.0451380851839186}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.581624984741211, \"num_examples\": 8.0, \"standard_deviation\": 0.08084077515969765}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5261999368667603, \"num_examples\": 35.0, \"standard_deviation\": 0.08169412520301647}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4969615936279297, \"num_examples\": 26.0, \"standard_deviation\": 0.071755730842774}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 7.11299991607666}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4097999334335327, \"num_examples\": 5.0, \"standard_deviation\": 0.038747695719467845}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.517714262008667, \"num_examples\": 21.0, \"standard_deviation\": 0.061463964122464916}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5446666479110718, \"num_examples\": 15.0, \"standard_deviation\": 0.052130287323057974}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.516800045967102, \"num_examples\": 10.0, \"standard_deviation\": 0.00769255893390053}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6003999710083008, \"num_examples\": 5.0, \"standard_deviation\": 0.058095146241701506}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4503333568572998, \"num_examples\": 6.0, \"standard_deviation\": 0.008496101707130922}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6106666326522827, \"num_examples\": 9.0, \"standard_deviation\": 0.03840994061855783}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4981364011764526, \"num_examples\": 22.0, \"standard_deviation\": 0.08487926400315471}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.4402222633361816, \"num_examples\": 9.0, \"standard_deviation\": 0.06952694952953714}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5382307767868042, \"num_examples\": 13.0, \"standard_deviation\": 0.07011421986904863}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5914000272750854, \"num_examples\": 5.0, \"standard_deviation\": 0.05549966627278486}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.5049999952316284, \"num_examples\": 8.0, \"standard_deviation\": 0.05649986819657105}}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7806249856948853, \"num_examples\": 96.0, \"standard_deviation\": 0.2130740338567658}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Barcelona\", \"Atl. Madrid\", \"Rayo Vallecano\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3076000213623047, \"num_examples\": 5.0, \"standard_deviation\": 0.547266652524158}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7516703605651855, \"num_examples\": 91.0, \"standard_deviation\": 0.12386376350830032}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Sevilla\", \"Real Sociedad\", \"Celta Vigo\", \"Betis\", \"Getafe\", \"Espanyol\", \"Eibar\", \"Osasuna\", \"Leganes\", \"Valladolid\", \"Rayo Vallecano\", \"Dep. La Coruna\", \"Huesca\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7664999961853027, \"num_examples\": 82.0, \"standard_deviation\": 0.12111732624544874}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Real Sociedad\", \"Celta Vigo\", \"Betis\", \"Ath Bilbao\", \"Eibar\", \"Malaga\", \"Las Palmas\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7886617183685303, \"num_examples\": 68.0, \"standard_deviation\": 0.110750800369582}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.7279999256134033}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7308499813079834, \"num_examples\": 20.0, \"standard_deviation\": 0.044055458692960334}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7521333694458008, \"num_examples\": 15.0, \"standard_deviation\": 0.026980258036771072}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 19.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7258332967758179, \"num_examples\": 6.0, \"standard_deviation\": 0.015654807079477893}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7696666717529297, \"num_examples\": 9.0, \"standard_deviation\": 0.01677192212474547}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6670000553131104, \"num_examples\": 5.0, \"standard_deviation\": 0.011998661602397197}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.812749981880188, \"num_examples\": 48.0, \"standard_deviation\": 0.12080950687573162}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Betis\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8931818008422852, \"num_examples\": 11.0, \"standard_deviation\": 0.15437909306727224}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.7834999561309814}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.015500068664551, \"num_examples\": 6.0, \"standard_deviation\": 0.06935167725796276}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.746399998664856, \"num_examples\": 5.0, \"standard_deviation\": 0.0846275239112201}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7888377904891968, \"num_examples\": 37.0, \"standard_deviation\": 0.0967131112190327}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 4.2235002517700195}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8091000318527222, \"num_examples\": 30.0, \"standard_deviation\": 0.09288318717091075}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Betis\", \"Espanyol\", \"Valladolid\", \"Rayo Vallecano\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.874916672706604, \"num_examples\": 12.0, \"standard_deviation\": 0.1025202804100392}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.7599999904632568}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9242857694625854, \"num_examples\": 7.0, \"standard_deviation\": 0.08115706746590438}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.805799961090088, \"num_examples\": 5.0, \"standard_deviation\": 0.08840013879014186}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.765222191810608, \"num_examples\": 18.0, \"standard_deviation\": 0.05058383714982351}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Sociedad\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8028333187103271, \"num_examples\": 6.0, \"standard_deviation\": 0.022814923866898082}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.746416687965393, \"num_examples\": 12.0, \"standard_deviation\": 0.050168519414117624}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 11.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.715499997138977, \"num_examples\": 6.0, \"standard_deviation\": 0.05048044249017647}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.777333378791809, \"num_examples\": 6.0, \"standard_deviation\": 0.023954268453996584}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7020000219345093, \"num_examples\": 7.0, \"standard_deviation\": 0.05625938425409879}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6588571071624756, \"num_examples\": 14.0, \"standard_deviation\": 0.11122867101113461}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 17.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6195555925369263, \"num_examples\": 9.0, \"standard_deviation\": 0.11657217624412193}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.729599952697754, \"num_examples\": 5.0, \"standard_deviation\": 0.04894795947550716}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6165555715560913, \"num_examples\": 9.0, \"standard_deviation\": 0.034824006703032366}}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.536402702331543, \"num_examples\": 1438.0, \"standard_deviation\": 0.7183493774036182}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.677500009536743}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2214670181274414, \"num_examples\": 1047.0, \"standard_deviation\": 0.36571990157969825}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.314000129699707}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0229127407073975, \"num_examples\": 607.0, \"standard_deviation\": 0.2517487463897575}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.0879998207092285}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2424192428588867, \"num_examples\": 167.0, \"standard_deviation\": 0.22909420641179595}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.2044999599456787}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.178499937057495, \"num_examples\": 100.0, \"standard_deviation\": 0.21140557276412297}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 10.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5209999084472656, \"num_examples\": 9.0, \"standard_deviation\": 0.19888749028583966}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1446263790130615, \"num_examples\": 91.0, \"standard_deviation\": 0.1801420037980705}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Celta Vigo\", \"Getafe\", \"Eibar\", \"Granada CF\", \"Osasuna\", \"Leganes\", \"Rayo Vallecano\", \"Malaga\", \"Las Palmas\", \"Dep. La Coruna\", \"Gijon\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2343125343322754, \"num_examples\": 48.0, \"standard_deviation\": 0.16805677932003402}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1983437538146973, \"num_examples\": 32.0, \"standard_deviation\": 0.18211160808732527}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3271000385284424, \"num_examples\": 10.0, \"standard_deviation\": 0.09632194988154817}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.1430001258850098}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.263000011444092, \"num_examples\": 5.0, \"standard_deviation\": 0.10042921765875942}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.391200065612793, \"num_examples\": 5.0, \"standard_deviation\": 0.01588041142542279}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1398181915283203, \"num_examples\": 22.0, \"standard_deviation\": 0.18182812555158442}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Celta Vigo\", \"Getafe\", \"Granada CF\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.207529306411743, \"num_examples\": 17.0, \"standard_deviation\": 0.0873563910706892}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Real Sociedad\", \"Ath Bilbao\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2534544467926025, \"num_examples\": 11.0, \"standard_deviation\": 0.06531254738579673}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Real Sociedad\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2893333435058594, \"num_examples\": 6.0, \"standard_deviation\": 0.07017057225826231}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.210400104522705, \"num_examples\": 5.0, \"standard_deviation\": 0.008802332655420795}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.12333345413208, \"num_examples\": 6.0, \"standard_deviation\": 0.05334192196912216}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.909600019454956, \"num_examples\": 5.0, \"standard_deviation\": 0.22568963289937505}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3062500953674316, \"num_examples\": 16.0, \"standard_deviation\": 0.10313805168818137}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.316500186920166}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.265714406967163, \"num_examples\": 7.0, \"standard_deviation\": 0.11690506508974201}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.337777853012085, \"num_examples\": 9.0, \"standard_deviation\": 0.07751970782684701}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.044511556625366, \"num_examples\": 43.0, \"standard_deviation\": 0.13470947976223566}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Sevilla\", \"Betis\", \"Levante\", \"Espanyol\", \"Alaves\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.084057092666626, \"num_examples\": 35.0, \"standard_deviation\": 0.10422381454804139}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Real Sociedad\", \"Ath Bilbao\", \"Levante\", \"Getafe\", \"Espanyol\", \"Eibar\", \"Alaves\", \"Dep. La Coruna\", \"Girona\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.123857021331787, \"num_examples\": 28.0, \"standard_deviation\": 0.06975481731062706}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Sociedad\", \"Getafe\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2211999893188477, \"num_examples\": 5.0, \"standard_deviation\": 0.04832029352768305}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1026957035064697, \"num_examples\": 23.0, \"standard_deviation\": 0.053927710892450624}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.373499870300293}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1237223148345947, \"num_examples\": 18.0, \"standard_deviation\": 0.023866536041470463}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1317691802978516, \"num_examples\": 13.0, \"standard_deviation\": 0.01372074693521993}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1222856044769287, \"num_examples\": 7.0, \"standard_deviation\": 0.006474344594251853}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1428332328796387, \"num_examples\": 6.0, \"standard_deviation\": 0.01147389554331046}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.102799892425537, \"num_examples\": 5.0, \"standard_deviation\": 0.030903524154622115}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0269999504089355, \"num_examples\": 5.0, \"standard_deviation\": 0.06329027806814187}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9248571395874023, \"num_examples\": 7.0, \"standard_deviation\": 0.05629637510599625}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.871500015258789, \"num_examples\": 8.0, \"standard_deviation\": 0.11506290438620764}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3378207683563232, \"num_examples\": 67.0, \"standard_deviation\": 0.22116572816937055}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.57450008392334}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.231374979019165, \"num_examples\": 24.0, \"standard_deviation\": 0.17978688215674044}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Betis\", \"Ath Bilbao\", \"Alaves\", \"Granada CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.354583263397217, \"num_examples\": 12.0, \"standard_deviation\": 0.1120805700220186}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.1605000495910645}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.452399969100952, \"num_examples\": 5.0, \"standard_deviation\": 0.09993899677080581}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2847142219543457, \"num_examples\": 7.0, \"standard_deviation\": 0.05181477238319656}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1081666946411133, \"num_examples\": 12.0, \"standard_deviation\": 0.14739068643738668}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.1089999675750732}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.215399980545044, \"num_examples\": 5.0, \"standard_deviation\": 0.1263086871635196}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.031571388244629, \"num_examples\": 7.0, \"standard_deviation\": 0.10846725172529717}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3972325325012207, \"num_examples\": 43.0, \"standard_deviation\": 0.21981918039794968}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Celta Vigo\", \"Ath Bilbao\", \"Eibar\", \"Osasuna\", \"Leganes\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.59541654586792, \"num_examples\": 12.0, \"standard_deviation\": 0.1937452764841143}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Celta Vigo\", \"Eibar\", \"Leganes\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.696833372116089, \"num_examples\": 6.0, \"standard_deviation\": 0.14030615316081302}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.49399995803833, \"num_examples\": 6.0, \"standard_deviation\": 0.18659575276899143}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3205161094665527, \"num_examples\": 31.0, \"standard_deviation\": 0.1772152490591258}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Ath Bilbao\", \"Getafe\", \"Eibar\", \"Alaves\", \"Granada CF\", \"Osasuna\", \"Valladolid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4161999225616455, \"num_examples\": 20.0, \"standard_deviation\": 0.14032709369657317}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Levante\", \"Getafe\", \"Espanyol\", \"Valladolid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.46286678314209, \"num_examples\": 15.0, \"standard_deviation\": 0.10417303883553103}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.494999885559082}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5172858238220215, \"num_examples\": 7.0, \"standard_deviation\": 0.0889637767766011}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.415250062942505, \"num_examples\": 8.0, \"standard_deviation\": 0.09254030887702594}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2761998176574707, \"num_examples\": 5.0, \"standard_deviation\": 0.14169454204030116}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.14654541015625, \"num_examples\": 11.0, \"standard_deviation\": 0.07609618252929833}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 13.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2009999752044678, \"num_examples\": 5.0}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1011667251586914, \"num_examples\": 6.0, \"standard_deviation\": 0.0780118467206887}}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9395999908447266, \"num_examples\": 440.0, \"standard_deviation\": 0.20562891095756958}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Sevilla\", \"Real Sociedad\", \"Betis\", \"Ath Bilbao\", \"Levante\", \"Getafe\", \"Eibar\", \"Leganes\", \"Malaga\", \"Dep. La Coruna\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.021199941635132, \"num_examples\": 185.0, \"standard_deviation\": 0.20379372028683096}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.808500051498413}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.043928623199463, \"num_examples\": 168.0, \"standard_deviation\": 0.19734722569921126}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.0380001068115234}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1375956535339355, \"num_examples\": 47.0, \"standard_deviation\": 0.20013501291394947}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 9.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.00771427154541, \"num_examples\": 14.0, \"standard_deviation\": 0.16363737903171469}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Ath Bilbao\", \"Getafe\", \"Eibar\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.128499984741211, \"num_examples\": 6.0, \"standard_deviation\": 0.08822995349001421}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9171249866485596, \"num_examples\": 8.0, \"standard_deviation\": 0.14789656803202247}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.192697048187256, \"num_examples\": 33.0, \"standard_deviation\": 0.188398098364026}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Ath Bilbao\", \"Leganes\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3559999465942383, \"num_examples\": 11.0, \"standard_deviation\": 0.1851312478474497}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 6.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4553332328796387, \"num_examples\": 6.0, \"standard_deviation\": 0.1467431169925098}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.236799955368042, \"num_examples\": 5.0, \"standard_deviation\": 0.1533377161022156}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1110453605651855, \"num_examples\": 22.0, \"standard_deviation\": 0.12689787560794055}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Getafe\", \"Dep. La Coruna\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1902856826782227, \"num_examples\": 7.0, \"standard_deviation\": 0.06581918012956703}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.074066638946533, \"num_examples\": 15.0, \"standard_deviation\": 0.13152383490400374}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Celta Vigo\", \"Atl. Madrid\", \"Ath Bilbao\", \"Getafe\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.150899887084961, \"num_examples\": 10.0, \"standard_deviation\": 0.04649271546556471}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.115000009536743, \"num_examples\": 5.0, \"standard_deviation\": 0.0400376345496097}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.186800003051758, \"num_examples\": 5.0, \"standard_deviation\": 0.011937900486172033}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9204000234603882, \"num_examples\": 5.0, \"standard_deviation\": 0.11023724810563358}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0075454711914062, \"num_examples\": 121.0, \"standard_deviation\": 0.18380390609506284}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.3919999599456787}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9203606843948364, \"num_examples\": 61.0, \"standard_deviation\": 0.1662956848385963}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Granada CF\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0820999145507812, \"num_examples\": 10.0, \"standard_deviation\": 0.1776501453895065}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 10.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.150599956512451, \"num_examples\": 5.0, \"standard_deviation\": 0.027047474967116167}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0136001110076904, \"num_examples\": 5.0, \"standard_deviation\": 0.23022397235496356}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8886470794677734, \"num_examples\": 51.0, \"standard_deviation\": 0.14406045550590413}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9141950607299805, \"num_examples\": 41.0, \"standard_deviation\": 0.1482617077157183}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.4049999713897705}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8933055400848389, \"num_examples\": 36.0, \"standard_deviation\": 0.143319576245852}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8438571691513062, \"num_examples\": 21.0, \"standard_deviation\": 0.07505453150207475}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7984285354614258, \"num_examples\": 7.0, \"standard_deviation\": 0.05343610511031125}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8665714263916016, \"num_examples\": 14.0, \"standard_deviation\": 0.07398817105783498}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Madrid\", \"Ath Bilbao\", \"Rayo Vallecano\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9175000190734863, \"num_examples\": 6.0, \"standard_deviation\": 0.02743371937743095}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.828374981880188, \"num_examples\": 8.0, \"standard_deviation\": 0.07490810681012455}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9625333547592163, \"num_examples\": 15.0, \"standard_deviation\": 0.18219511240509956}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.496999979019165}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.069399833679199, \"num_examples\": 5.0, \"standard_deviation\": 0.25506428628786715}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.90910005569458, \"num_examples\": 10.0, \"standard_deviation\": 0.09326486310583972}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Sevilla\", \"Espanyol\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9730000495910645, \"num_examples\": 5.0, \"standard_deviation\": 0.07709488229650494}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8451999425888062, \"num_examples\": 5.0, \"standard_deviation\": 0.057329111427431356}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0645999908447266, \"num_examples\": 5.0, \"standard_deviation\": 0.0811999789693519}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7839000225067139, \"num_examples\": 10.0, \"standard_deviation\": 0.04549831380926576}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Sociedad\", \"Betis\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.80840003490448, \"num_examples\": 5.0, \"standard_deviation\": 0.009522496068041024}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7594000101089478, \"num_examples\": 5.0, \"standard_deviation\": 0.05337617735589263}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0961833000183105, \"num_examples\": 60.0, \"standard_deviation\": 0.15630452355638982}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Sevilla\", \"Real Sociedad\", \"Betis\", \"Ath Bilbao\", \"Alaves\", \"Leganes\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.16558837890625, \"num_examples\": 34.0, \"standard_deviation\": 0.14375006576692417}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 1.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1210832595825195, \"num_examples\": 24.0, \"standard_deviation\": 0.12661844104693826}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.912600040435791, \"num_examples\": 5.0, \"standard_deviation\": 0.03143072536513709}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.175947427749634, \"num_examples\": 19.0, \"standard_deviation\": 0.07445106468654453}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Betis\", \"Ath Bilbao\", \"Leganes\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2178332805633545, \"num_examples\": 12.0, \"standard_deviation\": 0.03779115234495652}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.246000051498413, \"num_examples\": 6.0, \"standard_deviation\": 0.004258404070344001}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.189666748046875, \"num_examples\": 6.0, \"standard_deviation\": 0.035376310859655744}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.104142904281616, \"num_examples\": 7.0, \"standard_deviation\": 0.06658382096824782}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.272400140762329, \"num_examples\": 10.0, \"standard_deviation\": 0.12497249061672393}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Getafe\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.348400115966797, \"num_examples\": 5.0, \"standard_deviation\": 0.07532400003571077}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1963999271392822, \"num_examples\": 5.0, \"standard_deviation\": 0.11836610529415519}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.005423069000244, \"num_examples\": 26.0, \"standard_deviation\": 0.12173977945716374}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 5.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9658823013305664, \"num_examples\": 17.0, \"standard_deviation\": 0.11080638070252027}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Sevilla\", \"Betis\", \"Eibar\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0899999141693115, \"num_examples\": 5.0, \"standard_deviation\": 0.11569250085080164}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9141666889190674, \"num_examples\": 12.0, \"standard_deviation\": 0.052187991428665266}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Levante\", \"Espanyol\", \"Eibar\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9503999948501587, \"num_examples\": 5.0, \"standard_deviation\": 0.02571689285043479}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.888285756111145, \"num_examples\": 7.0, \"standard_deviation\": 0.05088251325689146}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.080111026763916, \"num_examples\": 9.0, \"standard_deviation\": 0.10531661555357891}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7965881824493408, \"num_examples\": 17.0, \"standard_deviation\": 0.10738538714466425}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.4664998054504395}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8526363372802734, \"num_examples\": 11.0, \"standard_deviation\": 0.08512780300993862}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Betis\", \"Levante\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8943333625793457, \"num_examples\": 6.0, \"standard_deviation\": 0.07458897392709589}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8026000261306763, \"num_examples\": 5.0, \"standard_deviation\": 0.06838574926317276}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.693833351135254, \"num_examples\": 6.0, \"standard_deviation\": 0.05540251482910541}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8803999423980713, \"num_examples\": 255.0, \"standard_deviation\": 0.18572290814492412}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 4.329500198364258}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7822197675704956, \"num_examples\": 91.0, \"standard_deviation\": 0.14150332355664325}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.4835000038146973}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7120611667633057, \"num_examples\": 49.0, \"standard_deviation\": 0.12885783726602504}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8527143001556396, \"num_examples\": 7.0, \"standard_deviation\": 0.19494885617266702}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6886190176010132, \"num_examples\": 42.0, \"standard_deviation\": 0.09586869575143969}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Celta Vigo\", \"Betis\", \"Ath Bilbao\", \"Getafe\", \"Espanyol\", \"Rayo Vallecano\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7181764841079712, \"num_examples\": 34.0, \"standard_deviation\": 0.07525032265501456}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Celta Vigo\", \"Rayo Vallecano\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8111249208450317, \"num_examples\": 8.0, \"standard_deviation\": 0.057903965037968685}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6895768642425537, \"num_examples\": 26.0, \"standard_deviation\": 0.053824556538473387}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Alaves\", \"Valladolid\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7197059392929077, \"num_examples\": 17.0, \"standard_deviation\": 0.03783812636765339}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.552999973297119}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7400000095367432, \"num_examples\": 7.0, \"standard_deviation\": 0.020035256237037214}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7055000066757202, \"num_examples\": 10.0, \"standard_deviation\": 0.04077792375818943}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 1.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.679800033569336, \"num_examples\": 5.0, \"standard_deviation\": 0.005875502791284435}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7311999797821045, \"num_examples\": 5.0, \"standard_deviation\": 0.04438666114111177}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6326667070388794, \"num_examples\": 9.0, \"standard_deviation\": 0.026675068215264375}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.562999963760376, \"num_examples\": 8.0, \"standard_deviation\": 0.06850198825505507}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8640713691711426, \"num_examples\": 42.0, \"standard_deviation\": 0.10756189579184125}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Real Sociedad\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0016000270843506, \"num_examples\": 5.0, \"standard_deviation\": 0.12478587141512815}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8454865217208862, \"num_examples\": 37.0, \"standard_deviation\": 0.09015206643994972}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.3305001258850098}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8021904230117798, \"num_examples\": 21.0, \"standard_deviation\": 0.062489202996928186}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 3.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8256428241729736, \"num_examples\": 14.0, \"standard_deviation\": 0.06204578297092834}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7918334007263184, \"num_examples\": 6.0, \"standard_deviation\": 0.055977830721116756}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8509999513626099, \"num_examples\": 8.0, \"standard_deviation\": 0.05372619851330265}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7552857398986816, \"num_examples\": 7.0, \"standard_deviation\": 0.026744247598707603}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9023125171661377, \"num_examples\": 16.0, \"standard_deviation\": 0.08933020655489582}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 4.548999786376953}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8578888177871704, \"num_examples\": 9.0, \"standard_deviation\": 0.06514375515880558}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9594285488128662, \"num_examples\": 7.0, \"standard_deviation\": 0.08357029769187901}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9348781108856201, \"num_examples\": 164.0, \"standard_deviation\": 0.18494716018716023}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Alaves\", \"Granada CF\", \"Leganes\", \"Mallorca\", \"Huesca\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.097083330154419, \"num_examples\": 24.0, \"standard_deviation\": 0.21453019665498507}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Espanyol\", \"Alaves\", \"Valladolid\", \"Rayo Vallecano\", \"Girona\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2005882263183594, \"num_examples\": 17.0, \"standard_deviation\": 0.13296209159383968}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.243000030517578}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0951666831970215, \"num_examples\": 6.0, \"standard_deviation\": 0.0531744531362685}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2580909729003906, \"num_examples\": 11.0, \"standard_deviation\": 0.12810578368033587}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3600001335144043, \"num_examples\": 6.0, \"standard_deviation\": 0.0670897461410409}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1358001232147217, \"num_examples\": 5.0, \"standard_deviation\": 0.05731956836572195}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8457143306732178, \"num_examples\": 7.0, \"standard_deviation\": 0.16017181314183218}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9070714712142944, \"num_examples\": 140.0, \"standard_deviation\": 0.16399988229020465}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.432499885559082}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8383620977401733, \"num_examples\": 58.0, \"standard_deviation\": 0.15310883481603166}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 13.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.6814285516738892, \"num_examples\": 7.0, \"standard_deviation\": 0.06792162655041245}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.859902024269104, \"num_examples\": 51.0, \"standard_deviation\": 0.1489375221804794}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.843999981880188, \"num_examples\": 46.0, \"standard_deviation\": 0.1296779505284467}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.7880001068115234}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.814740777015686, \"num_examples\": 27.0, \"standard_deviation\": 0.13859909486205543}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.4839999675750732}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7702000141143799, \"num_examples\": 15.0, \"standard_deviation\": 0.10171570377993173}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 1.9035000801086426}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.718400001525879, \"num_examples\": 5.0, \"standard_deviation\": 0.05415066845200203}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7961000204086304, \"num_examples\": 10.0, \"standard_deviation\": 0.10972943726800287}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 3.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8351999521255493, \"num_examples\": 5.0, \"standard_deviation\": 0.07514921227281476}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7569999694824219, \"num_examples\": 5.0, \"standard_deviation\": 0.12400029916881174}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8704166412353516, \"num_examples\": 12.0, \"standard_deviation\": 0.15719282292196454}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Celta Vigo\", \"Betis\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9937999248504639, \"num_examples\": 5.0, \"standard_deviation\": 0.13938661118604154}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7822856903076172, \"num_examples\": 7.0, \"standard_deviation\": 0.0992005510444512}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.885578989982605, \"num_examples\": 19.0, \"standard_deviation\": 0.10232268468852271}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.808500051498413, \"num_examples\": 6.0, \"standard_deviation\": 0.08832509894287553}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9211539030075073, \"num_examples\": 13.0, \"standard_deviation\": 0.0877151502412759}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 2.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9070000648498535, \"num_examples\": 6.0, \"standard_deviation\": 0.11798551423927742}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9332857131958008, \"num_examples\": 7.0, \"standard_deviation\": 0.04514352819304249}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.006200075149536, \"num_examples\": 5.0, \"standard_deviation\": 0.2186782559949743}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.955670714378357, \"num_examples\": 82.0, \"standard_deviation\": 0.15374545888996338}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.073499917984009}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.7638750076293945, \"num_examples\": 8.0, \"standard_deviation\": 0.045346685437420466}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.976405382156372, \"num_examples\": 74.0, \"standard_deviation\": 0.14684698771660212}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8324999809265137, \"num_examples\": 10.0, \"standard_deviation\": 0.1292486082035257}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 11.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.75600004196167, \"num_examples\": 5.0, \"standard_deviation\": 0.048526298943438115}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.909000039100647, \"num_examples\": 5.0, \"standard_deviation\": 0.13910823320667162}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9988906383514404, \"num_examples\": 64.0, \"standard_deviation\": 0.1363154542497943}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Celta Vigo\", \"Ath Bilbao\", \"Levante\", \"Espanyol\", \"Osasuna\", \"Valladolid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0648386478424072, \"num_examples\": 31.0, \"standard_deviation\": 0.12888594727868188}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.008857011795044, \"num_examples\": 21.0, \"standard_deviation\": 0.08870090173778429}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.867000102996826}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9217143058776855, \"num_examples\": 7.0, \"standard_deviation\": 0.010632073385962995}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0524284839630127, \"num_examples\": 14.0, \"standard_deviation\": 0.07778078002370589}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Granada CF\", \"Osasuna\", \"Rayo Vallecano\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.106750011444092, \"num_examples\": 8.0, \"standard_deviation\": 0.025768653513396775}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9800000190734863, \"num_examples\": 6.0, \"standard_deviation\": 0.06364462477248452}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1823999881744385, \"num_examples\": 10.0, \"standard_deviation\": 0.12071249782581625}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Celta Vigo\", \"Osasuna\", \"Huesca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2690000534057617, \"num_examples\": 5.0, \"standard_deviation\": 0.11025998575050365}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0957999229431152, \"num_examples\": 5.0, \"standard_deviation\": 0.04457174266438289}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9369393587112427, \"num_examples\": 33.0, \"standard_deviation\": 0.11184493332195741}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0241000652313232, \"num_examples\": 10.0, \"standard_deviation\": 0.09665713265776309}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 8.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0017998218536377, \"num_examples\": 5.0, \"standard_deviation\": 0.07839919489325681}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0464000701904297, \"num_examples\": 5.0, \"standard_deviation\": 0.10744386007695322}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8990434408187866, \"num_examples\": 23.0, \"standard_deviation\": 0.0956398462041582}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.30649995803833}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8690667152404785, \"num_examples\": 15.0, \"standard_deviation\": 0.08545124138221008}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Eibar\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9456666707992554, \"num_examples\": 6.0, \"standard_deviation\": 0.00895855862828591}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8179999589920044, \"num_examples\": 9.0, \"standard_deviation\": 0.07481203707922802}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.9552500247955322, \"num_examples\": 8.0, \"standard_deviation\": 0.08810453488956735}}]}]}]}]}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4953818321228027, \"num_examples\": 440.0, \"standard_deviation\": 0.31846251556885885}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.937000036239624}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.388880968093872, \"num_examples\": 252.0, \"standard_deviation\": 0.2736455119714186}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 2.9800000190734863}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3650331497192383, \"num_examples\": 241.0, \"standard_deviation\": 0.24555633601648574}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Sevilla\", \"Real Sociedad\", \"Celta Vigo\", \"Getafe\", \"Eibar\", \"Leganes\", \"Malaga\", \"Huesca\", \"Girona\", \"Gijon\", \"Elche\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4778409004211426, \"num_examples\": 88.0, \"standard_deviation\": 0.25300699066897536}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.250999927520752}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3297500610351562, \"num_examples\": 28.0, \"standard_deviation\": 0.26338070162444216}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Ath Bilbao\", \"Levante\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.754199981689453, \"num_examples\": 5.0, \"standard_deviation\": 0.15748732634108129}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.237478256225586, \"num_examples\": 23.0, \"standard_deviation\": 0.17714139062030704}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0460000038146973, \"num_examples\": 5.0, \"standard_deviation\": 0.14249370466012515}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2906665802001953, \"num_examples\": 18.0, \"standard_deviation\": 0.146430609050637}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Sevilla\", \"Celta Vigo\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4035000801086426, \"num_examples\": 6.0, \"standard_deviation\": 0.08772761362030293}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.234250068664551, \"num_examples\": 12.0, \"standard_deviation\": 0.13699012986360026}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1633999347686768, \"num_examples\": 5.0, \"standard_deviation\": 0.11713291447853222}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2848570346832275, \"num_examples\": 7.0, \"standard_deviation\": 0.12737388656284448}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.546950101852417, \"num_examples\": 60.0, \"standard_deviation\": 0.21564363630243075}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Celta Vigo\", \"Getafe\", \"Espanyol\", \"Osasuna\", \"Mallorca\", \"Girona\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6640625, \"num_examples\": 32.0, \"standard_deviation\": 0.1830432426894684}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Real Sociedad\", \"Celta Vigo\", \"Malaga\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8978748321533203, \"num_examples\": 8.0, \"standard_deviation\": 0.07133486466920085}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.586124897003174, \"num_examples\": 24.0, \"standard_deviation\": 0.13667433479361524}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 2.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5174667835235596, \"num_examples\": 15.0, \"standard_deviation\": 0.10961891944352471}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Getafe\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.612428665161133, \"num_examples\": 7.0, \"standard_deviation\": 0.04970214556303946}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.434375047683716, \"num_examples\": 8.0, \"standard_deviation\": 0.07466118072499632}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7005555629730225, \"num_examples\": 9.0, \"standard_deviation\": 0.09399401974220971}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.41310715675354, \"num_examples\": 28.0, \"standard_deviation\": 0.16663648735514366}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.321125030517578, \"num_examples\": 8.0, \"standard_deviation\": 0.1551120523884632}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.449899911880493, \"num_examples\": 20.0, \"standard_deviation\": 0.1565659974924222}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.1364998817443848}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3527777194976807, \"num_examples\": 9.0, \"standard_deviation\": 0.148459305974098}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5293636322021484, \"num_examples\": 11.0, \"standard_deviation\": 0.11182089602495457}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.5425000190734863}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4305999279022217, \"num_examples\": 5.0, \"standard_deviation\": 0.05720003370803054}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.611666679382324, \"num_examples\": 6.0, \"standard_deviation\": 0.07276649021948861}}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3001503944396973, \"num_examples\": 153.0, \"standard_deviation\": 0.21594518528394144}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2087173461914062, \"num_examples\": 46.0, \"standard_deviation\": 0.21211001454501735}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Ath Bilbao\", \"Alaves\", \"Valladolid\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3200371265411377, \"num_examples\": 27.0, \"standard_deviation\": 0.1499237250440484}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 10.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2415714263916016, \"num_examples\": 14.0, \"standard_deviation\": 0.10738516409161035}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Real Sociedad\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.313124895095825, \"num_examples\": 8.0, \"standard_deviation\": 0.071889780110892}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1461665630340576, \"num_examples\": 6.0, \"standard_deviation\": 0.06393378672128716}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.40453839302063, \"num_examples\": 13.0, \"standard_deviation\": 0.14315617755301163}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Villarreal\", \"Alaves\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5250000953674316, \"num_examples\": 6.0, \"standard_deviation\": 0.11988064433026886}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.301285743713379, \"num_examples\": 7.0, \"standard_deviation\": 0.05140301660925767}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0505263805389404, \"num_examples\": 19.0, \"standard_deviation\": 0.18533586643570268}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.257500171661377}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.176727294921875, \"num_examples\": 11.0, \"standard_deviation\": 0.09240225154159211}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.0195000171661377}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1643998622894287, \"num_examples\": 5.0, \"standard_deviation\": 0.1309787437991693}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.187000036239624, \"num_examples\": 6.0, \"standard_deviation\": 0.03354051938826855}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 1.8769999742507935, \"num_examples\": 8.0, \"standard_deviation\": 0.13352617838464031}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3394579887390137, \"num_examples\": 107.0, \"standard_deviation\": 0.2054239152911689}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.2669999599456787}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3804657459259033, \"num_examples\": 73.0, \"standard_deviation\": 0.21515883756073848}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Las Palmas\", \"Mallorca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.68066668510437, \"num_examples\": 6.0, \"standard_deviation\": 0.34764505730778084}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3535821437835693, \"num_examples\": 67.0, \"standard_deviation\": 0.1755640639132322}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Espanyol\", \"Valladolid\", \"Mallorca\", \"Huesca\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.58840012550354, \"num_examples\": 5.0, \"standard_deviation\": 0.13454885315450296}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3346452713012695, \"num_examples\": 62.0, \"standard_deviation\": 0.16444803323093826}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 1.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.371666669845581, \"num_examples\": 48.0, \"standard_deviation\": 0.15926233387039151}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Betis\", \"Ath Bilbao\", \"Granada CF\", \"Osasuna\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4814000129699707, \"num_examples\": 20.0, \"standard_deviation\": 0.13315823156501339}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 1.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4258666038513184, \"num_examples\": 15.0, \"standard_deviation\": 0.0724963982324933}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.0464999675750732}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.37666654586792, \"num_examples\": 9.0, \"standard_deviation\": 0.046778020761936136}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.499666690826416, \"num_examples\": 6.0, \"standard_deviation\": 0.027921977749732263}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6480000019073486, \"num_examples\": 5.0, \"standard_deviation\": 0.1347213040797429}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.293285608291626, \"num_examples\": 28.0, \"standard_deviation\": 0.12677669388356927}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1962499618530273, \"num_examples\": 8.0, \"standard_deviation\": 0.09879116697169542}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3320999145507812, \"num_examples\": 20.0, \"standard_deviation\": 0.11543162009299442}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.3450000286102295}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2880666255950928, \"num_examples\": 15.0, \"standard_deviation\": 0.09230548999366273}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.464200019836426, \"num_examples\": 5.0, \"standard_deviation\": 0.06685603480464865}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.207714319229126, \"num_examples\": 14.0, \"standard_deviation\": 0.10948952121201469}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Betis\", \"Espanyol\", \"Alaves\", \"Granada CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2820000648498535, \"num_examples\": 8.0, \"standard_deviation\": 0.04935682226754147}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1086666584014893, \"num_examples\": 6.0, \"standard_deviation\": 0.08692247685256185}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2514116764068604, \"num_examples\": 34.0, \"standard_deviation\": 0.14847721312958573}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Espanyol\", \"Valladolid\", \"Mallorca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4670000076293945, \"num_examples\": 5.0, \"standard_deviation\": 0.10246929017553233}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2142412662506104, \"num_examples\": 29.0, \"standard_deviation\": 0.12099980868880147}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 3.2919998168945312}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.120142936706543, \"num_examples\": 7.0, \"standard_deviation\": 0.06130189598987357}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2441818714141846, \"num_examples\": 22.0, \"standard_deviation\": 0.11995813902787304}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Levante\", \"Eibar\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.321833372116089, \"num_examples\": 12.0, \"standard_deviation\": 0.056628750859078536}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3818001747131348, \"num_examples\": 5.0, \"standard_deviation\": 0.03026733674405595}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2790000438690186, \"num_examples\": 7.0, \"standard_deviation\": 0.020970310659005516}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.1510000228881836, \"num_examples\": 10.0, \"standard_deviation\": 0.10904657483062213}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 9.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2139999866485596, \"num_examples\": 5.0, \"standard_deviation\": 0.11064724411253618}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.0879998207092285, \"num_examples\": 5.0, \"standard_deviation\": 0.06001243576872588}}]}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9113636016845703, \"num_examples\": 11.0, \"standard_deviation\": 0.33008299768807836}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Getafe\", \"Eibar\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1113333702087402, \"num_examples\": 6.0, \"standard_deviation\": 0.283300947368434}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6714000701904297, \"num_examples\": 5.0, \"standard_deviation\": 0.1944766912957348}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6381382942199707, \"num_examples\": 188.0, \"standard_deviation\": 0.3184422716657604}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.244999885559082}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4993691444396973, \"num_examples\": 65.0, \"standard_deviation\": 0.2941952275242821}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.367263078689575, \"num_examples\": 19.0, \"standard_deviation\": 0.22674338783242345}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Real Sociedad\", \"Celta Vigo\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6907999515533447, \"num_examples\": 5.0, \"standard_deviation\": 0.17487496544860145}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2517142295837402, \"num_examples\": 14.0, \"standard_deviation\": 0.09009142823235008}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Levante\", \"Leganes\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.3202857971191406, \"num_examples\": 7.0, \"standard_deviation\": 0.03236656537780567}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.183142900466919, \"num_examples\": 7.0, \"standard_deviation\": 0.07603458830405584}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5539348125457764, \"num_examples\": 46.0, \"standard_deviation\": 0.30146082278741204}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.8385000228881836}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4138123989105225, \"num_examples\": 16.0, \"standard_deviation\": 0.22610322132828714}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Betis\", \"Eibar\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.662600040435791, \"num_examples\": 5.0, \"standard_deviation\": 0.16852623483918205}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.300727367401123, \"num_examples\": 11.0, \"standard_deviation\": 0.1432766352346303}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4021999835968018, \"num_examples\": 5.0, \"standard_deviation\": 0.1238034957231916}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2161664962768555, \"num_examples\": 6.0, \"standard_deviation\": 0.0955571175780727}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.628666639328003, \"num_examples\": 30.0, \"standard_deviation\": 0.309879573636269}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.565000057220459}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.408222198486328, \"num_examples\": 9.0, \"standard_deviation\": 0.29817016121625023}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7231428623199463, \"num_examples\": 21.0, \"standard_deviation\": 0.26329495410433185}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8666250705718994, \"num_examples\": 8.0, \"standard_deviation\": 0.18347992126528664}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6348462104797363, \"num_examples\": 13.0, \"standard_deviation\": 0.2660885870758209}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Levante\", \"Mallorca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.884399890899658, \"num_examples\": 5.0, \"standard_deviation\": 0.20780870600022144}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.478874921798706, \"num_examples\": 8.0, \"standard_deviation\": 0.15752660200450566}}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7114715576171875, \"num_examples\": 123.0, \"standard_deviation\": 0.3061067527293756}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.751500129699707}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.647719144821167, \"num_examples\": 89.0, \"standard_deviation\": 0.28233740404905394}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 3.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.541276693344116, \"num_examples\": 47.0, \"standard_deviation\": 0.2283211735341277}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Celta Vigo\", \"Betis\", \"Getafe\", \"Espanyol\", \"Alaves\", \"Osasuna\", \"Valladolid\", \"Las Palmas\", \"Mallorca\", \"Huesca\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.65806245803833, \"num_examples\": 32.0, \"standard_deviation\": 0.16594468334372967}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.565000057220459}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.729749917984009, \"num_examples\": 16.0, \"standard_deviation\": 0.18602987733671247}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 13.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8647141456604004, \"num_examples\": 7.0, \"standard_deviation\": 0.17653569626123738}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6247777938842773, \"num_examples\": 9.0, \"standard_deviation\": 0.1099899066016901}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5863749980926514, \"num_examples\": 16.0, \"standard_deviation\": 0.10094535131714262}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Celta Vigo\", \"Betis\", \"Getafe\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6294000148773193, \"num_examples\": 10.0, \"standard_deviation\": 0.09169003195336961}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.575000047683716, \"num_examples\": 5.0, \"standard_deviation\": 0.09613967666392403}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.683799982070923, \"num_examples\": 5.0, \"standard_deviation\": 0.04065166743049574}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5146665573120117, \"num_examples\": 6.0, \"standard_deviation\": 0.07024339016566261}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.292133331298828, \"num_examples\": 15.0, \"standard_deviation\": 0.11587356085157455}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 16.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.2128889560699463, \"num_examples\": 9.0, \"standard_deviation\": 0.07171277335341245}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4110000133514404, \"num_examples\": 6.0, \"standard_deviation\": 0.047998141213028526}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7668333053588867, \"num_examples\": 42.0, \"standard_deviation\": 0.2893355111225542}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Real Sociedad\", \"Celta Vigo\", \"Betis\", \"Espanyol\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.948333263397217, \"num_examples\": 21.0, \"standard_deviation\": 0.26777323677847187}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Granada CF\", \"Osasuna\", \"Valladolid\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.31820011138916, \"num_examples\": 5.0, \"standard_deviation\": 0.2116392972147405}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.832750082015991, \"num_examples\": 16.0, \"standard_deviation\": 0.15492694228672343}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.1399998664855957}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9024999141693115, \"num_examples\": 8.0, \"standard_deviation\": 0.1782272554990332}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.763000011444092, \"num_examples\": 8.0, \"standard_deviation\": 0.08068234345190543}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5853333473205566, \"num_examples\": 21.0, \"standard_deviation\": 0.17275147256623966}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Levante\", \"Alaves\", \"Granada CF\", \"Leganes\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.678076982498169, \"num_examples\": 13.0, \"standard_deviation\": 0.14620768116573327}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Ath Bilbao\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.785599946975708, \"num_examples\": 5.0, \"standard_deviation\": 0.15108885423008114}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.610875129699707, \"num_examples\": 8.0, \"standard_deviation\": 0.09342301509561483}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4346249103546143, \"num_examples\": 8.0, \"standard_deviation\": 0.08313069420901108}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8783528804779053, \"num_examples\": 34.0, \"standard_deviation\": 0.3030275463844371}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Celta Vigo\", \"Ath Bilbao\", \"Getafe\", \"Alaves\", \"Leganes\", \"Dep. La Coruna\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1232306957244873, \"num_examples\": 13.0, \"standard_deviation\": 0.16309596414065342}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Valencia\", \"Real Sociedad\", \"Betis\", \"Osasuna\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.2314999103546143, \"num_examples\": 8.0, \"standard_deviation\": 0.08750371897014331}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.950000047683716, \"num_examples\": 5.0, \"standard_deviation\": 0.09025133642327005}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.726762056350708, \"num_examples\": 21.0, \"standard_deviation\": 0.2685185394872917}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.7144999504089355}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9392499923706055, \"num_examples\": 8.0, \"standard_deviation\": 0.24654548975234328}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5959999561309814, \"num_examples\": 13.0, \"standard_deviation\": 0.1848859812752245}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Alaves\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7445714473724365, \"num_examples\": 7.0, \"standard_deviation\": 0.11222433538371847}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4226667881011963, \"num_examples\": 6.0, \"standard_deviation\": 0.05977120666279555}}]}]}]}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.379721164703369, \"num_examples\": 391.0, \"standard_deviation\": 0.7502563547218822}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 3.677999973297119}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.36049222946167, \"num_examples\": 65.0, \"standard_deviation\": 0.7828758430335366}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.4739999771118164}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.000999927520752, \"num_examples\": 14.0, \"standard_deviation\": 0.8844238822735339}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Espanyol\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 5.560199737548828, \"num_examples\": 5.0, \"standard_deviation\": 1.094550892464884}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.690333366394043, \"num_examples\": 9.0, \"standard_deviation\": 0.5300443648267038}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.184666633605957, \"num_examples\": 51.0, \"standard_deviation\": 0.650295884941145}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 1.9194999933242798}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.002904891967773, \"num_examples\": 42.0, \"standard_deviation\": 0.4145277727985647}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.2235002517700195, \"num_examples\": 10.0, \"standard_deviation\": 0.6140323706428368}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 14.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.7505998611450195, \"num_examples\": 5.0, \"standard_deviation\": 0.16545335784113765}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.696400165557861, \"num_examples\": 5.0, \"standard_deviation\": 0.5286091874517911}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.9339687824249268, \"num_examples\": 32.0, \"standard_deviation\": 0.296223504166289}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Granada CF\", \"Gijon\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.277285575866699, \"num_examples\": 7.0, \"standard_deviation\": 0.10494688057020457}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.8378400802612305, \"num_examples\": 25.0, \"standard_deviation\": 0.2588255203199581}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 3.927500009536743}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.9974000453948975, \"num_examples\": 10.0, \"standard_deviation\": 0.23175766685865118}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Alaves\", \"Malaga\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.194799900054932, \"num_examples\": 5.0, \"standard_deviation\": 0.0994486220811559}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.799999952316284, \"num_examples\": 5.0, \"standard_deviation\": 0.1399988773845887}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.731466770172119, \"num_examples\": 15.0, \"standard_deviation\": 0.218071378888077}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 11.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.59842848777771, \"num_examples\": 7.0, \"standard_deviation\": 0.17900731754818494}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.8478751182556152, \"num_examples\": 8.0, \"standard_deviation\": 0.17913693417849152}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 5.032888889312744, \"num_examples\": 9.0, \"standard_deviation\": 0.8490011460292707}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.184168815612793, \"num_examples\": 326.0, \"standard_deviation\": 0.5682255214377477}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.995999813079834}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.457612991333008, \"num_examples\": 155.0, \"standard_deviation\": 0.5441459550524833}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 10.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.031450033187866, \"num_examples\": 20.0, \"standard_deviation\": 0.40887868302672903}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Sevilla\", \"Ath Bilbao\", \"Getafe\", \"Dep. La Coruna\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.381999969482422, \"num_examples\": 8.0, \"standard_deviation\": 0.3401733008649984}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7977499961853027, \"num_examples\": 12.0, \"standard_deviation\": 0.25485641382414165}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.0455000400543213, \"num_examples\": 6.0, \"standard_deviation\": 0.06886565021853794}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.549999952316284, \"num_examples\": 6.0, \"standard_deviation\": 0.04899935795886541}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.5207481384277344, \"num_examples\": 135.0, \"standard_deviation\": 0.5331989245478432}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.6737546920776367, \"num_examples\": 53.0, \"standard_deviation\": 0.5234116019773444}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.543605327606201, \"num_examples\": 38.0, \"standard_deviation\": 0.3975075022285699}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Sevilla\", \"Real Sociedad\", \"Ath Bilbao\", \"Getafe\", \"Eibar\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.599393844604492, \"num_examples\": 33.0, \"standard_deviation\": 0.3963813761361292}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.5350000858306885, \"num_examples\": 27.0, \"standard_deviation\": 0.3971315301290124}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Levante\", \"Alaves\", \"Osasuna\", \"Valladolid\", \"Rayo Vallecano\", \"Huesca\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.670799970626831, \"num_examples\": 20.0, \"standard_deviation\": 0.36188010597993425}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.302999973297119}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4975833892822266, \"num_examples\": 12.0, \"standard_deviation\": 0.21371487253896318}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 7.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.6081666946411133, \"num_examples\": 6.0, \"standard_deviation\": 0.2125608768886505}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.38700008392334, \"num_examples\": 6.0, \"standard_deviation\": 0.1473384955021149}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.9306249618530273, \"num_examples\": 8.0, \"standard_deviation\": 0.3825792711504464}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1470000743865967, \"num_examples\": 7.0, \"standard_deviation\": 0.17585647629541268}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.889166831970215, \"num_examples\": 6.0, \"standard_deviation\": 0.22762171980082418}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1754000186920166, \"num_examples\": 5.0, \"standard_deviation\": 0.08829444045193888}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.003466606140137, \"num_examples\": 15.0, \"standard_deviation\": 0.6450361017889498}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_loss\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 4.479571342468262, \"num_examples\": 7.0, \"standard_deviation\": 0.6256758195546556}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.5868749618530273, \"num_examples\": 8.0, \"standard_deviation\": 0.2563357099354329}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.421853542327881, \"num_examples\": 82.0, \"standard_deviation\": 0.5158231630033246}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.182000160217285}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.3272173404693604, \"num_examples\": 69.0, \"standard_deviation\": 0.3619107436617523}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Betis\", \"Levante\", \"Getafe\", \"Alaves\", \"Leganes\", \"Rayo Vallecano\", \"Las Palmas\", \"Huesca\", \"Gijon\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.5290000438690186, \"num_examples\": 38.0, \"standard_deviation\": 0.2530696482334277}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Betis\", \"Rayo Vallecano\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.772428512573242, \"num_examples\": 7.0, \"standard_deviation\": 0.36209833554341736}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.474032163619995, \"num_examples\": 31.0, \"standard_deviation\": 0.18026930403754868}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\", \"Betis\", \"Ath Bilbao\", \"Espanyol\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.537750005722046, \"num_examples\": 16.0, \"standard_deviation\": 0.15686700225879258}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.3474998474121094}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.3975000381469727, \"num_examples\": 6.0, \"standard_deviation\": 0.10585973317740531}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.6218998432159424, \"num_examples\": 10.0, \"standard_deviation\": 0.11732257994553992}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.2795000076293945}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.589599847793579, \"num_examples\": 5.0, \"standard_deviation\": 0.019096322996590323}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.6541998386383057, \"num_examples\": 5.0, \"standard_deviation\": 0.1583601070005399}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.406066656112671, \"num_examples\": 15.0, \"standard_deviation\": 0.17878157863998453}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Levante\", \"Alaves\", \"Leganes\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.5290000438690186, \"num_examples\": 5.0, \"standard_deviation\": 0.0755994045102795}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.344599962234497, \"num_examples\": 10.0, \"standard_deviation\": 0.18371769829074408}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_tie\", \"threshold\": 1.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.2696001529693604, \"num_examples\": 5.0, \"standard_deviation\": 0.18459305021814595}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.419600009918213, \"num_examples\": 5.0, \"standard_deviation\": 0.1489288123287712}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.0798709392547607, \"num_examples\": 31.0, \"standard_deviation\": 0.31927803488209167}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 7.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8476667404174805, \"num_examples\": 15.0, \"standard_deviation\": 0.19494414598054235}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 11.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.0341999530792236, \"num_examples\": 5.0, \"standard_deviation\": 0.047519008573854646}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7544000148773193, \"num_examples\": 10.0, \"standard_deviation\": 0.17256822213163248}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 4.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8916001319885254, \"num_examples\": 5.0, \"standard_deviation\": 0.1401115474540874}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6171998977661133, \"num_examples\": 5.0, \"standard_deviation\": 0.04775609821144802}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.297562599182129, \"num_examples\": 16.0, \"standard_deviation\": 0.2528620991830905}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.243499994277954}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1155998706817627, \"num_examples\": 5.0, \"standard_deviation\": 0.19188548517402035}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.38027286529541, \"num_examples\": 11.0, \"standard_deviation\": 0.23318447452169913}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 3.435999870300293}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.434999942779541, \"num_examples\": 5.0, \"standard_deviation\": 0.2952229602845033}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.3346667289733887, \"num_examples\": 6.0, \"standard_deviation\": 0.1499373203347211}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.9241538047790527, \"num_examples\": 13.0, \"standard_deviation\": 0.8266017080080891}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 3.1005001068115234}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.8088572025299072, \"num_examples\": 7.0, \"standard_deviation\": 0.9335348405436913}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 4.058666706085205, \"num_examples\": 6.0, \"standard_deviation\": 0.6558059131310865}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.936310052871704, \"num_examples\": 171.0, \"standard_deviation\": 0.4668510657695272}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.82450008392334}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.085282325744629, \"num_examples\": 85.0, \"standard_deviation\": 0.5330583897164322}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Rayo Vallecano\", \"Elche\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.875142812728882, \"num_examples\": 7.0, \"standard_deviation\": 1.281572313344948}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.014397382736206, \"num_examples\": 78.0, \"standard_deviation\": 0.3181835609413204}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.046999931335449}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9472458362579346, \"num_examples\": 61.0, \"standard_deviation\": 0.30886037354763624}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Villarreal\", \"Valencia\", \"Real Sociedad\", \"Ath Bilbao\", \"Las Palmas\", \"Girona\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.019306182861328, \"num_examples\": 49.0, \"standard_deviation\": 0.25620151607348235}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Celta Vigo\", \"Betis\", \"Levante\", \"Malaga\", \"Las Palmas\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4264445304870605, \"num_examples\": 9.0, \"standard_deviation\": 0.18072025226335706}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9277000427246094, \"num_examples\": 40.0, \"standard_deviation\": 0.16544348112689578}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.424499988555908}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.871851921081543, \"num_examples\": 27.0, \"standard_deviation\": 0.15360369086751519}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Getafe\", \"Eibar\", \"Osasuna\", \"Leganes\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.978222131729126, \"num_examples\": 9.0, \"standard_deviation\": 0.14139458125925655}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.818666696548462, \"num_examples\": 18.0, \"standard_deviation\": 0.13003437291630768}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.439499855041504}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7632501125335693, \"num_examples\": 12.0, \"standard_deviation\": 0.12498919753857567}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP2_AVG\", \"threshold\": 2.5339999198913574}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.830000162124634, \"num_examples\": 5.0, \"standard_deviation\": 0.017151879592795585}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.715571403503418, \"num_examples\": 7.0, \"standard_deviation\": 0.1453105578753976}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.929500102996826, \"num_examples\": 6.0, \"standard_deviation\": 0.03249892718179836}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.0436923503875732, \"num_examples\": 13.0, \"standard_deviation\": 0.12363189121353035}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Getafe\", \"Eibar\", \"Mallorca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.101250171661377, \"num_examples\": 8.0, \"standard_deviation\": 0.007717097085946555}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9516000747680664, \"num_examples\": 5.0, \"standard_deviation\": 0.16082195213745357}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6529998779296875, \"num_examples\": 12.0, \"standard_deviation\": 0.33032152869216774}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"games\", \"threshold\": 18.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.442199945449829, \"num_examples\": 5.0, \"standard_deviation\": 0.32824279781299265}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.8035714626312256, \"num_examples\": 7.0, \"standard_deviation\": 0.23596173298745002}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.2553529739379883, \"num_examples\": 17.0, \"standard_deviation\": 0.2190381368371635}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.000499963760376}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4626667499542236, \"num_examples\": 6.0, \"standard_deviation\": 0.10135265893863073}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.142272710800171, \"num_examples\": 11.0, \"standard_deviation\": 0.17976105481233903}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.9130001068115234}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.0543999671936035, \"num_examples\": 5.0, \"standard_deviation\": 0.17781426462423164}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.2154998779296875, \"num_examples\": 6.0, \"standard_deviation\": 0.14524887278212303}}]}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.789069652557373, \"num_examples\": 86.0, \"standard_deviation\": 0.330006012269902}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 8.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.420785665512085, \"num_examples\": 14.0, \"standard_deviation\": 0.2219611811221393}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OPX_AVG\", \"threshold\": 3.3334999084472656}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.253000020980835, \"num_examples\": 7.0, \"standard_deviation\": 0.11110935449594929}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.588571310043335, \"num_examples\": 7.0, \"standard_deviation\": 0.17287036728067245}}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.86068058013916, \"num_examples\": 72.0, \"standard_deviation\": 0.29832679567464354}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Valencia\", \"Espanyol\", \"Eibar\", \"Granada CF\", \"Osasuna\", \"Leganes\", \"Valladolid\", \"Rayo Vallecano\", \"Malaga\", \"Dep. La Coruna\", \"Mallorca\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.0188333988189697, \"num_examples\": 42.0, \"standard_deviation\": 0.2721692298407188}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_tie\", \"threshold\": 5.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.157888889312744, \"num_examples\": 18.0, \"standard_deviation\": 0.23812656155267573}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"away_wins\", \"threshold\": 15.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.9649999141693115, \"num_examples\": 6.0, \"standard_deviation\": 0.08049826081490319}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.254333257675171, \"num_examples\": 12.0, \"standard_deviation\": 0.23218917557852942}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"away_team\", \"mask\": [\"Real Sociedad\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.4235999584198, \"num_examples\": 5.0, \"standard_deviation\": 0.26559671977384197}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1334285736083984, \"num_examples\": 7.0, \"standard_deviation\": 0.08336826878661167}}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.914541721343994, \"num_examples\": 24.0, \"standard_deviation\": 0.2484469543652574}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Espanyol\", \"Malaga\", \"Cadiz CF\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 3.1408748626708984, \"num_examples\": 8.0, \"standard_deviation\": 0.1425934642903407}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.801374912261963, \"num_examples\": 16.0, \"standard_deviation\": 0.2097672842978069}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"home_team\", \"mask\": [\"Granada CF\", \"Rayo Vallecano\", \"Dep. La Coruna\", \"Mallorca\"]}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.890333414077759, \"num_examples\": 9.0, \"standard_deviation\": 0.16226654976482435}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.687000036239624, \"num_examples\": 7.0, \"standard_deviation\": 0.20848754056900481}}]}]}]}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6392667293548584, \"num_examples\": 30.0, \"standard_deviation\": 0.16077762998325595}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"OP1_AVG\", \"threshold\": 2.7764999866485596}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.7911109924316406, \"num_examples\": 9.0, \"standard_deviation\": 0.13986713893527547}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.574190378189087, \"num_examples\": 21.0, \"standard_deviation\": 0.12011391180103033}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_wins\", \"threshold\": 6.5}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6313750743865967, \"num_examples\": 8.0, \"standard_deviation\": 0.10520082752348445}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.5390000343322754, \"num_examples\": 13.0, \"standard_deviation\": 0.11508435821601105}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"home_loss\", \"threshold\": 6.0}, \"children\": [{\"value\": {\"type\": \"REGRESSION\", \"value\": 2.4670000076293945, \"num_examples\": 6.0, \"standard_deviation\": 0.0982053310327592}}, {\"value\": {\"type\": \"REGRESSION\", \"value\": 2.6007142066955566, \"num_examples\": 7.0, \"standard_deviation\": 0.08987852587833596}}]}]}]}]}]}]}]}]}]}]}]}, \"#tree_plot_4706a53e9d68419eb5fb212f28cd3f89\")\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = test_dataset_rfo[label_keys]\n",
        "test_features = test_dataset_rfo.drop(labels=label_keys, axis=1)\n",
        "# test_dataset\n",
        "# test_features\n",
        "tf_test_data = tfdf.keras.pd_dataframe_to_tf_dataset(test_features)\n",
        "tf_test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z49n0Cgiu0Yw",
        "outputId": "07cd2961-99ce-4168-db8c-bb2f653e29cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec={'home_team': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'away_team': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'home_wins': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'home_tie': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'home_loss': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_wins': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_tie': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_loss': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'games': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'OP1_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OPX_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP2_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3RSZ_UQqJuou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset_rfo = get_tf_dataset(test_dataset_rfo, label_keys)\n",
        "tf_train_dataset_rfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcrt46eHt4O6",
        "outputId": "4f196608-1a2c-43cc-b44e-e9a45b744ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=({'home_team': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'away_team': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'home_wins': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'home_tie': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'home_loss': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_wins': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_tie': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_loss': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'games': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'OP1_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OPX_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP2_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}, {'CP1_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'CPX_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'CP2_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None)})>"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model_1.evaluate(tf_train_dataset_rfo, verbose=1, return_dict=True)\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j30Q-25fuEA_",
        "outputId": "3dd23090-329b-44ec-936c-bf5881c97f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 48ms/step - loss: 1.0952 - CP1_AVG_loss: 0.2485 - CP2_AVG_loss: 0.5982 - CPX_AVG_loss: 0.2486\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 1.0952415466308594,\n",
              " 'CP1_AVG_loss': 0.2485017329454422,\n",
              " 'CP2_AVG_loss': 0.5981789827346802,\n",
              " 'CPX_AVG_loss': 0.248560830950737}"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_FHIoqIlweYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions_rf(predictions, dataset, target, num):\n",
        "  op1x2 = dataset[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]][:num]\n",
        "  op1x2 = np.array(op1x2).astype('float32')\n",
        "  target = np.array(target).astype('float32')\n",
        "  # print(\"target\")\n",
        "  # print(target)\n",
        "  direction_right = 0\n",
        "  absolute_errors = []\n",
        "  for prediction, cp1x2_val, op1x2_val in zip(predictions, target, op1x2):\n",
        "    print(f\"OP1X2: {op1x2_val} CP1X2: {cp1x2_val} pred: {prediction}\")\n",
        "    print(prediction)\n",
        "    real_diffs = get_diffs(op1x2_val, cp1x2_val)\n",
        "    pred_diffs = get_diffs(op1x2_val, prediction)\n",
        "    error_diffs = get_diffs(cp1x2_val, prediction)\n",
        "    absolute_errors += [abs(x) for x in error_diffs]\n",
        "    real_lowest = min_diff(real_diffs)\n",
        "    pred_lowest = min_diff(pred_diffs)\n",
        "    print(f\"real_diffs: {real_diffs}, pred_diffs: {pred_diffs}\")\n",
        "    print(f\"real low: {real_lowest}, pred_low: {pred_lowest}\")\n",
        "    if real_lowest == pred_lowest:\n",
        "      direction_right += 1\n",
        "\n",
        "  print(f\"mean abs error: {sum(absolute_errors)/num}\")\n",
        "  print(f\"correct_dir: {direction_right/num}\")"
      ],
      "metadata": {
        "id": "S6XUCW_UpJfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 10\n",
        "# taken_ds = tf_test_data.take(num)\n",
        "smaller_df = tfdf.keras.pd_dataframe_to_tf_dataset(test_features[:num])\n",
        "predictions = model_1.predict(smaller_df)\n",
        "predictions\n",
        "\n",
        "# taken_ds.shape\n",
        "# target = test_target\n",
        "# features = tf_test_data\n",
        "# tf_test_data\n",
        "\n",
        "# converted_ds = tfdf.as_dataframe(tf_test_data)\n",
        "# converted_ds\n",
        "predictions_zipped = list(zip(predictions[\"CP1_AVG\"].flatten(), predictions[\"CPX_AVG\"].flatten(), predictions[\"CP2_AVG\"].flatten()))\n",
        "# test_labels.shape\n",
        "# predictions_zipped\n",
        "# test_features\n",
        "# test_labels\n",
        "# predictions[\"CPX_AVG\"].shape\n",
        "# predictions[\"CP2_AVG\"].shape\n",
        "# test_features.shape\n",
        "# def compare_predictions(predictions, dataset, target, num):\n",
        "compare_predictions_rf(predictions_zipped, test_features, test_labels, num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B40MJ-yovtmd",
        "outputId": "131e4119-ee4c-4a74-87e5-532a6eef5fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n",
            "OP1X2: [3.307 3.145 2.246] CP1X2: [3.187 3.029 2.513] pred: (3.4338105, 3.145839, 2.249078)\n",
            "(3.4338105, 3.145839, 2.249078)\n",
            "real_diffs: (-0.119999886, -0.11599994, 0.26699996), pred_diffs: (0.12681055, 0.000838995, 0.0030779839)\n",
            "real low: H, pred_low: D\n",
            "OP1X2: [3.737 3.314 2.013] CP1X2: [3.484 3.374 2.179] pred: (4.0157876, 3.3307197, 1.9601387)\n",
            "(4.0157876, 3.3307197, 1.9601387)\n",
            "real_diffs: (-0.25300002, 0.06000018, 0.16599989), pred_diffs: (0.2787876, 0.016719818, -0.052861333)\n",
            "real low: H, pred_low: A\n",
            "OP1X2: [ 1.214  6.37  12.577] CP1X2: [ 1.217  6.787 13.65 ] pred: (1.2347541, 6.212232, 11.879961)\n",
            "(1.2347541, 6.212232, 11.879961)\n",
            "real_diffs: (0.003000021, 0.4170003, 1.073), pred_diffs: (0.020754099, -0.15776777, -0.69703865)\n",
            "real low: H, pred_low: A\n",
            "OP1X2: [2.037 3.349 3.627] CP1X2: [1.767 3.574 5.043] pred: (1.94287, 3.4516685, 4.1109514)\n",
            "(1.94287, 3.4516685, 4.1109514)\n",
            "real_diffs: (-0.26999998, 0.2249999, 1.4160001), pred_diffs: (-0.09412992, 0.102668524, 0.48395133)\n",
            "real low: H, pred_low: H\n",
            "OP1X2: [3.066 3.153 2.359] CP1X2: [3.771 3.052 2.212] pred: (3.6168518, 3.2208948, 2.2989504)\n",
            "(3.6168518, 3.2208948, 2.2989504)\n",
            "real_diffs: (0.7049999, -0.10100007, -0.14700007), pred_diffs: (0.5508518, 0.0678947, -0.060049534)\n",
            "real low: A, pred_low: A\n",
            "OP1X2: [1.692 3.713 4.901] CP1X2: [1.9   3.503 4.292] pred: (1.6738877, 3.7648706, 5.3384)\n",
            "(1.6738877, 3.7648706, 5.3384)\n",
            "real_diffs: (0.20799994, -0.21000004, -0.6090002), pred_diffs: (-0.018112302, 0.051870584, 0.43739986)\n",
            "real low: A, pred_low: H\n",
            "OP1X2: [7.987 4.694 1.374] CP1X2: [7.05  4.945 1.428] pred: (6.3496857, 4.4525256, 1.4161668)\n",
            "(6.3496857, 4.4525256, 1.4161668)\n",
            "real_diffs: (-0.9369998, 0.2510004, 0.05400002), pred_diffs: (-1.6373143, -0.24147415, 0.04216683)\n",
            "real low: H, pred_low: H\n",
            "OP1X2: [1.604 3.725 5.859] CP1X2: [1.57  3.913 6.634] pred: (1.5735682, 3.8718596, 6.0180993)\n",
            "(1.5735682, 3.8718596, 6.0180993)\n",
            "real_diffs: (-0.03399992, 0.1880002, 0.7749996), pred_diffs: (-0.030431747, 0.14685965, 0.1590991)\n",
            "real low: H, pred_low: H\n",
            "OP1X2: [4.707 3.371 1.807] CP1X2: [5.557 3.096 1.847] pred: (4.7918944, 3.34827, 1.8766332)\n",
            "(4.7918944, 3.34827, 1.8766332)\n",
            "real_diffs: (0.8500004, -0.2750001, 0.03999996), pred_diffs: (0.08489466, -0.022730112, 0.069633126)\n",
            "real low: D, pred_low: D\n",
            "OP1X2: [1.484 4.163 6.611] CP1X2: [1.579 4.043 6.111] pred: (1.4955634, 4.2115574, 6.8948836)\n",
            "(1.4955634, 4.2115574, 6.8948836)\n",
            "real_diffs: (0.09500003, -0.119999886, -0.5), pred_diffs: (0.01156342, 0.04855728, 0.28388357)\n",
            "real low: A, pred_low: H\n",
            "mean abs error: 1.0906805634498595\n",
            "correct_dir: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##predict greatest decrease##"
      ],
      "metadata": {
        "id": "ixy8Pa-l_EL9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BrZ_NtG_HMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset()"
      ],
      "metadata": {
        "id": "YreV3b9Y_Mzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_UV_dataset():\n",
        "  dataset_uv = dataset.copy()\n",
        "  dataset_uv[\"undervalued\"] = get_max_diff(dataset_uv)\n",
        "  dataset_uv = dataset_uv.drop([\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"], axis=1)\n",
        "  # dataset[\"\"]\n",
        "  return split_dataset(dataset_uv, False)"
      ],
      "metadata": {
        "id": "YzM7qU5K_b1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = get_UV_dataset()"
      ],
      "metadata": {
        "id": "jy3oLYZQMVC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_keys = [\"undervalued\"]\n",
        "\n",
        "tf_train_data = tfdf.keras.pd_dataframe_to_tf_dataset(train_dataset, label=\"undervalued\")\n",
        "tf_train_data\n",
        "tf_test_data = tfdf.keras.pd_dataframe_to_tf_dataset(test_dataset, label=\"undervalued\")\n",
        "tf_test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkVQWioAAefa",
        "outputId": "ce08217b-d1e9-4bd6-cac8-434b6b509f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'home_team': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'away_team': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'home_wins': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'home_tie': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'home_loss': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_wins': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_tie': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'away_loss': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'games': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'OP1_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OPX_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP2_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = tfdf.tuner.RandomSearch(num_trials=20)\n",
        "\n",
        "model_2 = tfdf.keras.RandomForestModel(verbose=1, tuner=tuner)\n",
        "model_2.compile(metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sNbJ-jbCyVJ",
        "outputId": "77ef72d1-968e-470b-e1d1-dc47fea59c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpkhxxxjbc as temporary training directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(tf_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTpmhVN0E_Kr",
        "outputId": "6bae8df4-f1e5-47fe-aa72-f57393f86ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading training dataset...\n",
            "Training dataset read in 0:00:00.346853. Found 2660 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:04.692977\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7a2f9db9e0b0>"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQViIBXdFFTq",
        "outputId": "74da6cac-5382-4d51-89ae-0b36931cdd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (12):\n",
            "\tOP1_AVG\n",
            "\tOP2_AVG\n",
            "\tOPX_AVG\n",
            "\taway_loss\n",
            "\taway_team\n",
            "\taway_tie\n",
            "\taway_wins\n",
            "\tgames\n",
            "\thome_loss\n",
            "\thome_team\n",
            "\thome_tie\n",
            "\thome_wins\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"home_team\"  0.370697 ################\n",
            "    2. \"away_team\"  0.364341 ###############\n",
            "    3.   \"OPX_AVG\"  0.163529 ###\n",
            "    4.   \"OP1_AVG\"  0.140393 ##\n",
            "    5.   \"OP2_AVG\"  0.128728 #\n",
            "    6. \"away_wins\"  0.114999 \n",
            "    7.     \"games\"  0.114843 \n",
            "    8. \"home_wins\"  0.107289 \n",
            "    9. \"away_loss\"  0.101739 \n",
            "   10. \"home_loss\"  0.101634 \n",
            "   11.  \"home_tie\"  0.099723 \n",
            "   12.  \"away_tie\"  0.099421 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"away_team\" 104.000000 ################\n",
            "    2. \"home_team\" 100.000000 ###############\n",
            "    3.   \"OPX_AVG\" 46.000000 ######\n",
            "    4.   \"OP1_AVG\" 24.000000 ###\n",
            "    5. \"home_wins\"  9.000000 \n",
            "    6.   \"OP2_AVG\"  6.000000 \n",
            "    7. \"away_wins\"  6.000000 \n",
            "    8.     \"games\"  5.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"home_team\" 15618.000000 ################\n",
            "    2. \"away_team\" 15397.000000 ###############\n",
            "    3.   \"OPX_AVG\" 9768.000000 ######\n",
            "    4.   \"OP2_AVG\" 8831.000000 #####\n",
            "    5.   \"OP1_AVG\" 8711.000000 #####\n",
            "    6.     \"games\" 7014.000000 ##\n",
            "    7. \"away_wins\" 6148.000000 \n",
            "    8. \"home_wins\" 5934.000000 \n",
            "    9. \"home_loss\" 5858.000000 \n",
            "   10. \"away_loss\" 5855.000000 \n",
            "   11.  \"home_tie\" 5670.000000 \n",
            "   12.  \"away_tie\" 5557.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"away_team\" 120960.754390 ################\n",
            "    2. \"home_team\" 120028.075972 ###############\n",
            "    3.   \"OPX_AVG\" 50964.174040 ####\n",
            "    4.   \"OP1_AVG\" 43114.875410 ##\n",
            "    5.   \"OP2_AVG\" 42804.208702 ##\n",
            "    6.     \"games\" 34033.480002 #\n",
            "    7. \"away_wins\" 29091.296563 \n",
            "    8. \"home_wins\" 27386.068425 \n",
            "    9. \"home_loss\" 26488.205245 \n",
            "   10. \"away_loss\" 26118.377319 \n",
            "   11.  \"home_tie\" 25420.279494 \n",
            "   12.  \"away_tie\" 25221.835137 \n",
            "\n",
            "\n",
            "Hyperparameter optimizer:\n",
            "\n",
            "Best parameters: *empty*\n",
            "Num steps: 1\n",
            "Best score: 0.473684\n",
            "\n",
            "Step #0 score:0.473684 parameters:{ *empty* }\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.473684 logloss:1.02867\n",
            "Number of trees: 300\n",
            "Total number of nodes: 201022\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 670.073 StdDev: 25.7451\n",
            "Min: 563 Max: 735 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 563, 571)  1   0.33%   0.33%\n",
            "[ 571, 580)  1   0.33%   0.67%\n",
            "[ 580, 588)  0   0.00%   0.67%\n",
            "[ 588, 597)  1   0.33%   1.00%\n",
            "[ 597, 606)  0   0.00%   1.00%\n",
            "[ 606, 614)  7   2.33%   3.33% ##\n",
            "[ 614, 623)  1   0.33%   3.67%\n",
            "[ 623, 632) 12   4.00%   7.67% ###\n",
            "[ 632, 640) 14   4.67%  12.33% ###\n",
            "[ 640, 649) 18   6.00%  18.33% ####\n",
            "[ 649, 658) 36  12.00%  30.33% ########\n",
            "[ 658, 666) 26   8.67%  39.00% ######\n",
            "[ 666, 675) 37  12.33%  51.33% ########\n",
            "[ 675, 684) 45  15.00%  66.33% ##########\n",
            "[ 684, 692) 39  13.00%  79.33% #########\n",
            "[ 692, 701) 36  12.00%  91.33% ########\n",
            "[ 701, 710) 17   5.67%  97.00% ####\n",
            "[ 710, 718)  5   1.67%  98.67% #\n",
            "[ 718, 727)  2   0.67%  99.33%\n",
            "[ 727, 735]  2   0.67% 100.00%\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 100661 Average: 10.2877 StdDev: 2.47614\n",
            "Min: 2 Max: 15 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  2,  3)     2   0.00%   0.00%\n",
            "[  3,  4)    54   0.05%   0.06%\n",
            "[  4,  5)   391   0.39%   0.44%\n",
            "[  5,  6)  1501   1.49%   1.94% #\n",
            "[  6,  7)  3895   3.87%   5.80% ###\n",
            "[  7,  8)  7910   7.86%  13.66% #####\n",
            "[  8,  9) 11426  11.35%  25.01% #######\n",
            "[  9, 10) 14306  14.21%  39.23% #########\n",
            "[ 10, 11) 15303  15.20%  54.43% ##########\n",
            "[ 11, 12) 14016  13.92%  68.35% #########\n",
            "[ 12, 13) 11383  11.31%  79.66% #######\n",
            "[ 13, 14)  8760   8.70%  88.36% ######\n",
            "[ 14, 15)  5958   5.92%  94.28% ####\n",
            "[ 15, 15]  5756   5.72% 100.00% ####\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 100661 Average: 7.9276 StdDev: 4.85191\n",
            "Min: 5 Max: 122 Ignored: 0\n",
            "----------------------------------------------\n",
            "[   5,  10) 83996  83.44%  83.44% ##########\n",
            "[  10,  16) 10645  10.58%  94.02% #\n",
            "[  16,  22)  3531   3.51%  97.53%\n",
            "[  22,  28)  1410   1.40%  98.93%\n",
            "[  28,  34)   563   0.56%  99.49%\n",
            "[  34,  40)   237   0.24%  99.72%\n",
            "[  40,  46)   126   0.13%  99.85%\n",
            "[  46,  52)    51   0.05%  99.90%\n",
            "[  52,  58)    36   0.04%  99.93%\n",
            "[  58,  64)    17   0.02%  99.95%\n",
            "[  64,  69)    14   0.01%  99.97%\n",
            "[  69,  75)    11   0.01%  99.98%\n",
            "[  75,  81)     8   0.01%  99.98%\n",
            "[  81,  87)     5   0.00%  99.99%\n",
            "[  87,  93)     4   0.00%  99.99%\n",
            "[  93,  99)     2   0.00% 100.00%\n",
            "[  99, 105)     2   0.00% 100.00%\n",
            "[ 105, 111)     1   0.00% 100.00%\n",
            "[ 111, 117)     0   0.00% 100.00%\n",
            "[ 117, 122]     2   0.00% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t15618 : home_team [CATEGORICAL]\n",
            "\t15397 : away_team [CATEGORICAL]\n",
            "\t9768 : OPX_AVG [NUMERICAL]\n",
            "\t8831 : OP2_AVG [NUMERICAL]\n",
            "\t8711 : OP1_AVG [NUMERICAL]\n",
            "\t7014 : games [NUMERICAL]\n",
            "\t6148 : away_wins [NUMERICAL]\n",
            "\t5934 : home_wins [NUMERICAL]\n",
            "\t5858 : home_loss [NUMERICAL]\n",
            "\t5855 : away_loss [NUMERICAL]\n",
            "\t5670 : home_tie [NUMERICAL]\n",
            "\t5557 : away_tie [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t104 : away_team [CATEGORICAL]\n",
            "\t100 : home_team [CATEGORICAL]\n",
            "\t46 : OPX_AVG [NUMERICAL]\n",
            "\t24 : OP1_AVG [NUMERICAL]\n",
            "\t9 : home_wins [NUMERICAL]\n",
            "\t6 : away_wins [NUMERICAL]\n",
            "\t6 : OP2_AVG [NUMERICAL]\n",
            "\t5 : games [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t280 : home_team [CATEGORICAL]\n",
            "\t254 : away_team [CATEGORICAL]\n",
            "\t117 : OPX_AVG [NUMERICAL]\n",
            "\t80 : OP1_AVG [NUMERICAL]\n",
            "\t65 : OP2_AVG [NUMERICAL]\n",
            "\t40 : away_wins [NUMERICAL]\n",
            "\t29 : games [NUMERICAL]\n",
            "\t19 : home_wins [NUMERICAL]\n",
            "\t8 : away_loss [NUMERICAL]\n",
            "\t5 : away_tie [NUMERICAL]\n",
            "\t2 : home_loss [NUMERICAL]\n",
            "\t1 : home_tie [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t571 : away_team [CATEGORICAL]\n",
            "\t548 : home_team [CATEGORICAL]\n",
            "\t258 : OPX_AVG [NUMERICAL]\n",
            "\t194 : OP1_AVG [NUMERICAL]\n",
            "\t157 : OP2_AVG [NUMERICAL]\n",
            "\t107 : away_wins [NUMERICAL]\n",
            "\t94 : games [NUMERICAL]\n",
            "\t67 : home_wins [NUMERICAL]\n",
            "\t36 : home_loss [NUMERICAL]\n",
            "\t36 : away_loss [NUMERICAL]\n",
            "\t15 : home_tie [NUMERICAL]\n",
            "\t15 : away_tie [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t1088 : away_team [CATEGORICAL]\n",
            "\t1072 : home_team [CATEGORICAL]\n",
            "\t463 : OPX_AVG [NUMERICAL]\n",
            "\t391 : OP1_AVG [NUMERICAL]\n",
            "\t347 : OP2_AVG [NUMERICAL]\n",
            "\t262 : games [NUMERICAL]\n",
            "\t236 : away_wins [NUMERICAL]\n",
            "\t161 : home_wins [NUMERICAL]\n",
            "\t131 : home_loss [NUMERICAL]\n",
            "\t116 : away_loss [NUMERICAL]\n",
            "\t89 : home_tie [NUMERICAL]\n",
            "\t84 : away_tie [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t3278 : away_team [CATEGORICAL]\n",
            "\t3215 : home_team [CATEGORICAL]\n",
            "\t1493 : OPX_AVG [NUMERICAL]\n",
            "\t1358 : OP1_AVG [NUMERICAL]\n",
            "\t1260 : OP2_AVG [NUMERICAL]\n",
            "\t986 : games [NUMERICAL]\n",
            "\t858 : away_wins [NUMERICAL]\n",
            "\t755 : home_wins [NUMERICAL]\n",
            "\t717 : home_loss [NUMERICAL]\n",
            "\t667 : away_loss [NUMERICAL]\n",
            "\t634 : home_tie [NUMERICAL]\n",
            "\t597 : away_tie [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t69346 : HigherCondition\n",
            "\t31015 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t204 : ContainsBitmapCondition\n",
            "\t96 : HigherCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t534 : ContainsBitmapCondition\n",
            "\t366 : HigherCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t1119 : ContainsBitmapCondition\n",
            "\t979 : HigherCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t2280 : HigherCondition\n",
            "\t2160 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t9325 : HigherCondition\n",
            "\t6493 : ContainsBitmapCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.381579 logloss:22.2902\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.423703 logloss:8.31627\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.436842 logloss:3.8253\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.449624 logloss:2.41407\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.453008 logloss:1.79949\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.452632 logloss:1.48269\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.463534 logloss:1.3974\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.465414 logloss:1.29\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.462782 logloss:1.23516\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.468421 logloss:1.18226\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.46015 logloss:1.16866\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.458647 logloss:1.13103\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.465789 logloss:1.11675\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.460902 logloss:1.09149\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.464286 logloss:1.09058\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.469173 logloss:1.07388\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.468421 logloss:1.07333\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.467669 logloss:1.06006\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.472932 logloss:1.05829\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.469925 logloss:1.05708\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.468045 logloss:1.04422\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.476316 logloss:1.04447\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.471053 logloss:1.04426\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.477068 logloss:1.04369\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.47406 logloss:1.04369\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.474436 logloss:1.04342\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.470677 logloss:1.04296\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.47406 logloss:1.04251\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.469549 logloss:1.02977\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.474812 logloss:1.0291\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.473684 logloss:1.02867\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions_lowest(predictions, target, num):\n",
        "  # print(\"target\")\n",
        "  # print(target)\n",
        "  direction_right = 0\n",
        "  for prediction, real in zip(predictions, target):\n",
        "    if prediction == real:\n",
        "      direction_right += 1\n",
        "  print(f\"correct_dir: {direction_right/num}\")"
      ],
      "metadata": {
        "id": "L1zUNhwHFyB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model_2.evaluate(tf_test_data, verbose=1, return_dict=True)\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "arBazeb9GHQn",
        "outputId": "9d517379-8886-47fa-cac7-263913ccb3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fd48fbb666cf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = tfdf.tuner.RandomSearch(num_trials=25, use_predefined_hps=True)\n",
        "model_3 = tfdf.keras.RandomForestModel(tuner=tuner)\n",
        "model_3.compile(metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYT1VeoZIDhc",
        "outputId": "ed9c70d3-dfd0-4369-dc7e-698832b2b255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmp3229yr4a as temporary training directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fit(tf_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpz_lCQUySFx",
        "outputId": "f9398611-172b-44a8-b349-0cd06f9938a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading training dataset...\n",
            "Training dataset read in 0:00:09.479976. Found 2660 examples.\n",
            "Training model...\n",
            "Model trained in 0:40:21.354139\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7e7997eb7a30>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model_3.evaluate(tf_test_data, verbose=1, return_dict=True)\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r847VA-QNZYr",
        "outputId": "cb465eb3-c6bf-4d04-f768-84615cedb6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step - loss: 0.0000e+00 - accuracy: 0.4329\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.0, 'accuracy': 0.4328947365283966}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f\"{pwd}/decrease_tree\"\n",
        "model_3.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImjLek7v83tc",
        "outputId": "f3dc249d-5dd8-4e8c-b514-a7e6b312f766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to linear_regression_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UV model##\n"
      ],
      "metadata": {
        "id": "oLZY9sX-Mlx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset()"
      ],
      "metadata": {
        "id": "GTemx53qs1t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_uv = dataset.copy()\n",
        "dataset_uv[\"undervalued\"] = get_max_diff(dataset_uv, False)\n",
        "dataset_uv = dataset_uv.drop([\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"], axis=1)\n",
        "dataset_uv = get_small_OHE_dataset(dataset_uv)\n",
        "uv_train, uv_test = split_dataset(dataset_uv, True)\n",
        "print_dataset_stats(dataset_uv)\n",
        "uv_train = uv_train.groupby(\"undervalued\").sample(n=442)\n",
        "# uv_train = uv_train.sample(frac=1)\n",
        "print(\"uv train\")\n",
        "print_dataset_stats(uv_train)\n",
        "uv_val = uv_train.groupby(\"undervalued\").sample(n=88)\n",
        "uv_val = uv_val.sample(frac=1)\n",
        "print(\"uv val\")\n",
        "print_dataset_stats(uv_val)\n",
        "# uv_train.drop(uv_val)\n",
        "uv_train = uv_train.drop(index=uv_val.index)\n",
        "uv_train = uv_train.sample(frac=1)\n",
        "print(\"uv train without val\")\n",
        "print_dataset_stats(uv_train)\n",
        "# uv_train, uv_test = split_dataset(uv_train, True)\n",
        "uv_val_target = uv_val[['undervalued']]\n",
        "uv_train_target = uv_train[['undervalued']]\n",
        "uv_test_target = uv_test[['undervalued']]\n",
        "uv_val_features= uv_val.drop(columns=['undervalued'])\n",
        "uv_train_features = uv_train.drop(columns=['undervalued'])\n",
        "uv_test_features = uv_test.drop(columns=['undervalued'])\n",
        "\n",
        "uv_val_target = np.array(uv_val_target).astype('float32')\n",
        "uv_train_target = np.array(uv_train_target).astype('float32')\n",
        "uv_test_target = np.array(uv_test_target).astype('float32')\n",
        "uv_val_features = np.array(uv_val_features).astype('float32')\n",
        "uv_train_features = np.array(uv_train_features).astype('float32')\n",
        "uv_test_features = np.array(uv_test_features).astype('float32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pis_aDBGMo1V",
        "outputId": "b453bd45-ea96-4978-edae-722c31bcb961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H% : 0.42660818713450294, D% : 0.18801169590643274, A% : 0.3853801169590643\n",
            "total: 3420, sum: 3420 nums: h 1459 x 643 a 1318\n",
            "uv train\n",
            "H% : 0.3333333333333333, D% : 0.3333333333333333, A% : 0.3333333333333333\n",
            "total: 1326, sum: 1326 nums: h 442 x 442 a 442\n",
            "uv val\n",
            "H% : 0.3333333333333333, D% : 0.3333333333333333, A% : 0.3333333333333333\n",
            "total: 264, sum: 264 nums: h 88 x 88 a 88\n",
            "uv train without val\n",
            "H% : 0.3333333333333333, D% : 0.3333333333333333, A% : 0.3333333333333333\n",
            "total: 1062, sum: 1062 nums: h 354 x 354 a 354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_h = (uv_train[\"undervalued\"].value_counts()[0])\n",
        "num_x = (uv_train[\"undervalued\"].value_counts()[1])\n",
        "num_a = (uv_train[\"undervalued\"].value_counts()[2])\n",
        "total = len(uv_train)\n",
        "print(f\"H% : {num_h/total}, D% : {num_x/total}, A% : {num_a/total}\")\n",
        "print(f\"total: {total}, sum: {num_h + num_x + num_a} nums: h {num_h} x {num_x} a {num_a}\")\n",
        "uv_train = uv_train.groupby(\"undervalued\").sample(n=442)\n",
        "uv_train = uv_train.sample(frac=1)\n",
        "uv_train_target[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISAHkkPgSl7N",
        "outputId": "286b1155-9526-418d-b6b6-21eb7c873bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H% : 0.3333333333333333, D% : 0.3333333333333333, A% : 0.3333333333333333\n",
            "total: 1326, sum: 1326 nums: h 442 x 442 a 442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [2.],\n",
              "       [0.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(uv_train_features)\n",
        "steps_per_epoch = len(uv_train_features)/32\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "model_4 = tf.keras.Sequential([\n",
        "      normalizer,\n",
        "      layers.Dense(5, activation='sigmoid'),\n",
        "      layers.Dense(5, activation='sigmoid'),\n",
        "      layers.Dense(3)\n",
        "])\n",
        "\n",
        "model_4.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SeVpAbrmOY0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode=\"max\",\n",
        "    min_delta=0,\n",
        "    patience=90,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")"
      ],
      "metadata": {
        "id": "Xu5cO1WGObn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model_4.fit(\n",
        "    uv_train_features,\n",
        "    uv_train_target,\n",
        "    epochs=400,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_freq=5,\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_data = (uv_val_features, uv_val_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCyIqEztOdoW",
        "outputId": "2ab20aa5-8904-4dc4-9b7b-53da09bd7350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5220 - loss: 0.9858\n",
            "Epoch 2/400\n",
            "\u001b[1m 1/34\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.6562 - loss: 0.8780"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5414 - loss: 0.9773\n",
            "Epoch 3/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4996 - loss: 0.9992\n",
            "Epoch 4/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5172 - loss: 0.9830\n",
            "Epoch 5/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5074 - loss: 0.9950 - val_accuracy: 0.3977 - val_loss: 1.0981\n",
            "Epoch 6/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4984 - loss: 0.9923\n",
            "Epoch 7/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5098 - loss: 0.9856\n",
            "Epoch 8/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5306 - loss: 0.9838\n",
            "Epoch 9/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5212 - loss: 0.9923\n",
            "Epoch 10/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5216 - loss: 0.9827 - val_accuracy: 0.3977 - val_loss: 1.0996\n",
            "Epoch 11/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4943 - loss: 0.9958\n",
            "Epoch 12/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4783 - loss: 1.0081\n",
            "Epoch 13/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4819 - loss: 0.9970\n",
            "Epoch 14/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4988 - loss: 0.9994\n",
            "Epoch 15/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5211 - loss: 0.9864 - val_accuracy: 0.3977 - val_loss: 1.1009\n",
            "Epoch 16/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5160 - loss: 0.9867\n",
            "Epoch 17/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5274 - loss: 0.9815\n",
            "Epoch 18/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5389 - loss: 0.9786\n",
            "Epoch 19/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5198 - loss: 0.9863\n",
            "Epoch 20/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5358 - loss: 0.9821 - val_accuracy: 0.3977 - val_loss: 1.1016\n",
            "Epoch 21/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5196 - loss: 0.9791\n",
            "Epoch 22/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.9972\n",
            "Epoch 23/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4909 - loss: 1.0007 \n",
            "Epoch 24/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: 1.0014 \n",
            "Epoch 25/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5236 - loss: 0.9840 - val_accuracy: 0.3902 - val_loss: 1.1029\n",
            "Epoch 26/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5271 - loss: 0.9855\n",
            "Epoch 27/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5032 - loss: 0.9899\n",
            "Epoch 28/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5211 - loss: 0.9702\n",
            "Epoch 29/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5189 - loss: 0.9827 \n",
            "Epoch 30/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5260 - loss: 0.9670 - val_accuracy: 0.3826 - val_loss: 1.1038\n",
            "Epoch 31/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9822\n",
            "Epoch 32/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5244 - loss: 0.9688\n",
            "Epoch 33/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5056 - loss: 0.9755 \n",
            "Epoch 34/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5286 - loss: 0.9900\n",
            "Epoch 35/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5177 - loss: 0.9752 - val_accuracy: 0.3939 - val_loss: 1.1050\n",
            "Epoch 36/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5221 - loss: 0.9826  \n",
            "Epoch 37/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 0.9866 \n",
            "Epoch 38/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5141 - loss: 0.9937 \n",
            "Epoch 39/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5115 - loss: 0.9910\n",
            "Epoch 40/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5239 - loss: 0.9725 - val_accuracy: 0.3788 - val_loss: 1.1067\n",
            "Epoch 41/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.9823\n",
            "Epoch 42/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.9670\n",
            "Epoch 43/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5139 - loss: 0.9830\n",
            "Epoch 44/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 0.9850 \n",
            "Epoch 45/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5055 - loss: 0.9954 - val_accuracy: 0.3902 - val_loss: 1.1072\n",
            "Epoch 46/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5064 - loss: 0.9896\n",
            "Epoch 47/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.9624 \n",
            "Epoch 48/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5092 - loss: 0.9849\n",
            "Epoch 49/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.9865\n",
            "Epoch 50/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5310 - loss: 0.9698 - val_accuracy: 0.3864 - val_loss: 1.1086\n",
            "Epoch 51/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.9710  \n",
            "Epoch 52/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.9760\n",
            "Epoch 53/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5222 - loss: 0.9783\n",
            "Epoch 54/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5242 - loss: 0.9700\n",
            "Epoch 55/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5107 - loss: 0.9871 - val_accuracy: 0.3826 - val_loss: 1.1077\n",
            "Epoch 56/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5056 - loss: 0.9940  \n",
            "Epoch 57/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5126 - loss: 0.9814\n",
            "Epoch 58/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.9560 \n",
            "Epoch 59/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5064 - loss: 0.9723 \n",
            "Epoch 60/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: 0.9832 - val_accuracy: 0.3864 - val_loss: 1.1081\n",
            "Epoch 61/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.9764\n",
            "Epoch 62/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5030 - loss: 0.9724\n",
            "Epoch 63/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.9734\n",
            "Epoch 64/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5063 - loss: 0.9781 \n",
            "Epoch 65/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5293 - loss: 0.9656 - val_accuracy: 0.3826 - val_loss: 1.1093\n",
            "Epoch 66/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5232 - loss: 0.9700\n",
            "Epoch 67/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.9707\n",
            "Epoch 68/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.9774\n",
            "Epoch 69/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5314 - loss: 0.9640\n",
            "Epoch 70/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5175 - loss: 0.9842 - val_accuracy: 0.3788 - val_loss: 1.1103\n",
            "Epoch 71/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5223 - loss: 0.9723  \n",
            "Epoch 72/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: 0.9858 \n",
            "Epoch 73/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5286 - loss: 0.9827\n",
            "Epoch 74/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5183 - loss: 0.9622\n",
            "Epoch 75/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5249 - loss: 0.9554 - val_accuracy: 0.3864 - val_loss: 1.1108\n",
            "Epoch 76/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5226 - loss: 0.9748\n",
            "Epoch 77/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4845 - loss: 0.9976\n",
            "Epoch 78/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5333 - loss: 0.9475\n",
            "Epoch 79/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4960 - loss: 0.9891\n",
            "Epoch 80/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5137 - loss: 0.9757 - val_accuracy: 0.3864 - val_loss: 1.1110\n",
            "Epoch 81/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5362 - loss: 0.9492\n",
            "Epoch 82/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 0.9520\n",
            "Epoch 83/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5030 - loss: 0.9749\n",
            "Epoch 84/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5105 - loss: 0.9695\n",
            "Epoch 85/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5112 - loss: 0.9772 - val_accuracy: 0.3788 - val_loss: 1.1117\n",
            "Epoch 86/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5326 - loss: 0.9623\n",
            "Epoch 87/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: 0.9820\n",
            "Epoch 88/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5270 - loss: 0.9574\n",
            "Epoch 89/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5282 - loss: 0.9634\n",
            "Epoch 90/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5158 - loss: 0.9687 - val_accuracy: 0.3864 - val_loss: 1.1123\n",
            "Epoch 91/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5231 - loss: 0.9584\n",
            "Epoch 92/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5139 - loss: 0.9747\n",
            "Epoch 93/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5322 - loss: 0.9626\n",
            "Epoch 94/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 0.9794  \n",
            "Epoch 95/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 0.9745 - val_accuracy: 0.3902 - val_loss: 1.1132\n",
            "Epoch 96/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5357 - loss: 0.9615\n",
            "Epoch 97/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5395 - loss: 0.9543\n",
            "Epoch 98/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5476 - loss: 0.9407\n",
            "Epoch 99/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 0.9733\n",
            "Epoch 100/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5046 - loss: 0.9891 - val_accuracy: 0.3902 - val_loss: 1.1135\n",
            "Epoch 101/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: 0.9610\n",
            "Epoch 102/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: 0.9742\n",
            "Epoch 103/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5212 - loss: 0.9608\n",
            "Epoch 104/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5289 - loss: 0.9584 \n",
            "Epoch 105/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5462 - loss: 0.9455 - val_accuracy: 0.3902 - val_loss: 1.1148\n",
            "Epoch 106/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5256 - loss: 0.9904 \n",
            "Epoch 107/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.9676\n",
            "Epoch 108/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5335 - loss: 0.9760 \n",
            "Epoch 109/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5304 - loss: 0.9594\n",
            "Epoch 110/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5244 - loss: 0.9709 - val_accuracy: 0.3902 - val_loss: 1.1168\n",
            "Epoch 111/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.9617\n",
            "Epoch 112/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5286 - loss: 0.9609\n",
            "Epoch 113/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 0.9827\n",
            "Epoch 114/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5152 - loss: 0.9799\n",
            "Epoch 115/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5525 - loss: 0.9403 - val_accuracy: 0.3977 - val_loss: 1.1175\n",
            "Epoch 116/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5470 - loss: 0.9537\n",
            "Epoch 117/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.9617\n",
            "Epoch 118/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5370 - loss: 0.9678 \n",
            "Epoch 119/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5287 - loss: 0.9620\n",
            "Epoch 120/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.9647 - val_accuracy: 0.3939 - val_loss: 1.1187\n",
            "Epoch 121/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4969 - loss: 0.9846\n",
            "Epoch 122/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5193 - loss: 0.9784\n",
            "Epoch 123/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 0.9828\n",
            "Epoch 124/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.9717 \n",
            "Epoch 125/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5486 - loss: 0.9692 - val_accuracy: 0.3939 - val_loss: 1.1185\n",
            "Epoch 126/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5403 - loss: 0.9539 \n",
            "Epoch 127/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5331 - loss: 0.9792\n",
            "Epoch 128/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5307 - loss: 0.9655\n",
            "Epoch 129/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5511 - loss: 0.9351\n",
            "Epoch 130/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5364 - loss: 0.9713 - val_accuracy: 0.3864 - val_loss: 1.1196\n",
            "Epoch 131/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5496 - loss: 0.9455 \n",
            "Epoch 132/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5579 - loss: 0.9472\n",
            "Epoch 133/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5320 - loss: 0.9748\n",
            "Epoch 134/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5362 - loss: 0.9469 \n",
            "Epoch 135/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5418 - loss: 0.9576 - val_accuracy: 0.3977 - val_loss: 1.1203\n",
            "Epoch 136/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 0.9391\n",
            "Epoch 137/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5507 - loss: 0.9392 \n",
            "Epoch 138/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5506 - loss: 0.9461\n",
            "Epoch 139/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5522 - loss: 0.9556 \n",
            "Epoch 140/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.9593 - val_accuracy: 0.3939 - val_loss: 1.1211\n",
            "Epoch 141/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.9470\n",
            "Epoch 142/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5540 - loss: 0.9408\n",
            "Epoch 143/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5575 - loss: 0.9450\n",
            "Epoch 144/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5524 - loss: 0.9419\n",
            "Epoch 145/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5431 - loss: 0.9478 - val_accuracy: 0.3939 - val_loss: 1.1217\n",
            "Epoch 146/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 0.9734 \n",
            "Epoch 147/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5408 - loss: 0.9599\n",
            "Epoch 148/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 0.9702\n",
            "Epoch 149/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5555 - loss: 0.9662\n",
            "Epoch 150/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5652 - loss: 0.9510 - val_accuracy: 0.3902 - val_loss: 1.1231\n",
            "Epoch 151/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5447 - loss: 0.9484\n",
            "Epoch 152/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 0.9453 \n",
            "Epoch 153/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5391 - loss: 0.9365 \n",
            "Epoch 154/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5255 - loss: 0.9601\n",
            "Epoch 155/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5256 - loss: 0.9658 - val_accuracy: 0.4015 - val_loss: 1.1240\n",
            "Epoch 156/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5369 - loss: 0.9603\n",
            "Epoch 157/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5517 - loss: 0.9641\n",
            "Epoch 158/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5424 - loss: 0.9543 \n",
            "Epoch 159/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5597 - loss: 0.9395\n",
            "Epoch 160/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5363 - loss: 0.9734 - val_accuracy: 0.3902 - val_loss: 1.1255\n",
            "Epoch 161/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.9883\n",
            "Epoch 162/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5434 - loss: 0.9583 \n",
            "Epoch 163/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5523 - loss: 0.9529\n",
            "Epoch 164/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.9401 \n",
            "Epoch 165/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5579 - loss: 0.9487 - val_accuracy: 0.3939 - val_loss: 1.1266\n",
            "Epoch 166/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5517 - loss: 0.9514\n",
            "Epoch 167/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5670 - loss: 0.9346\n",
            "Epoch 168/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5416 - loss: 0.9464\n",
            "Epoch 169/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5184 - loss: 0.9760\n",
            "Epoch 170/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5399 - loss: 0.9438 - val_accuracy: 0.3864 - val_loss: 1.1269\n",
            "Epoch 171/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5641 - loss: 0.9619\n",
            "Epoch 172/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5653 - loss: 0.9435\n",
            "Epoch 173/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5434 - loss: 0.9548\n",
            "Epoch 174/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5550 - loss: 0.9511\n",
            "Epoch 175/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5561 - loss: 0.9322 - val_accuracy: 0.3864 - val_loss: 1.1278\n",
            "Epoch 176/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5448 - loss: 0.9440\n",
            "Epoch 177/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5388 - loss: 0.9636\n",
            "Epoch 178/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5377 - loss: 0.9517\n",
            "Epoch 179/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5364 - loss: 0.9694\n",
            "Epoch 180/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5339 - loss: 0.9579 - val_accuracy: 0.3902 - val_loss: 1.1280\n",
            "Epoch 181/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5399 - loss: 0.9573\n",
            "Epoch 182/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5425 - loss: 0.9712\n",
            "Epoch 183/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 0.9563\n",
            "Epoch 184/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 0.9491\n",
            "Epoch 185/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 0.9577 - val_accuracy: 0.3902 - val_loss: 1.1283\n",
            "Epoch 186/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5688 - loss: 0.9262 \n",
            "Epoch 187/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5644 - loss: 0.9372 \n",
            "Epoch 188/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 0.9578\n",
            "Epoch 189/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5732 - loss: 0.9291\n",
            "Epoch 190/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 0.9281 - val_accuracy: 0.3902 - val_loss: 1.1293\n",
            "Epoch 191/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 0.9463\n",
            "Epoch 192/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5439 - loss: 0.9486\n",
            "Epoch 193/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 0.9509\n",
            "Epoch 194/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5485 - loss: 0.9402 \n",
            "Epoch 195/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5416 - loss: 0.9741 - val_accuracy: 0.3902 - val_loss: 1.1300\n",
            "Epoch 196/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 0.9261\n",
            "Epoch 197/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 0.9437\n",
            "Epoch 198/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5628 - loss: 0.9366\n",
            "Epoch 199/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5731 - loss: 0.9354\n",
            "Epoch 200/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 0.9589 - val_accuracy: 0.3902 - val_loss: 1.1309\n",
            "Epoch 201/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5496 - loss: 0.9476\n",
            "Epoch 202/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5640 - loss: 0.9250\n",
            "Epoch 203/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5507 - loss: 0.9493\n",
            "Epoch 204/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.9718\n",
            "Epoch 205/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5649 - loss: 0.9358 - val_accuracy: 0.3902 - val_loss: 1.1319\n",
            "Epoch 206/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5567 - loss: 0.9499\n",
            "Epoch 207/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5456 - loss: 0.9396 \n",
            "Epoch 208/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5648 - loss: 0.9449\n",
            "Epoch 209/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5633 - loss: 0.9445\n",
            "Epoch 210/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5622 - loss: 0.9208 - val_accuracy: 0.3864 - val_loss: 1.1322\n",
            "Epoch 211/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5661 - loss: 0.9407\n",
            "Epoch 212/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5497 - loss: 0.9473\n",
            "Epoch 213/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 0.9495\n",
            "Epoch 214/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5618 - loss: 0.9387\n",
            "Epoch 215/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 0.9286 - val_accuracy: 0.3864 - val_loss: 1.1345\n",
            "Epoch 216/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5676 - loss: 0.9417\n",
            "Epoch 217/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5551 - loss: 0.9369\n",
            "Epoch 218/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5558 - loss: 0.9415\n",
            "Epoch 219/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5468 - loss: 0.9458\n",
            "Epoch 220/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 0.9650 - val_accuracy: 0.3864 - val_loss: 1.1345\n",
            "Epoch 221/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5453 - loss: 0.9551\n",
            "Epoch 222/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5463 - loss: 0.9424\n",
            "Epoch 223/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 0.9532\n",
            "Epoch 224/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5612 - loss: 0.9473\n",
            "Epoch 225/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5453 - loss: 0.9490 - val_accuracy: 0.3826 - val_loss: 1.1352\n",
            "Epoch 226/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5493 - loss: 0.9537\n",
            "Epoch 227/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5530 - loss: 0.9424\n",
            "Epoch 228/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5350 - loss: 0.9407\n",
            "Epoch 229/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5604 - loss: 0.9373\n",
            "Epoch 230/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5619 - loss: 0.9274 - val_accuracy: 0.3826 - val_loss: 1.1369\n",
            "Epoch 231/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5573 - loss: 0.9381\n",
            "Epoch 232/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5541 - loss: 0.9485\n",
            "Epoch 233/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5530 - loss: 0.9419\n",
            "Epoch 234/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5609 - loss: 0.9307\n",
            "Epoch 235/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5621 - loss: 0.9400 - val_accuracy: 0.3788 - val_loss: 1.1379\n",
            "Epoch 236/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5684 - loss: 0.9433\n",
            "Epoch 237/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5468 - loss: 0.9589\n",
            "Epoch 238/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5746 - loss: 0.9276\n",
            "Epoch 239/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5584 - loss: 0.9403\n",
            "Epoch 240/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5640 - loss: 0.9260 - val_accuracy: 0.3826 - val_loss: 1.1388\n",
            "Epoch 241/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5640 - loss: 0.9425\n",
            "Epoch 242/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5590 - loss: 0.9277\n",
            "Epoch 243/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5737 - loss: 0.9237 \n",
            "Epoch 244/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 0.9508\n",
            "Epoch 245/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5666 - loss: 0.9372 - val_accuracy: 0.3826 - val_loss: 1.1396\n",
            "Epoch 246/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5613 - loss: 0.9297\n",
            "Epoch 247/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5444 - loss: 0.9526\n",
            "Epoch 248/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5593 - loss: 0.9466\n",
            "Epoch 249/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5707 - loss: 0.9278\n",
            "Epoch 250/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5617 - loss: 0.9426 - val_accuracy: 0.3864 - val_loss: 1.1401\n",
            "Epoch 251/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5738 - loss: 0.9384\n",
            "Epoch 252/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5355 - loss: 0.9603\n",
            "Epoch 253/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5799 - loss: 0.9231\n",
            "Epoch 254/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5658 - loss: 0.9423\n",
            "Epoch 255/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5291 - loss: 0.9750 - val_accuracy: 0.3864 - val_loss: 1.1411\n",
            "Epoch 256/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5581 - loss: 0.9606\n",
            "Epoch 257/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5774 - loss: 0.9351\n",
            "Epoch 258/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 0.9265\n",
            "Epoch 259/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5613 - loss: 0.9190\n",
            "Epoch 260/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5637 - loss: 0.9340 - val_accuracy: 0.3864 - val_loss: 1.1419\n",
            "Epoch 261/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5578 - loss: 0.9455\n",
            "Epoch 262/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.9300\n",
            "Epoch 263/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5513 - loss: 0.9455\n",
            "Epoch 264/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5848 - loss: 0.9350\n",
            "Epoch 265/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5853 - loss: 0.9213 - val_accuracy: 0.3864 - val_loss: 1.1428\n",
            "Epoch 266/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5714 - loss: 0.9388\n",
            "Epoch 267/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5413 - loss: 0.9404\n",
            "Epoch 268/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5474 - loss: 0.9312\n",
            "Epoch 269/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5493 - loss: 0.9474\n",
            "Epoch 270/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5604 - loss: 0.9415 - val_accuracy: 0.3864 - val_loss: 1.1435\n",
            "Epoch 271/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5635 - loss: 0.9238\n",
            "Epoch 272/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5465 - loss: 0.9553\n",
            "Epoch 273/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5596 - loss: 0.9373\n",
            "Epoch 274/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 0.9320\n",
            "Epoch 275/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5669 - loss: 0.9367 - val_accuracy: 0.3864 - val_loss: 1.1442\n",
            "Epoch 276/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5531 - loss: 0.9545\n",
            "Epoch 277/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 0.9130\n",
            "Epoch 278/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5709 - loss: 0.9096 \n",
            "Epoch 279/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5561 - loss: 0.9328\n",
            "Epoch 280/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5712 - loss: 0.9305 - val_accuracy: 0.3864 - val_loss: 1.1452\n",
            "Epoch 281/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5346 - loss: 0.9554 \n",
            "Epoch 282/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 0.9214\n",
            "Epoch 283/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5646 - loss: 0.9255\n",
            "Epoch 284/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5710 - loss: 0.9270\n",
            "Epoch 285/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 0.9253 - val_accuracy: 0.3902 - val_loss: 1.1457\n",
            "Epoch 286/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5733 - loss: 0.9104\n",
            "Epoch 287/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5584 - loss: 0.9305\n",
            "Epoch 288/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.9279\n",
            "Epoch 289/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5436 - loss: 0.9369\n",
            "Epoch 290/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5810 - loss: 0.9275 - val_accuracy: 0.3902 - val_loss: 1.1469\n",
            "Epoch 291/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5561 - loss: 0.9492\n",
            "Epoch 292/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5789 - loss: 0.9135\n",
            "Epoch 293/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.9537\n",
            "Epoch 294/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5606 - loss: 0.9340\n",
            "Epoch 295/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5621 - loss: 0.9322 - val_accuracy: 0.3902 - val_loss: 1.1480\n",
            "Epoch 296/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5685 - loss: 0.9292\n",
            "Epoch 297/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.9427\n",
            "Epoch 298/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 0.9129\n",
            "Epoch 299/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 0.9134\n",
            "Epoch 300/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5565 - loss: 0.9468 - val_accuracy: 0.3902 - val_loss: 1.1490\n",
            "Epoch 301/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.9408\n",
            "Epoch 302/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 0.9177\n",
            "Epoch 303/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5643 - loss: 0.9309 \n",
            "Epoch 304/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5579 - loss: 0.9319\n",
            "Epoch 305/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5579 - loss: 0.9416 - val_accuracy: 0.3902 - val_loss: 1.1503\n",
            "Epoch 306/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 0.9273\n",
            "Epoch 307/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5862 - loss: 0.9060\n",
            "Epoch 308/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5875 - loss: 0.9113\n",
            "Epoch 309/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5611 - loss: 0.9214\n",
            "Epoch 310/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5605 - loss: 0.9526 - val_accuracy: 0.3939 - val_loss: 1.1509\n",
            "Epoch 311/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5544 - loss: 0.9267\n",
            "Epoch 312/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 0.9445\n",
            "Epoch 313/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5825 - loss: 0.9091\n",
            "Epoch 314/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5234 - loss: 0.9507\n",
            "Epoch 315/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.9491 - val_accuracy: 0.3902 - val_loss: 1.1518\n",
            "Epoch 316/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5632 - loss: 0.9416\n",
            "Epoch 317/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5746 - loss: 0.9111\n",
            "Epoch 318/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 0.9354\n",
            "Epoch 319/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.9179\n",
            "Epoch 320/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5655 - loss: 0.9369 - val_accuracy: 0.3977 - val_loss: 1.1524\n",
            "Epoch 321/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.9014\n",
            "Epoch 322/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5686 - loss: 0.9078 \n",
            "Epoch 323/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5713 - loss: 0.9199 \n",
            "Epoch 324/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5440 - loss: 0.9478\n",
            "Epoch 325/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5680 - loss: 0.9243 - val_accuracy: 0.3977 - val_loss: 1.1543\n",
            "Epoch 326/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5825 - loss: 0.9228\n",
            "Epoch 327/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5730 - loss: 0.9276\n",
            "Epoch 328/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5715 - loss: 0.9265\n",
            "Epoch 329/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 0.9301\n",
            "Epoch 330/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5546 - loss: 0.9450 - val_accuracy: 0.4015 - val_loss: 1.1554\n",
            "Epoch 331/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5690 - loss: 0.9229\n",
            "Epoch 332/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5730 - loss: 0.9209\n",
            "Epoch 333/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.9206 \n",
            "Epoch 334/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5673 - loss: 0.9300\n",
            "Epoch 335/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5718 - loss: 0.9247 - val_accuracy: 0.3977 - val_loss: 1.1564\n",
            "Epoch 336/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5773 - loss: 0.8993\n",
            "Epoch 337/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5658 - loss: 0.9300\n",
            "Epoch 338/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 0.9180\n",
            "Epoch 339/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.9016\n",
            "Epoch 340/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5758 - loss: 0.9204 - val_accuracy: 0.3977 - val_loss: 1.1575\n",
            "Epoch 341/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5614 - loss: 0.9442\n",
            "Epoch 342/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5685 - loss: 0.9092\n",
            "Epoch 343/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5840 - loss: 0.9125\n",
            "Epoch 344/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5474 - loss: 0.9416\n",
            "Epoch 345/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5378 - loss: 0.9413 - val_accuracy: 0.3977 - val_loss: 1.1590\n",
            "Epoch 346/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5717 - loss: 0.9041\n",
            "Epoch 347/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5542 - loss: 0.9311\n",
            "Epoch 348/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5645 - loss: 0.9175\n",
            "Epoch 349/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5326 - loss: 0.9341\n",
            "Epoch 350/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5722 - loss: 0.9089 - val_accuracy: 0.3902 - val_loss: 1.1602\n",
            "Epoch 351/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5600 - loss: 0.9278\n",
            "Epoch 352/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5578 - loss: 0.9361\n",
            "Epoch 353/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5566 - loss: 0.9232\n",
            "Epoch 354/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5884 - loss: 0.9064\n",
            "Epoch 355/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6103 - loss: 0.8818 - val_accuracy: 0.3977 - val_loss: 1.1619\n",
            "Epoch 356/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5686 - loss: 0.9017\n",
            "Epoch 357/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.9124\n",
            "Epoch 358/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 0.9069\n",
            "Epoch 359/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5646 - loss: 0.9167\n",
            "Epoch 360/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5435 - loss: 0.9407 - val_accuracy: 0.3977 - val_loss: 1.1623\n",
            "Epoch 361/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.8872\n",
            "Epoch 362/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5678 - loss: 0.9180\n",
            "Epoch 363/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.9152\n",
            "Epoch 364/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5584 - loss: 0.9177\n",
            "Epoch 365/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5622 - loss: 0.9154 - val_accuracy: 0.3939 - val_loss: 1.1637\n",
            "Epoch 366/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5583 - loss: 0.9368 \n",
            "Epoch 367/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5564 - loss: 0.9440\n",
            "Epoch 368/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 0.9239\n",
            "Epoch 369/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.9024\n",
            "Epoch 370/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.9122 - val_accuracy: 0.3902 - val_loss: 1.1645\n",
            "Epoch 371/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5795 - loss: 0.9084\n",
            "Epoch 372/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5674 - loss: 0.9103 \n",
            "Epoch 373/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5896 - loss: 0.9058 \n",
            "Epoch 374/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5645 - loss: 0.9185\n",
            "Epoch 375/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5797 - loss: 0.9046 - val_accuracy: 0.3939 - val_loss: 1.1665\n",
            "Epoch 376/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5547 - loss: 0.9246\n",
            "Epoch 377/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5681 - loss: 0.8989\n",
            "Epoch 378/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5704 - loss: 0.9309\n",
            "Epoch 379/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5730 - loss: 0.9222\n",
            "Epoch 380/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 0.9173 - val_accuracy: 0.4015 - val_loss: 1.1682\n",
            "Epoch 381/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5789 - loss: 0.9016\n",
            "Epoch 382/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5450 - loss: 0.9303\n",
            "Epoch 383/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 0.8939\n",
            "Epoch 384/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 0.9070\n",
            "Epoch 385/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5690 - loss: 0.9438 - val_accuracy: 0.3939 - val_loss: 1.1690\n",
            "Epoch 386/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5425 - loss: 0.9482\n",
            "Epoch 387/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5441 - loss: 0.9247\n",
            "Epoch 388/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.8965\n",
            "Epoch 389/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 0.8875\n",
            "Epoch 390/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5523 - loss: 0.9224 - val_accuracy: 0.3939 - val_loss: 1.1703\n",
            "Epoch 391/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 0.9056\n",
            "Epoch 392/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5786 - loss: 0.8937\n",
            "Epoch 393/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5663 - loss: 0.9079\n",
            "Epoch 394/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5562 - loss: 0.9039\n",
            "Epoch 395/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 0.9096 - val_accuracy: 0.3902 - val_loss: 1.1717\n",
            "Epoch 396/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5738 - loss: 0.9148\n",
            "Epoch 397/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5700 - loss: 0.9188\n",
            "Epoch 398/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 0.9101\n",
            "Epoch 399/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5736 - loss: 0.9043\n",
            "Epoch 400/400\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5600 - loss: 0.9128 - val_accuracy: 0.3977 - val_loss: 1.1727\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "CPU times: user 49.8 s, sys: 2.27 s, total: 52.1 s\n",
            "Wall time: 1min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# features = uv_val_features\n",
        "# target = uv_val_target\n",
        "# features = uv_train_features\n",
        "# target = uv_train_target\n",
        "features = uv_test_features\n",
        "target = uv_test_target\n",
        "num = len(features)\n",
        "features = features[:num]\n",
        "target = target[:num]\n",
        "\n",
        "print(len(features))\n",
        "predictions = model_4.predict(features)\n",
        "\n",
        "target_data = np.array(target).astype('float32')\n",
        "target_data = [x[0] for x in target_data]\n",
        "correct = 0\n",
        "predicted_classes = [np.argmax(x) for x in predictions]\n",
        "for prediction_class, target_val in zip(predicted_classes, target_data):\n",
        "  # prediction_class = np.argmax(prediction)\n",
        "  # print(f\"pred: {prediction_class}, real: {target_val}\")\n",
        "  if prediction_class == target_val:\n",
        "    correct += 1\n",
        "\n",
        "print(f\"correct: {correct/num}, {correct}/{num}\")\n",
        "# confusion_matrix = tf.math.confusion_matrix(\n",
        "#     target,\n",
        "#     predicted_classes,\n",
        "#     num_classes=3,\n",
        "#     weights=None,\n",
        "#     dtype=tf.dtypes.int32,\n",
        "#     name=None\n",
        "# )\n",
        "# confusion_matrix\n",
        "plot_confusion_matrix(target, predicted_classes, [\"H\", \"D\", \"A\"], \"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "mCDdeXXcTOAk",
        "outputId": "ad98d755-65bb-46e7-e2ce-67a08b97d423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "760\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "correct: 0.37894736842105264, 288/760\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
        "  cm = tf.math.confusion_matrix(actual, predicted)\n",
        "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
        "  sns.set(rc={'figure.figsize':(4, 4)})\n",
        "  sns.set(font_scale=1.4)\n",
        "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
        "  ax.set_xlabel('Predicted Action')\n",
        "  ax.set_ylabel('Actual Action')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "U31AMW-4KH9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##odds model v2##"
      ],
      "metadata": {
        "id": "QmW7Su3SjODC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8mSB6ul2m1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_keys = [\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\"]\n",
        "curr_label = \"CP1_AVG\"\n",
        "# dataset_om = dataset.copy()\n",
        "# dataset_uv[\"undervalued\"] = get_max_diff(dataset_uv, False)\n",
        "# dataset_uv = dataset_uv.drop(label_keys, axis=1)\n",
        "dataset_om = get_small_OHE_dataset(dataset.copy())\n",
        "om_train, om_test = split_dataset(dataset_om, True)\n",
        "om_train = om_train.sample(frac=1)\n",
        "# uv_train, uv_test = split_dataset(uv_train, True)\n",
        "om_train_target = om_train[curr_label]\n",
        "om_test_target = om_test[curr_label]\n",
        "om_train_features = om_train.drop(columns=label_keys)\n",
        "om_test_features = om_test.drop(columns=label_keys)\n",
        "\n",
        "om_train_target = np.array(om_train_target).astype('float32')\n",
        "om_test_target = np.array(om_test_target).astype('float32')\n",
        "om_train_features = np.array(om_train_features).astype('float32')\n",
        "om_test_features = np.array(om_test_features).astype('float32')"
      ],
      "metadata": {
        "id": "bz_5F9mQjPyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_ZtrCL15R1IV",
        "outputId": "ebf44fa1-d99b-4108-dd58-3e90d143ad68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      home_wins  home_tie  home_loss  away_wins  away_tie  away_loss  games  \\\n",
              "317          16         9          6          7         7         17     31   \n",
              "2500          4         8          9          3         9         10     22   \n",
              "648           1         7         18         11         6          9     26   \n",
              "514           4         2          7          6         2          5     13   \n",
              "1815          9        12          8          8        10         11     29   \n",
              "2490          7         8          6          4         8          8     21   \n",
              "2255          6        12         17         11        13         11     35   \n",
              "1260          2         4          6          7         2          3     12   \n",
              "603           5         5         11         10         5          7     22   \n",
              "532           7         4          4          5         6          4     15   \n",
              "\n",
              "      OP1_AVG  OPX_AVG  OP2_AVG  ...  Malaga  Mallorca  Osasuna  \\\n",
              "317     1.501    4.012    7.007  ...       0         0        0   \n",
              "2500    1.814    3.401    4.592  ...       0         1        0   \n",
              "648     2.929    3.297    2.440  ...       0         0        1   \n",
              "514     2.367    3.316    2.995  ...       0         0        0   \n",
              "1815    2.140    3.227    3.585  ...       0         0        0   \n",
              "2490    1.476    4.288    6.648  ...       0         1        0   \n",
              "2255    2.594    3.137    2.824  ...       0         0        0   \n",
              "1260    2.152    3.159    3.657  ...       0         0        0   \n",
              "603     2.384    3.279    2.945  ...       0         0        0   \n",
              "532     1.225    6.154   13.234  ...       0         0        0   \n",
              "\n",
              "      Rayo Vallecano  Real Madrid  Real Sociedad  Sevilla  Valencia  \\\n",
              "317                0            0              0        0         0   \n",
              "2500               0            0              0        0         0   \n",
              "648                0            0              0        0         0   \n",
              "514                0            0              0        0         0   \n",
              "1815               0            0              0        0         0   \n",
              "2490               0            0              0        0         0   \n",
              "2255               0            0              0        0         0   \n",
              "1260               0            0              0        0         0   \n",
              "603                0            0              0        0         1   \n",
              "532                0            0              0        0         0   \n",
              "\n",
              "      Valladolid  Villarreal  \n",
              "317            0           1  \n",
              "2500           0           0  \n",
              "648            0           0  \n",
              "514            0           0  \n",
              "1815           0           0  \n",
              "2490           0           1  \n",
              "2255           0           0  \n",
              "1260           0           0  \n",
              "603            0           0  \n",
              "532            0           0  \n",
              "\n",
              "[10 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0c63e81-4067-4c5a-b7f8-bb01ba211f8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_wins</th>\n",
              "      <th>home_tie</th>\n",
              "      <th>home_loss</th>\n",
              "      <th>away_wins</th>\n",
              "      <th>away_tie</th>\n",
              "      <th>away_loss</th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>...</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>31</td>\n",
              "      <td>1.501</td>\n",
              "      <td>4.012</td>\n",
              "      <td>7.007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>22</td>\n",
              "      <td>1.814</td>\n",
              "      <td>3.401</td>\n",
              "      <td>4.592</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>2.929</td>\n",
              "      <td>3.297</td>\n",
              "      <td>2.440</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2.367</td>\n",
              "      <td>3.316</td>\n",
              "      <td>2.995</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1815</th>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>29</td>\n",
              "      <td>2.140</td>\n",
              "      <td>3.227</td>\n",
              "      <td>3.585</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2490</th>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>1.476</td>\n",
              "      <td>4.288</td>\n",
              "      <td>6.648</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2255</th>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>35</td>\n",
              "      <td>2.594</td>\n",
              "      <td>3.137</td>\n",
              "      <td>2.824</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2.152</td>\n",
              "      <td>3.159</td>\n",
              "      <td>3.657</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>2.384</td>\n",
              "      <td>3.279</td>\n",
              "      <td>2.945</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>1.225</td>\n",
              "      <td>6.154</td>\n",
              "      <td>13.234</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0c63e81-4067-4c5a-b7f8-bb01ba211f8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0c63e81-4067-4c5a-b7f8-bb01ba211f8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0c63e81-4067-4c5a-b7f8-bb01ba211f8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92852889-cb98-463b-bdc0-f697d7ec3879\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92852889-cb98-463b-bdc0-f697d7ec3879')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92852889-cb98-463b-bdc0-f697d7ec3879 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\",\n",
        "    min_delta=0,\n",
        "    patience=30,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(om_train_features)\n",
        "steps_per_epoch = len(om_train_features)/32\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "model_5 = tf.keras.Sequential([\n",
        "      normalizer,\n",
        "      layers.Dense(20, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(10, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_5.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "cgwKFLbYj62Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "om_train_features[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0eBzCYfUVA5q",
        "outputId": "2e23cf83-9b81-4784-b159-9457e9968b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16.   ,  9.   ,  6.   ,  7.   ,  7.   , 17.   , 31.   ,  1.501,\n",
              "         4.012,  7.007,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ],\n",
              "       [ 4.   ,  8.   ,  9.   ,  3.   ,  9.   , 10.   , 22.   ,  1.814,\n",
              "         3.401,  4.592,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
              "       [ 1.   ,  7.   , 18.   , 11.   ,  6.   ,  9.   , 26.   ,  2.929,\n",
              "         3.297,  2.44 ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
              "       [ 4.   ,  2.   ,  7.   ,  6.   ,  2.   ,  5.   , 13.   ,  2.367,\n",
              "         3.316,  2.995,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
              "         0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
              "       [ 9.   , 12.   ,  8.   ,  8.   , 10.   , 11.   , 29.   ,  2.14 ,\n",
              "         3.227,  3.585,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  1.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
              "       [ 7.   ,  8.   ,  6.   ,  4.   ,  8.   ,  8.   , 21.   ,  1.476,\n",
              "         4.288,  6.648,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ],\n",
              "       [ 6.   , 12.   , 17.   , 11.   , 13.   , 11.   , 35.   ,  2.594,\n",
              "         3.137,  2.824,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
              "       [ 2.   ,  4.   ,  6.   ,  7.   ,  2.   ,  3.   , 12.   ,  2.152,\n",
              "         3.159,  3.657,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
              "       [ 5.   ,  5.   , 11.   , 10.   ,  5.   ,  7.   , 22.   ,  2.384,\n",
              "         3.279,  2.945,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ],\n",
              "       [ 7.   ,  4.   ,  4.   ,  5.   ,  6.   ,  4.   , 15.   ,  1.225,\n",
              "         6.154, 13.234,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
              "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_5.fit(\n",
        "    om_train_features,\n",
        "    om_train_target,\n",
        "    epochs=500,\n",
        "    # callbacks=[early_stopping],\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split=0.2\n",
        "    # validation_data=(om_train_features[40:50], om_train_target[40:50])\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxuo0TPDlgoH",
        "outputId": "156bc6ca-c424-4190-aa69-f63319d651d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3772 - val_loss: 0.3316\n",
            "Epoch 2/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3369 - val_loss: 0.3400\n",
            "Epoch 3/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3957 - val_loss: 0.3344\n",
            "Epoch 4/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3567 - val_loss: 0.3300\n",
            "Epoch 5/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3625 - val_loss: 0.3402\n",
            "Epoch 6/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3742 - val_loss: 0.3382\n",
            "Epoch 7/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3858 - val_loss: 0.3393\n",
            "Epoch 8/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3583 - val_loss: 0.3297\n",
            "Epoch 9/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3462 - val_loss: 0.3329\n",
            "Epoch 10/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3474 - val_loss: 0.3368\n",
            "Epoch 11/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3811 - val_loss: 0.3308\n",
            "Epoch 12/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3688 - val_loss: 0.3308\n",
            "Epoch 13/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3644 - val_loss: 0.3301\n",
            "Epoch 14/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3588 - val_loss: 0.3318\n",
            "Epoch 15/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3493 - val_loss: 0.3282\n",
            "Epoch 16/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3621 - val_loss: 0.3357\n",
            "Epoch 17/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3756 - val_loss: 0.3379\n",
            "Epoch 18/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3752 - val_loss: 0.3330\n",
            "Epoch 19/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3785 - val_loss: 0.3320\n",
            "Epoch 20/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3683 - val_loss: 0.3311\n",
            "Epoch 21/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3330 - val_loss: 0.3304\n",
            "Epoch 22/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3667 - val_loss: 0.3271\n",
            "Epoch 23/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3878 - val_loss: 0.3306\n",
            "Epoch 24/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3864 - val_loss: 0.3311\n",
            "Epoch 25/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3992 - val_loss: 0.3305\n",
            "Epoch 26/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3359 - val_loss: 0.3412\n",
            "Epoch 27/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3973 - val_loss: 0.3306\n",
            "Epoch 28/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3644 - val_loss: 0.3437\n",
            "Epoch 29/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3500 - val_loss: 0.3313\n",
            "Epoch 30/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3954 - val_loss: 0.3307\n",
            "Epoch 31/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3699 - val_loss: 0.3302\n",
            "Epoch 32/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3760 - val_loss: 0.3326\n",
            "Epoch 33/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3641 - val_loss: 0.3299\n",
            "Epoch 34/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3603 - val_loss: 0.3310\n",
            "Epoch 35/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3606 - val_loss: 0.3374\n",
            "Epoch 36/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3553 - val_loss: 0.3398\n",
            "Epoch 37/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3441 - val_loss: 0.3302\n",
            "Epoch 38/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3813 - val_loss: 0.3311\n",
            "Epoch 39/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3559 - val_loss: 0.3337\n",
            "Epoch 40/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3724 - val_loss: 0.3291\n",
            "Epoch 41/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3829 - val_loss: 0.3330\n",
            "Epoch 42/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3526 - val_loss: 0.3320\n",
            "Epoch 43/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3878 - val_loss: 0.3285\n",
            "Epoch 44/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3728 - val_loss: 0.3311\n",
            "Epoch 45/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3305 - val_loss: 0.3283\n",
            "Epoch 46/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3608 - val_loss: 0.3259\n",
            "Epoch 47/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3430 - val_loss: 0.3269\n",
            "Epoch 48/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3790 - val_loss: 0.3299\n",
            "Epoch 49/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3598 - val_loss: 0.3277\n",
            "Epoch 50/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3639 - val_loss: 0.3298\n",
            "Epoch 51/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3719 - val_loss: 0.3309\n",
            "Epoch 52/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3753 - val_loss: 0.3317\n",
            "Epoch 53/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3607 - val_loss: 0.3323\n",
            "Epoch 54/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3453 - val_loss: 0.3345\n",
            "Epoch 55/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3795 - val_loss: 0.3291\n",
            "Epoch 56/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3546 - val_loss: 0.3334\n",
            "Epoch 57/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3531 - val_loss: 0.3282\n",
            "Epoch 58/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3592 - val_loss: 0.3290\n",
            "Epoch 59/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3583 - val_loss: 0.3291\n",
            "Epoch 60/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3848 - val_loss: 0.3328\n",
            "Epoch 61/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3795 - val_loss: 0.3328\n",
            "Epoch 62/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3671 - val_loss: 0.3281\n",
            "Epoch 63/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3394 - val_loss: 0.3300\n",
            "Epoch 64/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.3418 - val_loss: 0.3286\n",
            "Epoch 65/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3455 - val_loss: 0.3267\n",
            "Epoch 66/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3578 - val_loss: 0.3375\n",
            "Epoch 67/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3477 - val_loss: 0.3385\n",
            "Epoch 68/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3730 - val_loss: 0.3345\n",
            "Epoch 69/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3623 - val_loss: 0.3325\n",
            "Epoch 70/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3525 - val_loss: 0.3305\n",
            "Epoch 71/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4006 - val_loss: 0.3286\n",
            "Epoch 72/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3717 - val_loss: 0.3290\n",
            "Epoch 73/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3789 - val_loss: 0.3363\n",
            "Epoch 74/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3675 - val_loss: 0.3322\n",
            "Epoch 75/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3727 - val_loss: 0.3302\n",
            "Epoch 76/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3358 - val_loss: 0.3320\n",
            "Epoch 77/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3660 - val_loss: 0.3305\n",
            "Epoch 78/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3519 - val_loss: 0.3384\n",
            "Epoch 79/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3464 - val_loss: 0.3313\n",
            "Epoch 80/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3541 - val_loss: 0.3307\n",
            "Epoch 81/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3798 - val_loss: 0.3296\n",
            "Epoch 82/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3917 - val_loss: 0.3329\n",
            "Epoch 83/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4064 - val_loss: 0.3323\n",
            "Epoch 84/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3788 - val_loss: 0.3280\n",
            "Epoch 85/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3446 - val_loss: 0.3345\n",
            "Epoch 86/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3247 - val_loss: 0.3306\n",
            "Epoch 87/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3337 - val_loss: 0.3315\n",
            "Epoch 88/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3688 - val_loss: 0.3303\n",
            "Epoch 89/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3726 - val_loss: 0.3326\n",
            "Epoch 90/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3512 - val_loss: 0.3308\n",
            "Epoch 91/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3459 - val_loss: 0.3324\n",
            "Epoch 92/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3513 - val_loss: 0.3308\n",
            "Epoch 93/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3428 - val_loss: 0.3300\n",
            "Epoch 94/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3646 - val_loss: 0.3357\n",
            "Epoch 95/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3506 - val_loss: 0.3307\n",
            "Epoch 96/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3502 - val_loss: 0.3325\n",
            "Epoch 97/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3766 - val_loss: 0.3313\n",
            "Epoch 98/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3394 - val_loss: 0.3316\n",
            "Epoch 99/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3345 - val_loss: 0.3312\n",
            "Epoch 100/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3722 - val_loss: 0.3294\n",
            "Epoch 101/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3823 - val_loss: 0.3295\n",
            "Epoch 102/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3574 - val_loss: 0.3288\n",
            "Epoch 103/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3412 - val_loss: 0.3353\n",
            "Epoch 104/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3672 - val_loss: 0.3327\n",
            "Epoch 105/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3618 - val_loss: 0.3361\n",
            "Epoch 106/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3423 - val_loss: 0.3312\n",
            "Epoch 107/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3708 - val_loss: 0.3282\n",
            "Epoch 108/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3681 - val_loss: 0.3270\n",
            "Epoch 109/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3613 - val_loss: 0.3318\n",
            "Epoch 110/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3535 - val_loss: 0.3295\n",
            "Epoch 111/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3588 - val_loss: 0.3268\n",
            "Epoch 112/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3798 - val_loss: 0.3278\n",
            "Epoch 113/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3745 - val_loss: 0.3285\n",
            "Epoch 114/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3406 - val_loss: 0.3364\n",
            "Epoch 115/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3861 - val_loss: 0.3260\n",
            "Epoch 116/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3653 - val_loss: 0.3361\n",
            "Epoch 117/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3674 - val_loss: 0.3284\n",
            "Epoch 118/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3430 - val_loss: 0.3321\n",
            "Epoch 119/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3685 - val_loss: 0.3262\n",
            "Epoch 120/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3601 - val_loss: 0.3292\n",
            "Epoch 121/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3554 - val_loss: 0.3283\n",
            "Epoch 122/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3651 - val_loss: 0.3305\n",
            "Epoch 123/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3963 - val_loss: 0.3344\n",
            "Epoch 124/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3461 - val_loss: 0.3289\n",
            "Epoch 125/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3745 - val_loss: 0.3273\n",
            "Epoch 126/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3599 - val_loss: 0.3347\n",
            "Epoch 127/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3651 - val_loss: 0.3323\n",
            "Epoch 128/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3562 - val_loss: 0.3301\n",
            "Epoch 129/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3785 - val_loss: 0.3293\n",
            "Epoch 130/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3682 - val_loss: 0.3351\n",
            "Epoch 131/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3429 - val_loss: 0.3291\n",
            "Epoch 132/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3423 - val_loss: 0.3336\n",
            "Epoch 133/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3747 - val_loss: 0.3278\n",
            "Epoch 134/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3433 - val_loss: 0.3320\n",
            "Epoch 135/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3399 - val_loss: 0.3293\n",
            "Epoch 136/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3652 - val_loss: 0.3268\n",
            "Epoch 137/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3760 - val_loss: 0.3315\n",
            "Epoch 138/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3457 - val_loss: 0.3265\n",
            "Epoch 139/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3800 - val_loss: 0.3321\n",
            "Epoch 140/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3616 - val_loss: 0.3381\n",
            "Epoch 141/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3457 - val_loss: 0.3293\n",
            "Epoch 142/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3557 - val_loss: 0.3332\n",
            "Epoch 143/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3421 - val_loss: 0.3347\n",
            "Epoch 144/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3387 - val_loss: 0.3285\n",
            "Epoch 145/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3540 - val_loss: 0.3277\n",
            "Epoch 146/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3605 - val_loss: 0.3264\n",
            "Epoch 147/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3499 - val_loss: 0.3315\n",
            "Epoch 148/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3486 - val_loss: 0.3298\n",
            "Epoch 149/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3729 - val_loss: 0.3308\n",
            "Epoch 150/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3740 - val_loss: 0.3297\n",
            "Epoch 151/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3430 - val_loss: 0.3311\n",
            "Epoch 152/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3532 - val_loss: 0.3327\n",
            "Epoch 153/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3959 - val_loss: 0.3299\n",
            "Epoch 154/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3638 - val_loss: 0.3326\n",
            "Epoch 155/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3915 - val_loss: 0.3314\n",
            "Epoch 156/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3535 - val_loss: 0.3312\n",
            "Epoch 157/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3896 - val_loss: 0.3329\n",
            "Epoch 158/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3762 - val_loss: 0.3275\n",
            "Epoch 159/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3474 - val_loss: 0.3264\n",
            "Epoch 160/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3568 - val_loss: 0.3301\n",
            "Epoch 161/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3533 - val_loss: 0.3300\n",
            "Epoch 162/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3890 - val_loss: 0.3254\n",
            "Epoch 163/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3333 - val_loss: 0.3307\n",
            "Epoch 164/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3725 - val_loss: 0.3287\n",
            "Epoch 165/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3522 - val_loss: 0.3266\n",
            "Epoch 166/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3674 - val_loss: 0.3343\n",
            "Epoch 167/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3388 - val_loss: 0.3276\n",
            "Epoch 168/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3677 - val_loss: 0.3292\n",
            "Epoch 169/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3501 - val_loss: 0.3287\n",
            "Epoch 170/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3822 - val_loss: 0.3283\n",
            "Epoch 171/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3585 - val_loss: 0.3327\n",
            "Epoch 172/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3144 - val_loss: 0.3299\n",
            "Epoch 173/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3635 - val_loss: 0.3258\n",
            "Epoch 174/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3626 - val_loss: 0.3358\n",
            "Epoch 175/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3562 - val_loss: 0.3295\n",
            "Epoch 176/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3395 - val_loss: 0.3353\n",
            "Epoch 177/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3480 - val_loss: 0.3298\n",
            "Epoch 178/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3912 - val_loss: 0.3272\n",
            "Epoch 179/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3544 - val_loss: 0.3285\n",
            "Epoch 180/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3501 - val_loss: 0.3280\n",
            "Epoch 181/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3567 - val_loss: 0.3300\n",
            "Epoch 182/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3289 - val_loss: 0.3277\n",
            "Epoch 183/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3624 - val_loss: 0.3289\n",
            "Epoch 184/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3430 - val_loss: 0.3350\n",
            "Epoch 185/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3497 - val_loss: 0.3253\n",
            "Epoch 186/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3464 - val_loss: 0.3273\n",
            "Epoch 187/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3473 - val_loss: 0.3332\n",
            "Epoch 188/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3352 - val_loss: 0.3325\n",
            "Epoch 189/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3800 - val_loss: 0.3290\n",
            "Epoch 190/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3691 - val_loss: 0.3275\n",
            "Epoch 191/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3623 - val_loss: 0.3353\n",
            "Epoch 192/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3654 - val_loss: 0.3352\n",
            "Epoch 193/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3598 - val_loss: 0.3310\n",
            "Epoch 194/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3657 - val_loss: 0.3297\n",
            "Epoch 195/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3379 - val_loss: 0.3314\n",
            "Epoch 196/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3863 - val_loss: 0.3319\n",
            "Epoch 197/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3490 - val_loss: 0.3276\n",
            "Epoch 198/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3618 - val_loss: 0.3343\n",
            "Epoch 199/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3752 - val_loss: 0.3272\n",
            "Epoch 200/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3507 - val_loss: 0.3275\n",
            "Epoch 201/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3447 - val_loss: 0.3274\n",
            "Epoch 202/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3683 - val_loss: 0.3278\n",
            "Epoch 203/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3310 - val_loss: 0.3292\n",
            "Epoch 204/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3485 - val_loss: 0.3253\n",
            "Epoch 205/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3781 - val_loss: 0.3286\n",
            "Epoch 206/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3750 - val_loss: 0.3335\n",
            "Epoch 207/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3460 - val_loss: 0.3314\n",
            "Epoch 208/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3660 - val_loss: 0.3287\n",
            "Epoch 209/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3647 - val_loss: 0.3320\n",
            "Epoch 210/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3669 - val_loss: 0.3354\n",
            "Epoch 211/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3229 - val_loss: 0.3300\n",
            "Epoch 212/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3454 - val_loss: 0.3314\n",
            "Epoch 213/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3405 - val_loss: 0.3260\n",
            "Epoch 214/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3581 - val_loss: 0.3379\n",
            "Epoch 215/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Epoch 216/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3323 - val_loss: 0.3338\n",
            "Epoch 217/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3862 - val_loss: 0.3279\n",
            "Epoch 218/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3480 - val_loss: 0.3281\n",
            "Epoch 219/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3472 - val_loss: 0.3279\n",
            "Epoch 220/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3735 - val_loss: 0.3283\n",
            "Epoch 221/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3908 - val_loss: 0.3287\n",
            "Epoch 222/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3344 - val_loss: 0.3268\n",
            "Epoch 223/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3585 - val_loss: 0.3265\n",
            "Epoch 224/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3506 - val_loss: 0.3287\n",
            "Epoch 225/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3687 - val_loss: 0.3268\n",
            "Epoch 226/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3540 - val_loss: 0.3298\n",
            "Epoch 227/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3561 - val_loss: 0.3282\n",
            "Epoch 228/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3315 - val_loss: 0.3285\n",
            "Epoch 229/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3378 - val_loss: 0.3279\n",
            "Epoch 230/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3943 - val_loss: 0.3291\n",
            "Epoch 231/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3378 - val_loss: 0.3317\n",
            "Epoch 232/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3467 - val_loss: 0.3331\n",
            "Epoch 233/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3509 - val_loss: 0.3307\n",
            "Epoch 234/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3594 - val_loss: 0.3297\n",
            "Epoch 235/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3710 - val_loss: 0.3302\n",
            "Epoch 236/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3341 - val_loss: 0.3311\n",
            "Epoch 237/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3426 - val_loss: 0.3293\n",
            "Epoch 238/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3645 - val_loss: 0.3305\n",
            "Epoch 239/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3456 - val_loss: 0.3245\n",
            "Epoch 240/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3434 - val_loss: 0.3297\n",
            "Epoch 241/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3513 - val_loss: 0.3271\n",
            "Epoch 242/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3871 - val_loss: 0.3299\n",
            "Epoch 243/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3706 - val_loss: 0.3289\n",
            "Epoch 244/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3736 - val_loss: 0.3257\n",
            "Epoch 245/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3714 - val_loss: 0.3286\n",
            "Epoch 246/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3357 - val_loss: 0.3261\n",
            "Epoch 247/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3585 - val_loss: 0.3287\n",
            "Epoch 248/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3640 - val_loss: 0.3252\n",
            "Epoch 249/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3567 - val_loss: 0.3303\n",
            "Epoch 250/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3326 - val_loss: 0.3308\n",
            "Epoch 251/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3405 - val_loss: 0.3287\n",
            "Epoch 252/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3582 - val_loss: 0.3260\n",
            "Epoch 253/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3612 - val_loss: 0.3247\n",
            "Epoch 254/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3531 - val_loss: 0.3312\n",
            "Epoch 255/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3396 - val_loss: 0.3314\n",
            "Epoch 256/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3753 - val_loss: 0.3265\n",
            "Epoch 257/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3486 - val_loss: 0.3260\n",
            "Epoch 258/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3628 - val_loss: 0.3264\n",
            "Epoch 259/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3529 - val_loss: 0.3276\n",
            "Epoch 260/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3944 - val_loss: 0.3279\n",
            "Epoch 261/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3567 - val_loss: 0.3251\n",
            "Epoch 262/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3432 - val_loss: 0.3348\n",
            "Epoch 263/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3591 - val_loss: 0.3308\n",
            "Epoch 264/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3455 - val_loss: 0.3274\n",
            "Epoch 265/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3324 - val_loss: 0.3272\n",
            "Epoch 266/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3552 - val_loss: 0.3266\n",
            "Epoch 267/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3821 - val_loss: 0.3285\n",
            "Epoch 268/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3530 - val_loss: 0.3245\n",
            "Epoch 269/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3646 - val_loss: 0.3275\n",
            "Epoch 270/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3453 - val_loss: 0.3357\n",
            "Epoch 271/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3788 - val_loss: 0.3304\n",
            "Epoch 272/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3605 - val_loss: 0.3336\n",
            "Epoch 273/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3756 - val_loss: 0.3296\n",
            "Epoch 274/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3741 - val_loss: 0.3317\n",
            "Epoch 275/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3491 - val_loss: 0.3283\n",
            "Epoch 276/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3420 - val_loss: 0.3262\n",
            "Epoch 277/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3388 - val_loss: 0.3237\n",
            "Epoch 278/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3621 - val_loss: 0.3340\n",
            "Epoch 279/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3337 - val_loss: 0.3294\n",
            "Epoch 280/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3364 - val_loss: 0.3290\n",
            "Epoch 281/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3693 - val_loss: 0.3295\n",
            "Epoch 282/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3457 - val_loss: 0.3294\n",
            "Epoch 283/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3826 - val_loss: 0.3287\n",
            "Epoch 284/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3719 - val_loss: 0.3344\n",
            "Epoch 285/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3623 - val_loss: 0.3313\n",
            "Epoch 286/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3519 - val_loss: 0.3255\n",
            "Epoch 287/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3312 - val_loss: 0.3264\n",
            "Epoch 288/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3568 - val_loss: 0.3317\n",
            "Epoch 289/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3775 - val_loss: 0.3247\n",
            "Epoch 290/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3251 - val_loss: 0.3288\n",
            "Epoch 291/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3371 - val_loss: 0.3290\n",
            "Epoch 292/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3457 - val_loss: 0.3316\n",
            "Epoch 293/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3362 - val_loss: 0.3308\n",
            "Epoch 294/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3592 - val_loss: 0.3239\n",
            "Epoch 295/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3718 - val_loss: 0.3291\n",
            "Epoch 296/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3421 - val_loss: 0.3289\n",
            "Epoch 297/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3640 - val_loss: 0.3294\n",
            "Epoch 298/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3611 - val_loss: 0.3291\n",
            "Epoch 299/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3573 - val_loss: 0.3286\n",
            "Epoch 300/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3593 - val_loss: 0.3313\n",
            "Epoch 301/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3556 - val_loss: 0.3310\n",
            "Epoch 302/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3782 - val_loss: 0.3383\n",
            "Epoch 303/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3597 - val_loss: 0.3289\n",
            "Epoch 304/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3668 - val_loss: 0.3358\n",
            "Epoch 305/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3537 - val_loss: 0.3298\n",
            "Epoch 306/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3480 - val_loss: 0.3304\n",
            "Epoch 307/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3484 - val_loss: 0.3313\n",
            "Epoch 308/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3173 - val_loss: 0.3291\n",
            "Epoch 309/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3519 - val_loss: 0.3304\n",
            "Epoch 310/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3575 - val_loss: 0.3309\n",
            "Epoch 311/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3493 - val_loss: 0.3284\n",
            "Epoch 312/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3674 - val_loss: 0.3257\n",
            "Epoch 313/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3725 - val_loss: 0.3327\n",
            "Epoch 314/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3512 - val_loss: 0.3255\n",
            "Epoch 315/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3844 - val_loss: 0.3299\n",
            "Epoch 316/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3585 - val_loss: 0.3259\n",
            "Epoch 317/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3421 - val_loss: 0.3262\n",
            "Epoch 318/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3704 - val_loss: 0.3291\n",
            "Epoch 319/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3335 - val_loss: 0.3250\n",
            "Epoch 320/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4003 - val_loss: 0.3282\n",
            "Epoch 321/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3467 - val_loss: 0.3258\n",
            "Epoch 322/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3980 - val_loss: 0.3266\n",
            "Epoch 323/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3667 - val_loss: 0.3336\n",
            "Epoch 324/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3677 - val_loss: 0.3322\n",
            "Epoch 325/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3737 - val_loss: 0.3261\n",
            "Epoch 326/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3454 - val_loss: 0.3250\n",
            "Epoch 327/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3723 - val_loss: 0.3310\n",
            "Epoch 328/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3244 - val_loss: 0.3260\n",
            "Epoch 329/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3426 - val_loss: 0.3246\n",
            "Epoch 330/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3456 - val_loss: 0.3247\n",
            "Epoch 331/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3615 - val_loss: 0.3279\n",
            "Epoch 332/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3491 - val_loss: 0.3268\n",
            "Epoch 333/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3305 - val_loss: 0.3310\n",
            "Epoch 334/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3611 - val_loss: 0.3260\n",
            "Epoch 335/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3750 - val_loss: 0.3284\n",
            "Epoch 336/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3432 - val_loss: 0.3310\n",
            "Epoch 337/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3447 - val_loss: 0.3245\n",
            "Epoch 338/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3622 - val_loss: 0.3267\n",
            "Epoch 339/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3608 - val_loss: 0.3275\n",
            "Epoch 340/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3494 - val_loss: 0.3287\n",
            "Epoch 341/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3443 - val_loss: 0.3305\n",
            "Epoch 342/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3678 - val_loss: 0.3306\n",
            "Epoch 343/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3530 - val_loss: 0.3338\n",
            "Epoch 344/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3502 - val_loss: 0.3306\n",
            "Epoch 345/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3431 - val_loss: 0.3350\n",
            "Epoch 346/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3423 - val_loss: 0.3327\n",
            "Epoch 347/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3626 - val_loss: 0.3306\n",
            "Epoch 348/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3323 - val_loss: 0.3334\n",
            "Epoch 349/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3309 - val_loss: 0.3286\n",
            "Epoch 350/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3379 - val_loss: 0.3290\n",
            "Epoch 351/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3493 - val_loss: 0.3275\n",
            "Epoch 352/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3828 - val_loss: 0.3289\n",
            "Epoch 353/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3423 - val_loss: 0.3272\n",
            "Epoch 354/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3355 - val_loss: 0.3264\n",
            "Epoch 355/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3399 - val_loss: 0.3273\n",
            "Epoch 356/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3603 - val_loss: 0.3325\n",
            "Epoch 357/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3484 - val_loss: 0.3371\n",
            "Epoch 358/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3464 - val_loss: 0.3373\n",
            "Epoch 359/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3386 - val_loss: 0.3279\n",
            "Epoch 360/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3421 - val_loss: 0.3291\n",
            "Epoch 361/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3655 - val_loss: 0.3271\n",
            "Epoch 362/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3774 - val_loss: 0.3311\n",
            "Epoch 363/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3450 - val_loss: 0.3354\n",
            "Epoch 364/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3368 - val_loss: 0.3295\n",
            "Epoch 365/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3815 - val_loss: 0.3250\n",
            "Epoch 366/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3434 - val_loss: 0.3267\n",
            "Epoch 367/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3453 - val_loss: 0.3262\n",
            "Epoch 368/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4001 - val_loss: 0.3314\n",
            "Epoch 369/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3394 - val_loss: 0.3251\n",
            "Epoch 370/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3476 - val_loss: 0.3262\n",
            "Epoch 371/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3732 - val_loss: 0.3240\n",
            "Epoch 372/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3783 - val_loss: 0.3301\n",
            "Epoch 373/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3591 - val_loss: 0.3276\n",
            "Epoch 374/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3661 - val_loss: 0.3277\n",
            "Epoch 375/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3675 - val_loss: 0.3268\n",
            "Epoch 376/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3882 - val_loss: 0.3351\n",
            "Epoch 377/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3544 - val_loss: 0.3285\n",
            "Epoch 378/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3303 - val_loss: 0.3269\n",
            "Epoch 379/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3609 - val_loss: 0.3299\n",
            "Epoch 380/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3617 - val_loss: 0.3307\n",
            "Epoch 381/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3293 - val_loss: 0.3363\n",
            "Epoch 382/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3226 - val_loss: 0.3252\n",
            "Epoch 383/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3702 - val_loss: 0.3303\n",
            "Epoch 384/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3416 - val_loss: 0.3279\n",
            "Epoch 385/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3446 - val_loss: 0.3248\n",
            "Epoch 386/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3671 - val_loss: 0.3282\n",
            "Epoch 387/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3330 - val_loss: 0.3279\n",
            "Epoch 388/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3731 - val_loss: 0.3299\n",
            "Epoch 389/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3702 - val_loss: 0.3278\n",
            "Epoch 390/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3408 - val_loss: 0.3300\n",
            "Epoch 391/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3864 - val_loss: 0.3282\n",
            "Epoch 392/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3482 - val_loss: 0.3283\n",
            "Epoch 393/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3451 - val_loss: 0.3307\n",
            "Epoch 394/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3289 - val_loss: 0.3277\n",
            "Epoch 395/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3503 - val_loss: 0.3278\n",
            "Epoch 396/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3378 - val_loss: 0.3258\n",
            "Epoch 397/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3334 - val_loss: 0.3295\n",
            "Epoch 398/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3654 - val_loss: 0.3292\n",
            "Epoch 399/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3826 - val_loss: 0.3271\n",
            "Epoch 400/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3620 - val_loss: 0.3279\n",
            "Epoch 401/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3675 - val_loss: 0.3281\n",
            "Epoch 402/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3617 - val_loss: 0.3277\n",
            "Epoch 403/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3366 - val_loss: 0.3274\n",
            "Epoch 404/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3330 - val_loss: 0.3297\n",
            "Epoch 405/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3375 - val_loss: 0.3269\n",
            "Epoch 406/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3503 - val_loss: 0.3301\n",
            "Epoch 407/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4002 - val_loss: 0.3328\n",
            "Epoch 408/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3365 - val_loss: 0.3295\n",
            "Epoch 409/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3702 - val_loss: 0.3263\n",
            "Epoch 410/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3326 - val_loss: 0.3275\n",
            "Epoch 411/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3620 - val_loss: 0.3294\n",
            "Epoch 412/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3344 - val_loss: 0.3309\n",
            "Epoch 413/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3429 - val_loss: 0.3318\n",
            "Epoch 414/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3603 - val_loss: 0.3269\n",
            "Epoch 415/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3731 - val_loss: 0.3288\n",
            "Epoch 416/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3339 - val_loss: 0.3339\n",
            "Epoch 417/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3588 - val_loss: 0.3318\n",
            "Epoch 418/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3586 - val_loss: 0.3306\n",
            "Epoch 419/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3574 - val_loss: 0.3310\n",
            "Epoch 420/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3626 - val_loss: 0.3262\n",
            "Epoch 421/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3428 - val_loss: 0.3268\n",
            "Epoch 422/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3121 - val_loss: 0.3241\n",
            "Epoch 423/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3605 - val_loss: 0.3269\n",
            "Epoch 424/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3508 - val_loss: 0.3262\n",
            "Epoch 425/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3492 - val_loss: 0.3338\n",
            "Epoch 426/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3282 - val_loss: 0.3317\n",
            "Epoch 427/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3333 - val_loss: 0.3253\n",
            "Epoch 428/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3665 - val_loss: 0.3317\n",
            "Epoch 429/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3549 - val_loss: 0.3277\n",
            "Epoch 430/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3621 - val_loss: 0.3258\n",
            "Epoch 431/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3748 - val_loss: 0.3319\n",
            "Epoch 432/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3408 - val_loss: 0.3278\n",
            "Epoch 433/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3291 - val_loss: 0.3273\n",
            "Epoch 434/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3477 - val_loss: 0.3343\n",
            "Epoch 435/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3681 - val_loss: 0.3258\n",
            "Epoch 436/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3243 - val_loss: 0.3257\n",
            "Epoch 437/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3256 - val_loss: 0.3271\n",
            "Epoch 438/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3244 - val_loss: 0.3273\n",
            "Epoch 439/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3633 - val_loss: 0.3279\n",
            "Epoch 440/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3301 - val_loss: 0.3237\n",
            "Epoch 441/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3350 - val_loss: 0.3312\n",
            "Epoch 442/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3574 - val_loss: 0.3257\n",
            "Epoch 443/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3739 - val_loss: 0.3300\n",
            "Epoch 444/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3435 - val_loss: 0.3243\n",
            "Epoch 445/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3711 - val_loss: 0.3262\n",
            "Epoch 446/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3453 - val_loss: 0.3271\n",
            "Epoch 447/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3685 - val_loss: 0.3314\n",
            "Epoch 448/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3139 - val_loss: 0.3255\n",
            "Epoch 449/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3830 - val_loss: 0.3284\n",
            "Epoch 450/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3666 - val_loss: 0.3259\n",
            "Epoch 451/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3345 - val_loss: 0.3255\n",
            "Epoch 452/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4011 - val_loss: 0.3349\n",
            "Epoch 453/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3925 - val_loss: 0.3296\n",
            "Epoch 454/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3500 - val_loss: 0.3288\n",
            "Epoch 455/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3331 - val_loss: 0.3302\n",
            "Epoch 456/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3342 - val_loss: 0.3319\n",
            "Epoch 457/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3610 - val_loss: 0.3340\n",
            "Epoch 458/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3240 - val_loss: 0.3317\n",
            "Epoch 459/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3422 - val_loss: 0.3255\n",
            "Epoch 460/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3356 - val_loss: 0.3276\n",
            "Epoch 461/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3539 - val_loss: 0.3231\n",
            "Epoch 462/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3365 - val_loss: 0.3262\n",
            "Epoch 463/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3547 - val_loss: 0.3291\n",
            "Epoch 464/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3457 - val_loss: 0.3287\n",
            "Epoch 465/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3425 - val_loss: 0.3256\n",
            "Epoch 466/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3801 - val_loss: 0.3250\n",
            "Epoch 467/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3322 - val_loss: 0.3293\n",
            "Epoch 468/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3449 - val_loss: 0.3307\n",
            "Epoch 469/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3272 - val_loss: 0.3335\n",
            "Epoch 470/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3387 - val_loss: 0.3256\n",
            "Epoch 471/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3325 - val_loss: 0.3278\n",
            "Epoch 472/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3250 - val_loss: 0.3344\n",
            "Epoch 473/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3847 - val_loss: 0.3299\n",
            "Epoch 474/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3512 - val_loss: 0.3300\n",
            "Epoch 475/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3442 - val_loss: 0.3294\n",
            "Epoch 476/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3303 - val_loss: 0.3295\n",
            "Epoch 477/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3684 - val_loss: 0.3281\n",
            "Epoch 478/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3516 - val_loss: 0.3308\n",
            "Epoch 479/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3589 - val_loss: 0.3277\n",
            "Epoch 480/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3476 - val_loss: 0.3252\n",
            "Epoch 481/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3493 - val_loss: 0.3271\n",
            "Epoch 482/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3489 - val_loss: 0.3293\n",
            "Epoch 483/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3550 - val_loss: 0.3286\n",
            "Epoch 484/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3332 - val_loss: 0.3250\n",
            "Epoch 485/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3243 - val_loss: 0.3282\n",
            "Epoch 486/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3383 - val_loss: 0.3271\n",
            "Epoch 487/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3407 - val_loss: 0.3261\n",
            "Epoch 488/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3316 - val_loss: 0.3266\n",
            "Epoch 489/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3412 - val_loss: 0.3304\n",
            "Epoch 490/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3495 - val_loss: 0.3283\n",
            "Epoch 491/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3743 - val_loss: 0.3303\n",
            "Epoch 492/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3308 - val_loss: 0.3291\n",
            "Epoch 493/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3714 - val_loss: 0.3292\n",
            "Epoch 494/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3506 - val_loss: 0.3382\n",
            "Epoch 495/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3528 - val_loss: 0.3290\n",
            "Epoch 496/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3727 - val_loss: 0.3282\n",
            "Epoch 497/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3569 - val_loss: 0.3295\n",
            "Epoch 498/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3441 - val_loss: 0.3319\n",
            "Epoch 499/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3609 - val_loss: 0.3285\n",
            "Epoch 500/500\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3264 - val_loss: 0.3296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions(predictions, features, target):\n",
        "  op1x2 = features[[\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\"]]\n",
        "  op1x2 = np.array(op1x2).astype('float32')\n",
        "  direction_right = 0\n",
        "  for prediction, cp1x2_val, op1x2_val in zip(predictions, target, op1x2):\n",
        "    print(f\"OP1X2: {op1x2_val} CP1X2: {cp1x2_val} pred: {prediction}\")\n",
        "    real_diffs = get_diffs(op1x2_val, cp1x2_val)\n",
        "    pred_diffs = get_diffs(op1x2_val, prediction)\n",
        "    real_lowest = min_diff(real_diffs)\n",
        "    pred_lowest = min_diff(pred_diffs)\n",
        "    print(f\"real_diffs: {real_diffs}, pred_diffs: {pred_diffs}\")\n",
        "    print(f\"real low: {real_lowest}, pred_low: {pred_lowest}\")\n",
        "    if real_lowest == pred_lowest:\n",
        "      direction_right += 1\n",
        "\n",
        "  print(f\"correct_dir: {direction_right/num}\")\n",
        "\n",
        "def compare_predictions_single(predictions, comp_data, target):\n",
        "  op1x2 = np.array(comp_data).astype('float32')\n",
        "  for prediction, cp1x2_val, op1x2_val in zip(predictions, target, op1x2):\n",
        "    print(f\"OP1X2: {op1x2_val} CP1X2: {cp1x2_val} pred: {prediction}\")\n"
      ],
      "metadata": {
        "id": "WcNOL5konaS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_label = \"OP1_AVG\"\n",
        "target = om_test_target\n",
        "num = len(target)\n",
        "target = target[:num]\n",
        "features = om_test_features[:num]\n",
        "comp_data = om_test[comp_label][:num]\n",
        "\n",
        "predictions = model_5.predict(features)\n",
        "# compare_predictions_single(predictions, comp_data, target)\n",
        "get_mse(predictions, comp_data, target, om_test.iloc[:num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZthZvtMlKBs",
        "outputId": "34eefe8b-b922-4c13-f81f-e0708acf0661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "2660    0\n",
            "2661    0\n",
            "2662    0\n",
            "2663    0\n",
            "2664    0\n",
            "       ..\n",
            "3415    0\n",
            "3416    0\n",
            "3417    0\n",
            "3418    0\n",
            "3419    0\n",
            "Name: Almeria, Length: 760, dtype: int64\n",
            "OP1X2: 3.307 CP1X2: 3.187 pred: 3.246, error 0.059\n",
            "OP1X2: 3.737 CP1X2: 3.484 pred: 3.853, error 0.369\n",
            "OP1X2: 1.214 CP1X2: 1.217 pred: 1.265, error 0.048\n",
            "OP1X2: 2.037 CP1X2: 1.767 pred: 2.040, error 0.273\n",
            "OP1X2: 3.066 CP1X2: 3.771 pred: 3.222, error 0.549\n",
            "OP1X2: 1.692 CP1X2: 1.900 pred: 1.607, error 0.293\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 7.987 CP1X2: 7.050 pred: 1579810.625, error 1579803.625\n",
            "OP1X2: 1.604 CP1X2: 1.570 pred: 1.537, error 0.033\n",
            "OP1X2: 4.707 CP1X2: 5.557 pred: 4.745, error 0.812\n",
            "OP1X2: 1.484 CP1X2: 1.579 pred: 1.488, error 0.091\n",
            "OP1X2: 2.362 CP1X2: 2.591 pred: 2.329, error 0.262\n",
            "OP1X2: 1.560 CP1X2: 1.534 pred: 1.527, error 0.007\n",
            "OP1X2: 3.899 CP1X2: 5.077 pred: 3.855, error 1.222\n",
            "OP1X2: 2.280 CP1X2: 1.921 pred: 2.411, error 0.490\n",
            "OP1X2: 2.895 CP1X2: 3.245 pred: 2.674, error 0.571\n",
            "OP1X2: 1.634 CP1X2: 1.689 pred: 1.624, error 0.065\n",
            "OP1X2: 1.869 CP1X2: 1.915 pred: 1.853, error 0.062\n",
            "OP1X2: 2.918 CP1X2: 3.617 pred: 2.910, error 0.707\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.240 CP1X2: 2.379 pred: 1579805.625, error 1579803.250\n",
            "OP1X2: 2.740 CP1X2: 2.364 pred: 2.665, error 0.301\n",
            "OP1X2: 3.042 CP1X2: 2.801 pred: 3.017, error 0.216\n",
            "OP1X2: 1.727 CP1X2: 1.845 pred: 1.630, error 0.215\n",
            "OP1X2: 4.470 CP1X2: 3.830 pred: 4.834, error 1.004\n",
            "OP1X2: 2.180 CP1X2: 2.042 pred: 2.134, error 0.092\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 4.029 CP1X2: 3.510 pred: 1579807.000, error 1579803.500\n",
            "OP1X2: 5.064 CP1X2: 6.293 pred: 5.133, error 1.160\n",
            "OP1X2: 3.350 CP1X2: 5.107 pred: 3.321, error 1.786\n",
            "OP1X2: 1.206 CP1X2: 1.138 pred: 1.261, error 0.123\n",
            "OP1X2: 3.361 CP1X2: 3.977 pred: 3.718, error 0.259\n",
            "OP1X2: 4.032 CP1X2: 4.239 pred: 4.136, error 0.103\n",
            "OP1X2: 1.754 CP1X2: 1.628 pred: 1.719, error 0.091\n",
            "OP1X2: 2.094 CP1X2: 2.157 pred: 1.951, error 0.206\n",
            "OP1X2: 1.511 CP1X2: 1.372 pred: 1.503, error 0.131\n",
            "OP1X2: 2.811 CP1X2: 2.941 pred: 2.863, error 0.078\n",
            "OP1X2: 3.533 CP1X2: 4.879 pred: 3.321, error 1.558\n",
            "OP1X2: 2.090 CP1X2: 2.116 pred: 2.077, error 0.039\n",
            "OP1X2: 1.493 CP1X2: 1.510 pred: 1.519, error 0.009\n",
            "OP1X2: 1.392 CP1X2: 1.386 pred: 1.433, error 0.047\n",
            "OP1X2: 2.134 CP1X2: 1.937 pred: 2.143, error 0.206\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.121 CP1X2: 2.280 pred: 1579805.375, error 1579803.125\n",
            "OP1X2: 2.188 CP1X2: 2.075 pred: 2.110, error 0.035\n",
            "OP1X2: 2.365 CP1X2: 2.737 pred: 2.283, error 0.454\n",
            "OP1X2: 3.367 CP1X2: 2.559 pred: 3.286, error 0.727\n",
            "OP1X2: 7.923 CP1X2: 9.390 pred: 8.421, error 0.969\n",
            "OP1X2: 1.560 CP1X2: 1.846 pred: 1.555, error 0.291\n",
            "OP1X2: 1.265 CP1X2: 1.296 pred: 1.243, error 0.053\n",
            "OP1X2: 3.943 CP1X2: 4.674 pred: 4.330, error 0.344\n",
            "OP1X2: 3.738 CP1X2: 4.373 pred: 3.692, error 0.681\n",
            "OP1X2: 2.596 CP1X2: 2.973 pred: 2.538, error 0.435\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.562 CP1X2: 2.978 pred: 1579805.875, error 1579802.875\n",
            "OP1X2: 2.117 CP1X2: 2.040 pred: 2.287, error 0.247\n",
            "OP1X2: 1.145 CP1X2: 1.077 pred: 1.186, error 0.109\n",
            "OP1X2: 2.393 CP1X2: 2.343 pred: 2.382, error 0.039\n",
            "OP1X2: 1.554 CP1X2: 1.619 pred: 1.555, error 0.064\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.188 CP1X2: 1.955 pred: 1579805.000, error 1579803.000\n",
            "OP1X2: 1.914 CP1X2: 1.693 pred: 1.872, error 0.179\n",
            "OP1X2: 1.882 CP1X2: 1.752 pred: 1.796, error 0.044\n",
            "OP1X2: 1.579 CP1X2: 1.720 pred: 1.588, error 0.132\n",
            "OP1X2: 1.581 CP1X2: 1.724 pred: 1.534, error 0.190\n",
            "OP1X2: 2.646 CP1X2: 3.156 pred: 2.685, error 0.471\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.491 CP1X2: 1.371 pred: 1579804.625, error 1579803.250\n",
            "OP1X2: 7.597 CP1X2: 9.242 pred: 7.387, error 1.855\n",
            "OP1X2: 2.230 CP1X2: 2.415 pred: 2.332, error 0.083\n",
            "OP1X2: 5.063 CP1X2: 5.015 pred: 5.373, error 0.358\n",
            "OP1X2: 3.164 CP1X2: 3.293 pred: 3.157, error 0.136\n",
            "OP1X2: 2.499 CP1X2: 2.827 pred: 2.550, error 0.277\n",
            "OP1X2: 2.330 CP1X2: 2.418 pred: 2.233, error 0.185\n",
            "OP1X2: 3.772 CP1X2: 3.348 pred: 3.702, error 0.354\n",
            "OP1X2: 1.336 CP1X2: 1.365 pred: 1.332, error 0.033\n",
            "OP1X2: 1.804 CP1X2: 1.550 pred: 1.814, error 0.264\n",
            "OP1X2: 2.215 CP1X2: 2.532 pred: 2.156, error 0.376\n",
            "OP1X2: 6.207 CP1X2: 7.163 pred: 6.244, error 0.919\n",
            "OP1X2: 1.446 CP1X2: 1.414 pred: 1.441, error 0.027\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.595 CP1X2: 3.132 pred: 1579805.875, error 1579802.750\n",
            "OP1X2: 2.577 CP1X2: 3.359 pred: 2.598, error 0.761\n",
            "OP1X2: 3.255 CP1X2: 2.927 pred: 3.513, error 0.586\n",
            "OP1X2: 2.675 CP1X2: 2.929 pred: 2.829, error 0.100\n",
            "OP1X2: 2.544 CP1X2: 2.650 pred: 2.587, error 0.063\n",
            "OP1X2: 1.271 CP1X2: 1.288 pred: 1.320, error 0.032\n",
            "OP1X2: 2.715 CP1X2: 2.995 pred: 2.749, error 0.246\n",
            "OP1X2: 2.024 CP1X2: 1.946 pred: 2.083, error 0.137\n",
            "OP1X2: 1.950 CP1X2: 1.940 pred: 1.872, error 0.068\n",
            "OP1X2: 1.524 CP1X2: 1.433 pred: 1.537, error 0.104\n",
            "OP1X2: 2.738 CP1X2: 3.128 pred: 2.553, error 0.575\n",
            "OP1X2: 2.539 CP1X2: 2.351 pred: 2.644, error 0.293\n",
            "OP1X2: 2.476 CP1X2: 2.446 pred: 2.464, error 0.018\n",
            "OP1X2: 2.356 CP1X2: 2.287 pred: 2.248, error 0.039\n",
            "OP1X2: 2.040 CP1X2: 2.027 pred: 2.044, error 0.017\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.530 CP1X2: 1.562 pred: 1579804.625, error 1579803.125\n",
            "OP1X2: 1.575 CP1X2: 1.769 pred: 1.530, error 0.239\n",
            "OP1X2: 3.944 CP1X2: 4.910 pred: 4.096, error 0.814\n",
            "OP1X2: 1.500 CP1X2: 1.591 pred: 1.531, error 0.060\n",
            "OP1X2: 2.196 CP1X2: 2.292 pred: 2.140, error 0.152\n",
            "OP1X2: 2.611 CP1X2: 3.186 pred: 2.800, error 0.386\n",
            "OP1X2: 3.305 CP1X2: 3.578 pred: 3.475, error 0.103\n",
            "OP1X2: 1.543 CP1X2: 1.551 pred: 1.508, error 0.043\n",
            "OP1X2: 8.445 CP1X2: 11.035 pred: 9.113, error 1.922\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.419 CP1X2: 2.690 pred: 1579805.500, error 1579802.750\n",
            "OP1X2: 2.012 CP1X2: 2.241 pred: 1.965, error 0.276\n",
            "OP1X2: 1.471 CP1X2: 1.465 pred: 1.492, error 0.027\n",
            "OP1X2: 1.705 CP1X2: 1.733 pred: 1.642, error 0.091\n",
            "OP1X2: 3.448 CP1X2: 4.091 pred: 3.723, error 0.368\n",
            "OP1X2: 1.788 CP1X2: 1.771 pred: 1.677, error 0.094\n",
            "OP1X2: 1.427 CP1X2: 1.381 pred: 1.448, error 0.067\n",
            "OP1X2: 2.570 CP1X2: 2.484 pred: 2.381, error 0.103\n",
            "OP1X2: 1.472 CP1X2: 1.444 pred: 1.504, error 0.060\n",
            "OP1X2: 3.040 CP1X2: 3.222 pred: 3.079, error 0.143\n",
            "OP1X2: 1.777 CP1X2: 1.637 pred: 1.759, error 0.122\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.321 CP1X2: 1.376 pred: 1579804.000, error 1579802.625\n",
            "OP1X2: 1.753 CP1X2: 1.694 pred: 1.789, error 0.095\n",
            "OP1X2: 2.308 CP1X2: 2.422 pred: 2.269, error 0.153\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.324 CP1X2: 3.093 pred: 1579806.625, error 1579803.500\n",
            "OP1X2: 4.877 CP1X2: 6.348 pred: 5.271, error 1.077\n",
            "OP1X2: 1.854 CP1X2: 2.037 pred: 1.789, error 0.248\n",
            "OP1X2: 4.796 CP1X2: 5.747 pred: 4.830, error 0.917\n",
            "OP1X2: 2.005 CP1X2: 1.850 pred: 1.968, error 0.118\n",
            "OP1X2: 1.229 CP1X2: 1.261 pred: 1.253, error 0.008\n",
            "OP1X2: 2.023 CP1X2: 2.118 pred: 2.038, error 0.080\n",
            "OP1X2: 1.917 CP1X2: 2.064 pred: 1.933, error 0.131\n",
            "OP1X2: 2.762 CP1X2: 2.725 pred: 2.889, error 0.164\n",
            "OP1X2: 3.659 CP1X2: 3.680 pred: 3.666, error 0.014\n",
            "OP1X2: 2.026 CP1X2: 2.250 pred: 1.987, error 0.263\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.132 CP1X2: 1.114 pred: 1579803.000, error 1579801.875\n",
            "OP1X2: 2.052 CP1X2: 2.157 pred: 2.106, error 0.051\n",
            "OP1X2: 1.777 CP1X2: 1.909 pred: 1.748, error 0.161\n",
            "OP1X2: 1.479 CP1X2: 1.522 pred: 1.518, error 0.004\n",
            "OP1X2: 1.843 CP1X2: 1.939 pred: 1.825, error 0.114\n",
            "OP1X2: 1.558 CP1X2: 1.762 pred: 1.507, error 0.255\n",
            "OP1X2: 2.155 CP1X2: 2.103 pred: 2.133, error 0.030\n",
            "OP1X2: 4.933 CP1X2: 4.857 pred: 4.824, error 0.033\n",
            "OP1X2: 2.757 CP1X2: 3.542 pred: 2.831, error 0.711\n",
            "OP1X2: 1.402 CP1X2: 1.426 pred: 1.449, error 0.023\n",
            "OP1X2: 5.596 CP1X2: 6.057 pred: 5.778, error 0.279\n",
            "OP1X2: 4.054 CP1X2: 3.902 pred: 3.860, error 0.042\n",
            "OP1X2: 2.548 CP1X2: 2.490 pred: 2.410, error 0.080\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.336 CP1X2: 2.057 pred: 1579805.500, error 1579803.500\n",
            "OP1X2: 3.535 CP1X2: 2.735 pred: 3.569, error 0.834\n",
            "OP1X2: 2.317 CP1X2: 2.083 pred: 2.245, error 0.162\n",
            "OP1X2: 2.314 CP1X2: 2.178 pred: 2.309, error 0.131\n",
            "OP1X2: 1.170 CP1X2: 1.207 pred: 1.198, error 0.009\n",
            "OP1X2: 2.441 CP1X2: 2.096 pred: 2.319, error 0.223\n",
            "OP1X2: 2.532 CP1X2: 2.994 pred: 2.604, error 0.390\n",
            "OP1X2: 1.238 CP1X2: 1.249 pred: 1.322, error 0.073\n",
            "OP1X2: 2.514 CP1X2: 2.856 pred: 2.410, error 0.446\n",
            "OP1X2: 6.018 CP1X2: 6.777 pred: 6.326, error 0.451\n",
            "OP1X2: 2.413 CP1X2: 2.261 pred: 2.392, error 0.131\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.357 CP1X2: 2.173 pred: 1579805.500, error 1579803.375\n",
            "OP1X2: 1.788 CP1X2: 1.911 pred: 1.765, error 0.146\n",
            "OP1X2: 1.229 CP1X2: 1.197 pred: 1.309, error 0.112\n",
            "OP1X2: 1.841 CP1X2: 2.044 pred: 1.797, error 0.247\n",
            "OP1X2: 3.646 CP1X2: 3.951 pred: 4.080, error 0.129\n",
            "OP1X2: 1.551 CP1X2: 1.560 pred: 1.527, error 0.033\n",
            "OP1X2: 3.036 CP1X2: 3.463 pred: 3.056, error 0.407\n",
            "OP1X2: 2.019 CP1X2: 2.032 pred: 1.870, error 0.162\n",
            "OP1X2: 2.082 CP1X2: 2.603 pred: 2.015, error 0.588\n",
            "OP1X2: 3.196 CP1X2: 3.193 pred: 3.167, error 0.026\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.870 CP1X2: 4.278 pred: 1579807.250, error 1579803.000\n",
            "OP1X2: 2.374 CP1X2: 2.453 pred: 2.345, error 0.108\n",
            "OP1X2: 1.716 CP1X2: 1.845 pred: 1.667, error 0.178\n",
            "OP1X2: 1.729 CP1X2: 1.583 pred: 1.685, error 0.102\n",
            "OP1X2: 2.666 CP1X2: 2.860 pred: 2.698, error 0.162\n",
            "OP1X2: 2.533 CP1X2: 2.820 pred: 2.664, error 0.156\n",
            "OP1X2: 2.402 CP1X2: 2.400 pred: 2.260, error 0.140\n",
            "OP1X2: 2.036 CP1X2: 2.193 pred: 1.905, error 0.288\n",
            "OP1X2: 2.535 CP1X2: 2.327 pred: 2.662, error 0.335\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 4.593 CP1X2: 4.892 pred: 1579807.875, error 1579803.000\n",
            "OP1X2: 2.526 CP1X2: 2.428 pred: 2.618, error 0.190\n",
            "OP1X2: 1.892 CP1X2: 1.934 pred: 1.845, error 0.089\n",
            "OP1X2: 2.547 CP1X2: 2.816 pred: 2.469, error 0.347\n",
            "OP1X2: 1.657 CP1X2: 1.782 pred: 1.579, error 0.203\n",
            "OP1X2: 2.892 CP1X2: 2.981 pred: 2.883, error 0.098\n",
            "OP1X2: 2.919 CP1X2: 2.774 pred: 2.921, error 0.147\n",
            "OP1X2: 1.354 CP1X2: 1.336 pred: 1.405, error 0.069\n",
            "OP1X2: 1.709 CP1X2: 1.748 pred: 1.648, error 0.100\n",
            "OP1X2: 3.471 CP1X2: 3.026 pred: 3.933, error 0.907\n",
            "OP1X2: 1.143 CP1X2: 1.239 pred: 1.252, error 0.013\n",
            "OP1X2: 2.883 CP1X2: 2.936 pred: 2.788, error 0.148\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.556 CP1X2: 1.610 pred: 1579804.750, error 1579803.125\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.518 CP1X2: 2.440 pred: 1579806.250, error 1579803.750\n",
            "OP1X2: 3.059 CP1X2: 3.113 pred: 2.972, error 0.141\n",
            "OP1X2: 1.431 CP1X2: 1.527 pred: 1.446, error 0.081\n",
            "OP1X2: 5.589 CP1X2: 5.673 pred: 5.627, error 0.046\n",
            "OP1X2: 2.692 CP1X2: 2.880 pred: 2.625, error 0.255\n",
            "OP1X2: 3.091 CP1X2: 3.137 pred: 3.417, error 0.280\n",
            "OP1X2: 3.346 CP1X2: 4.208 pred: 3.474, error 0.734\n",
            "OP1X2: 3.030 CP1X2: 3.168 pred: 3.269, error 0.101\n",
            "OP1X2: 1.608 CP1X2: 1.741 pred: 1.634, error 0.107\n",
            "OP1X2: 1.780 CP1X2: 1.763 pred: 1.815, error 0.052\n",
            "OP1X2: 4.817 CP1X2: 4.727 pred: 4.795, error 0.068\n",
            "OP1X2: 1.440 CP1X2: 1.388 pred: 1.463, error 0.075\n",
            "OP1X2: 1.409 CP1X2: 1.375 pred: 1.429, error 0.054\n",
            "OP1X2: 4.580 CP1X2: 5.187 pred: 5.105, error 0.082\n",
            "OP1X2: 1.416 CP1X2: 1.453 pred: 1.492, error 0.039\n",
            "OP1X2: 2.178 CP1X2: 2.087 pred: 2.159, error 0.072\n",
            "OP1X2: 2.449 CP1X2: 2.755 pred: 2.477, error 0.278\n",
            "OP1X2: 5.105 CP1X2: 5.010 pred: 4.784, error 0.226\n",
            "OP1X2: 2.374 CP1X2: 2.321 pred: 2.265, error 0.056\n",
            "OP1X2: 1.416 CP1X2: 1.483 pred: 1.477, error 0.006\n",
            "OP1X2: 1.287 CP1X2: 1.308 pred: 1.342, error 0.034\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.741 CP1X2: 1.915 pred: 1579804.875, error 1579803.000\n",
            "OP1X2: 2.643 CP1X2: 3.113 pred: 2.582, error 0.531\n",
            "OP1X2: 2.779 CP1X2: 3.190 pred: 2.890, error 0.300\n",
            "OP1X2: 1.902 CP1X2: 1.906 pred: 1.768, error 0.138\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.857 CP1X2: 2.899 pred: 1579806.250, error 1579803.375\n",
            "OP1X2: 2.810 CP1X2: 3.209 pred: 2.768, error 0.441\n",
            "OP1X2: 3.431 CP1X2: 3.656 pred: 3.631, error 0.025\n",
            "OP1X2: 2.583 CP1X2: 2.397 pred: 2.876, error 0.479\n",
            "OP1X2: 3.701 CP1X2: 4.679 pred: 3.661, error 1.018\n",
            "OP1X2: 3.364 CP1X2: 3.966 pred: 3.427, error 0.539\n",
            "OP1X2: 1.130 CP1X2: 1.208 pred: 1.191, error 0.017\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.791 CP1X2: 1.870 pred: 1579805.000, error 1579803.125\n",
            "OP1X2: 3.009 CP1X2: 3.207 pred: 2.817, error 0.390\n",
            "OP1X2: 4.295 CP1X2: 5.360 pred: 4.322, error 1.038\n",
            "OP1X2: 1.738 CP1X2: 1.815 pred: 1.760, error 0.055\n",
            "OP1X2: 1.620 CP1X2: 1.668 pred: 1.638, error 0.030\n",
            "OP1X2: 2.758 CP1X2: 2.682 pred: 3.214, error 0.532\n",
            "OP1X2: 2.485 CP1X2: 2.387 pred: 2.366, error 0.021\n",
            "OP1X2: 2.057 CP1X2: 1.970 pred: 2.119, error 0.149\n",
            "OP1X2: 1.164 CP1X2: 1.227 pred: 1.214, error 0.013\n",
            "OP1X2: 2.826 CP1X2: 3.277 pred: 2.753, error 0.524\n",
            "OP1X2: 3.186 CP1X2: 3.687 pred: 3.661, error 0.026\n",
            "OP1X2: 2.298 CP1X2: 2.606 pred: 2.199, error 0.407\n",
            "OP1X2: 2.889 CP1X2: 3.003 pred: 2.871, error 0.132\n",
            "OP1X2: 1.830 CP1X2: 1.825 pred: 1.843, error 0.018\n",
            "OP1X2: 2.820 CP1X2: 3.295 pred: 2.952, error 0.343\n",
            "OP1X2: 1.959 CP1X2: 1.719 pred: 1.858, error 0.139\n",
            "OP1X2: 1.662 CP1X2: 1.661 pred: 1.631, error 0.030\n",
            "OP1X2: 1.797 CP1X2: 1.693 pred: 1.804, error 0.111\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 7.330 CP1X2: 7.134 pred: 1579810.125, error 1579803.000\n",
            "OP1X2: 1.602 CP1X2: 1.719 pred: 1.643, error 0.076\n",
            "OP1X2: 1.481 CP1X2: 1.521 pred: 1.506, error 0.015\n",
            "OP1X2: 2.661 CP1X2: 2.711 pred: 2.592, error 0.119\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.383 CP1X2: 3.329 pred: 1579806.625, error 1579803.250\n",
            "OP1X2: 1.836 CP1X2: 1.670 pred: 1.798, error 0.128\n",
            "OP1X2: 1.681 CP1X2: 1.639 pred: 1.646, error 0.007\n",
            "OP1X2: 4.380 CP1X2: 4.738 pred: 4.346, error 0.392\n",
            "OP1X2: 1.324 CP1X2: 1.342 pred: 1.393, error 0.051\n",
            "OP1X2: 2.939 CP1X2: 2.838 pred: 2.978, error 0.140\n",
            "OP1X2: 2.305 CP1X2: 2.295 pred: 2.463, error 0.168\n",
            "OP1X2: 2.562 CP1X2: 2.639 pred: 2.749, error 0.110\n",
            "OP1X2: 2.445 CP1X2: 2.481 pred: 2.619, error 0.138\n",
            "OP1X2: 1.243 CP1X2: 1.226 pred: 1.316, error 0.090\n",
            "OP1X2: 2.659 CP1X2: 2.557 pred: 3.067, error 0.510\n",
            "OP1X2: 2.131 CP1X2: 2.067 pred: 2.116, error 0.049\n",
            "OP1X2: 1.984 CP1X2: 2.041 pred: 1.935, error 0.106\n",
            "OP1X2: 3.222 CP1X2: 3.783 pred: 3.023, error 0.760\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.607 CP1X2: 1.641 pred: 1579804.625, error 1579803.000\n",
            "OP1X2: 2.003 CP1X2: 1.677 pred: 1.981, error 0.304\n",
            "OP1X2: 3.413 CP1X2: 3.643 pred: 3.528, error 0.115\n",
            "OP1X2: 3.397 CP1X2: 3.759 pred: 3.547, error 0.212\n",
            "OP1X2: 3.656 CP1X2: 4.122 pred: 4.215, error 0.093\n",
            "OP1X2: 2.062 CP1X2: 2.052 pred: 2.074, error 0.022\n",
            "OP1X2: 2.792 CP1X2: 2.999 pred: 2.869, error 0.130\n",
            "OP1X2: 1.648 CP1X2: 1.498 pred: 1.652, error 0.154\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.154 CP1X2: 2.067 pred: 1579805.500, error 1579803.375\n",
            "OP1X2: 1.890 CP1X2: 2.004 pred: 1.791, error 0.213\n",
            "OP1X2: 1.313 CP1X2: 1.396 pred: 1.415, error 0.019\n",
            "OP1X2: 2.959 CP1X2: 3.012 pred: 2.964, error 0.048\n",
            "OP1X2: 2.904 CP1X2: 2.793 pred: 2.797, error 0.004\n",
            "OP1X2: 2.197 CP1X2: 2.240 pred: 2.151, error 0.089\n",
            "OP1X2: 2.268 CP1X2: 2.180 pred: 2.207, error 0.027\n",
            "OP1X2: 8.583 CP1X2: 10.865 pred: 9.632, error 1.233\n",
            "OP1X2: 1.543 CP1X2: 1.708 pred: 1.601, error 0.107\n",
            "OP1X2: 3.041 CP1X2: 3.409 pred: 3.191, error 0.218\n",
            "OP1X2: 1.920 CP1X2: 1.932 pred: 1.830, error 0.102\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.613 CP1X2: 1.501 pred: 1579804.750, error 1579803.250\n",
            "OP1X2: 1.192 CP1X2: 1.179 pred: 1.249, error 0.070\n",
            "OP1X2: 2.326 CP1X2: 2.588 pred: 2.323, error 0.265\n",
            "OP1X2: 1.574 CP1X2: 1.393 pred: 1.582, error 0.189\n",
            "OP1X2: 2.110 CP1X2: 2.071 pred: 2.133, error 0.062\n",
            "OP1X2: 2.072 CP1X2: 2.337 pred: 2.041, error 0.296\n",
            "OP1X2: 1.703 CP1X2: 1.812 pred: 1.641, error 0.171\n",
            "OP1X2: 3.347 CP1X2: 3.997 pred: 3.467, error 0.530\n",
            "OP1X2: 1.586 CP1X2: 1.743 pred: 1.665, error 0.078\n",
            "OP1X2: 1.547 CP1X2: 1.482 pred: 1.538, error 0.056\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.898 CP1X2: 3.358 pred: 1579806.375, error 1579803.000\n",
            "OP1X2: 3.959 CP1X2: 4.876 pred: 4.012, error 0.864\n",
            "OP1X2: 2.501 CP1X2: 2.550 pred: 2.564, error 0.014\n",
            "OP1X2: 1.641 CP1X2: 1.673 pred: 1.669, error 0.004\n",
            "OP1X2: 1.288 CP1X2: 1.319 pred: 1.336, error 0.017\n",
            "OP1X2: 2.033 CP1X2: 2.037 pred: 2.058, error 0.021\n",
            "OP1X2: 1.439 CP1X2: 1.464 pred: 1.528, error 0.064\n",
            "OP1X2: 2.175 CP1X2: 2.227 pred: 2.235, error 0.008\n",
            "OP1X2: 1.737 CP1X2: 2.028 pred: 1.718, error 0.310\n",
            "OP1X2: 6.395 CP1X2: 6.017 pred: 6.568, error 0.551\n",
            "OP1X2: 1.583 CP1X2: 1.436 pred: 1.543, error 0.107\n",
            "OP1X2: 6.489 CP1X2: 5.315 pred: 6.735, error 1.420\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.264 CP1X2: 1.213 pred: 1579804.125, error 1579802.875\n",
            "OP1X2: 2.243 CP1X2: 2.133 pred: 2.197, error 0.064\n",
            "OP1X2: 1.902 CP1X2: 1.791 pred: 1.789, error 0.002\n",
            "OP1X2: 1.992 CP1X2: 2.170 pred: 2.051, error 0.119\n",
            "OP1X2: 1.371 CP1X2: 1.261 pred: 1.421, error 0.160\n",
            "OP1X2: 1.668 CP1X2: 1.662 pred: 1.700, error 0.038\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.836 CP1X2: 4.932 pred: 1579807.125, error 1579802.250\n",
            "OP1X2: 2.497 CP1X2: 2.525 pred: 2.567, error 0.042\n",
            "OP1X2: 2.575 CP1X2: 2.412 pred: 2.588, error 0.176\n",
            "OP1X2: 3.984 CP1X2: 4.306 pred: 4.546, error 0.240\n",
            "OP1X2: 1.896 CP1X2: 1.966 pred: 1.844, error 0.122\n",
            "OP1X2: 2.136 CP1X2: 2.637 pred: 2.132, error 0.505\n",
            "OP1X2: 2.703 CP1X2: 2.937 pred: 2.590, error 0.347\n",
            "OP1X2: 5.214 CP1X2: 5.010 pred: 5.328, error 0.318\n",
            "OP1X2: 2.233 CP1X2: 2.096 pred: 2.381, error 0.285\n",
            "OP1X2: 3.043 CP1X2: 2.861 pred: 3.141, error 0.280\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.981 CP1X2: 1.853 pred: 1579805.125, error 1579803.250\n",
            "OP1X2: 1.374 CP1X2: 1.332 pred: 1.389, error 0.057\n",
            "OP1X2: 4.652 CP1X2: 4.963 pred: 4.579, error 0.384\n",
            "OP1X2: 1.381 CP1X2: 1.367 pred: 1.430, error 0.063\n",
            "OP1X2: 1.561 CP1X2: 1.543 pred: 1.607, error 0.064\n",
            "OP1X2: 1.820 CP1X2: 1.798 pred: 1.784, error 0.014\n",
            "OP1X2: 1.703 CP1X2: 1.711 pred: 1.749, error 0.038\n",
            "OP1X2: 3.548 CP1X2: 3.787 pred: 3.769, error 0.018\n",
            "OP1X2: 3.644 CP1X2: 3.895 pred: 4.178, error 0.283\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.127 CP1X2: 1.130 pred: 1579803.125, error 1579802.000\n",
            "OP1X2: 1.274 CP1X2: 1.373 pred: 1.351, error 0.022\n",
            "OP1X2: 3.032 CP1X2: 3.097 pred: 3.204, error 0.107\n",
            "OP1X2: 1.893 CP1X2: 1.643 pred: 1.871, error 0.228\n",
            "OP1X2: 2.264 CP1X2: 2.445 pred: 2.343, error 0.102\n",
            "OP1X2: 4.830 CP1X2: 5.105 pred: 5.644, error 0.539\n",
            "OP1X2: 3.730 CP1X2: 3.299 pred: 3.665, error 0.366\n",
            "OP1X2: 1.838 CP1X2: 1.912 pred: 1.735, error 0.177\n",
            "OP1X2: 3.039 CP1X2: 2.383 pred: 3.122, error 0.739\n",
            "OP1X2: 1.237 CP1X2: 1.160 pred: 1.298, error 0.138\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.780 CP1X2: 1.727 pred: 1579805.500, error 1579803.750\n",
            "OP1X2: 2.680 CP1X2: 2.764 pred: 2.834, error 0.070\n",
            "OP1X2: 1.278 CP1X2: 1.286 pred: 1.344, error 0.058\n",
            "OP1X2: 2.586 CP1X2: 2.559 pred: 2.672, error 0.113\n",
            "OP1X2: 1.762 CP1X2: 1.836 pred: 1.694, error 0.142\n",
            "OP1X2: 2.080 CP1X2: 1.914 pred: 1.955, error 0.041\n",
            "OP1X2: 1.745 CP1X2: 1.938 pred: 1.758, error 0.180\n",
            "OP1X2: 1.652 CP1X2: 1.637 pred: 1.649, error 0.012\n",
            "OP1X2: 2.069 CP1X2: 2.199 pred: 2.104, error 0.095\n",
            "OP1X2: 1.670 CP1X2: 1.608 pred: 1.653, error 0.045\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.953 CP1X2: 1.906 pred: 1579805.250, error 1579803.375\n",
            "OP1X2: 2.260 CP1X2: 2.147 pred: 2.343, error 0.196\n",
            "OP1X2: 1.323 CP1X2: 1.602 pred: 1.404, error 0.198\n",
            "OP1X2: 5.857 CP1X2: 6.099 pred: 6.192, error 0.093\n",
            "OP1X2: 2.512 CP1X2: 2.477 pred: 2.762, error 0.285\n",
            "OP1X2: 2.179 CP1X2: 2.281 pred: 2.169, error 0.112\n",
            "OP1X2: 6.882 CP1X2: 7.426 pred: 8.132, error 0.706\n",
            "OP1X2: 1.978 CP1X2: 2.124 pred: 2.044, error 0.080\n",
            "OP1X2: 2.164 CP1X2: 2.167 pred: 2.375, error 0.208\n",
            "OP1X2: 2.751 CP1X2: 2.572 pred: 2.730, error 0.158\n",
            "OP1X2: 1.661 CP1X2: 1.660 pred: 1.681, error 0.021\n",
            "OP1X2: 1.483 CP1X2: 1.647 pred: 1.512, error 0.135\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.373 CP1X2: 2.255 pred: 1579805.250, error 1579803.000\n",
            "OP1X2: 1.635 CP1X2: 1.728 pred: 1.664, error 0.064\n",
            "OP1X2: 2.075 CP1X2: 1.855 pred: 2.129, error 0.274\n",
            "OP1X2: 1.327 CP1X2: 1.479 pred: 1.379, error 0.100\n",
            "OP1X2: 3.714 CP1X2: 3.232 pred: 3.942, error 0.710\n",
            "OP1X2: 2.217 CP1X2: 2.086 pred: 2.233, error 0.147\n",
            "OP1X2: 4.770 CP1X2: 3.739 pred: 5.417, error 1.678\n",
            "OP1X2: 2.071 CP1X2: 2.101 pred: 2.038, error 0.063\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.413 CP1X2: 1.382 pred: 1579804.625, error 1579803.250\n",
            "OP1X2: 1.496 CP1X2: 1.488 pred: 1.505, error 0.017\n",
            "OP1X2: 1.390 CP1X2: 1.389 pred: 1.425, error 0.036\n",
            "OP1X2: 3.951 CP1X2: 3.531 pred: 4.418, error 0.887\n",
            "OP1X2: 3.824 CP1X2: 2.987 pred: 4.222, error 1.235\n",
            "OP1X2: 1.917 CP1X2: 2.282 pred: 1.986, error 0.296\n",
            "OP1X2: 2.856 CP1X2: 3.030 pred: 2.693, error 0.337\n",
            "OP1X2: 3.194 CP1X2: 3.174 pred: 3.504, error 0.330\n",
            "OP1X2: 2.865 CP1X2: 3.135 pred: 2.712, error 0.423\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.120 CP1X2: 2.215 pred: 1579805.750, error 1579803.500\n",
            "OP1X2: 1.259 CP1X2: 1.374 pred: 1.342, error 0.032\n",
            "OP1X2: 1.916 CP1X2: 2.252 pred: 1.988, error 0.264\n",
            "OP1X2: 1.487 CP1X2: 1.240 pred: 1.486, error 0.246\n",
            "OP1X2: 2.363 CP1X2: 2.468 pred: 2.465, error 0.003\n",
            "OP1X2: 2.613 CP1X2: 1.969 pred: 2.615, error 0.646\n",
            "OP1X2: 3.238 CP1X2: 3.075 pred: 3.302, error 0.227\n",
            "OP1X2: 1.897 CP1X2: 2.055 pred: 1.920, error 0.135\n",
            "OP1X2: 2.717 CP1X2: 2.565 pred: 3.089, error 0.524\n",
            "OP1X2: 2.739 CP1X2: 2.707 pred: 2.970, error 0.263\n",
            "OP1X2: 2.036 CP1X2: 1.585 pred: 2.103, error 0.518\n",
            "OP1X2: 1.762 CP1X2: 1.673 pred: 1.747, error 0.074\n",
            "OP1X2: 2.283 CP1X2: 2.086 pred: 2.199, error 0.113\n",
            "OP1X2: 2.830 CP1X2: 3.082 pred: 2.606, error 0.476\n",
            "OP1X2: 2.229 CP1X2: 2.037 pred: 2.499, error 0.462\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.223 CP1X2: 2.395 pred: 1579806.875, error 1579804.500\n",
            "OP1X2: 2.574 CP1X2: 2.512 pred: 3.076, error 0.564\n",
            "OP1X2: 2.978 CP1X2: 2.779 pred: 2.913, error 0.134\n",
            "OP1X2: 2.779 CP1X2: 2.950 pred: 2.890, error 0.060\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.436 CP1X2: 2.627 pred: 1579805.625, error 1579803.000\n",
            "OP1X2: 2.233 CP1X2: 1.934 pred: 2.170, error 0.236\n",
            "OP1X2: 1.645 CP1X2: 1.811 pred: 1.616, error 0.195\n",
            "OP1X2: 2.502 CP1X2: 2.576 pred: 2.329, error 0.247\n",
            "OP1X2: 3.183 CP1X2: 3.321 pred: 3.082, error 0.239\n",
            "OP1X2: 2.178 CP1X2: 2.117 pred: 2.168, error 0.051\n",
            "OP1X2: 1.757 CP1X2: 1.732 pred: 1.704, error 0.028\n",
            "OP1X2: 5.590 CP1X2: 6.986 pred: 5.521, error 1.465\n",
            "OP1X2: 1.304 CP1X2: 1.316 pred: 1.363, error 0.047\n",
            "OP1X2: 2.214 CP1X2: 2.283 pred: 2.250, error 0.033\n",
            "OP1X2: 3.245 CP1X2: 2.733 pred: 2.997, error 0.264\n",
            "OP1X2: 1.745 CP1X2: 1.592 pred: 1.609, error 0.017\n",
            "OP1X2: 1.704 CP1X2: 1.695 pred: 1.690, error 0.005\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 6.839 CP1X2: 7.109 pred: 1579809.500, error 1579802.375\n",
            "OP1X2: 2.817 CP1X2: 2.909 pred: 2.980, error 0.071\n",
            "OP1X2: 3.250 CP1X2: 3.739 pred: 3.258, error 0.481\n",
            "OP1X2: 2.487 CP1X2: 1.939 pred: 2.403, error 0.464\n",
            "OP1X2: 1.221 CP1X2: 1.247 pred: 1.242, error 0.005\n",
            "OP1X2: 2.676 CP1X2: 2.835 pred: 2.521, error 0.314\n",
            "OP1X2: 3.511 CP1X2: 3.407 pred: 3.474, error 0.067\n",
            "OP1X2: 3.756 CP1X2: 4.459 pred: 3.705, error 0.754\n",
            "OP1X2: 4.025 CP1X2: 4.427 pred: 4.003, error 0.424\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.210 CP1X2: 2.159 pred: 1579805.250, error 1579803.125\n",
            "OP1X2: 2.431 CP1X2: 2.726 pred: 2.342, error 0.384\n",
            "OP1X2: 1.734 CP1X2: 1.941 pred: 1.648, error 0.293\n",
            "OP1X2: 3.070 CP1X2: 3.438 pred: 3.056, error 0.382\n",
            "OP1X2: 1.960 CP1X2: 1.790 pred: 1.840, error 0.050\n",
            "OP1X2: 1.740 CP1X2: 1.954 pred: 1.711, error 0.243\n",
            "OP1X2: 3.860 CP1X2: 3.939 pred: 3.807, error 0.132\n",
            "OP1X2: 2.112 CP1X2: 2.457 pred: 2.126, error 0.331\n",
            "OP1X2: 3.110 CP1X2: 3.238 pred: 3.150, error 0.088\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.414 CP1X2: 2.849 pred: 1579805.625, error 1579802.750\n",
            "OP1X2: 1.414 CP1X2: 1.438 pred: 1.455, error 0.017\n",
            "OP1X2: 1.289 CP1X2: 1.354 pred: 1.343, error 0.011\n",
            "OP1X2: 3.156 CP1X2: 3.183 pred: 3.126, error 0.057\n",
            "OP1X2: 1.938 CP1X2: 2.052 pred: 1.929, error 0.123\n",
            "OP1X2: 4.650 CP1X2: 6.537 pred: 4.675, error 1.862\n",
            "OP1X2: 3.073 CP1X2: 3.132 pred: 2.957, error 0.175\n",
            "OP1X2: 1.635 CP1X2: 1.718 pred: 1.498, error 0.220\n",
            "OP1X2: 1.902 CP1X2: 2.016 pred: 1.839, error 0.177\n",
            "OP1X2: 1.571 CP1X2: 1.584 pred: 1.559, error 0.025\n",
            "OP1X2: 3.246 CP1X2: 3.488 pred: 3.321, error 0.167\n",
            "OP1X2: 2.017 CP1X2: 2.068 pred: 1.969, error 0.099\n",
            "OP1X2: 1.424 CP1X2: 1.302 pred: 1.441, error 0.139\n",
            "OP1X2: 1.679 CP1X2: 1.721 pred: 1.729, error 0.008\n",
            "OP1X2: 1.713 CP1X2: 1.580 pred: 1.566, error 0.014\n",
            "OP1X2: 2.530 CP1X2: 2.614 pred: 2.565, error 0.049\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.538 CP1X2: 1.495 pred: 1579804.500, error 1579803.000\n",
            "OP1X2: 2.841 CP1X2: 2.841 pred: 2.742, error 0.099\n",
            "OP1X2: 3.723 CP1X2: 4.172 pred: 3.968, error 0.204\n",
            "OP1X2: 1.945 CP1X2: 1.898 pred: 1.810, error 0.088\n",
            "OP1X2: 2.416 CP1X2: 2.388 pred: 2.358, error 0.030\n",
            "OP1X2: 1.334 CP1X2: 1.248 pred: 1.380, error 0.132\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.868 CP1X2: 2.770 pred: 1579806.250, error 1579803.500\n",
            "OP1X2: 1.772 CP1X2: 1.794 pred: 1.716, error 0.078\n",
            "OP1X2: 2.845 CP1X2: 2.805 pred: 2.910, error 0.105\n",
            "OP1X2: 2.791 CP1X2: 2.554 pred: 2.720, error 0.166\n",
            "OP1X2: 1.630 CP1X2: 1.682 pred: 1.679, error 0.003\n",
            "OP1X2: 2.125 CP1X2: 1.943 pred: 1.923, error 0.020\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.517 CP1X2: 1.690 pred: 1579804.500, error 1579802.750\n",
            "OP1X2: 5.210 CP1X2: 7.194 pred: 4.780, error 2.414\n",
            "OP1X2: 1.779 CP1X2: 2.146 pred: 1.679, error 0.467\n",
            "OP1X2: 1.263 CP1X2: 1.168 pred: 1.217, error 0.049\n",
            "OP1X2: 1.695 CP1X2: 1.518 pred: 1.722, error 0.204\n",
            "OP1X2: 2.484 CP1X2: 2.526 pred: 2.525, error 0.001\n",
            "OP1X2: 2.501 CP1X2: 2.635 pred: 2.433, error 0.202\n",
            "OP1X2: 3.541 CP1X2: 4.043 pred: 3.666, error 0.377\n",
            "OP1X2: 3.061 CP1X2: 2.761 pred: 3.127, error 0.366\n",
            "OP1X2: 1.930 CP1X2: 1.605 pred: 1.842, error 0.237\n",
            "OP1X2: 1.390 CP1X2: 1.348 pred: 1.391, error 0.043\n",
            "OP1X2: 2.020 CP1X2: 2.259 pred: 2.082, error 0.177\n",
            "OP1X2: 2.066 CP1X2: 1.998 pred: 2.060, error 0.062\n",
            "OP1X2: 2.846 CP1X2: 2.774 pred: 2.839, error 0.065\n",
            "OP1X2: 3.575 CP1X2: 3.895 pred: 3.464, error 0.431\n",
            "OP1X2: 2.580 CP1X2: 2.513 pred: 2.639, error 0.126\n",
            "OP1X2: 2.242 CP1X2: 2.075 pred: 2.204, error 0.129\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.054 CP1X2: 1.948 pred: 1579805.500, error 1579803.500\n",
            "OP1X2: 1.342 CP1X2: 1.327 pred: 1.364, error 0.037\n",
            "OP1X2: 2.644 CP1X2: 2.915 pred: 2.644, error 0.271\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.481 CP1X2: 1.300 pred: 1579804.500, error 1579803.250\n",
            "OP1X2: 3.071 CP1X2: 3.275 pred: 3.086, error 0.189\n",
            "OP1X2: 1.326 CP1X2: 1.271 pred: 1.326, error 0.055\n",
            "OP1X2: 2.569 CP1X2: 2.505 pred: 2.419, error 0.086\n",
            "OP1X2: 1.833 CP1X2: 1.837 pred: 1.776, error 0.061\n",
            "OP1X2: 6.529 CP1X2: 7.056 pred: 6.979, error 0.077\n",
            "OP1X2: 2.848 CP1X2: 2.535 pred: 2.826, error 0.291\n",
            "OP1X2: 1.860 CP1X2: 1.988 pred: 1.924, error 0.064\n",
            "OP1X2: 1.508 CP1X2: 1.642 pred: 1.439, error 0.203\n",
            "OP1X2: 2.047 CP1X2: 2.016 pred: 2.148, error 0.132\n",
            "OP1X2: 1.835 CP1X2: 1.666 pred: 1.788, error 0.122\n",
            "OP1X2: 1.520 CP1X2: 1.635 pred: 1.508, error 0.127\n",
            "OP1X2: 2.518 CP1X2: 2.411 pred: 2.467, error 0.056\n",
            "OP1X2: 3.429 CP1X2: 4.562 pred: 3.205, error 1.357\n",
            "OP1X2: 3.222 CP1X2: 3.444 pred: 3.351, error 0.093\n",
            "OP1X2: 1.430 CP1X2: 1.846 pred: 1.452, error 0.394\n",
            "OP1X2: 1.697 CP1X2: 2.036 pred: 1.649, error 0.387\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.615 CP1X2: 1.382 pred: 1579804.750, error 1579803.375\n",
            "OP1X2: 2.669 CP1X2: 2.616 pred: 2.552, error 0.064\n",
            "OP1X2: 1.751 CP1X2: 1.685 pred: 1.718, error 0.033\n",
            "OP1X2: 1.891 CP1X2: 1.717 pred: 1.794, error 0.077\n",
            "OP1X2: 2.261 CP1X2: 2.569 pred: 2.171, error 0.398\n",
            "OP1X2: 2.195 CP1X2: 2.296 pred: 2.178, error 0.118\n",
            "OP1X2: 2.890 CP1X2: 3.832 pred: 3.101, error 0.731\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.234 CP1X2: 2.299 pred: 1579805.375, error 1579803.125\n",
            "OP1X2: 1.950 CP1X2: 1.972 pred: 1.840, error 0.132\n",
            "OP1X2: 2.959 CP1X2: 3.309 pred: 2.895, error 0.414\n",
            "OP1X2: 1.737 CP1X2: 1.605 pred: 1.711, error 0.106\n",
            "OP1X2: 1.333 CP1X2: 1.426 pred: 1.380, error 0.046\n",
            "OP1X2: 3.268 CP1X2: 2.949 pred: 3.395, error 0.446\n",
            "OP1X2: 4.362 CP1X2: 5.451 pred: 4.497, error 0.954\n",
            "OP1X2: 2.632 CP1X2: 2.858 pred: 2.508, error 0.350\n",
            "OP1X2: 1.933 CP1X2: 1.871 pred: 1.920, error 0.049\n",
            "OP1X2: 2.189 CP1X2: 2.387 pred: 2.141, error 0.246\n",
            "OP1X2: 3.063 CP1X2: 3.316 pred: 3.025, error 0.291\n",
            "OP1X2: 1.287 CP1X2: 1.215 pred: 1.335, error 0.120\n",
            "OP1X2: 2.686 CP1X2: 3.605 pred: 2.755, error 0.850\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.829 CP1X2: 1.729 pred: 1579805.125, error 1579803.375\n",
            "OP1X2: 1.598 CP1X2: 1.622 pred: 1.612, error 0.010\n",
            "OP1X2: 1.905 CP1X2: 2.009 pred: 1.924, error 0.085\n",
            "OP1X2: 1.571 CP1X2: 1.675 pred: 1.599, error 0.076\n",
            "OP1X2: 2.603 CP1X2: 2.980 pred: 2.499, error 0.481\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 4.068 CP1X2: 4.324 pred: 1579807.625, error 1579803.250\n",
            "OP1X2: 1.816 CP1X2: 1.952 pred: 1.615, error 0.337\n",
            "OP1X2: 2.480 CP1X2: 2.455 pred: 2.517, error 0.062\n",
            "OP1X2: 1.380 CP1X2: 1.330 pred: 1.406, error 0.076\n",
            "OP1X2: 1.956 CP1X2: 2.180 pred: 1.904, error 0.276\n",
            "OP1X2: 1.221 CP1X2: 1.247 pred: 1.261, error 0.014\n",
            "OP1X2: 1.556 CP1X2: 1.330 pred: 1.570, error 0.240\n",
            "OP1X2: 1.835 CP1X2: 1.710 pred: 1.735, error 0.025\n",
            "OP1X2: 4.629 CP1X2: 4.915 pred: 4.425, error 0.490\n",
            "OP1X2: 2.008 CP1X2: 2.227 pred: 1.953, error 0.274\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.781 CP1X2: 1.771 pred: 1579804.750, error 1579803.000\n",
            "OP1X2: 1.426 CP1X2: 1.348 pred: 1.424, error 0.076\n",
            "OP1X2: 1.745 CP1X2: 1.689 pred: 1.622, error 0.067\n",
            "OP1X2: 1.812 CP1X2: 1.638 pred: 1.810, error 0.172\n",
            "OP1X2: 6.219 CP1X2: 6.968 pred: 6.329, error 0.639\n",
            "OP1X2: 1.972 CP1X2: 2.153 pred: 1.886, error 0.267\n",
            "OP1X2: 2.411 CP1X2: 2.231 pred: 2.311, error 0.080\n",
            "OP1X2: 1.821 CP1X2: 1.884 pred: 1.728, error 0.156\n",
            "OP1X2: 2.470 CP1X2: 2.401 pred: 2.507, error 0.106\n",
            "OP1X2: 1.880 CP1X2: 1.655 pred: 1.798, error 0.143\n",
            "OP1X2: 1.645 CP1X2: 1.463 pred: 1.651, error 0.188\n",
            "OP1X2: 1.154 CP1X2: 1.165 pred: 1.223, error 0.058\n",
            "OP1X2: 3.083 CP1X2: 3.827 pred: 3.294, error 0.533\n",
            "OP1X2: 1.929 CP1X2: 1.925 pred: 1.876, error 0.049\n",
            "OP1X2: 2.115 CP1X2: 2.606 pred: 1.939, error 0.667\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.141 CP1X2: 3.480 pred: 1579806.750, error 1579803.250\n",
            "OP1X2: 2.047 CP1X2: 1.970 pred: 1.996, error 0.026\n",
            "OP1X2: 1.805 CP1X2: 1.538 pred: 1.772, error 0.234\n",
            "OP1X2: 2.554 CP1X2: 2.634 pred: 2.493, error 0.141\n",
            "OP1X2: 1.904 CP1X2: 2.034 pred: 1.701, error 0.333\n",
            "OP1X2: 4.213 CP1X2: 4.639 pred: 4.103, error 0.536\n",
            "OP1X2: 3.012 CP1X2: 3.384 pred: 3.147, error 0.237\n",
            "OP1X2: 2.528 CP1X2: 2.610 pred: 2.393, error 0.217\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.247 CP1X2: 1.191 pred: 1579804.250, error 1579803.000\n",
            "OP1X2: 2.804 CP1X2: 2.785 pred: 3.071, error 0.286\n",
            "OP1X2: 1.548 CP1X2: 1.459 pred: 1.479, error 0.020\n",
            "OP1X2: 2.278 CP1X2: 2.660 pred: 2.237, error 0.423\n",
            "OP1X2: 4.224 CP1X2: 6.095 pred: 4.688, error 1.407\n",
            "OP1X2: 2.000 CP1X2: 2.216 pred: 1.958, error 0.258\n",
            "OP1X2: 4.012 CP1X2: 5.750 pred: 4.046, error 1.704\n",
            "OP1X2: 1.674 CP1X2: 1.797 pred: 1.653, error 0.144\n",
            "OP1X2: 2.497 CP1X2: 2.515 pred: 2.650, error 0.135\n",
            "OP1X2: 1.565 CP1X2: 1.683 pred: 1.557, error 0.126\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.780 CP1X2: 2.373 pred: 1579805.875, error 1579803.500\n",
            "OP1X2: 1.719 CP1X2: 1.580 pred: 1.763, error 0.183\n",
            "OP1X2: 1.890 CP1X2: 1.985 pred: 1.800, error 0.185\n",
            "OP1X2: 1.290 CP1X2: 1.231 pred: 1.341, error 0.110\n",
            "OP1X2: 1.598 CP1X2: 1.600 pred: 1.538, error 0.062\n",
            "OP1X2: 2.791 CP1X2: 2.993 pred: 2.843, error 0.150\n",
            "OP1X2: 1.325 CP1X2: 1.463 pred: 1.421, error 0.042\n",
            "OP1X2: 2.234 CP1X2: 2.275 pred: 2.240, error 0.035\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.136 CP1X2: 1.145 pred: 1579803.375, error 1579802.250\n",
            "OP1X2: 2.140 CP1X2: 2.364 pred: 2.183, error 0.181\n",
            "OP1X2: 1.382 CP1X2: 1.359 pred: 1.344, error 0.015\n",
            "OP1X2: 4.693 CP1X2: 5.747 pred: 4.815, error 0.932\n",
            "OP1X2: 2.485 CP1X2: 2.657 pred: 2.425, error 0.232\n",
            "OP1X2: 4.220 CP1X2: 5.939 pred: 4.485, error 1.454\n",
            "OP1X2: 2.247 CP1X2: 2.261 pred: 2.162, error 0.099\n",
            "OP1X2: 1.568 CP1X2: 1.570 pred: 1.563, error 0.007\n",
            "OP1X2: 2.246 CP1X2: 2.372 pred: 2.279, error 0.093\n",
            "OP1X2: 1.552 CP1X2: 1.525 pred: 1.557, error 0.032\n",
            "OP1X2: 2.195 CP1X2: 2.194 pred: 2.168, error 0.026\n",
            "OP1X2: 2.077 CP1X2: 2.243 pred: 2.204, error 0.039\n",
            "OP1X2: 1.217 CP1X2: 1.223 pred: 1.242, error 0.019\n",
            "OP1X2: 2.211 CP1X2: 2.197 pred: 2.206, error 0.009\n",
            "OP1X2: 2.504 CP1X2: 2.635 pred: 2.485, error 0.150\n",
            "OP1X2: 3.043 CP1X2: 3.005 pred: 3.090, error 0.085\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.660 CP1X2: 1.721 pred: 1579805.000, error 1579803.250\n",
            "OP1X2: 5.308 CP1X2: 6.195 pred: 5.388, error 0.807\n",
            "OP1X2: 1.782 CP1X2: 2.021 pred: 1.662, error 0.359\n",
            "OP1X2: 2.435 CP1X2: 2.607 pred: 2.378, error 0.229\n",
            "OP1X2: 2.476 CP1X2: 2.380 pred: 2.385, error 0.005\n",
            "OP1X2: 2.127 CP1X2: 2.104 pred: 2.198, error 0.094\n",
            "OP1X2: 1.576 CP1X2: 1.714 pred: 1.602, error 0.112\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 3.889 CP1X2: 3.716 pred: 1579807.125, error 1579803.375\n",
            "OP1X2: 2.712 CP1X2: 3.070 pred: 2.785, error 0.285\n",
            "OP1X2: 1.742 CP1X2: 1.636 pred: 1.715, error 0.079\n",
            "OP1X2: 2.859 CP1X2: 2.550 pred: 3.001, error 0.451\n",
            "OP1X2: 3.705 CP1X2: 3.465 pred: 3.880, error 0.415\n",
            "OP1X2: 1.896 CP1X2: 1.724 pred: 1.784, error 0.060\n",
            "OP1X2: 2.095 CP1X2: 2.110 pred: 2.109, error 0.001\n",
            "OP1X2: 2.154 CP1X2: 2.426 pred: 2.272, error 0.154\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.146 CP1X2: 1.121 pred: 1579803.375, error 1579802.250\n",
            "OP1X2: 3.637 CP1X2: 3.954 pred: 3.420, error 0.534\n",
            "OP1X2: 1.661 CP1X2: 1.795 pred: 1.614, error 0.181\n",
            "OP1X2: 4.459 CP1X2: 5.033 pred: 5.015, error 0.018\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.627 CP1X2: 2.789 pred: 1579806.125, error 1579803.375\n",
            "OP1X2: 2.483 CP1X2: 2.247 pred: 2.370, error 0.123\n",
            "OP1X2: 1.602 CP1X2: 1.807 pred: 1.654, error 0.153\n",
            "OP1X2: 5.523 CP1X2: 6.815 pred: 5.602, error 1.213\n",
            "OP1X2: 1.301 CP1X2: 1.377 pred: 1.372, error 0.005\n",
            "OP1X2: 2.747 CP1X2: 2.741 pred: 2.686, error 0.055\n",
            "OP1X2: 4.720 CP1X2: 4.756 pred: 5.108, error 0.352\n",
            "OP1X2: 2.069 CP1X2: 2.108 pred: 2.006, error 0.102\n",
            "OP1X2: 1.499 CP1X2: 1.570 pred: 1.527, error 0.043\n",
            "OP1X2: 1.823 CP1X2: 1.846 pred: 1.808, error 0.038\n",
            "OP1X2: 1.265 CP1X2: 1.336 pred: 1.300, error 0.036\n",
            "OP1X2: 1.354 CP1X2: 1.605 pred: 1.419, error 0.186\n",
            "OP1X2: 5.438 CP1X2: 6.060 pred: 5.445, error 0.615\n",
            "OP1X2: 1.557 CP1X2: 1.511 pred: 1.532, error 0.021\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.645 CP1X2: 1.708 pred: 1579805.000, error 1579803.250\n",
            "OP1X2: 2.296 CP1X2: 2.160 pred: 2.184, error 0.024\n",
            "OP1X2: 5.320 CP1X2: 4.115 pred: 5.584, error 1.469\n",
            "OP1X2: 2.217 CP1X2: 2.020 pred: 2.214, error 0.194\n",
            "OP1X2: 1.749 CP1X2: 1.688 pred: 1.739, error 0.051\n",
            "OP1X2: 1.826 CP1X2: 2.003 pred: 1.861, error 0.142\n",
            "OP1X2: 2.315 CP1X2: 2.181 pred: 2.545, error 0.364\n",
            "OP1X2: 1.716 CP1X2: 1.603 pred: 1.735, error 0.132\n",
            "OP1X2: 2.286 CP1X2: 2.130 pred: 2.227, error 0.097\n",
            "OP1X2: 3.254 CP1X2: 3.032 pred: 3.422, error 0.390\n",
            "OP1X2: 1.765 CP1X2: 1.743 pred: 1.739, error 0.004\n",
            "OP1X2: 1.556 CP1X2: 1.420 pred: 1.499, error 0.079\n",
            "OP1X2: 2.786 CP1X2: 2.568 pred: 2.710, error 0.142\n",
            "OP1X2: 2.228 CP1X2: 2.206 pred: 2.183, error 0.023\n",
            "OP1X2: 2.285 CP1X2: 2.178 pred: 2.440, error 0.262\n",
            "OP1X2: 2.271 CP1X2: 2.500 pred: 2.194, error 0.306\n",
            "OP1X2: 3.450 CP1X2: 3.624 pred: 3.542, error 0.082\n",
            "OP1X2: 1.218 CP1X2: 1.180 pred: 1.295, error 0.115\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 4.200 CP1X2: 4.560 pred: 1579807.750, error 1579803.250\n",
            "OP1X2: 2.064 CP1X2: 2.052 pred: 2.135, error 0.083\n",
            "OP1X2: 1.696 CP1X2: 1.800 pred: 1.703, error 0.097\n",
            "OP1X2: 3.557 CP1X2: 3.742 pred: 3.663, error 0.079\n",
            "OP1X2: 2.064 CP1X2: 2.276 pred: 2.081, error 0.195\n",
            "OP1X2: 1.329 CP1X2: 1.457 pred: 1.311, error 0.146\n",
            "OP1X2: 4.730 CP1X2: 5.102 pred: 4.727, error 0.375\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.936 CP1X2: 2.234 pred: 1579805.375, error 1579803.125\n",
            "OP1X2: 3.202 CP1X2: 3.795 pred: 3.017, error 0.778\n",
            "OP1X2: 1.959 CP1X2: 2.372 pred: 1.960, error 0.412\n",
            "OP1X2: 1.986 CP1X2: 1.862 pred: 1.967, error 0.105\n",
            "OP1X2: 1.705 CP1X2: 1.630 pred: 1.744, error 0.114\n",
            "OP1X2: 1.971 CP1X2: 1.899 pred: 1.899, error 0.000\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 4.385 CP1X2: 4.978 pred: 1579807.750, error 1579802.750\n",
            "OP1X2: 1.351 CP1X2: 1.408 pred: 1.429, error 0.021\n",
            "OP1X2: 2.875 CP1X2: 3.223 pred: 3.128, error 0.095\n",
            "OP1X2: 2.887 CP1X2: 3.741 pred: 2.911, error 0.830\n",
            "OP1X2: 2.412 CP1X2: 2.456 pred: 2.402, error 0.054\n",
            "OP1X2: 1.280 CP1X2: 1.278 pred: 1.339, error 0.061\n",
            "OP1X2: 1.580 CP1X2: 1.641 pred: 1.611, error 0.030\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.731 CP1X2: 1.805 pred: 1579804.750, error 1579803.000\n",
            "OP1X2: 2.498 CP1X2: 2.719 pred: 2.409, error 0.310\n",
            "OP1X2: 1.730 CP1X2: 1.757 pred: 1.764, error 0.007\n",
            "OP1X2: 1.925 CP1X2: 2.036 pred: 1.858, error 0.178\n",
            "OP1X2: 5.222 CP1X2: 5.488 pred: 5.476, error 0.012\n",
            "OP1X2: 2.419 CP1X2: 3.169 pred: 2.396, error 0.773\n",
            "OP1X2: 1.535 CP1X2: 1.520 pred: 1.568, error 0.048\n",
            "OP1X2: 1.697 CP1X2: 1.745 pred: 1.697, error 0.048\n",
            "OP1X2: 3.108 CP1X2: 3.557 pred: 2.938, error 0.619\n",
            "OP1X2: 2.303 CP1X2: 2.360 pred: 2.379, error 0.019\n",
            "OP1X2: 1.306 CP1X2: 1.457 pred: 1.364, error 0.093\n",
            "OP1X2: 2.147 CP1X2: 1.885 pred: 2.244, error 0.359\n",
            "OP1X2: 4.605 CP1X2: 4.732 pred: 4.911, error 0.179\n",
            "OP1X2: 4.095 CP1X2: 4.575 pred: 4.602, error 0.027\n",
            "OP1X2: 1.622 CP1X2: 1.523 pred: 1.536, error 0.013\n",
            "OP1X2: 2.109 CP1X2: 2.104 pred: 2.124, error 0.020\n",
            "OP1X2: 4.015 CP1X2: 4.581 pred: 4.228, error 0.353\n",
            "OP1X2: 1.240 CP1X2: 1.314 pred: 1.323, error 0.009\n",
            "OP1X2: 1.975 CP1X2: 2.128 pred: 2.027, error 0.101\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.819 CP1X2: 3.417 pred: 1579806.125, error 1579802.750\n",
            "OP1X2: 1.424 CP1X2: 1.431 pred: 1.530, error 0.099\n",
            "OP1X2: 2.755 CP1X2: 3.515 pred: 2.734, error 0.781\n",
            "OP1X2: 1.563 CP1X2: 1.584 pred: 1.578, error 0.006\n",
            "OP1X2: 5.564 CP1X2: 6.747 pred: 5.869, error 0.878\n",
            "OP1X2: 1.848 CP1X2: 1.829 pred: 1.734, error 0.095\n",
            "OP1X2: 2.297 CP1X2: 2.243 pred: 2.309, error 0.066\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.931 CP1X2: 1.791 pred: 1579805.125, error 1579803.375\n",
            "OP1X2: 2.016 CP1X2: 2.170 pred: 2.000, error 0.170\n",
            "OP1X2: 2.006 CP1X2: 1.965 pred: 1.930, error 0.035\n",
            "OP1X2: 2.172 CP1X2: 2.542 pred: 2.255, error 0.287\n",
            "OP1X2: 2.058 CP1X2: 1.896 pred: 2.089, error 0.193\n",
            "OP1X2: 2.388 CP1X2: 2.642 pred: 2.353, error 0.289\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.637 CP1X2: 2.503 pred: 1579806.125, error 1579803.625\n",
            "OP1X2: 1.938 CP1X2: 2.154 pred: 1.963, error 0.191\n",
            "OP1X2: 1.270 CP1X2: 1.258 pred: 1.257, error 0.001\n",
            "OP1X2: 1.538 CP1X2: 1.571 pred: 1.537, error 0.034\n",
            "OP1X2: 1.648 CP1X2: 1.712 pred: 1.610, error 0.102\n",
            "OP1X2: 2.918 CP1X2: 3.951 pred: 3.157, error 0.794\n",
            "OP1X2: 2.111 CP1X2: 1.919 pred: 2.112, error 0.193\n",
            "OP1X2: 3.116 CP1X2: 3.324 pred: 3.295, error 0.029\n",
            "OP1X2: 2.506 CP1X2: 3.080 pred: 2.659, error 0.421\n",
            "OP1X2: 2.067 CP1X2: 1.934 pred: 2.096, error 0.162\n",
            "OP1X2: 1.885 CP1X2: 1.876 pred: 1.876, error 0.000\n",
            "OP1X2: 2.080 CP1X2: 2.417 pred: 2.161, error 0.256\n",
            "OP1X2: 4.759 CP1X2: 4.976 pred: 4.541, error 0.435\n",
            "OP1X2: 5.086 CP1X2: 3.615 pred: 5.334, error 1.719\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.350 CP1X2: 1.293 pred: 1579804.500, error 1579803.250\n",
            "OP1X2: 2.623 CP1X2: 2.765 pred: 2.498, error 0.267\n",
            "OP1X2: 2.717 CP1X2: 2.692 pred: 2.836, error 0.144\n",
            "OP1X2: 1.594 CP1X2: 1.605 pred: 1.614, error 0.009\n",
            "OP1X2: 2.360 CP1X2: 2.386 pred: 2.409, error 0.023\n",
            "OP1X2: 1.264 CP1X2: 1.286 pred: 1.361, error 0.075\n",
            "OP1X2: 1.870 CP1X2: 1.665 pred: 1.725, error 0.060\n",
            "OP1X2: 2.102 CP1X2: 2.115 pred: 2.110, error 0.005\n",
            "OP1X2: 2.236 CP1X2: 2.737 pred: 2.352, error 0.385\n",
            "OP1X2: 1.374 CP1X2: 1.394 pred: 1.394, error 0.000\n",
            "OP1X2: 3.643 CP1X2: 3.743 pred: 3.742, error 0.001\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.820 CP1X2: 3.436 pred: 1579806.375, error 1579803.000\n",
            "OP1X2: 3.675 CP1X2: 4.834 pred: 4.043, error 0.791\n",
            "OP1X2: 1.743 CP1X2: 1.739 pred: 1.692, error 0.047\n",
            "OP1X2: 1.875 CP1X2: 2.093 pred: 1.846, error 0.247\n",
            "OP1X2: 3.351 CP1X2: 2.394 pred: 3.522, error 1.128\n",
            "OP1X2: 2.244 CP1X2: 2.639 pred: 2.325, error 0.314\n",
            "OP1X2: 1.895 CP1X2: 1.954 pred: 1.939, error 0.015\n",
            "OP1X2: 3.329 CP1X2: 4.778 pred: 3.405, error 1.373\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.580 CP1X2: 2.590 pred: 1579806.125, error 1579803.500\n",
            "OP1X2: 2.484 CP1X2: 2.789 pred: 2.432, error 0.357\n",
            "OP1X2: 2.703 CP1X2: 2.397 pred: 2.840, error 0.443\n",
            "OP1X2: 1.764 CP1X2: 1.781 pred: 1.816, error 0.035\n",
            "OP1X2: 2.164 CP1X2: 1.985 pred: 2.172, error 0.187\n",
            "OP1X2: 1.383 CP1X2: 1.322 pred: 1.436, error 0.114\n",
            "OP1X2: 3.377 CP1X2: 3.773 pred: 3.495, error 0.278\n",
            "OP1X2: 3.548 CP1X2: 3.847 pred: 3.509, error 0.338\n",
            "OP1X2: 2.653 CP1X2: 2.777 pred: 2.564, error 0.213\n",
            "OP1X2: 1.262 CP1X2: 1.355 pred: 1.383, error 0.028\n",
            "OP1X2: 1.371 CP1X2: 1.322 pred: 1.364, error 0.042\n",
            "OP1X2: 2.718 CP1X2: 3.270 pred: 2.911, error 0.359\n",
            "OP1X2: 2.195 CP1X2: 2.668 pred: 2.194, error 0.474\n",
            "OP1X2: 1.975 CP1X2: 2.223 pred: 1.944, error 0.279\n",
            "OP1X2: 1.506 CP1X2: 1.687 pred: 1.510, error 0.177\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.594 CP1X2: 1.644 pred: 1579804.750, error 1579803.125\n",
            "OP1X2: 3.573 CP1X2: 3.144 pred: 3.749, error 0.605\n",
            "OP1X2: 1.385 CP1X2: 1.405 pred: 1.410, error 0.005\n",
            "OP1X2: 6.293 CP1X2: 5.543 pred: 6.973, error 1.430\n",
            "OP1X2: 1.958 CP1X2: 1.998 pred: 1.873, error 0.125\n",
            "OP1X2: 1.763 CP1X2: 1.643 pred: 1.551, error 0.092\n",
            "OP1X2: 2.210 CP1X2: 2.093 pred: 2.342, error 0.249\n",
            "OP1X2: 1.425 CP1X2: 1.395 pred: 1.487, error 0.092\n",
            "OP1X2: 2.099 CP1X2: 2.257 pred: 2.157, error 0.100\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.405 CP1X2: 1.386 pred: 1579804.500, error 1579803.125\n",
            "OP1X2: 1.741 CP1X2: 1.705 pred: 1.844, error 0.139\n",
            "OP1X2: 2.653 CP1X2: 2.734 pred: 2.591, error 0.143\n",
            "OP1X2: 1.301 CP1X2: 1.209 pred: 1.351, error 0.142\n",
            "OP1X2: 1.610 CP1X2: 1.658 pred: 1.584, error 0.074\n",
            "OP1X2: 3.146 CP1X2: 2.292 pred: 3.518, error 1.226\n",
            "OP1X2: 4.289 CP1X2: 5.005 pred: 4.509, error 0.496\n",
            "OP1X2: 1.737 CP1X2: 1.521 pred: 1.798, error 0.277\n",
            "OP1X2: 1.814 CP1X2: 2.133 pred: 1.805, error 0.328\n",
            "OP1X2: 3.496 CP1X2: 3.120 pred: 3.663, error 0.543\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 5.376 CP1X2: 7.147 pred: 1579808.500, error 1579801.375\n",
            "OP1X2: 1.557 CP1X2: 1.463 pred: 1.588, error 0.125\n",
            "OP1X2: 2.140 CP1X2: 1.937 pred: 2.265, error 0.328\n",
            "OP1X2: 1.676 CP1X2: 1.559 pred: 1.637, error 0.078\n",
            "OP1X2: 1.349 CP1X2: 1.312 pred: 1.385, error 0.073\n",
            "OP1X2: 1.300 CP1X2: 1.317 pred: 1.425, error 0.108\n",
            "OP1X2: 2.633 CP1X2: 3.327 pred: 2.729, error 0.598\n",
            "OP1X2: 3.457 CP1X2: 2.996 pred: 3.694, error 0.698\n",
            "OP1X2: 2.785 CP1X2: 3.760 pred: 3.037, error 0.723\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 1.641 CP1X2: 1.382 pred: 1579804.500, error 1579803.125\n",
            "OP1X2: 2.530 CP1X2: 3.730 pred: 2.670, error 1.060\n",
            "OP1X2: 1.910 CP1X2: 1.897 pred: 1.780, error 0.117\n",
            "OP1X2: 1.241 CP1X2: 1.215 pred: 1.309, error 0.094\n",
            "OP1X2: 2.608 CP1X2: 2.539 pred: 2.798, error 0.259\n",
            "OP1X2: 2.286 CP1X2: 2.647 pred: 2.453, error 0.194\n",
            "OP1X2: 2.767 CP1X2: 3.163 pred: 2.961, error 0.202\n",
            "error too high, ignoring in calculation: Almeria\n",
            "OP1X2: 2.243 CP1X2: 2.119 pred: 1579805.750, error 1579803.625\n",
            "OP1X2: 1.314 CP1X2: 1.219 pred: 1.394, error 0.175\n",
            "OP1X2: 3.341 CP1X2: 4.479 pred: 3.255, error 1.224\n",
            "OP1X2: 2.250 CP1X2: 2.330 pred: 2.250, error 0.080\n",
            "OP1X2: 2.313 CP1X2: 2.342 pred: 2.329, error 0.013\n",
            "OP1X2: 1.861 CP1X2: 1.932 pred: 1.821, error 0.111\n",
            "mean abs error: 0.254797235218405\n",
            "avg percent error: 0.08585045960290694\n",
            "too high: 76 occurences , avg of 1579803.105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.evaluate(om_test_features, om_test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftio2R7SoYiG",
        "outputId": "f038f9cf-d0d6-44ad-b3f9-7d5e52588db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160335.9844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160112.5"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "om_train_features[:10]"
      ],
      "metadata": {
        "id": "9NW0HyRpU846"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mse(predictions, op_col, cp_col, db):\n",
        "\n",
        "  # print(\"target\")\n",
        "  # print(target)\n",
        "  num = len(predictions)\n",
        "  if (len(predictions)) != len(op_col) or len(op_col) != len(cp_col):\n",
        "    ValueError(\"wrong\")\n",
        "  error_sum = 0\n",
        "  percent_diff_sum = 0\n",
        "  too_high_count = 0\n",
        "  too_high_sum = 0\n",
        "  too_high_rows = []\n",
        "  print(db[\"Almeria\"])\n",
        "  for prediction, op_val, cp_val, (index, row) in zip(predictions, op_col, cp_col, db.iterrows()):\n",
        "    prediction = prediction[0]\n",
        "    error = abs(prediction - cp_val)\n",
        "    if error > 10:\n",
        "      num -= 1\n",
        "      too_high_count += 1\n",
        "      too_high_sum += error\n",
        "\n",
        "      if (row[\"Almeria\"] == 1):\n",
        "        print(f\"error too high, ignoring in calculation: Almeria\")\n",
        "      else:\n",
        "        print(f\"error too high, ignoring in calculation: NOT Almeria\")\n",
        "        print(f\"{row}\")\n",
        "    else:\n",
        "      error_sum += error\n",
        "      percent_diff_sum += error/cp_val\n",
        "    print(f\"OP1X2: {format(op_val, '.3f')} CP1X2: {format(cp_val, '.3f')} pred: {format(prediction, '.3f')}, error {format(error, '.3f')}\")\n",
        "\n",
        "  print(f\"mean abs error: {error_sum/num}\")\n",
        "  print(f\"avg percent error: {percent_diff_sum/num}\")\n",
        "  print(f\"too high: {too_high_count} occurences , avg of {too_high_sum/too_high_count}\")"
      ],
      "metadata": {
        "id": "BmgoudsUPYnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f\"{pwd}/OP1_point_25_too_high_sometimes.keras\"\n",
        "model_5.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHRN84ZhfRQN",
        "outputId": "e1b7bfea-08c0-4449-ed00-329efa2f7b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/JSIP Final Project/dbs/OP1_point_25_too_high_sometimes.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model freaks out when evaluating a game with Almeria in it because they've never played in the dataset we're training on, so it just doesnt know what to do and assumes theyll lose by a lot.\n",
        "\n",
        "this kind of works out because theyre a terrible team (19/20), so they probably will lose"
      ],
      "metadata": {
        "id": "bkRKAwrymEJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##diff model##"
      ],
      "metadata": {
        "id": "Uanma6X33tRs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tKHFGJN3xgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset_with_result()"
      ],
      "metadata": {
        "id": "_p2jJoaEz_3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_keys = [\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"DIFF1\", \"DIFFX\", \"DIFF2\"]\n",
        "other_dropped_keys = [\"result\", \"OP_MAX_ODD\", \"OP_MID_ODD\", \"OP_MIN_ODD\"]\n",
        "curr_label = \"DIFF1\"\n",
        "# dataset_uv[\"undervalued\"] = get_max_diff(dataset_uv, False)\n",
        "# dataset_uv = dataset_uv.drop(label_keys, axis=1)\n",
        "dataset_dm = get_diff_database(dataset.copy())\n",
        "dataset_dm = get_weighted_OHE_dataset(dataset_dm)\n",
        "dataset_dm = get_stat_percent_database(dataset_dm)\n",
        "dataset_dm = get_odds_percent_database(dataset_dm)\n",
        "dataset_dm = get_power_database(dataset_dm)\n",
        "dataset_dm = get_odds_rankings(dataset_dm, True)\n",
        "dataset_dm = dataset_dm[dataset_dm[\"games\"] >= 4]\n",
        "dm_train, dm_test = split_dataset(dataset_dm, True)\n",
        "dm_train = dm_train.sample(frac=1)\n",
        "# uv_train, uv_test = split_dataset(uv_train, True)\n",
        "dm_train_target = dm_train[curr_label].drop(columns=other_dropped_keys)\n",
        "dm_test_target = dm_test[curr_label].drop(columns=other_dropped_keys)\n",
        "dm_train_features = dm_train.drop(columns=dropped_keys).drop(columns=other_dropped_keys)\n",
        "dm_test_features = dm_test.drop(columns=dropped_keys).drop(columns=other_dropped_keys)\n",
        "\n",
        "# dm_train_target = np.array(dm_train_target).astype('float32')\n",
        "# dm_test_target = np.array(dm_test_target).astype('float32')\n",
        "# dm_train_features = np.array(dm_train_features).astype('float32')\n",
        "# dm_test_features = np.array(dm_test_features).astype('float32')"
      ],
      "metadata": {
        "id": "4N1itCx23vHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm_test_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "FruvUPsYvkMj",
        "outputId": "1b00f555-0d72-4654-b40f-557ee8d8fc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  OP1_AVG  OPX_AVG  OP2_AVG  Alaves  Almeria  Ath Bilbao  \\\n",
              "2580     30    3.627    3.395    2.042       0        0           0   \n",
              "2581     30    4.420    3.376    1.842       0        0           0   \n",
              "2582     30    2.045    3.386    3.581       0        0           1   \n",
              "2583     30    1.343    4.915    8.984       0        0           0   \n",
              "2584     30    1.790    3.463    4.650       1        0           0   \n",
              "...     ...      ...      ...      ...     ...      ...         ...   \n",
              "3415     37    1.314    5.714    7.809       0        0           0   \n",
              "3416     37    3.341    3.939    1.954       0        0           0   \n",
              "3417     37    2.250    3.304    3.124       0        0           0   \n",
              "3418     37    2.313    3.401    2.947       1        0           0   \n",
              "3419     37    1.861    3.684    3.929       0        0           0   \n",
              "\n",
              "      Atl. Madrid  Barcelona  Betis  Cadiz CF  Celta Vigo  Dep. La Coruna  \\\n",
              "2580            0          0      1         2           0               0   \n",
              "2581            1          0      0         0           0               0   \n",
              "2582            0          0      0         0           0               0   \n",
              "2583            0          0      0         0           0               0   \n",
              "2584            0          0      0         0           0               0   \n",
              "...           ...        ...    ...       ...         ...             ...   \n",
              "3415            0          0      1         0           0               0   \n",
              "3416            0          1      0         0           0               0   \n",
              "3417            0          0      0         0           0               0   \n",
              "3418            0          0      0         0           0               0   \n",
              "3419            0          0      0         0           2               0   \n",
              "\n",
              "      Eibar  Elche  Espanyol  Getafe  Gijon  Girona  Granada CF  Huesca  \\\n",
              "2580      0      0         0       0      0       0           0       0   \n",
              "2581      0      0         0       0      0       0           0       0   \n",
              "2582      0      0         0       0      0       0           0       0   \n",
              "2583      0      0         0       1      0       0           0       0   \n",
              "2584      0      0         0       0      0       0           0       0   \n",
              "...     ...    ...       ...     ...    ...     ...         ...     ...   \n",
              "3415      0      0         0       0      0       0           0       0   \n",
              "3416      0      0         0       0      0       0           0       0   \n",
              "3417      0      0         0       2      0       0           0       0   \n",
              "3418      0      0         0       0      0       0           0       0   \n",
              "3419      0      0         0       0      0       0           0       0   \n",
              "\n",
              "      Las Palmas  Leganes  Levante  Malaga  Mallorca  Osasuna  Rayo Vallecano  \\\n",
              "2580           0        0        0       0         0        0               0   \n",
              "2581           0        0        0       0         2        0               0   \n",
              "2582           0        0        0       0         0        0               0   \n",
              "2583           0        0        0       0         0        0               0   \n",
              "2584           0        0        0       0         0        2               0   \n",
              "...          ...      ...      ...     ...       ...      ...             ...   \n",
              "3415           0        0        0       0         0        0               0   \n",
              "3416           0        0        0       0         0        0               0   \n",
              "3417           0        0        0       0         1        0               0   \n",
              "3418           2        0        0       0         0        0               0   \n",
              "3419           0        0        0       0         0        0               0   \n",
              "\n",
              "      Real Madrid  Real Sociedad  Sevilla  Valencia  Valladolid  Villarreal  \\\n",
              "2580            0              0        0         0           0           0   \n",
              "2581            0              0        0         0           0           0   \n",
              "2582            0              0        0         0           0           2   \n",
              "2583            2              0        0         0           0           0   \n",
              "2584            0              0        0         0           0           0   \n",
              "...           ...            ...      ...       ...         ...         ...   \n",
              "3415            2              0        0         0           0           0   \n",
              "3416            0              0        2         0           0           0   \n",
              "3417            0              0        0         0           0           0   \n",
              "3418            0              0        0         0           0           0   \n",
              "3419            0              0        0         1           0           0   \n",
              "\n",
              "      home_wins_rate  home_tie_rate  home_loss_rate  away_wins_rate  \\\n",
              "2580        0.166667       0.433333        0.400000        0.533333   \n",
              "2581        0.200000       0.266667        0.533333        0.566667   \n",
              "2582        0.400000       0.300000        0.300000        0.366667   \n",
              "2583        0.700000       0.200000        0.100000        0.233333   \n",
              "2584        0.333333       0.266667        0.400000        0.166667   \n",
              "...              ...            ...             ...             ...   \n",
              "3415        0.783784       0.189189        0.027027        0.378378   \n",
              "3416        0.270270       0.297297        0.432432        0.675676   \n",
              "3417        0.270270       0.351351        0.378378        0.189189   \n",
              "3418        0.270270       0.243243        0.486486        0.324324   \n",
              "3419        0.270270       0.270270        0.459459        0.351351   \n",
              "\n",
              "      away_tie_rate  away_loss_rate  OP1_RATE  OPX_RATE  OP2_RATE  HOME_POWER  \n",
              "2580       0.166667        0.300000  0.400154  0.374559  0.225287    0.621622  \n",
              "2581       0.200000        0.233333  0.458601  0.350280  0.191118    0.500000  \n",
              "2582       0.366667        0.266667  0.226920  0.375721  0.397359    1.000000  \n",
              "2583       0.366667        0.400000  0.088112  0.322464  0.589424    1.920000  \n",
              "2584       0.233333        0.600000  0.180753  0.349692  0.469555    1.647059  \n",
              "...             ...             ...       ...       ...       ...         ...  \n",
              "3415       0.378378        0.243243  0.088562  0.385118  0.526319    1.547619  \n",
              "3416       0.189189        0.135135  0.361815  0.426576  0.211609    0.543860  \n",
              "3417       0.432432        0.378378  0.259276  0.380733  0.359991    1.100000  \n",
              "3418       0.243243        0.432432  0.267059  0.392680  0.340261    0.878788  \n",
              "3419       0.243243        0.405405  0.196432  0.388854  0.414714    0.857143  \n",
              "\n",
              "[760 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85f5488e-5bef-4df7-9dab-620dbf0be2da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2580</th>\n",
              "      <td>30</td>\n",
              "      <td>3.627</td>\n",
              "      <td>3.395</td>\n",
              "      <td>2.042</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.400154</td>\n",
              "      <td>0.374559</td>\n",
              "      <td>0.225287</td>\n",
              "      <td>0.621622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2581</th>\n",
              "      <td>30</td>\n",
              "      <td>4.420</td>\n",
              "      <td>3.376</td>\n",
              "      <td>1.842</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.458601</td>\n",
              "      <td>0.350280</td>\n",
              "      <td>0.191118</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>30</td>\n",
              "      <td>2.045</td>\n",
              "      <td>3.386</td>\n",
              "      <td>3.581</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.226920</td>\n",
              "      <td>0.375721</td>\n",
              "      <td>0.397359</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>30</td>\n",
              "      <td>1.343</td>\n",
              "      <td>4.915</td>\n",
              "      <td>8.984</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.088112</td>\n",
              "      <td>0.322464</td>\n",
              "      <td>0.589424</td>\n",
              "      <td>1.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2584</th>\n",
              "      <td>30</td>\n",
              "      <td>1.790</td>\n",
              "      <td>3.463</td>\n",
              "      <td>4.650</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.180753</td>\n",
              "      <td>0.349692</td>\n",
              "      <td>0.469555</td>\n",
              "      <td>1.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>37</td>\n",
              "      <td>1.314</td>\n",
              "      <td>5.714</td>\n",
              "      <td>7.809</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.385118</td>\n",
              "      <td>0.526319</td>\n",
              "      <td>1.547619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>37</td>\n",
              "      <td>3.341</td>\n",
              "      <td>3.939</td>\n",
              "      <td>1.954</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.361815</td>\n",
              "      <td>0.426576</td>\n",
              "      <td>0.211609</td>\n",
              "      <td>0.543860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>37</td>\n",
              "      <td>2.250</td>\n",
              "      <td>3.304</td>\n",
              "      <td>3.124</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.259276</td>\n",
              "      <td>0.380733</td>\n",
              "      <td>0.359991</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>37</td>\n",
              "      <td>2.313</td>\n",
              "      <td>3.401</td>\n",
              "      <td>2.947</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.392680</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>0.878788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3419</th>\n",
              "      <td>37</td>\n",
              "      <td>1.861</td>\n",
              "      <td>3.684</td>\n",
              "      <td>3.929</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.196432</td>\n",
              "      <td>0.388854</td>\n",
              "      <td>0.414714</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>760 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85f5488e-5bef-4df7-9dab-620dbf0be2da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85f5488e-5bef-4df7-9dab-620dbf0be2da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85f5488e-5bef-4df7-9dab-620dbf0be2da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b01d9d8-2559-4909-ad02-ca0be1349559\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b01d9d8-2559-4909-ad02-ca0be1349559')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b01d9d8-2559-4909-ad02-ca0be1349559 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_173cbe41-d916-4409-b49d-05d2e6106ac2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dm_test_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_173cbe41-d916-4409-b49d-05d2e6106ac2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dm_test_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dm_test_features"
            }
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def penalized_loss(y_true, y_pred):\n",
        "    y_true_positive = tf.math.greater_equal(y_true, 0)\n",
        "    y_pred_positive = tf.math.greater_equal(y_pred, 0)\n",
        "    y_true_negative = tf.math.less_equal(y_true, 0)\n",
        "    y_pred_negative = tf.math.less_equal(y_pred, 0)\n",
        "    both_pos = tf.math.logical_and(y_true_positive, y_pred_positive)\n",
        "    both_neg = tf.math.logical_and(y_true_negative, y_pred_negative)\n",
        "    same_dir = tf.math.logical_or(both_pos, both_neg)\n",
        "    # wrong_dir = tf.math.logical_not(same_dir)\n",
        "    # mask = tf.where(wrong_dir, 1., 0.)\n",
        "    # mask = tf.where(wrong_dir, y_true, 10000000000000.)\n",
        "    # loss = tf.math.abs((y_true - y_pred))\n",
        "    mae = tf.keras.losses.MeanAbsoluteError()\n",
        "    loss = mae(y_true, y_pred)\n",
        "    new_loss = tf.where(same_dir, loss, loss * 10.10)\n",
        "\n",
        "\n",
        "\n",
        "    # y_pred_addition = tf.math.add(mask, y_pred)\n",
        "    return tf.math.reduce_mean(new_loss)\n",
        "\n",
        "\n",
        "class WeightedMeanAbsoluteError(tf.keras.losses.MeanAbsoluteError):\n",
        "    def call(self, y_true, y_pred):\n",
        "        tf.get_logger().setLevel(\"DEBUG\")\n",
        "        tf.get_logger().debug(y_true)\n",
        "        y_true_positive = tf.math.greater(y_true, 0)\n",
        "        y_pred_positive = tf.math.greater(y_pred, 0)\n",
        "        y_true_negative = tf.math.less(y_true, 0)\n",
        "        y_pred_negative= tf.math.less(y_pred, 0)\n",
        "        both_pos = tf.math.logical_and(y_true_positive, y_pred_positive)\n",
        "        both_neg = tf.math.logical_and(y_true_negative, y_pred_negative)\n",
        "        same_dir = tf.math.logical_or(both_pos, both_neg)\n",
        "        wrong_dir = tf.math.logical_not(same_dir)\n",
        "        # mask = tf.where(wrong_dir, 1., 0.)\n",
        "        mask = tf.math.multiply(tf.cast(wrong_dir, tf.float32), 2)\n",
        "\n",
        "        y_pred_addition = tf.math.multiply(mask, y_true)\n",
        "        # y_pred = tf.math.add(y_pred, y_pred_addition)\n",
        "        return super().call(y_true, y_pred)"
      ],
      "metadata": {
        "id": "5_Ml60b47Tb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(dm_train_features))\n",
        "steps_per_epoch = len(dm_train_features)/32\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "      # normalizer,\n",
        "      layers.Dense(20),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.5),\n",
        "      layers.Dense(10),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.5),\n",
        "      # layers.Dense(10),\n",
        "      # layers.LeakyReLU(),\n",
        "      # layers.Dropout(rate=0.5),\n",
        "      layers.Dense(10),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.5),\n",
        "      layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_6.compile(\n",
        "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=1.0),\n",
        "    loss=tf.keras.losses.MSE)"
      ],
      "metadata": {
        "id": "bNL4yyMK4RBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_6.fit(\n",
        "    np.array(dm_train_features),\n",
        "    np.array(dm_train_target),\n",
        "    epochs=500,\n",
        "    callbacks=[early_stopping],\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split=0.2\n",
        "    # validation_data=(om_train_features[40:50], om_train_target[40:50])\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnENGO9v4Ueo",
        "outputId": "09d6c9e5-b520-4f85-fa07-0d075e4f5543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2019828.2500 - val_loss: 301.5154\n",
            "Epoch 2/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7820.7881 - val_loss: 3.3903\n",
            "Epoch 3/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2645.9634 - val_loss: 18.9266\n",
            "Epoch 4/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1366.1985 - val_loss: 1.5544\n",
            "Epoch 5/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 865.2478 - val_loss: 4.2492\n",
            "Epoch 6/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 566.8868 - val_loss: 7.2075\n",
            "Epoch 7/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.2590 - val_loss: 7.9838\n",
            "Epoch 8/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.9337 - val_loss: 3.9087\n",
            "Epoch 9/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.9386 - val_loss: 4.2197\n",
            "Epoch 10/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.5704 - val_loss: 3.4911\n",
            "Epoch 11/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.4085 - val_loss: 2.4976\n",
            "Epoch 12/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72.2394 - val_loss: 1.8556\n",
            "Epoch 13/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.7394 - val_loss: 2.1888\n",
            "Epoch 14/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.5158 - val_loss: 1.0781\n",
            "Epoch 15/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39.2754 - val_loss: 1.6794\n",
            "Epoch 16/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.0828 - val_loss: 1.6702\n",
            "Epoch 17/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.6805 - val_loss: 1.0267\n",
            "Epoch 18/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.6108 - val_loss: 0.7773\n",
            "Epoch 19/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.5451 - val_loss: 1.7643\n",
            "Epoch 20/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7554 - val_loss: 0.7634\n",
            "Epoch 21/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2437 - val_loss: 0.9024\n",
            "Epoch 22/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.8259 - val_loss: 0.7875\n",
            "Epoch 23/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.6775 - val_loss: 0.6312\n",
            "Epoch 24/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8688 - val_loss: 0.6651\n",
            "Epoch 25/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7145 - val_loss: 0.7793\n",
            "Epoch 26/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8956 - val_loss: 0.5385\n",
            "Epoch 27/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6424 - val_loss: 0.6038\n",
            "Epoch 28/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3026 - val_loss: 0.6881\n",
            "Epoch 29/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0457 - val_loss: 0.6339\n",
            "Epoch 30/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4700 - val_loss: 0.6126\n",
            "Epoch 31/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6388 - val_loss: 0.5289\n",
            "Epoch 32/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3976 - val_loss: 0.6506\n",
            "Epoch 33/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8540 - val_loss: 0.7173\n",
            "Epoch 34/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3163 - val_loss: 0.5854\n",
            "Epoch 35/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6007 - val_loss: 0.6582\n",
            "Epoch 36/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6186 - val_loss: 0.5529\n",
            "Epoch 37/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5160 - val_loss: 0.6458\n",
            "Epoch 38/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1039 - val_loss: 0.5713\n",
            "Epoch 39/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0351 - val_loss: 0.5227\n",
            "Epoch 40/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2978 - val_loss: 0.5728\n",
            "Epoch 41/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3569 - val_loss: 0.5468\n",
            "Epoch 42/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6631 - val_loss: 0.5165\n",
            "Epoch 43/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4435 - val_loss: 0.5650\n",
            "Epoch 44/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5590 - val_loss: 0.5404\n",
            "Epoch 45/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8413 - val_loss: 0.5862\n",
            "Epoch 46/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9662 - val_loss: 0.5120\n",
            "Epoch 47/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0560 - val_loss: 0.5120\n",
            "Epoch 48/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6946 - val_loss: 0.4978\n",
            "Epoch 49/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7173 - val_loss: 0.5483\n",
            "Epoch 50/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9009 - val_loss: 0.4836\n",
            "Epoch 51/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8729 - val_loss: 0.5027\n",
            "Epoch 52/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4373 - val_loss: 0.4925\n",
            "Epoch 53/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6267 - val_loss: 0.4576\n",
            "Epoch 54/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6163 - val_loss: 0.5047\n",
            "Epoch 55/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2284 - val_loss: 0.4674\n",
            "Epoch 56/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2682 - val_loss: 0.4568\n",
            "Epoch 57/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2245 - val_loss: 0.4729\n",
            "Epoch 58/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0653 - val_loss: 0.4885\n",
            "Epoch 59/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9980 - val_loss: 0.4831\n",
            "Epoch 60/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1936 - val_loss: 0.4974\n",
            "Epoch 61/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1159 - val_loss: 0.4842\n",
            "Epoch 62/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9268 - val_loss: 0.4891\n",
            "Epoch 63/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1407 - val_loss: 0.4648\n",
            "Epoch 64/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1928 - val_loss: 0.4702\n",
            "Epoch 65/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8586 - val_loss: 0.4662\n",
            "Epoch 66/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7365 - val_loss: 0.4811\n",
            "Epoch 67/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7689 - val_loss: 0.4695\n",
            "Epoch 68/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9489 - val_loss: 0.4631\n",
            "Epoch 69/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6416 - val_loss: 0.4566\n",
            "Epoch 70/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7467 - val_loss: 0.4611\n",
            "Epoch 71/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0722 - val_loss: 0.4583\n",
            "Epoch 72/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7682 - val_loss: 0.4582\n",
            "Epoch 73/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6982 - val_loss: 0.4657\n",
            "Epoch 74/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8897 - val_loss: 0.4635\n",
            "Epoch 75/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7499 - val_loss: 0.4584\n",
            "Epoch 76/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0319 - val_loss: 0.4640\n",
            "Epoch 77/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7270 - val_loss: 0.4594\n",
            "Epoch 78/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6573 - val_loss: 0.4583\n",
            "Epoch 79/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7002 - val_loss: 0.4699\n",
            "Epoch 80/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6285 - val_loss: 0.4600\n",
            "Epoch 81/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1041 - val_loss: 0.4562\n",
            "Epoch 82/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5857 - val_loss: 0.4551\n",
            "Epoch 83/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6278 - val_loss: 0.4571\n",
            "Epoch 84/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7591 - val_loss: 0.4563\n",
            "Epoch 85/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4619 - val_loss: 0.4588\n",
            "Epoch 86/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6817 - val_loss: 0.4576\n",
            "Epoch 87/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8625 - val_loss: 0.4593\n",
            "Epoch 88/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7388 - val_loss: 0.4526\n",
            "Epoch 89/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6198 - val_loss: 0.4506\n",
            "Epoch 90/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6018 - val_loss: 0.4527\n",
            "Epoch 91/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8730 - val_loss: 0.4520\n",
            "Epoch 92/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4605 - val_loss: 0.4626\n",
            "Epoch 93/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6849 - val_loss: 0.4542\n",
            "Epoch 94/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5121 - val_loss: 0.4528\n",
            "Epoch 95/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6137 - val_loss: 0.4554\n",
            "Epoch 96/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5887 - val_loss: 0.4489\n",
            "Epoch 97/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6610 - val_loss: 0.4495\n",
            "Epoch 98/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4603 - val_loss: 0.4585\n",
            "Epoch 99/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6193 - val_loss: 0.4502\n",
            "Epoch 100/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5142 - val_loss: 0.4547\n",
            "Epoch 101/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4436 - val_loss: 0.4487\n",
            "Epoch 102/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6580 - val_loss: 0.4547\n",
            "Epoch 103/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8396 - val_loss: 0.4501\n",
            "Epoch 104/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5198 - val_loss: 0.4474\n",
            "Epoch 105/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6503 - val_loss: 0.4465\n",
            "Epoch 106/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6551 - val_loss: 0.4452\n",
            "Epoch 107/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9033 - val_loss: 0.4436\n",
            "Epoch 108/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5944 - val_loss: 0.4466\n",
            "Epoch 109/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7761 - val_loss: 0.4455\n",
            "Epoch 110/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4654 - val_loss: 0.4514\n",
            "Epoch 111/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4232 - val_loss: 0.4530\n",
            "Epoch 112/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5362 - val_loss: 0.4498\n",
            "Epoch 113/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5444 - val_loss: 0.4457\n",
            "Epoch 114/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4858 - val_loss: 0.4458\n",
            "Epoch 115/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4697 - val_loss: 0.4481\n",
            "Epoch 116/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5546 - val_loss: 0.4438\n",
            "Epoch 117/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6723 - val_loss: 0.4462\n",
            "Epoch 118/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4819 - val_loss: 0.4456\n",
            "Epoch 119/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5830 - val_loss: 0.4488\n",
            "Epoch 120/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7586 - val_loss: 0.4434\n",
            "Epoch 121/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4872 - val_loss: 0.4452\n",
            "Epoch 122/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4942 - val_loss: 0.4482\n",
            "Epoch 123/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5768 - val_loss: 0.4420\n",
            "Epoch 124/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6702 - val_loss: 0.4444\n",
            "Epoch 125/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6047 - val_loss: 0.4445\n",
            "Epoch 126/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5153 - val_loss: 0.4456\n",
            "Epoch 127/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5958 - val_loss: 0.4427\n",
            "Epoch 128/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4916 - val_loss: 0.4440\n",
            "Epoch 129/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5846 - val_loss: 0.4421\n",
            "Epoch 130/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5061 - val_loss: 0.4419\n",
            "Epoch 131/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5646 - val_loss: 0.4443\n",
            "Epoch 132/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5184 - val_loss: 0.4417\n",
            "Epoch 133/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5664 - val_loss: 0.4450\n",
            "Epoch 134/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6854 - val_loss: 0.4440\n",
            "Epoch 135/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5682 - val_loss: 0.4428\n",
            "Epoch 136/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5085 - val_loss: 0.4433\n",
            "Epoch 137/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3724 - val_loss: 0.4422\n",
            "Epoch 138/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4041 - val_loss: 0.4547\n",
            "Epoch 139/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4029 - val_loss: 0.4449\n",
            "Epoch 140/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4696 - val_loss: 0.4457\n",
            "Epoch 141/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4939 - val_loss: 0.4450\n",
            "Epoch 142/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5497 - val_loss: 0.4414\n",
            "Epoch 143/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6038 - val_loss: 0.4458\n",
            "Epoch 144/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4476 - val_loss: 0.4448\n",
            "Epoch 145/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4678 - val_loss: 0.4423\n",
            "Epoch 146/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6398 - val_loss: 0.4416\n",
            "Epoch 147/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6137 - val_loss: 0.4447\n",
            "Epoch 148/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8230 - val_loss: 0.4431\n",
            "Epoch 149/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9268 - val_loss: 0.4420\n",
            "Epoch 150/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7519 - val_loss: 0.4437\n",
            "Epoch 151/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5934 - val_loss: 0.4410\n",
            "Epoch 152/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6590 - val_loss: 0.4429\n",
            "Epoch 153/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5574 - val_loss: 0.4411\n",
            "Epoch 154/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4454 - val_loss: 0.4434\n",
            "Epoch 155/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4791 - val_loss: 0.4421\n",
            "Epoch 156/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6365 - val_loss: 0.4435\n",
            "Epoch 157/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7404 - val_loss: 0.4415\n",
            "Epoch 158/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5145 - val_loss: 0.4416\n",
            "Epoch 159/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5905 - val_loss: 0.4416\n",
            "Epoch 160/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4828 - val_loss: 0.4420\n",
            "Epoch 161/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6203 - val_loss: 0.4408\n",
            "Epoch 162/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4017 - val_loss: 0.4451\n",
            "Epoch 163/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5886 - val_loss: 0.4412\n",
            "Epoch 164/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6831 - val_loss: 0.4415\n",
            "Epoch 165/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4394 - val_loss: 0.4427\n",
            "Epoch 166/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4816 - val_loss: 0.4527\n",
            "Epoch 167/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5904 - val_loss: 0.4446\n",
            "Epoch 168/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5204 - val_loss: 0.4422\n",
            "Epoch 169/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5219 - val_loss: 0.4434\n",
            "Epoch 170/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7199 - val_loss: 0.4414\n",
            "Epoch 171/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7365 - val_loss: 0.4441\n",
            "Epoch 172/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8584 - val_loss: 0.4426\n",
            "Epoch 173/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6138 - val_loss: 0.4404\n",
            "Epoch 174/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4976 - val_loss: 0.4445\n",
            "Epoch 175/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5364 - val_loss: 0.4405\n",
            "Epoch 176/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6116 - val_loss: 0.4413\n",
            "Epoch 177/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5653 - val_loss: 0.4442\n",
            "Epoch 178/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5662 - val_loss: 0.4401\n",
            "Epoch 179/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6778 - val_loss: 0.4405\n",
            "Epoch 180/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6477 - val_loss: 0.4410\n",
            "Epoch 181/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8197 - val_loss: 0.4404\n",
            "Epoch 182/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4907 - val_loss: 0.4409\n",
            "Epoch 183/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6063 - val_loss: 0.4403\n",
            "Epoch 184/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7764 - val_loss: 0.4411\n",
            "Epoch 185/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5572 - val_loss: 0.4409\n",
            "Epoch 186/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4371 - val_loss: 0.4422\n",
            "Epoch 187/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4344 - val_loss: 0.4424\n",
            "Epoch 188/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4452 - val_loss: 0.4403\n",
            "Epoch 189/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6590 - val_loss: 0.4417\n",
            "Epoch 190/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9464 - val_loss: 0.4400\n",
            "Epoch 191/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4509 - val_loss: 0.4400\n",
            "Epoch 192/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5826 - val_loss: 0.4410\n",
            "Epoch 193/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6071 - val_loss: 0.4416\n",
            "Epoch 194/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6134 - val_loss: 0.4402\n",
            "Epoch 195/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7417 - val_loss: 0.4402\n",
            "Epoch 196/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5703 - val_loss: 0.4453\n",
            "Epoch 197/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5241 - val_loss: 0.4426\n",
            "Epoch 198/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5503 - val_loss: 0.4401\n",
            "Epoch 199/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7410 - val_loss: 0.4426\n",
            "Epoch 200/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5242 - val_loss: 0.4399\n",
            "Epoch 201/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5147 - val_loss: 0.4409\n",
            "Epoch 202/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5961 - val_loss: 0.4400\n",
            "Epoch 203/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6123 - val_loss: 0.4404\n",
            "Epoch 204/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4828 - val_loss: 0.4402\n",
            "Epoch 205/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6432 - val_loss: 0.4405\n",
            "Epoch 206/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6426 - val_loss: 0.4404\n",
            "Epoch 207/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5431 - val_loss: 0.4499\n",
            "Epoch 208/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4935 - val_loss: 0.4406\n",
            "Epoch 209/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6155 - val_loss: 0.4405\n",
            "Epoch 210/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7005 - val_loss: 0.4407\n",
            "Epoch 211/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5263 - val_loss: 0.4406\n",
            "Epoch 212/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5023 - val_loss: 0.4419\n",
            "Epoch 213/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4968 - val_loss: 0.4397\n",
            "Epoch 214/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5830 - val_loss: 0.4426\n",
            "Epoch 215/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6219 - val_loss: 0.4397\n",
            "Epoch 216/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5482 - val_loss: 0.4399\n",
            "Epoch 217/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4017 - val_loss: 0.4399\n",
            "Epoch 218/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6306 - val_loss: 0.4398\n",
            "Epoch 219/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5517 - val_loss: 0.4400\n",
            "Epoch 220/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5216 - val_loss: 0.4416\n",
            "Epoch 221/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6090 - val_loss: 0.4397\n",
            "Epoch 222/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5752 - val_loss: 0.4415\n",
            "Epoch 223/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4558 - val_loss: 0.4420\n",
            "Epoch 224/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5067 - val_loss: 0.4397\n",
            "Epoch 225/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5422 - val_loss: 0.4420\n",
            "Epoch 226/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6190 - val_loss: 0.4398\n",
            "Epoch 227/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5175 - val_loss: 0.4413\n",
            "Epoch 228/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5043 - val_loss: 0.4399\n",
            "Epoch 229/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6261 - val_loss: 0.4400\n",
            "Epoch 230/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5760 - val_loss: 0.4397\n",
            "Epoch 231/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4770 - val_loss: 0.4404\n",
            "Epoch 232/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4740 - val_loss: 0.4401\n",
            "Epoch 233/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5096 - val_loss: 0.4396\n",
            "Epoch 234/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7337 - val_loss: 0.4396\n",
            "Epoch 235/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7483 - val_loss: 0.4401\n",
            "Epoch 236/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5849 - val_loss: 0.4396\n",
            "Epoch 237/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4976 - val_loss: 0.4396\n",
            "Epoch 238/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5845 - val_loss: 0.4398\n",
            "Epoch 239/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7685 - val_loss: 0.4397\n",
            "Epoch 240/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5480 - val_loss: 0.4412\n",
            "Epoch 241/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7873 - val_loss: 0.4411\n",
            "Epoch 242/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6877 - val_loss: 0.4399\n",
            "Epoch 243/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4030 - val_loss: 0.4403\n",
            "Epoch 244/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8690 - val_loss: 0.4416\n",
            "Epoch 245/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5843 - val_loss: 0.4435\n",
            "Epoch 246/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4295 - val_loss: 0.4406\n",
            "Epoch 247/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4614 - val_loss: 0.4414\n",
            "Epoch 248/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6141 - val_loss: 0.4403\n",
            "Epoch 249/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7070 - val_loss: 0.4399\n",
            "Epoch 250/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8143 - val_loss: 0.4397\n",
            "Epoch 251/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4940 - val_loss: 0.4398\n",
            "Epoch 252/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6349 - val_loss: 0.4401\n",
            "Epoch 253/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7365 - val_loss: 0.4396\n",
            "Epoch 254/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3972 - val_loss: 0.4417\n",
            "Epoch 255/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4966 - val_loss: 0.4399\n",
            "Epoch 256/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7074 - val_loss: 0.4397\n",
            "Epoch 257/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5048 - val_loss: 0.4401\n",
            "Epoch 258/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6822 - val_loss: 0.4397\n",
            "Epoch 259/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4857 - val_loss: 0.4411\n",
            "Epoch 260/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5517 - val_loss: 0.4402\n",
            "Epoch 261/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4931 - val_loss: 0.4406\n",
            "Epoch 262/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4775 - val_loss: 0.4410\n",
            "Epoch 263/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5634 - val_loss: 0.4403\n",
            "Epoch 264/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6018 - val_loss: 0.4402\n",
            "Epoch 265/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5428 - val_loss: 0.4399\n",
            "Epoch 266/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5674 - val_loss: 0.4395\n",
            "Epoch 267/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6921 - val_loss: 0.4397\n",
            "Epoch 268/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5942 - val_loss: 0.4397\n",
            "Epoch 269/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6291 - val_loss: 0.4397\n",
            "Epoch 270/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5847 - val_loss: 0.4402\n",
            "Epoch 271/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5286 - val_loss: 0.4393\n",
            "Epoch 272/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8004 - val_loss: 0.4398\n",
            "Epoch 273/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5235 - val_loss: 0.4396\n",
            "Epoch 274/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5476 - val_loss: 0.4394\n",
            "Epoch 275/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5885 - val_loss: 0.4396\n",
            "Epoch 276/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5582 - val_loss: 0.4393\n",
            "Epoch 277/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6766 - val_loss: 0.4399\n",
            "Epoch 278/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5144 - val_loss: 0.4397\n",
            "Epoch 279/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6167 - val_loss: 0.4393\n",
            "Epoch 280/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6294 - val_loss: 0.4404\n",
            "Epoch 281/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6187 - val_loss: 0.4393\n",
            "Epoch 282/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6412 - val_loss: 0.4398\n",
            "Epoch 283/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5700 - val_loss: 0.4393\n",
            "Epoch 284/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4841 - val_loss: 0.4401\n",
            "Epoch 285/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8307 - val_loss: 0.4406\n",
            "Epoch 286/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7894 - val_loss: 0.4395\n",
            "Epoch 287/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6187 - val_loss: 0.4395\n",
            "Epoch 288/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4062 - val_loss: 0.4457\n",
            "Epoch 289/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6409 - val_loss: 0.4395\n",
            "Epoch 290/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8298 - val_loss: 0.4395\n",
            "Epoch 291/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5367 - val_loss: 0.4404\n",
            "Epoch 292/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5274 - val_loss: 0.4400\n",
            "Epoch 293/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6847 - val_loss: 0.4393\n",
            "Epoch 294/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6283 - val_loss: 0.4393\n",
            "Epoch 295/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5104 - val_loss: 0.4400\n",
            "Epoch 296/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8109 - val_loss: 0.4393\n",
            "Epoch 297/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4742 - val_loss: 0.4393\n",
            "Epoch 298/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6174 - val_loss: 0.4395\n",
            "Epoch 299/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4540 - val_loss: 0.4395\n",
            "Epoch 300/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5011 - val_loss: 0.4395\n",
            "Epoch 301/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5343 - val_loss: 0.4415\n",
            "Epoch 302/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6546 - val_loss: 0.4394\n",
            "Epoch 303/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6093 - val_loss: 0.4395\n",
            "Epoch 304/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7024 - val_loss: 0.4395\n",
            "Epoch 305/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5590 - val_loss: 0.4391\n",
            "Epoch 306/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7370 - val_loss: 0.4392\n",
            "Epoch 307/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6251 - val_loss: 0.4393\n",
            "Epoch 308/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4548 - val_loss: 0.4393\n",
            "Epoch 309/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5580 - val_loss: 0.4461\n",
            "Epoch 310/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5736 - val_loss: 0.4394\n",
            "Epoch 311/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5719 - val_loss: 0.4399\n",
            "Epoch 312/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4744 - val_loss: 0.4393\n",
            "Epoch 313/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7232 - val_loss: 0.4395\n",
            "Epoch 314/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5455 - val_loss: 0.4392\n",
            "Epoch 315/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4504 - val_loss: 0.4392\n",
            "Epoch 316/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8248 - val_loss: 0.4393\n",
            "Epoch 317/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6163 - val_loss: 0.4405\n",
            "Epoch 318/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6405 - val_loss: 0.4395\n",
            "Epoch 319/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7353 - val_loss: 0.4392\n",
            "Epoch 320/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5482 - val_loss: 0.4391\n",
            "Epoch 321/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5190 - val_loss: 0.4392\n",
            "Epoch 322/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6618 - val_loss: 0.4390\n",
            "Epoch 323/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4690 - val_loss: 0.4392\n",
            "Epoch 324/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5455 - val_loss: 0.4391\n",
            "Epoch 325/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4480 - val_loss: 0.4408\n",
            "Epoch 326/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5443 - val_loss: 0.4392\n",
            "Epoch 327/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5494 - val_loss: 0.4400\n",
            "Epoch 328/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5632 - val_loss: 0.4389\n",
            "Epoch 329/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6367 - val_loss: 0.4393\n",
            "Epoch 330/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4936 - val_loss: 0.4393\n",
            "Epoch 331/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4764 - val_loss: 0.4408\n",
            "Epoch 332/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5853 - val_loss: 0.4397\n",
            "Epoch 333/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5212 - val_loss: 0.4397\n",
            "Epoch 334/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4624 - val_loss: 0.4401\n",
            "Epoch 335/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5081 - val_loss: 0.4392\n",
            "Epoch 336/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4311 - val_loss: 0.4400\n",
            "Epoch 337/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5353 - val_loss: 0.4392\n",
            "Epoch 338/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6020 - val_loss: 0.4390\n",
            "Epoch 339/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5604 - val_loss: 0.4390\n",
            "Epoch 340/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4841 - val_loss: 0.4392\n",
            "Epoch 341/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6179 - val_loss: 0.4391\n",
            "Epoch 342/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4922 - val_loss: 0.4391\n",
            "Epoch 343/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4351 - val_loss: 0.4390\n",
            "Epoch 344/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5601 - val_loss: 0.4402\n",
            "Epoch 345/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5003 - val_loss: 0.4410\n",
            "Epoch 346/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6677 - val_loss: 0.4401\n",
            "Epoch 347/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4174 - val_loss: 0.4395\n",
            "Epoch 348/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4886 - val_loss: 0.4394\n",
            "Epoch 349/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4770 - val_loss: 0.4393\n",
            "Epoch 350/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7377 - val_loss: 0.4393\n",
            "Epoch 351/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6302 - val_loss: 0.4396\n",
            "Epoch 352/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5325 - val_loss: 0.4394\n",
            "Epoch 353/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5277 - val_loss: 0.4392\n",
            "Epoch 354/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5534 - val_loss: 0.4394\n",
            "Epoch 355/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5287 - val_loss: 0.4422\n",
            "Epoch 356/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6887 - val_loss: 0.4414\n",
            "Epoch 357/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6527 - val_loss: 0.4391\n",
            "Epoch 358/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6117 - val_loss: 0.4392\n",
            "Epoch 359/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4849 - val_loss: 0.4392\n",
            "Epoch 360/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7025 - val_loss: 0.4400\n",
            "Epoch 361/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4691 - val_loss: 0.4392\n",
            "Epoch 362/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5467 - val_loss: 0.4398\n",
            "Epoch 363/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5293 - val_loss: 0.4390\n",
            "Epoch 364/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6093 - val_loss: 0.4391\n",
            "Epoch 365/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6589 - val_loss: 0.4401\n",
            "Epoch 366/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4153 - val_loss: 0.4390\n",
            "Epoch 367/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4424 - val_loss: 0.4393\n",
            "Epoch 368/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5641 - val_loss: 0.4392\n",
            "Epoch 369/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6218 - val_loss: 0.4391\n",
            "Epoch 370/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5959 - val_loss: 0.4392\n",
            "Epoch 371/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5025 - val_loss: 0.4395\n",
            "Epoch 372/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5781 - val_loss: 0.4391\n",
            "Epoch 373/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8021 - val_loss: 0.4394\n",
            "Epoch 374/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5302 - val_loss: 0.4398\n",
            "Epoch 375/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6902 - val_loss: 0.4390\n",
            "Epoch 376/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9339 - val_loss: 0.4389\n",
            "Epoch 377/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6157 - val_loss: 0.4390\n",
            "Epoch 378/500\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5226 - val_loss: 0.4393\n",
            "Epoch 378: early stopping\n",
            "Restoring model weights from the end of the best epoch: 328.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "jzZARAk-zjzd",
        "outputId": "037186cd-c1ce-4019-eb6e-ad09878557ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_dm(predictions, op_col, diff_col, db):\n",
        "\n",
        "  # print(\"target\")\n",
        "  # print(target)\n",
        "  num = len(predictions)\n",
        "  if (len(predictions)) != len(op_col) or len(op_col) != len(diff_col):\n",
        "    ValueError(\"wrong\")\n",
        "  error_sum = 0\n",
        "  percent_diff_sum = 0\n",
        "  percent_num = 0\n",
        "  too_high_count = 0\n",
        "  too_high_sum = 0\n",
        "  correct_dir = 0\n",
        "\n",
        "  pred_down = 0\n",
        "  pred_down_correct = 0\n",
        "\n",
        "  pred_up = 0\n",
        "  pred_up_correct = 0\n",
        "\n",
        "  winnings = 0\n",
        "\n",
        "  for prediction, op_val, diff, (index, row) in zip(predictions, op_col, diff_col, db.iterrows()):\n",
        "    prediction = prediction[0]\n",
        "    error = abs(prediction - diff)\n",
        "    if error > 10:\n",
        "      num -= 1\n",
        "      too_high_count += 1\n",
        "      too_high_sum += error\n",
        "      if (row[\"Almeria\"] == 1):\n",
        "        print(f\"error too high, ignoring in calculation: Almeria\")\n",
        "      else:\n",
        "        print(f\"error too high, ignoring in calculation: NOT Almeria\")\n",
        "        # print(f\"{row}\")\n",
        "    else:\n",
        "      pred_dir = 1 if prediction >= 0 else 0\n",
        "      true_dir = 1 if diff >= 0 else 0\n",
        "      if pred_dir == 1:\n",
        "        pred_up += 1\n",
        "        if pred_dir == true_dir:\n",
        "          pred_up_correct += 1\n",
        "      else:\n",
        "        pred_down += 1\n",
        "        if pred_dir == true_dir:\n",
        "          pred_down_correct += 1\n",
        "        winnings += row[\"OP1_AVG\"] - 1 if row[\"result\"] == \"H\" else -1\n",
        "\n",
        "      is_correct_dir = (prediction >= 0 and diff >= 0) or (prediction <= 0 and diff <= 0)\n",
        "      if (is_correct_dir):\n",
        "        correct_dir += 1\n",
        "      error_sum += error\n",
        "      if (diff == 0):\n",
        "        percent_diff = -1\n",
        "      else:\n",
        "        percent_num += 1\n",
        "        percent_diff = error/abs(diff)\n",
        "        percent_diff_sum += percent_diff\n",
        "    print(f\"OP1X2: {format(op_val, '.3f')} diff: {format(diff, '.4f')} pred: {format(prediction, '.4f')}, error: {format(error, '.5f')}, % off {format(percent_diff * 100, '.3f')}% correct_dir: {is_correct_dir}\")\n",
        "\n",
        "  print(f\"mean abs error: {error_sum/num}\")\n",
        "  # print(f\"correct dir: {format((correct_dir/num) * 100, '.2f')}%\")\n",
        "  print(f\"avg percent diff: {format((percent_diff_sum/num) * 100, '.2f')}%\")\n",
        "  print(f\"too high: {too_high_count} occurences, avg of {too_high_sum/too_high_count}\")\n",
        "  print_percent_str(\"correct_dir\", correct_dir, num)\n",
        "  print_percent_str(\"correct_dir\", correct_dir, num)\n",
        "  print_percent_str(\"up accuracy\", pred_up_correct, pred_up)\n",
        "  print_percent_str(\"down accuracy\", pred_down_correct, pred_down)\n",
        "  print_percent_str(\"down ev\", winnings, pred_down)"
      ],
      "metadata": {
        "id": "T_Gb40C64dLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_label = \"OP1_AVG\"\n",
        "target = dm_test_target\n",
        "features = dm_test_features\n",
        "comp_db = dm_test\n",
        "# max_odd = \"D\"\n",
        "# mid_odd = \"A\"\n",
        "# min_odd = \"H\"\n",
        "# comp_db = dm_test[(dm_test[\"OP_MAX_ODD\"] == max_odd) & (dm_test[\"OP_MID_ODD\"] == mid_odd) & (dm_test[\"OP_MIN_ODD\"] == min_odd)]\n",
        "# targets = comp_db[curr_label].drop(columns=other_dropped_keys)\n",
        "# features = comp_db.drop(columns=dropped_keys).drop(columns=other_dropped_keys)\n",
        "num = len(target)\n",
        "target = target[:num]\n",
        "features = features[:num]\n",
        "comp_data = comp_db[comp_label][:num]\n",
        "\n",
        "predictions = model_6.predict(np.array(features))\n",
        "# compare_predictions_single(predictions, comp_data, target)\n",
        "evaluate_dm(predictions, comp_data, target, comp_db.iloc[:num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o358lhkz7mut",
        "outputId": "453a6ff0-f213-41df-a936-b9083041d7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "OP1X2: 3.627 diff: -0.3000 pred: 0.1002, error: 0.40023, % off 133.408% correct_dir: False\n",
            "OP1X2: 4.420 diff: -0.1700 pred: 0.0963, error: 0.26630, % off 156.647% correct_dir: False\n",
            "OP1X2: 2.045 diff: 0.5740 pred: 0.0979, error: 0.47611, % off 82.946% correct_dir: True\n",
            "OP1X2: 1.343 diff: 0.0730 pred: 0.0957, error: 0.02272, % off 31.123% correct_dir: True\n",
            "OP1X2: 1.790 diff: 0.2370 pred: 0.0988, error: 0.13815, % off 58.292% correct_dir: True\n",
            "OP1X2: 2.660 diff: 0.2280 pred: 0.0983, error: 0.12974, % off 56.905% correct_dir: True\n",
            "OP1X2: 3.744 diff: 0.9900 pred: 0.1008, error: 0.88919, % off 89.817% correct_dir: True\n",
            "OP1X2: 6.102 diff: 0.9950 pred: 0.0984, error: 0.89655, % off 90.106% correct_dir: True\n",
            "OP1X2: 2.169 diff: 0.2410 pred: 0.0961, error: 0.14491, % off 60.128% correct_dir: True\n",
            "OP1X2: 2.098 diff: -0.0950 pred: 0.0996, error: 0.19461, % off 204.849% correct_dir: False\n",
            "OP1X2: 2.382 diff: 0.5160 pred: 0.0971, error: 0.41891, % off 81.184% correct_dir: True\n",
            "OP1X2: 2.571 diff: 0.1930 pred: 0.0977, error: 0.09533, % off 49.395% correct_dir: True\n",
            "OP1X2: 2.245 diff: 0.0030 pred: 0.0977, error: 0.09469, % off 3156.394% correct_dir: True\n",
            "OP1X2: 3.225 diff: 0.0980 pred: 0.0994, error: 0.00139, % off 1.419% correct_dir: True\n",
            "OP1X2: 2.213 diff: 0.1280 pred: 0.0977, error: 0.03031, % off 23.678% correct_dir: True\n",
            "OP1X2: 1.400 diff: -0.0510 pred: 0.0935, error: 0.14451, % off 283.346% correct_dir: False\n",
            "OP1X2: 1.927 diff: -0.1590 pred: 0.0967, error: 0.25567, % off 160.800% correct_dir: False\n",
            "OP1X2: 3.087 diff: -0.1470 pred: 0.0994, error: 0.24640, % off 167.620% correct_dir: False\n",
            "OP1X2: 1.197 diff: -0.0240 pred: 0.0878, error: 0.11179, % off 465.777% correct_dir: False\n",
            "OP1X2: 1.542 diff: -0.2200 pred: 0.0948, error: 0.31481, % off 143.097% correct_dir: False\n",
            "OP1X2: 1.483 diff: -0.0210 pred: 0.0960, error: 0.11699, % off 557.110% correct_dir: False\n",
            "OP1X2: 2.023 diff: -0.1410 pred: 0.0941, error: 0.23513, % off 166.761% correct_dir: False\n",
            "OP1X2: 1.312 diff: 0.0540 pred: 0.0918, error: 0.03775, % off 69.914% correct_dir: True\n",
            "OP1X2: 1.975 diff: 0.1560 pred: 0.0954, error: 0.06056, % off 38.821% correct_dir: True\n",
            "OP1X2: 4.615 diff: -0.5920 pred: 0.1032, error: 0.69524, % off 117.439% correct_dir: False\n",
            "OP1X2: 3.534 diff: -0.0720 pred: 0.0981, error: 0.17010, % off 236.250% correct_dir: False\n",
            "OP1X2: 2.425 diff: 0.2740 pred: 0.0973, error: 0.17667, % off 64.480% correct_dir: True\n",
            "OP1X2: 3.582 diff: -0.3530 pred: 0.0995, error: 0.45250, % off 128.187% correct_dir: False\n",
            "OP1X2: 3.416 diff: -0.1390 pred: 0.0996, error: 0.23856, % off 171.629% correct_dir: False\n",
            "OP1X2: 1.449 diff: -0.1430 pred: 0.0926, error: 0.23557, % off 164.731% correct_dir: False\n",
            "OP1X2: 1.449 diff: 0.0970 pred: 0.0931, error: 0.00385, % off 3.973% correct_dir: True\n",
            "OP1X2: 2.959 diff: -0.1160 pred: 0.0987, error: 0.21470, % off 185.088% correct_dir: False\n",
            "OP1X2: 1.917 diff: 0.2130 pred: 0.0952, error: 0.11778, % off 55.294% correct_dir: True\n",
            "OP1X2: 3.608 diff: -0.2010 pred: 0.0987, error: 0.29968, % off 149.092% correct_dir: False\n",
            "OP1X2: 1.314 diff: 0.1200 pred: 0.0943, error: 0.02567, % off 21.391% correct_dir: True\n",
            "OP1X2: 2.824 diff: -0.1100 pred: 0.0997, error: 0.20969, % off 190.624% correct_dir: False\n",
            "OP1X2: 2.684 diff: 0.2010 pred: 0.0973, error: 0.10372, % off 51.604% correct_dir: True\n",
            "OP1X2: 2.998 diff: 0.7570 pred: 0.0973, error: 0.65972, % off 87.149% correct_dir: True\n",
            "OP1X2: 1.278 diff: -0.0350 pred: 0.0889, error: 0.12386, % off 353.893% correct_dir: False\n",
            "OP1X2: 2.816 diff: 0.0790 pred: 0.0994, error: 0.02043, % off 25.857% correct_dir: True\n",
            "OP1X2: 3.177 diff: 0.1850 pred: 0.0983, error: 0.08672, % off 46.875% correct_dir: True\n",
            "OP1X2: 1.732 diff: 0.0780 pred: 0.0937, error: 0.01575, % off 20.186% correct_dir: True\n",
            "OP1X2: 3.511 diff: -0.5080 pred: 0.0987, error: 0.60666, % off 119.421% correct_dir: False\n",
            "OP1X2: 1.958 diff: -0.2970 pred: 0.0972, error: 0.39424, % off 132.740% correct_dir: False\n",
            "OP1X2: 1.673 diff: -0.2510 pred: 0.0958, error: 0.34677, % off 138.154% correct_dir: False\n",
            "OP1X2: 1.964 diff: 0.0060 pred: 0.0937, error: 0.08767, % off 1461.198% correct_dir: True\n",
            "OP1X2: 2.150 diff: 0.0670 pred: 0.0970, error: 0.03000, % off 44.776% correct_dir: True\n",
            "OP1X2: 2.183 diff: -0.0710 pred: 0.0968, error: 0.16777, % off 236.298% correct_dir: False\n",
            "OP1X2: 2.419 diff: -0.0600 pred: 0.0993, error: 0.15932, % off 265.535% correct_dir: False\n",
            "OP1X2: 2.548 diff: -0.7380 pred: 0.0986, error: 0.83660, % off 113.360% correct_dir: False\n",
            "OP1X2: 2.921 diff: 0.4900 pred: 0.0970, error: 0.39296, % off 80.196% correct_dir: True\n",
            "OP1X2: 3.935 diff: -0.3020 pred: 0.0995, error: 0.40148, % off 132.940% correct_dir: False\n",
            "OP1X2: 1.339 diff: 0.0720 pred: 0.0904, error: 0.01844, % off 25.616% correct_dir: True\n",
            "OP1X2: 5.565 diff: 1.3800 pred: 0.0995, error: 1.28052, % off 92.791% correct_dir: True\n",
            "OP1X2: 1.514 diff: 0.0760 pred: 0.0921, error: 0.01606, % off 21.134% correct_dir: True\n",
            "OP1X2: 2.224 diff: 0.3430 pred: 0.0992, error: 0.24378, % off 71.073% correct_dir: True\n",
            "OP1X2: 2.128 diff: 0.0010 pred: 0.0974, error: 0.09636, % off 9636.724% correct_dir: True\n",
            "OP1X2: 1.550 diff: 0.0600 pred: 0.0957, error: 0.03568, % off 59.463% correct_dir: True\n",
            "OP1X2: 3.618 diff: 0.6260 pred: 0.0964, error: 0.52962, % off 84.604% correct_dir: True\n",
            "OP1X2: 1.305 diff: 0.0930 pred: 0.0933, error: 0.00032, % off 0.341% correct_dir: True\n",
            "OP1X2: 2.247 diff: 0.5430 pred: 0.0966, error: 0.44645, % off 82.219% correct_dir: True\n",
            "OP1X2: 1.682 diff: -0.3330 pred: 0.0933, error: 0.42635, % off 128.033% correct_dir: False\n",
            "OP1X2: 1.587 diff: -0.1070 pred: 0.0964, error: 0.20338, % off 190.073% correct_dir: False\n",
            "OP1X2: 2.016 diff: -0.0540 pred: 0.0958, error: 0.14980, % off 277.406% correct_dir: False\n",
            "OP1X2: 1.490 diff: 0.0630 pred: 0.0949, error: 0.03189, % off 50.622% correct_dir: True\n",
            "OP1X2: 4.257 diff: -1.5820 pred: 0.1007, error: 1.68267, % off 106.363% correct_dir: False\n",
            "OP1X2: 4.711 diff: -1.0590 pred: 0.0986, error: 1.15764, % off 109.315% correct_dir: False\n",
            "OP1X2: 2.048 diff: 0.8180 pred: 0.0959, error: 0.72210, % off 88.276% correct_dir: True\n",
            "OP1X2: 1.973 diff: -0.2030 pred: 0.0922, error: 0.29525, % off 145.442% correct_dir: False\n",
            "OP1X2: 2.077 diff: 0.1090 pred: 0.0968, error: 0.01223, % off 11.217% correct_dir: True\n",
            "OP1X2: 1.674 diff: -0.1310 pred: 0.0979, error: 0.22891, % off 174.739% correct_dir: False\n",
            "OP1X2: 2.096 diff: -0.2850 pred: 0.0945, error: 0.37952, % off 133.165% correct_dir: False\n",
            "OP1X2: 2.707 diff: -0.0800 pred: 0.0947, error: 0.17467, % off 218.336% correct_dir: False\n",
            "OP1X2: 2.114 diff: 0.7320 pred: 0.0961, error: 0.63592, % off 86.874% correct_dir: True\n",
            "OP1X2: 3.839 diff: 0.9010 pred: 0.0977, error: 0.80327, % off 89.153% correct_dir: True\n",
            "OP1X2: 2.453 diff: 0.2440 pred: 0.0981, error: 0.14594, % off 59.812% correct_dir: True\n",
            "OP1X2: 3.499 diff: -0.5020 pred: 0.0976, error: 0.59961, % off 119.445% correct_dir: False\n",
            "OP1X2: 3.129 diff: 0.0010 pred: 0.0983, error: 0.09728, % off 9726.770% correct_dir: True\n",
            "OP1X2: 1.754 diff: -0.3090 pred: 0.0957, error: 0.40474, % off 130.985% correct_dir: False\n",
            "OP1X2: 2.007 diff: -0.0270 pred: 0.0947, error: 0.12174, % off 450.873% correct_dir: False\n",
            "OP1X2: 2.188 diff: -0.1130 pred: 0.1027, error: 0.21568, % off 190.864% correct_dir: False\n",
            "OP1X2: 2.365 diff: 0.3720 pred: 0.1012, error: 0.27081, % off 72.799% correct_dir: True\n",
            "OP1X2: 3.367 diff: -0.8080 pred: 0.1030, error: 0.91098, % off 112.745% correct_dir: False\n",
            "OP1X2: 7.923 diff: 1.4670 pred: 0.1037, error: 1.36332, % off 92.932% correct_dir: True\n",
            "OP1X2: 1.560 diff: 0.2860 pred: 0.1003, error: 0.18570, % off 64.932% correct_dir: True\n",
            "OP1X2: 1.265 diff: 0.0310 pred: 0.0980, error: 0.06701, % off 216.164% correct_dir: True\n",
            "OP1X2: 3.943 diff: 0.7310 pred: 0.1056, error: 0.62540, % off 85.555% correct_dir: True\n",
            "OP1X2: 3.738 diff: 0.6350 pred: 0.1055, error: 0.52949, % off 83.384% correct_dir: True\n",
            "OP1X2: 2.596 diff: 0.3770 pred: 0.1049, error: 0.27207, % off 72.167% correct_dir: True\n",
            "OP1X2: 2.562 diff: 0.4160 pred: 0.1046, error: 0.31143, % off 74.862% correct_dir: True\n",
            "OP1X2: 2.117 diff: -0.0770 pred: 0.0995, error: 0.17648, % off 229.198% correct_dir: False\n",
            "OP1X2: 1.145 diff: -0.0680 pred: 0.0883, error: 0.15631, % off 229.862% correct_dir: False\n",
            "OP1X2: 2.393 diff: -0.0500 pred: 0.1012, error: 0.15118, % off 302.353% correct_dir: False\n",
            "OP1X2: 1.554 diff: 0.0650 pred: 0.1009, error: 0.03592, % off 55.269% correct_dir: True\n",
            "OP1X2: 2.188 diff: -0.2330 pred: 0.1000, error: 0.33301, % off 142.922% correct_dir: False\n",
            "OP1X2: 1.914 diff: -0.2210 pred: 0.1040, error: 0.32495, % off 147.038% correct_dir: False\n",
            "OP1X2: 1.882 diff: -0.1300 pred: 0.1016, error: 0.23164, % off 178.181% correct_dir: False\n",
            "OP1X2: 1.579 diff: 0.1410 pred: 0.1024, error: 0.03865, % off 27.409% correct_dir: True\n",
            "OP1X2: 1.581 diff: 0.1430 pred: 0.1020, error: 0.04097, % off 28.654% correct_dir: True\n",
            "OP1X2: 2.646 diff: 0.5100 pred: 0.1049, error: 0.40510, % off 79.432% correct_dir: True\n",
            "OP1X2: 1.491 diff: -0.1200 pred: 0.1001, error: 0.22010, % off 183.414% correct_dir: False\n",
            "OP1X2: 7.597 diff: 1.6450 pred: 0.1002, error: 1.54477, % off 93.907% correct_dir: True\n",
            "OP1X2: 2.230 diff: 0.1850 pred: 0.1035, error: 0.08147, % off 44.040% correct_dir: True\n",
            "OP1X2: 5.063 diff: -0.0480 pred: 0.1045, error: 0.15251, % off 317.725% correct_dir: False\n",
            "OP1X2: 3.164 diff: 0.1290 pred: 0.1033, error: 0.02575, % off 19.960% correct_dir: True\n",
            "OP1X2: 2.499 diff: 0.3280 pred: 0.1034, error: 0.22459, % off 68.473% correct_dir: True\n",
            "OP1X2: 2.330 diff: 0.0880 pred: 0.1026, error: 0.01464, % off 16.631% correct_dir: True\n",
            "OP1X2: 3.772 diff: -0.4240 pred: 0.1037, error: 0.52773, % off 124.465% correct_dir: False\n",
            "OP1X2: 1.336 diff: 0.0290 pred: 0.1021, error: 0.07313, % off 252.180% correct_dir: True\n",
            "OP1X2: 1.804 diff: -0.2540 pred: 0.0991, error: 0.35314, % off 139.032% correct_dir: False\n",
            "OP1X2: 2.215 diff: 0.3170 pred: 0.1042, error: 0.21281, % off 67.132% correct_dir: True\n",
            "OP1X2: 6.207 diff: 0.9560 pred: 0.1054, error: 0.85064, % off 88.979% correct_dir: True\n",
            "OP1X2: 1.446 diff: -0.0320 pred: 0.0990, error: 0.13099, % off 409.341% correct_dir: False\n",
            "OP1X2: 2.595 diff: 0.5370 pred: 0.1023, error: 0.43473, % off 80.956% correct_dir: True\n",
            "OP1X2: 2.577 diff: 0.7820 pred: 0.1036, error: 0.67837, % off 86.748% correct_dir: True\n",
            "OP1X2: 3.255 diff: -0.3280 pred: 0.1045, error: 0.43252, % off 131.866% correct_dir: False\n",
            "OP1X2: 2.675 diff: 0.2540 pred: 0.1042, error: 0.14975, % off 58.957% correct_dir: True\n",
            "OP1X2: 2.544 diff: 0.1060 pred: 0.1043, error: 0.00171, % off 1.614% correct_dir: True\n",
            "OP1X2: 1.271 diff: 0.0170 pred: 0.0951, error: 0.07813, % off 459.607% correct_dir: True\n",
            "OP1X2: 2.715 diff: 0.2800 pred: 0.1030, error: 0.17701, % off 63.219% correct_dir: True\n",
            "OP1X2: 2.024 diff: -0.0780 pred: 0.1008, error: 0.17884, % off 229.282% correct_dir: False\n",
            "OP1X2: 1.950 diff: -0.0100 pred: 0.1019, error: 0.11185, % off 1118.514% correct_dir: False\n",
            "OP1X2: 1.524 diff: -0.0910 pred: 0.0982, error: 0.18917, % off 207.881% correct_dir: False\n",
            "OP1X2: 2.738 diff: 0.3900 pred: 0.1000, error: 0.29000, % off 74.360% correct_dir: True\n",
            "OP1X2: 2.539 diff: -0.1880 pred: 0.1042, error: 0.29216, % off 155.403% correct_dir: False\n",
            "OP1X2: 2.476 diff: -0.0300 pred: 0.1023, error: 0.13234, % off 441.149% correct_dir: False\n",
            "OP1X2: 2.356 diff: -0.0690 pred: 0.1049, error: 0.17392, % off 252.055% correct_dir: False\n",
            "OP1X2: 2.040 diff: -0.0130 pred: 0.1033, error: 0.11625, % off 894.260% correct_dir: False\n",
            "OP1X2: 1.530 diff: 0.0320 pred: 0.1010, error: 0.06905, % off 215.769% correct_dir: True\n",
            "OP1X2: 1.575 diff: 0.1940 pred: 0.1016, error: 0.09240, % off 47.630% correct_dir: True\n",
            "OP1X2: 3.944 diff: 0.9660 pred: 0.1048, error: 0.86120, % off 89.151% correct_dir: True\n",
            "OP1X2: 1.500 diff: 0.0910 pred: 0.0988, error: 0.00776, % off 8.522% correct_dir: True\n",
            "OP1X2: 2.196 diff: 0.0960 pred: 0.1018, error: 0.00584, % off 6.086% correct_dir: True\n",
            "OP1X2: 2.611 diff: 0.5750 pred: 0.1025, error: 0.47254, % off 82.181% correct_dir: True\n",
            "OP1X2: 3.305 diff: 0.2730 pred: 0.1044, error: 0.16864, % off 61.772% correct_dir: True\n",
            "OP1X2: 1.543 diff: 0.0080 pred: 0.0996, error: 0.09162, % off 1145.201% correct_dir: True\n",
            "OP1X2: 8.445 diff: 2.5900 pred: 0.1057, error: 2.48433, % off 95.920% correct_dir: True\n",
            "OP1X2: 2.419 diff: 0.2710 pred: 0.1022, error: 0.16881, % off 62.291% correct_dir: True\n",
            "OP1X2: 2.012 diff: 0.2290 pred: 0.1044, error: 0.12461, % off 54.416% correct_dir: True\n",
            "OP1X2: 1.471 diff: -0.0060 pred: 0.0991, error: 0.10508, % off 1751.345% correct_dir: False\n",
            "OP1X2: 1.705 diff: 0.0280 pred: 0.0996, error: 0.07156, % off 255.579% correct_dir: True\n",
            "OP1X2: 3.448 diff: 0.6430 pred: 0.1043, error: 0.53867, % off 83.774% correct_dir: True\n",
            "OP1X2: 1.788 diff: -0.0170 pred: 0.0987, error: 0.11566, % off 680.345% correct_dir: False\n",
            "OP1X2: 1.427 diff: -0.0460 pred: 0.1006, error: 0.14664, % off 318.785% correct_dir: False\n",
            "OP1X2: 2.570 diff: -0.0860 pred: 0.1033, error: 0.18930, % off 220.122% correct_dir: False\n",
            "OP1X2: 1.472 diff: -0.0280 pred: 0.0995, error: 0.12755, % off 455.532% correct_dir: False\n",
            "OP1X2: 3.040 diff: 0.1820 pred: 0.1039, error: 0.07807, % off 42.894% correct_dir: True\n",
            "OP1X2: 1.777 diff: -0.1400 pred: 0.1018, error: 0.24176, % off 172.688% correct_dir: False\n",
            "OP1X2: 1.321 diff: 0.0550 pred: 0.0967, error: 0.04171, % off 75.835% correct_dir: True\n",
            "OP1X2: 1.753 diff: -0.0590 pred: 0.1001, error: 0.15910, % off 269.668% correct_dir: False\n",
            "OP1X2: 2.308 diff: 0.1140 pred: 0.0996, error: 0.01439, % off 12.623% correct_dir: True\n",
            "OP1X2: 3.324 diff: -0.2310 pred: 0.1017, error: 0.33265, % off 144.006% correct_dir: False\n",
            "OP1X2: 4.877 diff: 1.4710 pred: 0.1038, error: 1.36722, % off 92.945% correct_dir: True\n",
            "OP1X2: 1.854 diff: 0.1830 pred: 0.1003, error: 0.08270, % off 45.189% correct_dir: True\n",
            "OP1X2: 4.796 diff: 0.9510 pred: 0.1017, error: 0.84932, % off 89.308% correct_dir: True\n",
            "OP1X2: 2.005 diff: -0.1550 pred: 0.1039, error: 0.25891, % off 167.038% correct_dir: False\n",
            "OP1X2: 1.229 diff: 0.0320 pred: 0.0970, error: 0.06498, % off 203.055% correct_dir: True\n",
            "OP1X2: 2.023 diff: 0.0950 pred: 0.1027, error: 0.00774, % off 8.145% correct_dir: True\n",
            "OP1X2: 1.917 diff: 0.1470 pred: 0.1037, error: 0.04330, % off 29.453% correct_dir: True\n",
            "OP1X2: 2.762 diff: -0.0370 pred: 0.1040, error: 0.14095, % off 380.956% correct_dir: False\n",
            "OP1X2: 3.659 diff: 0.0210 pred: 0.1030, error: 0.08202, % off 390.550% correct_dir: True\n",
            "OP1X2: 2.026 diff: 0.2240 pred: 0.1014, error: 0.12262, % off 54.739% correct_dir: True\n",
            "OP1X2: 1.132 diff: -0.0180 pred: 0.0871, error: 0.10512, % off 583.976% correct_dir: False\n",
            "OP1X2: 2.052 diff: 0.1050 pred: 0.1026, error: 0.00241, % off 2.295% correct_dir: True\n",
            "OP1X2: 1.777 diff: 0.1320 pred: 0.1011, error: 0.03094, % off 23.437% correct_dir: True\n",
            "OP1X2: 1.479 diff: 0.0430 pred: 0.0990, error: 0.05598, % off 130.185% correct_dir: True\n",
            "OP1X2: 1.843 diff: 0.0960 pred: 0.1018, error: 0.00579, % off 6.033% correct_dir: True\n",
            "OP1X2: 1.558 diff: 0.2040 pred: 0.0980, error: 0.10603, % off 51.973% correct_dir: True\n",
            "OP1X2: 2.155 diff: -0.0520 pred: 0.1022, error: 0.15425, % off 296.628% correct_dir: False\n",
            "OP1X2: 4.933 diff: -0.0760 pred: 0.1025, error: 0.17849, % off 234.852% correct_dir: False\n",
            "OP1X2: 2.757 diff: 0.7850 pred: 0.1030, error: 0.68197, % off 86.876% correct_dir: True\n",
            "OP1X2: 1.402 diff: 0.0240 pred: 0.0991, error: 0.07510, % off 312.916% correct_dir: True\n",
            "OP1X2: 5.596 diff: 0.4610 pred: 0.1039, error: 0.35709, % off 77.459% correct_dir: True\n",
            "OP1X2: 4.054 diff: -0.1520 pred: 0.1001, error: 0.25206, % off 165.831% correct_dir: False\n",
            "OP1X2: 2.548 diff: -0.0580 pred: 0.1024, error: 0.16037, % off 276.497% correct_dir: False\n",
            "OP1X2: 2.336 diff: -0.2790 pred: 0.1020, error: 0.38099, % off 136.556% correct_dir: False\n",
            "OP1X2: 3.535 diff: -0.8000 pred: 0.1030, error: 0.90301, % off 112.876% correct_dir: False\n",
            "OP1X2: 2.317 diff: -0.2340 pred: 0.0992, error: 0.33317, % off 142.378% correct_dir: False\n",
            "OP1X2: 2.314 diff: -0.1360 pred: 0.1017, error: 0.23767, % off 174.754% correct_dir: False\n",
            "OP1X2: 1.170 diff: 0.0370 pred: 0.0938, error: 0.05675, % off 153.387% correct_dir: True\n",
            "OP1X2: 2.441 diff: -0.3450 pred: 0.1010, error: 0.44599, % off 129.272% correct_dir: False\n",
            "OP1X2: 2.532 diff: 0.4620 pred: 0.1034, error: 0.35862, % off 77.623% correct_dir: True\n",
            "OP1X2: 1.238 diff: 0.0110 pred: 0.0928, error: 0.08182, % off 743.806% correct_dir: True\n",
            "OP1X2: 2.514 diff: 0.3420 pred: 0.1014, error: 0.24060, % off 70.350% correct_dir: True\n",
            "OP1X2: 6.018 diff: 0.7590 pred: 0.1041, error: 0.65487, % off 86.281% correct_dir: True\n",
            "OP1X2: 2.413 diff: -0.1520 pred: 0.0994, error: 0.25141, % off 165.404% correct_dir: False\n",
            "OP1X2: 2.357 diff: -0.1840 pred: 0.1019, error: 0.28590, % off 155.380% correct_dir: False\n",
            "OP1X2: 1.788 diff: 0.1230 pred: 0.1032, error: 0.01984, % off 16.128% correct_dir: True\n",
            "OP1X2: 1.229 diff: -0.0320 pred: 0.0940, error: 0.12596, % off 393.638% correct_dir: False\n",
            "OP1X2: 1.841 diff: 0.2030 pred: 0.1001, error: 0.10294, % off 50.709% correct_dir: True\n",
            "OP1X2: 3.646 diff: 0.3050 pred: 0.1021, error: 0.20293, % off 66.534% correct_dir: True\n",
            "OP1X2: 1.551 diff: 0.0090 pred: 0.0982, error: 0.08922, % off 991.368% correct_dir: True\n",
            "OP1X2: 3.036 diff: 0.4270 pred: 0.1034, error: 0.32357, % off 75.778% correct_dir: True\n",
            "OP1X2: 2.019 diff: 0.0130 pred: 0.0982, error: 0.08523, % off 655.591% correct_dir: True\n",
            "OP1X2: 2.082 diff: 0.5210 pred: 0.1014, error: 0.41958, % off 80.534% correct_dir: True\n",
            "OP1X2: 3.196 diff: -0.0030 pred: 0.1018, error: 0.10479, % off 3493.093% correct_dir: False\n",
            "OP1X2: 3.870 diff: 0.4080 pred: 0.1028, error: 0.30524, % off 74.814% correct_dir: True\n",
            "OP1X2: 2.374 diff: 0.0790 pred: 0.1007, error: 0.02171, % off 27.477% correct_dir: True\n",
            "OP1X2: 1.716 diff: 0.1290 pred: 0.0998, error: 0.02919, % off 22.630% correct_dir: True\n",
            "OP1X2: 1.729 diff: -0.1460 pred: 0.1019, error: 0.24791, % off 169.799% correct_dir: False\n",
            "OP1X2: 2.666 diff: 0.1940 pred: 0.0998, error: 0.09419, % off 48.553% correct_dir: True\n",
            "OP1X2: 2.533 diff: 0.2870 pred: 0.1014, error: 0.18557, % off 64.659% correct_dir: True\n",
            "OP1X2: 2.402 diff: -0.0020 pred: 0.1008, error: 0.10283, % off 5141.894% correct_dir: False\n",
            "OP1X2: 2.036 diff: 0.1570 pred: 0.1013, error: 0.05569, % off 35.472% correct_dir: True\n",
            "OP1X2: 2.535 diff: -0.2080 pred: 0.1035, error: 0.31148, % off 149.751% correct_dir: False\n",
            "OP1X2: 4.593 diff: 0.2990 pred: 0.1018, error: 0.19719, % off 65.949% correct_dir: True\n",
            "OP1X2: 2.526 diff: -0.0980 pred: 0.1028, error: 0.20078, % off 204.881% correct_dir: False\n",
            "OP1X2: 1.892 diff: 0.0420 pred: 0.1003, error: 0.05832, % off 138.857% correct_dir: True\n",
            "OP1X2: 2.547 diff: 0.2690 pred: 0.0975, error: 0.17154, % off 63.769% correct_dir: True\n",
            "OP1X2: 1.657 diff: 0.1250 pred: 0.0991, error: 0.02587, % off 20.698% correct_dir: True\n",
            "OP1X2: 2.892 diff: 0.0890 pred: 0.1009, error: 0.01192, % off 13.390% correct_dir: True\n",
            "OP1X2: 2.919 diff: -0.1450 pred: 0.1030, error: 0.24797, % off 171.012% correct_dir: False\n",
            "OP1X2: 1.354 diff: -0.0180 pred: 0.0962, error: 0.11417, % off 634.275% correct_dir: False\n",
            "OP1X2: 1.709 diff: 0.0390 pred: 0.0993, error: 0.06034, % off 154.724% correct_dir: True\n",
            "OP1X2: 3.471 diff: -0.4450 pred: 0.1037, error: 0.54871, % off 123.307% correct_dir: False\n",
            "OP1X2: 1.143 diff: 0.0960 pred: 0.0865, error: 0.00947, % off 9.860% correct_dir: True\n",
            "OP1X2: 2.883 diff: 0.0530 pred: 0.1037, error: 0.05072, % off 95.705% correct_dir: True\n",
            "OP1X2: 1.556 diff: 0.0540 pred: 0.0977, error: 0.04372, % off 80.961% correct_dir: True\n",
            "OP1X2: 2.518 diff: -0.0780 pred: 0.1009, error: 0.17891, % off 229.372% correct_dir: False\n",
            "OP1X2: 3.059 diff: 0.0540 pred: 0.1030, error: 0.04898, % off 90.711% correct_dir: True\n",
            "OP1X2: 1.431 diff: 0.0960 pred: 0.0966, error: 0.00061, % off 0.631% correct_dir: True\n",
            "OP1X2: 5.589 diff: 0.0840 pred: 0.1016, error: 0.01761, % off 20.960% correct_dir: True\n",
            "OP1X2: 2.692 diff: 0.1880 pred: 0.1002, error: 0.08779, % off 46.696% correct_dir: True\n",
            "OP1X2: 3.091 diff: 0.0460 pred: 0.1014, error: 0.05544, % off 120.515% correct_dir: True\n",
            "OP1X2: 3.346 diff: 0.8620 pred: 0.1036, error: 0.75835, % off 87.976% correct_dir: True\n",
            "OP1X2: 3.030 diff: 0.1380 pred: 0.1001, error: 0.03787, % off 27.442% correct_dir: True\n",
            "OP1X2: 1.608 diff: 0.1330 pred: 0.1020, error: 0.03103, % off 23.329% correct_dir: True\n",
            "OP1X2: 1.780 diff: -0.0170 pred: 0.0989, error: 0.11587, % off 681.586% correct_dir: False\n",
            "OP1X2: 4.817 diff: -0.0900 pred: 0.1024, error: 0.19238, % off 213.759% correct_dir: False\n",
            "OP1X2: 1.440 diff: -0.0520 pred: 0.0994, error: 0.15141, % off 291.174% correct_dir: False\n",
            "OP1X2: 1.409 diff: -0.0340 pred: 0.0975, error: 0.13153, % off 386.860% correct_dir: False\n",
            "OP1X2: 4.580 diff: 0.6070 pred: 0.1024, error: 0.50458, % off 83.127% correct_dir: True\n",
            "OP1X2: 1.416 diff: 0.0370 pred: 0.0958, error: 0.05885, % off 159.054% correct_dir: True\n",
            "OP1X2: 2.178 diff: -0.0910 pred: 0.1002, error: 0.19119, % off 210.096% correct_dir: False\n",
            "OP1X2: 2.449 diff: 0.3060 pred: 0.1026, error: 0.20336, % off 66.456% correct_dir: True\n",
            "OP1X2: 5.105 diff: -0.0950 pred: 0.1002, error: 0.19519, % off 205.465% correct_dir: False\n",
            "OP1X2: 2.374 diff: -0.0530 pred: 0.0999, error: 0.15287, % off 288.432% correct_dir: False\n",
            "OP1X2: 1.416 diff: 0.0670 pred: 0.0982, error: 0.03122, % off 46.602% correct_dir: True\n",
            "OP1X2: 1.287 diff: 0.0210 pred: 0.0936, error: 0.07265, % off 345.938% correct_dir: True\n",
            "OP1X2: 1.741 diff: 0.1740 pred: 0.0976, error: 0.07637, % off 43.892% correct_dir: True\n",
            "OP1X2: 2.643 diff: 0.4700 pred: 0.1010, error: 0.36896, % off 78.502% correct_dir: True\n",
            "OP1X2: 2.779 diff: 0.4110 pred: 0.1003, error: 0.31074, % off 75.605% correct_dir: True\n",
            "OP1X2: 1.902 diff: 0.0040 pred: 0.0975, error: 0.09353, % off 2338.167% correct_dir: True\n",
            "OP1X2: 2.857 diff: 0.0420 pred: 0.1010, error: 0.05902, % off 140.531% correct_dir: True\n",
            "OP1X2: 2.810 diff: 0.3990 pred: 0.1011, error: 0.29787, % off 74.654% correct_dir: True\n",
            "OP1X2: 3.431 diff: 0.2250 pred: 0.0994, error: 0.12555, % off 55.801% correct_dir: True\n",
            "OP1X2: 2.583 diff: -0.1860 pred: 0.1025, error: 0.28847, % off 155.090% correct_dir: False\n",
            "OP1X2: 3.701 diff: 0.9780 pred: 0.1009, error: 0.87713, % off 89.686% correct_dir: True\n",
            "OP1X2: 3.364 diff: 0.6020 pred: 0.1031, error: 0.49886, % off 82.868% correct_dir: True\n",
            "OP1X2: 1.130 diff: 0.0780 pred: 0.0885, error: 0.01052, % off 13.489% correct_dir: True\n",
            "OP1X2: 1.791 diff: 0.0790 pred: 0.0985, error: 0.01949, % off 24.670% correct_dir: True\n",
            "OP1X2: 3.009 diff: 0.1980 pred: 0.0978, error: 0.10019, % off 50.602% correct_dir: True\n",
            "OP1X2: 4.295 diff: 1.0650 pred: 0.1049, error: 0.96013, % off 90.153% correct_dir: True\n",
            "OP1X2: 1.738 diff: 0.0770 pred: 0.0989, error: 0.02194, % off 28.489% correct_dir: True\n",
            "OP1X2: 1.620 diff: 0.0480 pred: 0.0992, error: 0.05121, % off 106.686% correct_dir: True\n",
            "OP1X2: 2.758 diff: -0.0760 pred: 0.1015, error: 0.17748, % off 233.533% correct_dir: False\n",
            "OP1X2: 2.485 diff: -0.0980 pred: 0.0986, error: 0.19662, % off 200.637% correct_dir: False\n",
            "OP1X2: 2.057 diff: -0.0870 pred: 0.0998, error: 0.18676, % off 214.673% correct_dir: False\n",
            "OP1X2: 1.164 diff: 0.0630 pred: 0.0881, error: 0.02507, % off 39.795% correct_dir: True\n",
            "OP1X2: 2.826 diff: 0.4510 pred: 0.1008, error: 0.35019, % off 77.648% correct_dir: True\n",
            "OP1X2: 3.186 diff: 0.5010 pred: 0.1019, error: 0.39906, % off 79.654% correct_dir: True\n",
            "OP1X2: 2.298 diff: 0.3080 pred: 0.0987, error: 0.20931, % off 67.957% correct_dir: True\n",
            "OP1X2: 2.889 diff: 0.1140 pred: 0.1003, error: 0.01373, % off 12.042% correct_dir: True\n",
            "OP1X2: 1.830 diff: -0.0050 pred: 0.1012, error: 0.10621, % off 2124.106% correct_dir: False\n",
            "OP1X2: 2.820 diff: 0.4750 pred: 0.1001, error: 0.37491, % off 78.928% correct_dir: True\n",
            "OP1X2: 1.959 diff: -0.2400 pred: 0.0998, error: 0.33976, % off 141.568% correct_dir: False\n",
            "OP1X2: 1.662 diff: -0.0010 pred: 0.0988, error: 0.09978, % off 9978.982% correct_dir: False\n",
            "OP1X2: 1.797 diff: -0.1040 pred: 0.0972, error: 0.20118, % off 193.447% correct_dir: False\n",
            "OP1X2: 7.330 diff: -0.1960 pred: 0.1004, error: 0.29641, % off 151.230% correct_dir: False\n",
            "OP1X2: 1.602 diff: 0.1170 pred: 0.0978, error: 0.01925, % off 16.451% correct_dir: True\n",
            "OP1X2: 1.481 diff: 0.0400 pred: 0.0978, error: 0.05783, % off 144.565% correct_dir: True\n",
            "OP1X2: 2.661 diff: 0.0500 pred: 0.1008, error: 0.05080, % off 101.604% correct_dir: True\n",
            "OP1X2: 3.383 diff: -0.0540 pred: 0.0999, error: 0.15393, % off 285.054% correct_dir: False\n",
            "OP1X2: 1.836 diff: -0.1660 pred: 0.0951, error: 0.26113, % off 157.307% correct_dir: False\n",
            "OP1X2: 1.681 diff: -0.0420 pred: 0.0972, error: 0.13922, % off 331.482% correct_dir: False\n",
            "OP1X2: 4.380 diff: 0.3580 pred: 0.1031, error: 0.25488, % off 71.194% correct_dir: True\n",
            "OP1X2: 1.324 diff: 0.0180 pred: 0.0931, error: 0.07514, % off 417.439% correct_dir: True\n",
            "OP1X2: 2.939 diff: -0.1010 pred: 0.0992, error: 0.20024, % off 198.257% correct_dir: False\n",
            "OP1X2: 2.305 diff: -0.0100 pred: 0.1007, error: 0.11065, % off 1106.526% correct_dir: False\n",
            "OP1X2: 2.562 diff: 0.0770 pred: 0.1012, error: 0.02416, % off 31.375% correct_dir: True\n",
            "OP1X2: 2.445 diff: 0.0360 pred: 0.1003, error: 0.06429, % off 178.572% correct_dir: True\n",
            "OP1X2: 1.243 diff: -0.0170 pred: 0.0948, error: 0.11185, % off 657.936% correct_dir: False\n",
            "OP1X2: 2.659 diff: -0.1020 pred: 0.1008, error: 0.20280, % off 198.824% correct_dir: False\n",
            "OP1X2: 2.131 diff: -0.0640 pred: 0.0964, error: 0.16037, % off 250.571% correct_dir: False\n",
            "OP1X2: 1.984 diff: 0.0570 pred: 0.0989, error: 0.04192, % off 73.535% correct_dir: True\n",
            "OP1X2: 3.222 diff: 0.5610 pred: 0.0980, error: 0.46302, % off 82.535% correct_dir: True\n",
            "OP1X2: 1.607 diff: 0.0340 pred: 0.0967, error: 0.06268, % off 184.361% correct_dir: True\n",
            "OP1X2: 2.003 diff: -0.3260 pred: 0.0994, error: 0.42539, % off 130.489% correct_dir: False\n",
            "OP1X2: 3.413 diff: 0.2300 pred: 0.1008, error: 0.12915, % off 56.154% correct_dir: True\n",
            "OP1X2: 3.397 diff: 0.3620 pred: 0.1003, error: 0.26170, % off 72.293% correct_dir: True\n",
            "OP1X2: 3.656 diff: 0.4660 pred: 0.1010, error: 0.36502, % off 78.331% correct_dir: True\n",
            "OP1X2: 2.062 diff: -0.0100 pred: 0.0973, error: 0.10729, % off 1072.908% correct_dir: False\n",
            "OP1X2: 2.792 diff: 0.2070 pred: 0.0995, error: 0.10749, % off 51.928% correct_dir: True\n",
            "OP1X2: 1.648 diff: -0.1500 pred: 0.0963, error: 0.24633, % off 164.218% correct_dir: False\n",
            "OP1X2: 2.154 diff: -0.0870 pred: 0.0988, error: 0.18580, % off 213.558% correct_dir: False\n",
            "OP1X2: 1.890 diff: 0.1140 pred: 0.0977, error: 0.01631, % off 14.304% correct_dir: True\n",
            "OP1X2: 1.313 diff: 0.0830 pred: 0.0943, error: 0.01134, % off 13.664% correct_dir: True\n",
            "OP1X2: 2.959 diff: 0.0530 pred: 0.1017, error: 0.04873, % off 91.948% correct_dir: True\n",
            "OP1X2: 2.904 diff: -0.1110 pred: 0.1003, error: 0.21132, % off 190.381% correct_dir: False\n",
            "OP1X2: 2.197 diff: 0.0430 pred: 0.0996, error: 0.05662, % off 131.682% correct_dir: True\n",
            "OP1X2: 2.268 diff: -0.0880 pred: 0.0970, error: 0.18501, % off 210.236% correct_dir: False\n",
            "OP1X2: 8.583 diff: 2.2820 pred: 0.1013, error: 2.18074, % off 95.563% correct_dir: True\n",
            "OP1X2: 1.543 diff: 0.1650 pred: 0.0972, error: 0.06781, % off 41.099% correct_dir: True\n",
            "OP1X2: 3.041 diff: 0.3680 pred: 0.0997, error: 0.26832, % off 72.913% correct_dir: True\n",
            "OP1X2: 1.920 diff: 0.0120 pred: 0.0982, error: 0.08616, % off 717.954% correct_dir: True\n",
            "OP1X2: 1.613 diff: -0.1120 pred: 0.0949, error: 0.20690, % off 184.735% correct_dir: False\n",
            "OP1X2: 1.192 diff: -0.0130 pred: 0.0928, error: 0.10581, % off 813.897% correct_dir: False\n",
            "OP1X2: 2.326 diff: 0.2620 pred: 0.0995, error: 0.16253, % off 62.034% correct_dir: True\n",
            "OP1X2: 1.574 diff: -0.1810 pred: 0.0972, error: 0.27824, % off 153.723% correct_dir: False\n",
            "OP1X2: 2.110 diff: -0.0390 pred: 0.0970, error: 0.13601, % off 348.747% correct_dir: False\n",
            "OP1X2: 2.072 diff: 0.2650 pred: 0.0969, error: 0.16807, % off 63.422% correct_dir: True\n",
            "OP1X2: 1.703 diff: 0.1090 pred: 0.0990, error: 0.00999, % off 9.169% correct_dir: True\n",
            "OP1X2: 3.347 diff: 0.6500 pred: 0.1008, error: 0.54918, % off 84.489% correct_dir: True\n",
            "OP1X2: 1.586 diff: 0.1570 pred: 0.0978, error: 0.05917, % off 37.686% correct_dir: True\n",
            "OP1X2: 1.547 diff: -0.0650 pred: 0.0989, error: 0.16387, % off 252.102% correct_dir: False\n",
            "OP1X2: 2.898 diff: 0.4600 pred: 0.0983, error: 0.36173, % off 78.637% correct_dir: True\n",
            "OP1X2: 3.959 diff: 0.9170 pred: 0.0984, error: 0.81861, % off 89.271% correct_dir: True\n",
            "OP1X2: 2.501 diff: 0.0490 pred: 0.0981, error: 0.04906, % off 100.114% correct_dir: True\n",
            "OP1X2: 1.641 diff: 0.0320 pred: 0.0980, error: 0.06598, % off 206.180% correct_dir: True\n",
            "OP1X2: 1.288 diff: 0.0310 pred: 0.0922, error: 0.06120, % off 197.418% correct_dir: True\n",
            "OP1X2: 2.033 diff: 0.0040 pred: 0.0976, error: 0.09361, % off 2340.247% correct_dir: True\n",
            "OP1X2: 1.439 diff: 0.0250 pred: 0.0952, error: 0.07023, % off 280.906% correct_dir: True\n",
            "OP1X2: 2.175 diff: 0.0520 pred: 0.0997, error: 0.04771, % off 91.742% correct_dir: True\n",
            "OP1X2: 1.737 diff: 0.2910 pred: 0.0982, error: 0.19279, % off 66.251% correct_dir: True\n",
            "OP1X2: 6.395 diff: -0.3780 pred: 0.1025, error: 0.48052, % off 127.122% correct_dir: False\n",
            "OP1X2: 1.583 diff: -0.1470 pred: 0.0960, error: 0.24300, % off 165.306% correct_dir: False\n",
            "OP1X2: 6.489 diff: -1.1740 pred: 0.1008, error: 1.27477, % off 108.584% correct_dir: False\n",
            "OP1X2: 1.264 diff: -0.0510 pred: 0.0915, error: 0.14251, % off 279.426% correct_dir: False\n",
            "OP1X2: 2.243 diff: -0.1100 pred: 0.0972, error: 0.20715, % off 188.322% correct_dir: False\n",
            "OP1X2: 1.902 diff: -0.1110 pred: 0.0939, error: 0.20491, % off 184.602% correct_dir: False\n",
            "OP1X2: 1.992 diff: 0.1780 pred: 0.0985, error: 0.07953, % off 44.679% correct_dir: True\n",
            "OP1X2: 1.371 diff: -0.1100 pred: 0.0954, error: 0.20542, % off 186.750% correct_dir: False\n",
            "OP1X2: 1.668 diff: -0.0060 pred: 0.0968, error: 0.10280, % off 1713.387% correct_dir: False\n",
            "OP1X2: 3.836 diff: 1.0960 pred: 0.0992, error: 0.99679, % off 90.948% correct_dir: True\n",
            "OP1X2: 2.497 diff: 0.0280 pred: 0.0990, error: 0.07101, % off 253.602% correct_dir: True\n",
            "OP1X2: 2.575 diff: -0.1630 pred: 0.1013, error: 0.26432, % off 162.157% correct_dir: False\n",
            "OP1X2: 3.984 diff: 0.3220 pred: 0.0994, error: 0.22259, % off 69.128% correct_dir: True\n",
            "OP1X2: 1.896 diff: 0.0700 pred: 0.0967, error: 0.02668, % off 38.110% correct_dir: True\n",
            "OP1X2: 2.136 diff: 0.5010 pred: 0.0953, error: 0.40574, % off 80.987% correct_dir: True\n",
            "OP1X2: 2.703 diff: 0.2340 pred: 0.0981, error: 0.13586, % off 58.061% correct_dir: True\n",
            "OP1X2: 5.214 diff: -0.2040 pred: 0.1018, error: 0.30583, % off 149.918% correct_dir: False\n",
            "OP1X2: 2.233 diff: -0.1370 pred: 0.0994, error: 0.23638, % off 172.543% correct_dir: False\n",
            "OP1X2: 3.043 diff: -0.1820 pred: 0.1003, error: 0.28232, % off 155.121% correct_dir: False\n",
            "OP1X2: 1.981 diff: -0.1280 pred: 0.0979, error: 0.22595, % off 176.522% correct_dir: False\n",
            "OP1X2: 1.374 diff: -0.0420 pred: 0.0912, error: 0.13316, % off 317.056% correct_dir: False\n",
            "OP1X2: 4.652 diff: 0.3110 pred: 0.0976, error: 0.21343, % off 68.627% correct_dir: True\n",
            "OP1X2: 1.381 diff: -0.0140 pred: 0.0916, error: 0.10555, % off 753.952% correct_dir: False\n",
            "OP1X2: 1.561 diff: -0.0180 pred: 0.0957, error: 0.11370, % off 631.673% correct_dir: False\n",
            "OP1X2: 1.820 diff: -0.0220 pred: 0.0976, error: 0.11962, % off 543.748% correct_dir: False\n",
            "OP1X2: 1.703 diff: 0.0080 pred: 0.0959, error: 0.08786, % off 1098.275% correct_dir: True\n",
            "OP1X2: 3.548 diff: 0.2390 pred: 0.1022, error: 0.13676, % off 57.221% correct_dir: True\n",
            "OP1X2: 3.644 diff: 0.2510 pred: 0.0989, error: 0.15214, % off 60.614% correct_dir: True\n",
            "OP1X2: 1.127 diff: 0.0030 pred: 0.0871, error: 0.08411, % off 2803.627% correct_dir: True\n",
            "OP1X2: 1.274 diff: 0.0990 pred: 0.0912, error: 0.00780, % off 7.878% correct_dir: True\n",
            "OP1X2: 3.032 diff: 0.0650 pred: 0.0983, error: 0.03327, % off 51.181% correct_dir: True\n",
            "OP1X2: 1.893 diff: -0.2500 pred: 0.0959, error: 0.34589, % off 138.356% correct_dir: False\n",
            "OP1X2: 2.264 diff: 0.1810 pred: 0.0988, error: 0.08223, % off 45.429% correct_dir: True\n",
            "OP1X2: 4.830 diff: 0.2750 pred: 0.0998, error: 0.17517, % off 63.696% correct_dir: True\n",
            "OP1X2: 3.730 diff: -0.4310 pred: 0.0963, error: 0.52732, % off 122.347% correct_dir: False\n",
            "OP1X2: 1.838 diff: 0.0740 pred: 0.0964, error: 0.02239, % off 30.261% correct_dir: True\n",
            "OP1X2: 3.039 diff: -0.6560 pred: 0.1014, error: 0.75744, % off 115.463% correct_dir: False\n",
            "OP1X2: 1.237 diff: -0.0770 pred: 0.0901, error: 0.16706, % off 216.963% correct_dir: False\n",
            "OP1X2: 1.780 diff: -0.0530 pred: 0.0960, error: 0.14903, % off 281.183% correct_dir: False\n",
            "OP1X2: 2.680 diff: 0.0840 pred: 0.0980, error: 0.01396, % off 16.621% correct_dir: True\n",
            "OP1X2: 1.278 diff: 0.0080 pred: 0.0912, error: 0.08322, % off 1040.290% correct_dir: True\n",
            "OP1X2: 2.586 diff: -0.0270 pred: 0.0970, error: 0.12397, % off 459.137% correct_dir: False\n",
            "OP1X2: 1.762 diff: 0.0740 pred: 0.0959, error: 0.02193, % off 29.641% correct_dir: True\n",
            "OP1X2: 2.080 diff: -0.1660 pred: 0.0955, error: 0.26151, % off 157.535% correct_dir: False\n",
            "OP1X2: 1.745 diff: 0.1930 pred: 0.0951, error: 0.09794, % off 50.748% correct_dir: True\n",
            "OP1X2: 1.652 diff: -0.0150 pred: 0.0973, error: 0.11226, % off 748.397% correct_dir: False\n",
            "OP1X2: 2.069 diff: 0.1300 pred: 0.0941, error: 0.03587, % off 27.592% correct_dir: True\n",
            "OP1X2: 1.670 diff: -0.0620 pred: 0.0968, error: 0.15881, % off 256.147% correct_dir: False\n",
            "OP1X2: 1.953 diff: -0.0470 pred: 0.0986, error: 0.14559, % off 309.777% correct_dir: False\n",
            "OP1X2: 2.260 diff: -0.1130 pred: 0.0976, error: 0.21058, % off 186.354% correct_dir: False\n",
            "OP1X2: 1.323 diff: 0.2790 pred: 0.0949, error: 0.18412, % off 65.992% correct_dir: True\n",
            "OP1X2: 5.857 diff: 0.2420 pred: 0.1001, error: 0.14192, % off 58.645% correct_dir: True\n",
            "OP1X2: 2.512 diff: -0.0350 pred: 0.0980, error: 0.13299, % off 379.981% correct_dir: False\n",
            "OP1X2: 2.179 diff: 0.1020 pred: 0.0945, error: 0.00746, % off 7.313% correct_dir: True\n",
            "OP1X2: 6.882 diff: 0.5440 pred: 0.1002, error: 0.44378, % off 81.577% correct_dir: True\n",
            "OP1X2: 1.978 diff: 0.1460 pred: 0.0971, error: 0.04886, % off 33.466% correct_dir: True\n",
            "OP1X2: 2.164 diff: 0.0030 pred: 0.0975, error: 0.09451, % off 3150.149% correct_dir: True\n",
            "OP1X2: 2.751 diff: -0.1790 pred: 0.0983, error: 0.27730, % off 154.915% correct_dir: False\n",
            "OP1X2: 1.661 diff: -0.0010 pred: 0.0950, error: 0.09600, % off 9599.812% correct_dir: False\n",
            "OP1X2: 1.483 diff: 0.1640 pred: 0.0948, error: 0.06922, % off 42.207% correct_dir: True\n",
            "OP1X2: 2.373 diff: -0.1180 pred: 0.0954, error: 0.21341, % off 180.856% correct_dir: False\n",
            "OP1X2: 1.635 diff: 0.0930 pred: 0.0952, error: 0.00224, % off 2.408% correct_dir: True\n",
            "OP1X2: 2.075 diff: -0.2200 pred: 0.0954, error: 0.31535, % off 143.343% correct_dir: False\n",
            "OP1X2: 1.327 diff: 0.1520 pred: 0.0923, error: 0.05971, % off 39.282% correct_dir: True\n",
            "OP1X2: 3.714 diff: -0.4820 pred: 0.0985, error: 0.58052, % off 120.439% correct_dir: False\n",
            "OP1X2: 2.217 diff: -0.1310 pred: 0.0972, error: 0.22817, % off 174.175% correct_dir: False\n",
            "OP1X2: 4.770 diff: -1.0310 pred: 0.0988, error: 1.12977, % off 109.580% correct_dir: False\n",
            "OP1X2: 2.071 diff: 0.0300 pred: 0.0945, error: 0.06449, % off 214.975% correct_dir: True\n",
            "OP1X2: 1.413 diff: -0.0310 pred: 0.0940, error: 0.12496, % off 403.093% correct_dir: False\n",
            "OP1X2: 1.496 diff: -0.0080 pred: 0.0942, error: 0.10225, % off 1278.115% correct_dir: False\n",
            "OP1X2: 1.390 diff: -0.0010 pred: 0.0944, error: 0.09538, % off 9539.033% correct_dir: False\n",
            "OP1X2: 3.951 diff: -0.4200 pred: 0.0984, error: 0.51842, % off 123.434% correct_dir: False\n",
            "OP1X2: 3.824 diff: -0.8370 pred: 0.0996, error: 0.93658, % off 111.897% correct_dir: False\n",
            "OP1X2: 1.917 diff: 0.3650 pred: 0.0974, error: 0.26761, % off 73.318% correct_dir: True\n",
            "OP1X2: 2.856 diff: 0.1740 pred: 0.0940, error: 0.08002, % off 45.990% correct_dir: True\n",
            "OP1X2: 3.194 diff: -0.0200 pred: 0.1003, error: 0.12033, % off 601.673% correct_dir: False\n",
            "OP1X2: 2.865 diff: 0.2700 pred: 0.0981, error: 0.17194, % off 63.680% correct_dir: True\n",
            "OP1X2: 2.120 diff: 0.0950 pred: 0.0962, error: 0.00120, % off 1.263% correct_dir: True\n",
            "OP1X2: 1.259 diff: 0.1150 pred: 0.0904, error: 0.02459, % off 21.379% correct_dir: True\n",
            "OP1X2: 1.916 diff: 0.3360 pred: 0.0965, error: 0.23948, % off 71.275% correct_dir: True\n",
            "OP1X2: 1.487 diff: -0.2470 pred: 0.0916, error: 0.33858, % off 137.078% correct_dir: False\n",
            "OP1X2: 2.363 diff: 0.1050 pred: 0.0988, error: 0.00623, % off 5.931% correct_dir: True\n",
            "OP1X2: 2.613 diff: -0.6440 pred: 0.0978, error: 0.74176, % off 115.180% correct_dir: False\n",
            "OP1X2: 3.238 diff: -0.1630 pred: 0.0961, error: 0.25906, % off 158.935% correct_dir: False\n",
            "OP1X2: 1.897 diff: 0.1580 pred: 0.0950, error: 0.06299, % off 39.869% correct_dir: True\n",
            "OP1X2: 2.717 diff: -0.1520 pred: 0.0965, error: 0.24848, % off 163.475% correct_dir: False\n",
            "OP1X2: 2.739 diff: -0.0320 pred: 0.0973, error: 0.12932, % off 404.127% correct_dir: False\n",
            "OP1X2: 2.036 diff: -0.4510 pred: 0.0969, error: 0.54791, % off 121.488% correct_dir: False\n",
            "OP1X2: 1.762 diff: -0.0890 pred: 0.0979, error: 0.18690, % off 210.002% correct_dir: False\n",
            "OP1X2: 2.283 diff: -0.1970 pred: 0.0985, error: 0.29553, % off 150.013% correct_dir: False\n",
            "OP1X2: 2.830 diff: 0.2520 pred: 0.0935, error: 0.15852, % off 62.905% correct_dir: True\n",
            "OP1X2: 2.229 diff: -0.1920 pred: 0.0973, error: 0.28931, % off 150.680% correct_dir: False\n",
            "OP1X2: 3.223 diff: -0.8280 pred: 0.0980, error: 0.92604, % off 111.841% correct_dir: False\n",
            "OP1X2: 2.574 diff: -0.0620 pred: 0.0978, error: 0.15980, % off 257.741% correct_dir: False\n",
            "OP1X2: 2.978 diff: -0.1990 pred: 0.0949, error: 0.29385, % off 147.665% correct_dir: False\n",
            "OP1X2: 2.779 diff: 0.1710 pred: 0.0973, error: 0.07365, % off 43.070% correct_dir: True\n",
            "OP1X2: 1.571 diff: 0.0130 pred: 0.1025, error: 0.08949, % off 688.401% correct_dir: True\n",
            "OP1X2: 3.246 diff: 0.2420 pred: 0.1030, error: 0.13895, % off 57.418% correct_dir: True\n",
            "OP1X2: 2.017 diff: 0.0510 pred: 0.0990, error: 0.04804, % off 94.204% correct_dir: True\n",
            "OP1X2: 1.424 diff: -0.1220 pred: 0.0998, error: 0.22184, % off 181.836% correct_dir: False\n",
            "OP1X2: 1.679 diff: 0.0420 pred: 0.1046, error: 0.06258, % off 149.007% correct_dir: True\n",
            "OP1X2: 1.713 diff: -0.1330 pred: 0.1027, error: 0.23571, % off 177.222% correct_dir: False\n",
            "OP1X2: 2.530 diff: 0.0840 pred: 0.1052, error: 0.02115, % off 25.182% correct_dir: True\n",
            "OP1X2: 1.538 diff: -0.0430 pred: 0.1001, error: 0.14310, % off 332.787% correct_dir: False\n",
            "OP1X2: 2.841 diff: 0.0000 pred: 0.1040, error: 0.10395, % off -100.000% correct_dir: True\n",
            "OP1X2: 3.723 diff: 0.4490 pred: 0.1050, error: 0.34404, % off 76.624% correct_dir: True\n",
            "OP1X2: 1.945 diff: -0.0470 pred: 0.1004, error: 0.14742, % off 313.658% correct_dir: False\n",
            "OP1X2: 2.416 diff: -0.0280 pred: 0.1043, error: 0.13231, % off 472.533% correct_dir: False\n",
            "OP1X2: 1.334 diff: -0.0860 pred: 0.0959, error: 0.18188, % off 211.485% correct_dir: False\n",
            "OP1X2: 2.868 diff: -0.0980 pred: 0.1030, error: 0.20096, % off 205.060% correct_dir: False\n",
            "OP1X2: 1.772 diff: 0.0220 pred: 0.1032, error: 0.08117, % off 368.967% correct_dir: True\n",
            "OP1X2: 2.845 diff: -0.0400 pred: 0.1050, error: 0.14502, % off 362.557% correct_dir: False\n",
            "OP1X2: 2.791 diff: -0.2370 pred: 0.1018, error: 0.33882, % off 142.964% correct_dir: False\n",
            "OP1X2: 1.630 diff: 0.0520 pred: 0.1025, error: 0.05051, % off 97.144% correct_dir: True\n",
            "OP1X2: 2.125 diff: -0.1820 pred: 0.1045, error: 0.28652, % off 157.427% correct_dir: False\n",
            "OP1X2: 1.517 diff: 0.1730 pred: 0.0998, error: 0.07315, % off 42.285% correct_dir: True\n",
            "OP1X2: 5.210 diff: 1.9840 pred: 0.1007, error: 1.88332, % off 94.926% correct_dir: True\n",
            "OP1X2: 1.779 diff: 0.3670 pred: 0.1021, error: 0.26490, % off 72.180% correct_dir: True\n",
            "OP1X2: 1.263 diff: -0.0950 pred: 0.0999, error: 0.19491, % off 205.164% correct_dir: False\n",
            "OP1X2: 1.695 diff: -0.1770 pred: 0.1024, error: 0.27940, % off 157.856% correct_dir: False\n",
            "OP1X2: 2.484 diff: 0.0420 pred: 0.1026, error: 0.06057, % off 144.205% correct_dir: True\n",
            "OP1X2: 2.501 diff: 0.1340 pred: 0.1031, error: 0.03089, % off 23.052% correct_dir: True\n",
            "OP1X2: 3.541 diff: 0.5020 pred: 0.1056, error: 0.39638, % off 78.960% correct_dir: True\n",
            "OP1X2: 3.061 diff: -0.3000 pred: 0.1042, error: 0.40422, % off 134.740% correct_dir: False\n",
            "OP1X2: 1.930 diff: -0.3250 pred: 0.1008, error: 0.42584, % off 131.028% correct_dir: False\n",
            "OP1X2: 1.390 diff: -0.0420 pred: 0.0977, error: 0.13975, % off 332.732% correct_dir: False\n",
            "OP1X2: 2.020 diff: 0.2390 pred: 0.1043, error: 0.13470, % off 56.360% correct_dir: True\n",
            "OP1X2: 2.066 diff: -0.0680 pred: 0.0993, error: 0.16730, % off 246.037% correct_dir: False\n",
            "OP1X2: 2.846 diff: -0.0720 pred: 0.1038, error: 0.17582, % off 244.201% correct_dir: False\n",
            "OP1X2: 3.575 diff: 0.3200 pred: 0.1045, error: 0.21546, % off 67.331% correct_dir: True\n",
            "OP1X2: 2.580 diff: -0.0670 pred: 0.1044, error: 0.17144, % off 255.888% correct_dir: False\n",
            "OP1X2: 2.242 diff: -0.1670 pred: 0.1034, error: 0.27039, % off 161.910% correct_dir: False\n",
            "OP1X2: 2.054 diff: -0.1060 pred: 0.1022, error: 0.20820, % off 196.419% correct_dir: False\n",
            "OP1X2: 1.342 diff: -0.0150 pred: 0.0985, error: 0.11351, % off 756.745% correct_dir: False\n",
            "OP1X2: 2.644 diff: 0.2710 pred: 0.1039, error: 0.16714, % off 61.674% correct_dir: True\n",
            "OP1X2: 1.481 diff: -0.1810 pred: 0.0998, error: 0.28078, % off 155.128% correct_dir: False\n",
            "OP1X2: 3.071 diff: 0.2040 pred: 0.1042, error: 0.09982, % off 48.933% correct_dir: True\n",
            "OP1X2: 1.326 diff: -0.0550 pred: 0.1010, error: 0.15599, % off 283.615% correct_dir: False\n",
            "OP1X2: 2.569 diff: -0.0640 pred: 0.0998, error: 0.16376, % off 255.881% correct_dir: False\n",
            "OP1X2: 1.833 diff: 0.0040 pred: 0.1009, error: 0.09694, % off 2423.520% correct_dir: True\n",
            "OP1X2: 6.529 diff: 0.5270 pred: 0.1030, error: 0.42403, % off 80.461% correct_dir: True\n",
            "OP1X2: 2.848 diff: -0.3130 pred: 0.1043, error: 0.41733, % off 133.331% correct_dir: False\n",
            "OP1X2: 1.860 diff: 0.1280 pred: 0.1027, error: 0.02528, % off 19.749% correct_dir: True\n",
            "OP1X2: 1.508 diff: 0.1340 pred: 0.1009, error: 0.03306, % off 24.675% correct_dir: True\n",
            "OP1X2: 2.047 diff: -0.0310 pred: 0.1013, error: 0.13231, % off 426.811% correct_dir: False\n",
            "OP1X2: 1.835 diff: -0.1690 pred: 0.1035, error: 0.27252, % off 161.256% correct_dir: False\n",
            "OP1X2: 1.520 diff: 0.1150 pred: 0.0988, error: 0.01619, % off 14.077% correct_dir: True\n",
            "OP1X2: 2.518 diff: -0.1070 pred: 0.1039, error: 0.21091, % off 197.109% correct_dir: False\n",
            "OP1X2: 3.429 diff: 1.1330 pred: 0.1043, error: 1.02871, % off 90.796% correct_dir: True\n",
            "OP1X2: 3.222 diff: 0.2220 pred: 0.1019, error: 0.12007, % off 54.086% correct_dir: True\n",
            "OP1X2: 1.430 diff: 0.4160 pred: 0.0990, error: 0.31696, % off 76.192% correct_dir: True\n",
            "OP1X2: 1.697 diff: 0.3390 pred: 0.1010, error: 0.23797, % off 70.199% correct_dir: True\n",
            "OP1X2: 1.615 diff: -0.2330 pred: 0.0990, error: 0.33200, % off 142.489% correct_dir: False\n",
            "OP1X2: 2.669 diff: -0.0530 pred: 0.1041, error: 0.15706, % off 296.342% correct_dir: False\n",
            "OP1X2: 1.751 diff: -0.0660 pred: 0.1005, error: 0.16651, % off 252.283% correct_dir: False\n",
            "OP1X2: 1.891 diff: -0.1740 pred: 0.0996, error: 0.27364, % off 157.262% correct_dir: False\n",
            "OP1X2: 2.261 diff: 0.3080 pred: 0.1028, error: 0.20520, % off 66.623% correct_dir: True\n",
            "OP1X2: 2.195 diff: 0.1010 pred: 0.0998, error: 0.00116, % off 1.144% correct_dir: True\n",
            "OP1X2: 2.890 diff: 0.9420 pred: 0.1032, error: 0.83882, % off 89.047% correct_dir: True\n",
            "OP1X2: 2.234 diff: 0.0650 pred: 0.1030, error: 0.03799, % off 58.452% correct_dir: True\n",
            "OP1X2: 1.950 diff: 0.0220 pred: 0.1034, error: 0.08140, % off 370.023% correct_dir: True\n",
            "OP1X2: 2.959 diff: 0.3500 pred: 0.1019, error: 0.24811, % off 70.890% correct_dir: True\n",
            "OP1X2: 1.737 diff: -0.1320 pred: 0.1013, error: 0.23332, % off 176.757% correct_dir: False\n",
            "OP1X2: 1.333 diff: 0.0930 pred: 0.0971, error: 0.00405, % off 4.356% correct_dir: True\n",
            "OP1X2: 3.268 diff: -0.3190 pred: 0.1029, error: 0.42194, % off 132.269% correct_dir: False\n",
            "OP1X2: 4.362 diff: 1.0890 pred: 0.1051, error: 0.98391, % off 90.349% correct_dir: True\n",
            "OP1X2: 2.632 diff: 0.2260 pred: 0.1046, error: 0.12139, % off 53.713% correct_dir: True\n",
            "OP1X2: 1.933 diff: -0.0620 pred: 0.1008, error: 0.16278, % off 262.556% correct_dir: False\n",
            "OP1X2: 2.189 diff: 0.1980 pred: 0.1000, error: 0.09798, % off 49.483% correct_dir: True\n",
            "OP1X2: 3.063 diff: 0.2530 pred: 0.1036, error: 0.14944, % off 59.069% correct_dir: True\n",
            "OP1X2: 1.287 diff: -0.0720 pred: 0.0982, error: 0.17024, % off 236.450% correct_dir: False\n",
            "OP1X2: 2.686 diff: 0.9190 pred: 0.1030, error: 0.81600, % off 88.793% correct_dir: True\n",
            "OP1X2: 1.829 diff: -0.1000 pred: 0.1007, error: 0.20074, % off 200.740% correct_dir: False\n",
            "OP1X2: 1.598 diff: 0.0240 pred: 0.0989, error: 0.07490, % off 312.086% correct_dir: True\n",
            "OP1X2: 1.905 diff: 0.1040 pred: 0.1023, error: 0.00169, % off 1.623% correct_dir: True\n",
            "OP1X2: 1.571 diff: 0.1040 pred: 0.0993, error: 0.00472, % off 4.536% correct_dir: True\n",
            "OP1X2: 2.603 diff: 0.3770 pred: 0.1011, error: 0.27594, % off 73.195% correct_dir: True\n",
            "OP1X2: 4.068 diff: 0.2560 pred: 0.1031, error: 0.15287, % off 59.714% correct_dir: True\n",
            "OP1X2: 1.816 diff: 0.1360 pred: 0.1040, error: 0.03201, % off 23.534% correct_dir: True\n",
            "OP1X2: 2.480 diff: -0.0250 pred: 0.1031, error: 0.12810, % off 512.399% correct_dir: False\n",
            "OP1X2: 1.380 diff: -0.0500 pred: 0.0999, error: 0.14993, % off 299.870% correct_dir: False\n",
            "OP1X2: 1.956 diff: 0.2240 pred: 0.1017, error: 0.12228, % off 54.591% correct_dir: True\n",
            "OP1X2: 1.221 diff: 0.0260 pred: 0.0933, error: 0.06733, % off 258.943% correct_dir: True\n",
            "OP1X2: 1.556 diff: -0.2260 pred: 0.0995, error: 0.32554, % off 144.045% correct_dir: False\n",
            "OP1X2: 1.835 diff: -0.1250 pred: 0.1014, error: 0.22640, % off 181.121% correct_dir: False\n",
            "OP1X2: 4.629 diff: 0.2860 pred: 0.1008, error: 0.18520, % off 64.754% correct_dir: True\n",
            "OP1X2: 2.008 diff: 0.2190 pred: 0.0988, error: 0.12018, % off 54.876% correct_dir: True\n",
            "OP1X2: 1.781 diff: -0.0100 pred: 0.1000, error: 0.11002, % off 1100.225% correct_dir: False\n",
            "OP1X2: 1.426 diff: -0.0780 pred: 0.0962, error: 0.17420, % off 223.336% correct_dir: False\n",
            "OP1X2: 1.745 diff: -0.0560 pred: 0.1024, error: 0.15845, % off 282.941% correct_dir: False\n",
            "OP1X2: 1.812 diff: -0.1740 pred: 0.1015, error: 0.27547, % off 158.315% correct_dir: False\n",
            "OP1X2: 6.219 diff: 0.7490 pred: 0.1048, error: 0.64420, % off 86.008% correct_dir: True\n",
            "OP1X2: 1.972 diff: 0.1810 pred: 0.1020, error: 0.07896, % off 43.625% correct_dir: True\n",
            "OP1X2: 2.411 diff: -0.1800 pred: 0.1025, error: 0.28255, % off 156.970% correct_dir: False\n",
            "OP1X2: 1.821 diff: 0.0630 pred: 0.0977, error: 0.03475, % off 55.152% correct_dir: True\n",
            "OP1X2: 2.470 diff: -0.0690 pred: 0.1044, error: 0.17337, % off 251.267% correct_dir: False\n",
            "OP1X2: 1.880 diff: -0.2250 pred: 0.1003, error: 0.32533, % off 144.592% correct_dir: False\n",
            "OP1X2: 1.645 diff: -0.1820 pred: 0.1003, error: 0.28226, % off 155.086% correct_dir: False\n",
            "OP1X2: 1.154 diff: 0.0110 pred: 0.0921, error: 0.08109, % off 737.192% correct_dir: True\n",
            "OP1X2: 3.083 diff: 0.7440 pred: 0.1050, error: 0.63905, % off 85.894% correct_dir: True\n",
            "OP1X2: 1.929 diff: -0.0040 pred: 0.1004, error: 0.10440, % off 2609.978% correct_dir: False\n",
            "OP1X2: 2.115 diff: 0.4910 pred: 0.0985, error: 0.39248, % off 79.934% correct_dir: True\n",
            "OP1X2: 3.141 diff: 0.3390 pred: 0.1026, error: 0.23638, % off 69.728% correct_dir: True\n",
            "OP1X2: 2.047 diff: -0.0770 pred: 0.1007, error: 0.17772, % off 230.799% correct_dir: False\n",
            "OP1X2: 1.805 diff: -0.2670 pred: 0.0992, error: 0.36617, % off 137.142% correct_dir: False\n",
            "OP1X2: 2.554 diff: 0.0800 pred: 0.1022, error: 0.02219, % off 27.741% correct_dir: True\n",
            "OP1X2: 1.904 diff: 0.1300 pred: 0.1019, error: 0.02810, % off 21.613% correct_dir: True\n",
            "OP1X2: 4.213 diff: 0.4260 pred: 0.1043, error: 0.32165, % off 75.505% correct_dir: True\n",
            "OP1X2: 3.012 diff: 0.3720 pred: 0.1025, error: 0.26952, % off 72.453% correct_dir: True\n",
            "OP1X2: 2.528 diff: 0.0820 pred: 0.0985, error: 0.01648, % off 20.098% correct_dir: True\n",
            "OP1X2: 1.247 diff: -0.0560 pred: 0.0933, error: 0.14930, % off 266.607% correct_dir: False\n",
            "OP1X2: 2.804 diff: -0.0190 pred: 0.1032, error: 0.12217, % off 642.988% correct_dir: False\n",
            "OP1X2: 1.548 diff: -0.0890 pred: 0.0990, error: 0.18795, % off 211.183% correct_dir: False\n",
            "OP1X2: 2.278 diff: 0.3820 pred: 0.0986, error: 0.28340, % off 74.188% correct_dir: True\n",
            "OP1X2: 4.224 diff: 1.8710 pred: 0.1034, error: 1.76757, % off 94.472% correct_dir: True\n",
            "OP1X2: 2.000 diff: 0.2160 pred: 0.1021, error: 0.11390, % off 52.730% correct_dir: True\n",
            "OP1X2: 4.012 diff: 1.7380 pred: 0.1009, error: 1.63708, % off 94.193% correct_dir: True\n",
            "OP1X2: 1.674 diff: 0.1230 pred: 0.0996, error: 0.02339, % off 19.019% correct_dir: True\n",
            "OP1X2: 2.497 diff: 0.0180 pred: 0.1024, error: 0.08440, % off 468.912% correct_dir: True\n",
            "OP1X2: 1.565 diff: 0.1180 pred: 0.0975, error: 0.02050, % off 17.371% correct_dir: True\n",
            "OP1X2: 2.780 diff: -0.4070 pred: 0.0998, error: 0.50685, % off 124.532% correct_dir: False\n",
            "OP1X2: 1.719 diff: -0.1390 pred: 0.1019, error: 0.24094, % off 173.335% correct_dir: False\n",
            "OP1X2: 1.890 diff: 0.0950 pred: 0.1023, error: 0.00727, % off 7.653% correct_dir: True\n",
            "OP1X2: 1.290 diff: -0.0590 pred: 0.0982, error: 0.15717, % off 266.392% correct_dir: False\n",
            "OP1X2: 1.598 diff: 0.0020 pred: 0.0989, error: 0.09692, % off 4846.097% correct_dir: True\n",
            "OP1X2: 2.791 diff: 0.2020 pred: 0.1016, error: 0.10044, % off 49.721% correct_dir: True\n",
            "OP1X2: 1.325 diff: 0.1380 pred: 0.0960, error: 0.04195, % off 30.401% correct_dir: True\n",
            "OP1X2: 2.234 diff: 0.0410 pred: 0.0990, error: 0.05799, % off 141.448% correct_dir: True\n",
            "OP1X2: 1.136 diff: 0.0090 pred: 0.0878, error: 0.07878, % off 875.379% correct_dir: True\n",
            "OP1X2: 2.140 diff: 0.2240 pred: 0.0994, error: 0.12458, % off 55.614% correct_dir: True\n",
            "OP1X2: 1.382 diff: -0.0230 pred: 0.0989, error: 0.12186, % off 529.830% correct_dir: False\n",
            "OP1X2: 4.693 diff: 1.0540 pred: 0.1037, error: 0.95032, % off 90.163% correct_dir: True\n",
            "OP1X2: 2.485 diff: 0.1720 pred: 0.1025, error: 0.06949, % off 40.402% correct_dir: True\n",
            "OP1X2: 4.220 diff: 1.7190 pred: 0.1034, error: 1.61560, % off 93.985% correct_dir: True\n",
            "OP1X2: 2.247 diff: 0.0140 pred: 0.0989, error: 0.08486, % off 606.115% correct_dir: True\n",
            "OP1X2: 1.568 diff: 0.0020 pred: 0.0982, error: 0.09620, % off 4809.751% correct_dir: True\n",
            "OP1X2: 2.246 diff: 0.1260 pred: 0.1008, error: 0.02518, % off 19.987% correct_dir: True\n",
            "OP1X2: 1.552 diff: -0.0270 pred: 0.0994, error: 0.12645, % off 468.325% correct_dir: False\n",
            "OP1X2: 2.195 diff: -0.0010 pred: 0.0995, error: 0.10049, % off 10049.821% correct_dir: False\n",
            "OP1X2: 2.077 diff: 0.1660 pred: 0.1012, error: 0.06481, % off 39.044% correct_dir: True\n",
            "OP1X2: 1.217 diff: 0.0060 pred: 0.0936, error: 0.08762, % off 1460.327% correct_dir: True\n",
            "OP1X2: 2.211 diff: -0.0140 pred: 0.0996, error: 0.11363, % off 811.658% correct_dir: False\n",
            "OP1X2: 2.504 diff: 0.1310 pred: 0.1011, error: 0.02989, % off 22.817% correct_dir: True\n",
            "OP1X2: 3.043 diff: -0.0380 pred: 0.1015, error: 0.13953, % off 367.178% correct_dir: False\n",
            "OP1X2: 1.660 diff: 0.0610 pred: 0.1002, error: 0.03920, % off 64.263% correct_dir: True\n",
            "OP1X2: 5.308 diff: 0.8870 pred: 0.1034, error: 0.78356, % off 88.338% correct_dir: True\n",
            "OP1X2: 1.782 diff: 0.2390 pred: 0.0989, error: 0.14013, % off 58.632% correct_dir: True\n",
            "OP1X2: 2.435 diff: 0.1720 pred: 0.1024, error: 0.06964, % off 40.490% correct_dir: True\n",
            "OP1X2: 2.476 diff: -0.0960 pred: 0.0966, error: 0.19260, % off 200.626% correct_dir: False\n",
            "OP1X2: 2.127 diff: -0.0230 pred: 0.1019, error: 0.12486, % off 542.849% correct_dir: False\n",
            "OP1X2: 1.576 diff: 0.1380 pred: 0.0990, error: 0.03899, % off 28.256% correct_dir: True\n",
            "OP1X2: 3.889 diff: -0.1730 pred: 0.1014, error: 0.27436, % off 158.589% correct_dir: False\n",
            "OP1X2: 2.712 diff: 0.3580 pred: 0.1009, error: 0.25709, % off 71.813% correct_dir: True\n",
            "OP1X2: 1.742 diff: -0.1060 pred: 0.0995, error: 0.20545, % off 193.821% correct_dir: False\n",
            "OP1X2: 2.859 diff: -0.3090 pred: 0.1002, error: 0.40918, % off 132.421% correct_dir: False\n",
            "OP1X2: 3.705 diff: -0.2400 pred: 0.1011, error: 0.34108, % off 142.117% correct_dir: False\n",
            "OP1X2: 1.896 diff: -0.1720 pred: 0.0990, error: 0.27103, % off 157.574% correct_dir: False\n",
            "OP1X2: 2.095 diff: 0.0150 pred: 0.0983, error: 0.08334, % off 555.599% correct_dir: True\n",
            "OP1X2: 2.154 diff: 0.2720 pred: 0.1027, error: 0.16927, % off 62.230% correct_dir: True\n",
            "OP1X2: 1.146 diff: -0.0250 pred: 0.0906, error: 0.11555, % off 462.207% correct_dir: False\n",
            "OP1X2: 3.637 diff: 0.3170 pred: 0.1017, error: 0.21526, % off 67.905% correct_dir: True\n",
            "OP1X2: 1.661 diff: 0.1340 pred: 0.0981, error: 0.03588, % off 26.777% correct_dir: True\n",
            "OP1X2: 4.459 diff: 0.5740 pred: 0.1022, error: 0.47178, % off 82.192% correct_dir: True\n",
            "OP1X2: 2.627 diff: 0.1620 pred: 0.1003, error: 0.06166, % off 38.060% correct_dir: True\n",
            "OP1X2: 2.483 diff: -0.2360 pred: 0.0982, error: 0.33420, % off 141.612% correct_dir: False\n",
            "OP1X2: 1.602 diff: 0.2050 pred: 0.0984, error: 0.10655, % off 51.978% correct_dir: True\n",
            "OP1X2: 5.523 diff: 1.2920 pred: 0.1056, error: 1.18639, % off 91.826% correct_dir: True\n",
            "OP1X2: 1.301 diff: 0.0760 pred: 0.0939, error: 0.01788, % off 23.527% correct_dir: True\n",
            "OP1X2: 2.747 diff: -0.0060 pred: 0.0988, error: 0.10483, % off 1747.121% correct_dir: False\n",
            "OP1X2: 4.720 diff: 0.0360 pred: 0.1023, error: 0.06628, % off 184.103% correct_dir: True\n",
            "OP1X2: 2.069 diff: 0.0390 pred: 0.1002, error: 0.06125, % off 157.039% correct_dir: True\n",
            "OP1X2: 1.499 diff: 0.0710 pred: 0.0969, error: 0.02587, % off 36.431% correct_dir: True\n",
            "OP1X2: 1.823 diff: 0.0230 pred: 0.0996, error: 0.07661, % off 333.071% correct_dir: True\n",
            "OP1X2: 1.265 diff: 0.0710 pred: 0.0937, error: 0.02268, % off 31.946% correct_dir: True\n",
            "OP1X2: 1.354 diff: 0.2510 pred: 0.0949, error: 0.15607, % off 62.177% correct_dir: True\n",
            "OP1X2: 5.438 diff: 0.6220 pred: 0.1039, error: 0.51812, % off 83.299% correct_dir: True\n",
            "OP1X2: 1.557 diff: -0.0460 pred: 0.0965, error: 0.14253, % off 309.849% correct_dir: False\n",
            "OP1X2: 1.645 diff: 0.0630 pred: 0.0959, error: 0.03285, % off 52.147% correct_dir: True\n",
            "OP1X2: 2.296 diff: -0.1360 pred: 0.1013, error: 0.23733, % off 174.504% correct_dir: False\n",
            "OP1X2: 5.320 diff: -1.2050 pred: 0.1010, error: 1.30603, % off 108.384% correct_dir: False\n",
            "OP1X2: 2.217 diff: -0.1970 pred: 0.1004, error: 0.29738, % off 150.955% correct_dir: False\n",
            "OP1X2: 1.749 diff: -0.0610 pred: 0.1011, error: 0.16208, % off 265.703% correct_dir: False\n",
            "OP1X2: 1.826 diff: 0.1770 pred: 0.1002, error: 0.07679, % off 43.384% correct_dir: True\n",
            "OP1X2: 2.315 diff: -0.1340 pred: 0.1010, error: 0.23499, % off 175.364% correct_dir: False\n",
            "OP1X2: 1.716 diff: -0.1130 pred: 0.0983, error: 0.21134, % off 187.028% correct_dir: False\n",
            "OP1X2: 2.286 diff: -0.1560 pred: 0.0980, error: 0.25400, % off 162.822% correct_dir: False\n",
            "OP1X2: 3.254 diff: -0.2220 pred: 0.1014, error: 0.32340, % off 145.678% correct_dir: False\n",
            "OP1X2: 1.765 diff: -0.0220 pred: 0.1005, error: 0.12250, % off 556.842% correct_dir: False\n",
            "OP1X2: 1.556 diff: -0.1360 pred: 0.1002, error: 0.23616, % off 173.647% correct_dir: False\n",
            "OP1X2: 2.786 diff: -0.2180 pred: 0.1016, error: 0.31955, % off 146.583% correct_dir: False\n",
            "OP1X2: 2.228 diff: -0.0220 pred: 0.0996, error: 0.12165, % off 552.945% correct_dir: False\n",
            "OP1X2: 2.285 diff: -0.1070 pred: 0.0995, error: 0.20648, % off 192.972% correct_dir: False\n",
            "OP1X2: 2.271 diff: 0.2290 pred: 0.0959, error: 0.13312, % off 58.131% correct_dir: True\n",
            "OP1X2: 3.450 diff: 0.1740 pred: 0.1000, error: 0.07397, % off 42.513% correct_dir: True\n",
            "OP1X2: 1.218 diff: -0.0380 pred: 0.0908, error: 0.12885, % off 339.078% correct_dir: False\n",
            "OP1X2: 4.200 diff: 0.3600 pred: 0.1007, error: 0.25927, % off 72.020% correct_dir: True\n",
            "OP1X2: 2.064 diff: -0.0120 pred: 0.0994, error: 0.11143, % off 928.558% correct_dir: False\n",
            "OP1X2: 1.696 diff: 0.1040 pred: 0.0998, error: 0.00417, % off 4.007% correct_dir: True\n",
            "OP1X2: 3.557 diff: 0.1850 pred: 0.0981, error: 0.08690, % off 46.972% correct_dir: True\n",
            "OP1X2: 2.064 diff: 0.2120 pred: 0.0977, error: 0.11430, % off 53.915% correct_dir: True\n",
            "OP1X2: 1.329 diff: 0.1280 pred: 0.0953, error: 0.03271, % off 25.553% correct_dir: True\n",
            "OP1X2: 4.730 diff: 0.3720 pred: 0.1005, error: 0.27152, % off 72.990% correct_dir: True\n",
            "OP1X2: 1.936 diff: 0.2980 pred: 0.0984, error: 0.19955, % off 66.963% correct_dir: True\n",
            "OP1X2: 3.202 diff: 0.5930 pred: 0.0978, error: 0.49517, % off 83.502% correct_dir: True\n",
            "OP1X2: 1.959 diff: 0.4130 pred: 0.0998, error: 0.31316, % off 75.826% correct_dir: True\n",
            "OP1X2: 1.986 diff: -0.1240 pred: 0.1001, error: 0.22406, % off 180.693% correct_dir: False\n",
            "OP1X2: 1.705 diff: -0.0750 pred: 0.0985, error: 0.17349, % off 231.325% correct_dir: False\n",
            "OP1X2: 1.971 diff: -0.0720 pred: 0.0971, error: 0.16913, % off 234.899% correct_dir: False\n",
            "OP1X2: 4.385 diff: 0.5930 pred: 0.0997, error: 0.49325, % off 83.179% correct_dir: True\n",
            "OP1X2: 1.351 diff: 0.0570 pred: 0.0946, error: 0.03760, % off 65.958% correct_dir: True\n",
            "OP1X2: 2.875 diff: 0.3480 pred: 0.0990, error: 0.24902, % off 71.558% correct_dir: True\n",
            "OP1X2: 2.887 diff: 0.8540 pred: 0.1013, error: 0.75269, % off 88.138% correct_dir: True\n",
            "OP1X2: 2.412 diff: 0.0440 pred: 0.1022, error: 0.05818, % off 132.232% correct_dir: True\n",
            "OP1X2: 1.280 diff: -0.0020 pred: 0.0954, error: 0.09742, % off 4870.976% correct_dir: False\n",
            "OP1X2: 1.580 diff: 0.0610 pred: 0.0963, error: 0.03533, % off 57.922% correct_dir: True\n",
            "OP1X2: 1.731 diff: 0.0740 pred: 0.0953, error: 0.02125, % off 28.720% correct_dir: True\n",
            "OP1X2: 2.498 diff: 0.2210 pred: 0.0993, error: 0.12173, % off 55.081% correct_dir: True\n",
            "OP1X2: 1.730 diff: 0.0270 pred: 0.0960, error: 0.06898, % off 255.481% correct_dir: True\n",
            "OP1X2: 1.925 diff: 0.1110 pred: 0.1000, error: 0.01099, % off 9.904% correct_dir: True\n",
            "OP1X2: 5.222 diff: 0.2660 pred: 0.1007, error: 0.16526, % off 62.127% correct_dir: True\n",
            "OP1X2: 2.419 diff: 0.7500 pred: 0.0998, error: 0.65019, % off 86.692% correct_dir: True\n",
            "OP1X2: 1.535 diff: -0.0150 pred: 0.0973, error: 0.11228, % off 748.546% correct_dir: False\n",
            "OP1X2: 1.697 diff: 0.0480 pred: 0.0971, error: 0.04908, % off 102.258% correct_dir: True\n",
            "OP1X2: 3.108 diff: 0.4490 pred: 0.0970, error: 0.35201, % off 78.399% correct_dir: True\n",
            "OP1X2: 2.303 diff: 0.0570 pred: 0.1013, error: 0.04429, % off 77.694% correct_dir: True\n",
            "OP1X2: 1.306 diff: 0.1510 pred: 0.0912, error: 0.05980, % off 39.600% correct_dir: True\n",
            "OP1X2: 2.147 diff: -0.2620 pred: 0.0980, error: 0.35997, % off 137.391% correct_dir: False\n",
            "OP1X2: 4.605 diff: 0.1270 pred: 0.1006, error: 0.02639, % off 20.781% correct_dir: True\n",
            "OP1X2: 4.095 diff: 0.4800 pred: 0.1019, error: 0.37814, % off 78.780% correct_dir: True\n",
            "OP1X2: 1.622 diff: -0.0990 pred: 0.0980, error: 0.19699, % off 198.985% correct_dir: False\n",
            "OP1X2: 2.109 diff: -0.0050 pred: 0.0979, error: 0.10286, % off 2057.286% correct_dir: False\n",
            "OP1X2: 4.015 diff: 0.5660 pred: 0.1027, error: 0.46331, % off 81.857% correct_dir: True\n",
            "OP1X2: 1.240 diff: 0.0740 pred: 0.0931, error: 0.01910, % off 25.810% correct_dir: True\n",
            "OP1X2: 1.975 diff: 0.1530 pred: 0.0990, error: 0.05396, % off 35.268% correct_dir: True\n",
            "OP1X2: 2.819 diff: 0.5980 pred: 0.0985, error: 0.49947, % off 83.523% correct_dir: True\n",
            "OP1X2: 1.424 diff: 0.0070 pred: 0.0958, error: 0.08878, % off 1268.351% correct_dir: True\n",
            "OP1X2: 2.755 diff: 0.7600 pred: 0.1002, error: 0.65981, % off 86.817% correct_dir: True\n",
            "OP1X2: 1.563 diff: 0.0210 pred: 0.0968, error: 0.07585, % off 361.174% correct_dir: True\n",
            "OP1X2: 5.564 diff: 1.1830 pred: 0.1043, error: 1.07874, % off 91.187% correct_dir: True\n",
            "OP1X2: 1.848 diff: -0.0190 pred: 0.0942, error: 0.11318, % off 595.678% correct_dir: False\n",
            "OP1X2: 2.297 diff: -0.0540 pred: 0.0982, error: 0.15220, % off 281.847% correct_dir: False\n",
            "OP1X2: 1.931 diff: -0.1400 pred: 0.0988, error: 0.23880, % off 170.569% correct_dir: False\n",
            "OP1X2: 2.016 diff: 0.1540 pred: 0.0975, error: 0.05652, % off 36.700% correct_dir: True\n",
            "OP1X2: 2.006 diff: -0.0410 pred: 0.0963, error: 0.13730, % off 334.887% correct_dir: False\n",
            "OP1X2: 2.172 diff: 0.3700 pred: 0.0976, error: 0.27244, % off 73.632% correct_dir: True\n",
            "OP1X2: 2.058 diff: -0.1620 pred: 0.0982, error: 0.26020, % off 160.615% correct_dir: False\n",
            "OP1X2: 2.388 diff: 0.2540 pred: 0.0989, error: 0.15509, % off 61.057% correct_dir: True\n",
            "OP1X2: 2.637 diff: -0.1340 pred: 0.0992, error: 0.23323, % off 174.052% correct_dir: False\n",
            "OP1X2: 1.938 diff: 0.2160 pred: 0.0949, error: 0.12107, % off 56.053% correct_dir: True\n",
            "OP1X2: 1.270 diff: -0.0120 pred: 0.0927, error: 0.10474, % off 872.850% correct_dir: False\n",
            "OP1X2: 1.538 diff: 0.0330 pred: 0.0989, error: 0.06594, % off 199.826% correct_dir: True\n",
            "OP1X2: 1.648 diff: 0.0640 pred: 0.0974, error: 0.03335, % off 52.111% correct_dir: True\n",
            "OP1X2: 2.918 diff: 1.0330 pred: 0.1000, error: 0.93300, % off 90.319% correct_dir: True\n",
            "OP1X2: 2.111 diff: -0.1920 pred: 0.0952, error: 0.28716, % off 149.563% correct_dir: False\n",
            "OP1X2: 3.116 diff: 0.2080 pred: 0.0990, error: 0.10896, % off 52.383% correct_dir: True\n",
            "OP1X2: 2.506 diff: 0.5740 pred: 0.0983, error: 0.47574, % off 82.881% correct_dir: True\n",
            "OP1X2: 2.067 diff: -0.1330 pred: 0.0974, error: 0.23043, % off 173.254% correct_dir: False\n",
            "OP1X2: 1.885 diff: -0.0090 pred: 0.0974, error: 0.10638, % off 1181.972% correct_dir: False\n",
            "OP1X2: 2.080 diff: 0.3370 pred: 0.0967, error: 0.24031, % off 71.308% correct_dir: True\n",
            "OP1X2: 4.759 diff: 0.2170 pred: 0.0977, error: 0.11934, % off 54.994% correct_dir: True\n",
            "OP1X2: 5.086 diff: -1.4710 pred: 0.0998, error: 1.57082, % off 106.786% correct_dir: False\n",
            "OP1X2: 1.350 diff: -0.0570 pred: 0.0937, error: 0.15067, % off 264.327% correct_dir: False\n",
            "OP1X2: 2.623 diff: 0.1420 pred: 0.1000, error: 0.04204, % off 29.602% correct_dir: True\n",
            "OP1X2: 2.717 diff: -0.0250 pred: 0.0991, error: 0.12411, % off 496.437% correct_dir: False\n",
            "OP1X2: 1.594 diff: 0.0110 pred: 0.0970, error: 0.08600, % off 781.825% correct_dir: True\n",
            "OP1X2: 2.360 diff: 0.0260 pred: 0.0998, error: 0.07376, % off 283.705% correct_dir: True\n",
            "OP1X2: 1.264 diff: 0.0220 pred: 0.0918, error: 0.06984, % off 317.476% correct_dir: True\n",
            "OP1X2: 1.870 diff: -0.2050 pred: 0.0961, error: 0.30105, % off 146.855% correct_dir: False\n",
            "OP1X2: 2.102 diff: 0.0130 pred: 0.0971, error: 0.08406, % off 646.615% correct_dir: True\n",
            "OP1X2: 2.236 diff: 0.5010 pred: 0.0974, error: 0.40363, % off 80.565% correct_dir: True\n",
            "OP1X2: 1.374 diff: 0.0200 pred: 0.0939, error: 0.07394, % off 369.686% correct_dir: True\n",
            "OP1X2: 3.643 diff: 0.1000 pred: 0.1006, error: 0.00060, % off 0.602% correct_dir: True\n",
            "OP1X2: 2.820 diff: 0.6160 pred: 0.0978, error: 0.51816, % off 84.117% correct_dir: True\n",
            "OP1X2: 3.675 diff: 1.1590 pred: 0.0991, error: 1.05989, % off 91.448% correct_dir: True\n",
            "OP1X2: 1.743 diff: -0.0040 pred: 0.0989, error: 0.10288, % off 2571.894% correct_dir: False\n",
            "OP1X2: 1.875 diff: 0.2180 pred: 0.0949, error: 0.12309, % off 56.461% correct_dir: True\n",
            "OP1X2: 3.351 diff: -0.9570 pred: 0.1021, error: 1.05911, % off 110.670% correct_dir: False\n",
            "OP1X2: 2.244 diff: 0.3950 pred: 0.0968, error: 0.29817, % off 75.486% correct_dir: True\n",
            "OP1X2: 1.895 diff: 0.0590 pred: 0.0972, error: 0.03825, % off 64.830% correct_dir: True\n",
            "OP1X2: 3.329 diff: 1.4490 pred: 0.1016, error: 1.34739, % off 92.988% correct_dir: True\n",
            "OP1X2: 2.580 diff: 0.0100 pred: 0.0981, error: 0.08805, % off 880.531% correct_dir: True\n",
            "OP1X2: 2.484 diff: 0.3050 pred: 0.0967, error: 0.20833, % off 68.306% correct_dir: True\n",
            "OP1X2: 2.703 diff: -0.3060 pred: 0.0997, error: 0.40573, % off 132.592% correct_dir: False\n",
            "OP1X2: 1.764 diff: 0.0170 pred: 0.0955, error: 0.07853, % off 461.917% correct_dir: True\n",
            "OP1X2: 2.164 diff: -0.1790 pred: 0.0981, error: 0.27708, % off 154.792% correct_dir: False\n",
            "OP1X2: 1.383 diff: -0.0610 pred: 0.0926, error: 0.15357, % off 251.758% correct_dir: False\n",
            "OP1X2: 3.377 diff: 0.3960 pred: 0.0996, error: 0.29636, % off 74.839% correct_dir: True\n",
            "OP1X2: 3.548 diff: 0.2990 pred: 0.0954, error: 0.20360, % off 68.093% correct_dir: True\n",
            "OP1X2: 2.653 diff: 0.1240 pred: 0.0979, error: 0.02606, % off 21.020% correct_dir: True\n",
            "OP1X2: 1.262 diff: 0.0930 pred: 0.0933, error: 0.00033, % off 0.357% correct_dir: True\n",
            "OP1X2: 1.371 diff: -0.0490 pred: 0.0951, error: 0.14406, % off 293.993% correct_dir: False\n",
            "OP1X2: 2.718 diff: 0.5520 pred: 0.1006, error: 0.45144, % off 81.782% correct_dir: True\n",
            "OP1X2: 2.195 diff: 0.4730 pred: 0.0952, error: 0.37780, % off 79.874% correct_dir: True\n",
            "OP1X2: 1.975 diff: 0.2480 pred: 0.0957, error: 0.15230, % off 61.412% correct_dir: True\n",
            "OP1X2: 1.506 diff: 0.1810 pred: 0.0942, error: 0.08682, % off 47.968% correct_dir: True\n",
            "OP1X2: 1.594 diff: 0.0500 pred: 0.0934, error: 0.04337, % off 86.736% correct_dir: True\n",
            "OP1X2: 3.573 diff: -0.4290 pred: 0.0990, error: 0.52804, % off 123.087% correct_dir: False\n",
            "OP1X2: 1.385 diff: 0.0200 pred: 0.0947, error: 0.07468, % off 373.417% correct_dir: True\n",
            "OP1X2: 6.293 diff: -0.7500 pred: 0.1019, error: 0.85191, % off 113.587% correct_dir: False\n",
            "OP1X2: 1.958 diff: 0.0400 pred: 0.0962, error: 0.05623, % off 140.576% correct_dir: True\n",
            "OP1X2: 1.763 diff: -0.1200 pred: 0.0937, error: 0.21371, % off 178.094% correct_dir: False\n",
            "OP1X2: 2.210 diff: -0.1170 pred: 0.0979, error: 0.21486, % off 183.639% correct_dir: False\n",
            "OP1X2: 1.425 diff: -0.0300 pred: 0.0926, error: 0.12265, % off 408.824% correct_dir: False\n",
            "OP1X2: 2.099 diff: 0.1580 pred: 0.0950, error: 0.06300, % off 39.872% correct_dir: True\n",
            "OP1X2: 1.405 diff: -0.0190 pred: 0.0940, error: 0.11302, % off 594.869% correct_dir: False\n",
            "OP1X2: 1.741 diff: -0.0360 pred: 0.0956, error: 0.13160, % off 365.569% correct_dir: False\n",
            "OP1X2: 2.653 diff: 0.0810 pred: 0.0978, error: 0.01678, % off 20.721% correct_dir: True\n",
            "OP1X2: 1.301 diff: -0.0920 pred: 0.0941, error: 0.18614, % off 202.330% correct_dir: False\n",
            "OP1X2: 1.610 diff: 0.0480 pred: 0.0953, error: 0.04725, % off 98.447% correct_dir: True\n",
            "OP1X2: 3.146 diff: -0.8540 pred: 0.0963, error: 0.95030, % off 111.276% correct_dir: False\n",
            "OP1X2: 4.289 diff: 0.7160 pred: 0.0992, error: 0.61676, % off 86.139% correct_dir: True\n",
            "OP1X2: 1.737 diff: -0.2160 pred: 0.0938, error: 0.30984, % off 143.446% correct_dir: False\n",
            "OP1X2: 1.814 diff: 0.3190 pred: 0.0955, error: 0.22349, % off 70.060% correct_dir: True\n",
            "OP1X2: 3.496 diff: -0.3760 pred: 0.1010, error: 0.47703, % off 126.870% correct_dir: False\n",
            "OP1X2: 5.376 diff: 1.7710 pred: 0.0977, error: 1.67333, % off 94.485% correct_dir: True\n",
            "OP1X2: 1.557 diff: -0.0940 pred: 0.0950, error: 0.18899, % off 201.057% correct_dir: False\n",
            "OP1X2: 2.140 diff: -0.2030 pred: 0.0971, error: 0.30009, % off 147.829% correct_dir: False\n",
            "OP1X2: 1.676 diff: -0.1170 pred: 0.0957, error: 0.21270, % off 181.791% correct_dir: False\n",
            "OP1X2: 1.349 diff: -0.0370 pred: 0.0931, error: 0.13007, % off 351.551% correct_dir: False\n",
            "OP1X2: 1.300 diff: 0.0170 pred: 0.0899, error: 0.07291, % off 428.851% correct_dir: True\n",
            "OP1X2: 2.633 diff: 0.6940 pred: 0.0985, error: 0.59546, % off 85.802% correct_dir: True\n",
            "OP1X2: 3.457 diff: -0.4610 pred: 0.1002, error: 0.56116, % off 121.727% correct_dir: False\n",
            "OP1X2: 2.785 diff: 0.9750 pred: 0.0969, error: 0.87815, % off 90.066% correct_dir: True\n",
            "OP1X2: 1.641 diff: -0.2590 pred: 0.0913, error: 0.35028, % off 135.244% correct_dir: False\n",
            "OP1X2: 2.530 diff: 1.2000 pred: 0.0963, error: 1.10374, % off 91.979% correct_dir: True\n",
            "OP1X2: 1.910 diff: -0.0130 pred: 0.0971, error: 0.11015, % off 847.290% correct_dir: False\n",
            "OP1X2: 1.241 diff: -0.0260 pred: 0.0899, error: 0.11587, % off 445.653% correct_dir: False\n",
            "OP1X2: 2.608 diff: -0.0690 pred: 0.0993, error: 0.16833, % off 243.951% correct_dir: False\n",
            "OP1X2: 2.286 diff: 0.3610 pred: 0.0979, error: 0.26307, % off 72.873% correct_dir: True\n",
            "OP1X2: 2.767 diff: 0.3960 pred: 0.0961, error: 0.29988, % off 75.726% correct_dir: True\n",
            "OP1X2: 2.243 diff: -0.1240 pred: 0.0962, error: 0.22018, % off 177.566% correct_dir: False\n",
            "OP1X2: 1.314 diff: -0.0950 pred: 0.0950, error: 0.19004, % off 200.039% correct_dir: False\n",
            "OP1X2: 3.341 diff: 1.1380 pred: 0.0965, error: 1.04149, % off 91.519% correct_dir: True\n",
            "OP1X2: 2.250 diff: 0.0800 pred: 0.0959, error: 0.01590, % off 19.874% correct_dir: True\n",
            "OP1X2: 2.313 diff: 0.0290 pred: 0.0986, error: 0.06958, % off 239.934% correct_dir: True\n",
            "OP1X2: 1.861 diff: 0.0710 pred: 0.0932, error: 0.02217, % off 31.229% correct_dir: True\n",
            "mean abs error: 0.24728799906412238\n",
            "avg percent diff: 320.08%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-409-77633cf7db2f>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# compare_predictions_single(predictions, comp_data, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mevaluate_dm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-387-ee5d6c044c5e>\u001b[0m in \u001b[0;36mevaluate_dm\u001b[0;34m(predictions, op_col, diff_col, db)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;31m# print(f\"correct dir: {format((correct_dir/num) * 100, '.2f')}%\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"avg percent diff: {format((percent_diff_sum/num) * 100, '.2f')}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"too high: {too_high_count} occurences, avg of {too_high_sum/too_high_count}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m   \u001b[0mprint_percent_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"correct_dir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mprint_percent_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"up accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_up_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "Lvqi2CdUxpsK",
        "outputId": "d048a295-ab6c-4b0b-dd03-73b58f9d3a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  OP1_AVG  OPX_AVG  OP2_AVG  CP1_AVG  CPX_AVG  CP2_AVG  DIFF1  \\\n",
              "2580     30    3.627    3.395    2.042    3.327    3.181    2.337 -0.300   \n",
              "2581     30    4.420    3.376    1.842    4.250    3.137    2.045 -0.170   \n",
              "2586     30    3.744    3.370    2.013    4.734    3.421    1.853  0.990   \n",
              "2587     30    6.102    4.633    1.467    7.097    4.867    1.437  0.995   \n",
              "2593     31    3.225    3.124    2.344    3.323    3.034    2.426  0.098   \n",
              "...     ...      ...      ...      ...      ...      ...      ...    ...   \n",
              "3380     34    3.573    3.536    1.993    3.144    3.550    2.233 -0.429   \n",
              "3382     34    6.293    4.738    1.430    5.543    4.527    1.546 -0.750   \n",
              "3394     35    4.289    3.504    1.819    5.005    3.703    1.728  0.716   \n",
              "3397     35    3.496    3.374    2.060    3.120    3.265    2.369 -0.376   \n",
              "3398     35    5.376    4.774    1.484    7.147    5.386    1.380  1.771   \n",
              "\n",
              "      DIFFX  DIFF2  Alaves  Almeria  Ath Bilbao  Atl. Madrid  Barcelona  \\\n",
              "2580 -0.214  0.295       0        0           0            0          0   \n",
              "2581 -0.239  0.203       0        0           0            1          0   \n",
              "2586  0.051 -0.160       0        0           0            0          0   \n",
              "2587  0.234 -0.030       0        0           0            0          1   \n",
              "2593 -0.090  0.082       0        0           0            0          0   \n",
              "...     ...    ...     ...      ...         ...          ...        ...   \n",
              "3380  0.014  0.240       2        0           0            0          0   \n",
              "3382 -0.211  0.116       0        0           0            0          0   \n",
              "3394  0.199 -0.091       0        0           0            1          0   \n",
              "3397 -0.109  0.309       0        0           0            0          0   \n",
              "3398  0.612 -0.104       0        2           0            0          1   \n",
              "\n",
              "      Betis  Cadiz CF  Celta Vigo  Dep. La Coruna  Eibar  Elche  Espanyol  \\\n",
              "2580      1         2           0               0      0      0         0   \n",
              "2581      0         0           0               0      0      0         0   \n",
              "2586      0         0           0               0      0      2         0   \n",
              "2587      0         0           0               0      0      0         0   \n",
              "2593      0         0           0               0      0      0         0   \n",
              "...     ...       ...         ...             ...    ...    ...       ...   \n",
              "3380      0         0           0               0      0      0         0   \n",
              "3382      0         0           0               0      0      0         0   \n",
              "3394      0         0           0               0      0      0         0   \n",
              "3397      1         0           0               0      0      0         0   \n",
              "3398      0         0           0               0      0      0         0   \n",
              "\n",
              "      Getafe  Gijon  Girona  Granada CF  Huesca  Las Palmas  Leganes  Levante  \\\n",
              "2580       0      0       0           0       0           0        0        0   \n",
              "2581       0      0       0           0       0           0        0        0   \n",
              "2586       0      0       0           0       0           0        0        0   \n",
              "2587       0      0       0           0       0           0        0        2   \n",
              "2593       2      0       0           0       0           0        0        0   \n",
              "...      ...    ...     ...         ...     ...         ...      ...      ...   \n",
              "3380       0      0       1           0       0           0        0        0   \n",
              "3382       0      0       0           2       0           0        0        0   \n",
              "3394       2      0       0           0       0           0        0        0   \n",
              "3397       0      0       0           0       0           2        0        0   \n",
              "3398       0      0       0           0       0           0        0        0   \n",
              "\n",
              "      Malaga  Mallorca  Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  \\\n",
              "2580       0         0        0               0            0              0   \n",
              "2581       0         2        0               0            0              0   \n",
              "2586       0         0        0               0            0              1   \n",
              "2587       0         0        0               0            0              0   \n",
              "2593       0         0        0               0            0              0   \n",
              "...      ...       ...      ...             ...          ...            ...   \n",
              "3380       0         0        0               0            0              0   \n",
              "3382       0         0        0               0            1              0   \n",
              "3394       0         0        0               0            0              0   \n",
              "3397       0         0        0               0            0              0   \n",
              "3398       0         0        0               0            0              0   \n",
              "\n",
              "      Sevilla  Valencia  Valladolid  Villarreal  home_wins_rate  \\\n",
              "2580        0         0           0           0        0.166667   \n",
              "2581        0         0           0           0        0.200000   \n",
              "2586        0         0           0           0        0.266667   \n",
              "2587        0         0           0           0        0.133333   \n",
              "2593        0         0           0           1        0.225806   \n",
              "...       ...       ...         ...         ...             ...   \n",
              "3380        0         0           0           0        0.323529   \n",
              "3382        0         0           0           0        0.117647   \n",
              "3394        0         0           0           0        0.285714   \n",
              "3397        0         0           0           0        0.285714   \n",
              "3398        0         0           0           0        0.057143   \n",
              "\n",
              "      home_tie_rate  home_loss_rate  away_wins_rate  away_tie_rate  \\\n",
              "2580       0.433333        0.400000        0.533333       0.166667   \n",
              "2581       0.266667        0.533333        0.566667       0.200000   \n",
              "2586       0.266667        0.466667        0.466667       0.300000   \n",
              "2587       0.333333        0.533333        0.533333       0.300000   \n",
              "2593       0.354839        0.419355        0.387097       0.322581   \n",
              "...             ...             ...             ...            ...   \n",
              "3380       0.235294        0.441176        0.676471       0.147059   \n",
              "3382       0.264706        0.617647        0.794118       0.176471   \n",
              "3394       0.371429        0.342857        0.628571       0.114286   \n",
              "3397       0.200000        0.514286        0.400000       0.371429   \n",
              "3398       0.314286        0.628571        0.657143       0.200000   \n",
              "\n",
              "      away_loss_rate  OP1_RATE  OPX_RATE  OP2_RATE  HOME_POWER  \n",
              "2580        0.300000  0.400154  0.374559  0.225287    0.621622  \n",
              "2581        0.233333  0.458601  0.350280  0.191118    0.500000  \n",
              "2586        0.233333  0.410211  0.369234  0.220554    0.648649  \n",
              "2587        0.133333  0.500082  0.379692  0.120226    0.439024  \n",
              "2593        0.290323  0.370988  0.359370  0.269642    0.735294  \n",
              "...              ...       ...       ...       ...         ...  \n",
              "3380        0.176471  0.392551  0.388486  0.218963    0.588235  \n",
              "3382        0.029412  0.505016  0.380226  0.114758    0.283333  \n",
              "3394        0.257143  0.446213  0.364544  0.189243    0.687500  \n",
              "3397        0.228571  0.391489  0.377828  0.230683    0.658537  \n",
              "3398        0.142857  0.462094  0.410349  0.127557    0.283019  \n",
              "\n",
              "[120 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c455fe2a-fe84-4d71-95a1-abda07289d25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2580</th>\n",
              "      <td>30</td>\n",
              "      <td>3.627</td>\n",
              "      <td>3.395</td>\n",
              "      <td>2.042</td>\n",
              "      <td>3.327</td>\n",
              "      <td>3.181</td>\n",
              "      <td>2.337</td>\n",
              "      <td>-0.300</td>\n",
              "      <td>-0.214</td>\n",
              "      <td>0.295</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.400154</td>\n",
              "      <td>0.374559</td>\n",
              "      <td>0.225287</td>\n",
              "      <td>0.621622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2581</th>\n",
              "      <td>30</td>\n",
              "      <td>4.420</td>\n",
              "      <td>3.376</td>\n",
              "      <td>1.842</td>\n",
              "      <td>4.250</td>\n",
              "      <td>3.137</td>\n",
              "      <td>2.045</td>\n",
              "      <td>-0.170</td>\n",
              "      <td>-0.239</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.458601</td>\n",
              "      <td>0.350280</td>\n",
              "      <td>0.191118</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2586</th>\n",
              "      <td>30</td>\n",
              "      <td>3.744</td>\n",
              "      <td>3.370</td>\n",
              "      <td>2.013</td>\n",
              "      <td>4.734</td>\n",
              "      <td>3.421</td>\n",
              "      <td>1.853</td>\n",
              "      <td>0.990</td>\n",
              "      <td>0.051</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.410211</td>\n",
              "      <td>0.369234</td>\n",
              "      <td>0.220554</td>\n",
              "      <td>0.648649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2587</th>\n",
              "      <td>30</td>\n",
              "      <td>6.102</td>\n",
              "      <td>4.633</td>\n",
              "      <td>1.467</td>\n",
              "      <td>7.097</td>\n",
              "      <td>4.867</td>\n",
              "      <td>1.437</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.234</td>\n",
              "      <td>-0.030</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.500082</td>\n",
              "      <td>0.379692</td>\n",
              "      <td>0.120226</td>\n",
              "      <td>0.439024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2593</th>\n",
              "      <td>31</td>\n",
              "      <td>3.225</td>\n",
              "      <td>3.124</td>\n",
              "      <td>2.344</td>\n",
              "      <td>3.323</td>\n",
              "      <td>3.034</td>\n",
              "      <td>2.426</td>\n",
              "      <td>0.098</td>\n",
              "      <td>-0.090</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.354839</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.322581</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.370988</td>\n",
              "      <td>0.359370</td>\n",
              "      <td>0.269642</td>\n",
              "      <td>0.735294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>34</td>\n",
              "      <td>3.573</td>\n",
              "      <td>3.536</td>\n",
              "      <td>1.993</td>\n",
              "      <td>3.144</td>\n",
              "      <td>3.550</td>\n",
              "      <td>2.233</td>\n",
              "      <td>-0.429</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.240</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>0.147059</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.392551</td>\n",
              "      <td>0.388486</td>\n",
              "      <td>0.218963</td>\n",
              "      <td>0.588235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3382</th>\n",
              "      <td>34</td>\n",
              "      <td>6.293</td>\n",
              "      <td>4.738</td>\n",
              "      <td>1.430</td>\n",
              "      <td>5.543</td>\n",
              "      <td>4.527</td>\n",
              "      <td>1.546</td>\n",
              "      <td>-0.750</td>\n",
              "      <td>-0.211</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.505016</td>\n",
              "      <td>0.380226</td>\n",
              "      <td>0.114758</td>\n",
              "      <td>0.283333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3394</th>\n",
              "      <td>35</td>\n",
              "      <td>4.289</td>\n",
              "      <td>3.504</td>\n",
              "      <td>1.819</td>\n",
              "      <td>5.005</td>\n",
              "      <td>3.703</td>\n",
              "      <td>1.728</td>\n",
              "      <td>0.716</td>\n",
              "      <td>0.199</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.114286</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.446213</td>\n",
              "      <td>0.364544</td>\n",
              "      <td>0.189243</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>35</td>\n",
              "      <td>3.496</td>\n",
              "      <td>3.374</td>\n",
              "      <td>2.060</td>\n",
              "      <td>3.120</td>\n",
              "      <td>3.265</td>\n",
              "      <td>2.369</td>\n",
              "      <td>-0.376</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>0.309</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.391489</td>\n",
              "      <td>0.377828</td>\n",
              "      <td>0.230683</td>\n",
              "      <td>0.658537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>35</td>\n",
              "      <td>5.376</td>\n",
              "      <td>4.774</td>\n",
              "      <td>1.484</td>\n",
              "      <td>7.147</td>\n",
              "      <td>5.386</td>\n",
              "      <td>1.380</td>\n",
              "      <td>1.771</td>\n",
              "      <td>0.612</td>\n",
              "      <td>-0.104</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.410349</td>\n",
              "      <td>0.127557</td>\n",
              "      <td>0.283019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c455fe2a-fe84-4d71-95a1-abda07289d25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c455fe2a-fe84-4d71-95a1-abda07289d25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c455fe2a-fe84-4d71-95a1-abda07289d25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b437c8a-63d6-4ed2-b072-5042876d9d80\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b437c8a-63d6-4ed2-b072-5042876d9d80')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b437c8a-63d6-4ed2-b072-5042876d9d80 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_af55206a-f1ab-44ff-97d9-3645b162a542\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_af55206a-f1ab-44ff-97d9-3645b162a542 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features"
            }
          },
          "metadata": {},
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"DIFF_55A_31D_13EV.keras\"\n",
        "model_path = f\"{model_save_pwd}/{model_name}\"\n",
        "model_6.save(f\"{model_path}\")\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZd9USblvZA1",
        "outputId": "46447d16-5003-45ac-f5bd-3ceb92a0d26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/JSIP Final Project/models/DIFF_55A_31D_13EV.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# direction model"
      ],
      "metadata": {
        "id": "j3Tq1gW0t9Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycZrySdwt_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPL_p67_vACz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset()"
      ],
      "metadata": {
        "id": "j5lmHjydubD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_keys = [\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"DIR1\", \"DIRX\", \"DIR2\"]\n",
        "curr_label = \"DIR1\"\n",
        "# dataset_uv[\"undervalued\"] = get_max_diff(dataset_uv, False)\n",
        "# dataset_uv = dataset_uv.drop(label_keys, axis=1)\n",
        "dataset_dirm = get_dir_database(dataset.copy())\n",
        "dataset_dirm = get_small_OHE_dataset(dataset_dirm)\n",
        "dataset_dirm = get_stat_percent_database(dataset_dirm)\n",
        "dirm_train, dirm_test = split_dataset(dataset_dirm, True)\n",
        "# dirm_train = dirm_train.sample(frac=1)\n",
        "get_dir_dataset_stats(dirm_train, curr_label)\n",
        "# dirm_train = dirm_train_split.sample(frac=1)\n",
        "# dirm_train = dirm_train.groupby(curr_label).sample(n=1206)\n",
        "# get_dir_dataset_stats(dirm_train, curr_label)\n",
        "# dirm_val = dirm_train.groupby(curr_label).sample(frac=.2)\n",
        "# get_dir_dataset_stats(dirm_val, curr_label)\n",
        "# dirm_train = dirm_train.drop(index=dirm_val.index)\n",
        "# get_dir_dataset_stats(dirm_train, curr_label)\n",
        "# dirm_train = dirm_train.sample(frac=1)\n",
        "# dirm_val = dirm_val.sample(frac=1)\n",
        "\n",
        "# dirm_val_target = dirm_val[curr_label]\n",
        "dirm_train_target = dirm_train[curr_label]\n",
        "dirm_test_target = dirm_test[curr_label]\n",
        "# dirm_val_features = dirm_val.drop(columns=dropped_keys)\n",
        "dirm_train_features = dirm_train.drop(columns=dropped_keys)\n",
        "dirm_test_features = dirm_test.drop(columns=dropped_keys)\n",
        "\n",
        "# dirm_val_target = np.array(dirm_val_target).astype('float32')\n",
        "dirm_train_target = np.array(dirm_train_target).astype('float32')\n",
        "dirm_test_target = np.array(dirm_test_target).astype('float32')\n",
        "# dirm_val_features = np.array(dirm_val_features).astype('float32')\n",
        "dirm_train_features = np.array(dirm_train_features).astype('float32')\n",
        "dirm_test_features = np.array(dirm_test_features).astype('float32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWm3B-dfuaeo",
        "outputId": "16d00c4e-c475-429f-d5b2-146d8fd7affb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U% : 54.662%, 1454/2660; D% : 45.338%, 1206/2660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(dirm_train_features)\n",
        "steps_per_epoch = len(dirm_train_features)/32\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "dirm_weights = class_weight.compute_class_weight('balanced',\n",
        "                                            classes=np.unique(np.array(dirm_train_target)),\n",
        "                                            y=np.array(dirm_train_target))\n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "      # normalizer,\n",
        "      layers.Dense(15, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(15, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(15, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      # layers.Dense(8, activation=\"sigmoid\"),\n",
        "      layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_7.compile(\n",
        "    optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.015),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MsNpK_0f0odN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirm_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvuAYZxSe7kw",
        "outputId": "c87d4c53-4646-4d4f-c42b-1e657b48c23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.103, 0.915])"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model_7.fit(\n",
        "    dirm_train_features,\n",
        "    dirm_train_target,\n",
        "    epochs=400,\n",
        "    callbacks=[early_stopping],\n",
        "    # validation_freq=5,\n",
        "    # Suppress logging.\n",
        "    class_weight={0: dirm_weights[0], 1: dirm_weights[1]},\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfV4FUeN0wUb",
        "outputId": "3815990c-9755-43f4-efb0-828db0d25996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4790 - loss: 0.9824 - val_accuracy: 0.4699 - val_loss: 0.7475\n",
            "Epoch 2/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4542 - loss: 1.0114 - val_accuracy: 0.4718 - val_loss: 0.7320\n",
            "Epoch 3/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4714 - loss: 0.9957 - val_accuracy: 0.4906 - val_loss: 0.7203\n",
            "Epoch 4/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4598 - loss: 0.9804 - val_accuracy: 0.5282 - val_loss: 0.7116\n",
            "Epoch 5/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4700 - loss: 0.9441 - val_accuracy: 0.5414 - val_loss: 0.7043\n",
            "Epoch 6/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4902 - loss: 0.9126 - val_accuracy: 0.5395 - val_loss: 0.7002\n",
            "Epoch 7/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4907 - loss: 0.9074 - val_accuracy: 0.5602 - val_loss: 0.6971\n",
            "Epoch 8/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4568 - loss: 0.9283 - val_accuracy: 0.5602 - val_loss: 0.6950\n",
            "Epoch 9/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4765 - loss: 0.9178 - val_accuracy: 0.5489 - val_loss: 0.6937\n",
            "Epoch 10/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4771 - loss: 0.8767 - val_accuracy: 0.5470 - val_loss: 0.6931\n",
            "Epoch 11/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4711 - loss: 0.9088 - val_accuracy: 0.5489 - val_loss: 0.6926\n",
            "Epoch 12/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4551 - loss: 0.9073 - val_accuracy: 0.5451 - val_loss: 0.6924\n",
            "Epoch 13/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4812 - loss: 0.8758 - val_accuracy: 0.5451 - val_loss: 0.6922\n",
            "Epoch 14/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5025 - loss: 0.8714 - val_accuracy: 0.5432 - val_loss: 0.6921\n",
            "Epoch 15/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4876 - loss: 0.8893 - val_accuracy: 0.5451 - val_loss: 0.6922\n",
            "Epoch 16/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4704 - loss: 0.8830 - val_accuracy: 0.5414 - val_loss: 0.6925\n",
            "Epoch 17/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4815 - loss: 0.8543 - val_accuracy: 0.5432 - val_loss: 0.6924\n",
            "Epoch 18/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4691 - loss: 0.8622 - val_accuracy: 0.5451 - val_loss: 0.6924\n",
            "Epoch 19/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.8708 - val_accuracy: 0.5489 - val_loss: 0.6929\n",
            "Epoch 20/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4632 - loss: 0.8783 - val_accuracy: 0.5451 - val_loss: 0.6928\n",
            "Epoch 21/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5300 - loss: 0.8066 - val_accuracy: 0.5376 - val_loss: 0.6931\n",
            "Epoch 22/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4987 - loss: 0.8607 - val_accuracy: 0.5301 - val_loss: 0.6932\n",
            "Epoch 23/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4609 - loss: 0.8974 - val_accuracy: 0.5320 - val_loss: 0.6933\n",
            "Epoch 24/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4648 - loss: 0.8863 - val_accuracy: 0.5301 - val_loss: 0.6928\n",
            "Epoch 25/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4943 - loss: 0.8245 - val_accuracy: 0.5338 - val_loss: 0.6928\n",
            "Epoch 26/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4733 - loss: 0.8577 - val_accuracy: 0.5338 - val_loss: 0.6926\n",
            "Epoch 27/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4939 - loss: 0.8308 - val_accuracy: 0.5301 - val_loss: 0.6926\n",
            "Epoch 28/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4808 - loss: 0.8404 - val_accuracy: 0.5301 - val_loss: 0.6921\n",
            "Epoch 29/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4540 - loss: 0.8261 - val_accuracy: 0.5301 - val_loss: 0.6918\n",
            "Epoch 30/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4787 - loss: 0.8330 - val_accuracy: 0.5301 - val_loss: 0.6914\n",
            "Epoch 31/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4656 - loss: 0.8196 - val_accuracy: 0.5263 - val_loss: 0.6913\n",
            "Epoch 32/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4942 - loss: 0.8029 - val_accuracy: 0.5263 - val_loss: 0.6910\n",
            "Epoch 33/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4794 - loss: 0.8023 - val_accuracy: 0.5244 - val_loss: 0.6912\n",
            "Epoch 34/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5075 - loss: 0.7813 - val_accuracy: 0.5263 - val_loss: 0.6911\n",
            "Epoch 35/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4866 - loss: 0.7998 - val_accuracy: 0.5244 - val_loss: 0.6909\n",
            "Epoch 36/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4816 - loss: 0.8249 - val_accuracy: 0.5263 - val_loss: 0.6906\n",
            "Epoch 37/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4778 - loss: 0.8198 - val_accuracy: 0.5282 - val_loss: 0.6903\n",
            "Epoch 38/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4851 - loss: 0.8096 - val_accuracy: 0.5301 - val_loss: 0.6901\n",
            "Epoch 39/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4833 - loss: 0.8037 - val_accuracy: 0.5282 - val_loss: 0.6898\n",
            "Epoch 40/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4887 - loss: 0.7969 - val_accuracy: 0.5244 - val_loss: 0.6898\n",
            "Epoch 41/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4907 - loss: 0.7998 - val_accuracy: 0.5263 - val_loss: 0.6898\n",
            "Epoch 42/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4881 - loss: 0.7980 - val_accuracy: 0.5263 - val_loss: 0.6896\n",
            "Epoch 43/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4683 - loss: 0.7875 - val_accuracy: 0.5263 - val_loss: 0.6895\n",
            "Epoch 44/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4801 - loss: 0.7841 - val_accuracy: 0.5263 - val_loss: 0.6893\n",
            "Epoch 45/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4776 - loss: 0.7991 - val_accuracy: 0.5226 - val_loss: 0.6892\n",
            "Epoch 46/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5008 - loss: 0.7561 - val_accuracy: 0.5207 - val_loss: 0.6889\n",
            "Epoch 47/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4576 - loss: 0.7875 - val_accuracy: 0.5207 - val_loss: 0.6889\n",
            "Epoch 48/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4914 - loss: 0.7681 - val_accuracy: 0.5226 - val_loss: 0.6888\n",
            "Epoch 49/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4625 - loss: 0.7962 - val_accuracy: 0.5188 - val_loss: 0.6887\n",
            "Epoch 50/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4906 - loss: 0.7707 - val_accuracy: 0.5169 - val_loss: 0.6885\n",
            "Epoch 51/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4741 - loss: 0.7855 - val_accuracy: 0.5169 - val_loss: 0.6883\n",
            "Epoch 52/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4965 - loss: 0.7745 - val_accuracy: 0.5150 - val_loss: 0.6883\n",
            "Epoch 53/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4683 - loss: 0.7886 - val_accuracy: 0.5188 - val_loss: 0.6882\n",
            "Epoch 54/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4901 - loss: 0.7510 - val_accuracy: 0.5188 - val_loss: 0.6882\n",
            "Epoch 55/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4857 - loss: 0.7820 - val_accuracy: 0.5207 - val_loss: 0.6881\n",
            "Epoch 56/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4863 - loss: 0.7657 - val_accuracy: 0.5207 - val_loss: 0.6881\n",
            "Epoch 57/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4805 - loss: 0.7741 - val_accuracy: 0.5188 - val_loss: 0.6881\n",
            "Epoch 58/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4737 - loss: 0.7723 - val_accuracy: 0.5244 - val_loss: 0.6880\n",
            "Epoch 59/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4895 - loss: 0.7592 - val_accuracy: 0.5282 - val_loss: 0.6880\n",
            "Epoch 60/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5090 - loss: 0.7515 - val_accuracy: 0.5263 - val_loss: 0.6881\n",
            "Epoch 61/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4922 - loss: 0.7680 - val_accuracy: 0.5320 - val_loss: 0.6880\n",
            "Epoch 62/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4994 - loss: 0.7574 - val_accuracy: 0.5338 - val_loss: 0.6880\n",
            "Epoch 63/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4937 - loss: 0.7713 - val_accuracy: 0.5301 - val_loss: 0.6880\n",
            "Epoch 64/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.7565 - val_accuracy: 0.5301 - val_loss: 0.6880\n",
            "Epoch 65/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4635 - loss: 0.7746 - val_accuracy: 0.5263 - val_loss: 0.6880\n",
            "Epoch 66/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4783 - loss: 0.7545 - val_accuracy: 0.5263 - val_loss: 0.6880\n",
            "Epoch 67/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4870 - loss: 0.7564 - val_accuracy: 0.5301 - val_loss: 0.6879\n",
            "Epoch 68/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4846 - loss: 0.7756 - val_accuracy: 0.5244 - val_loss: 0.6879\n",
            "Epoch 69/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5055 - loss: 0.7387 - val_accuracy: 0.5244 - val_loss: 0.6880\n",
            "Epoch 70/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4889 - loss: 0.7518 - val_accuracy: 0.5244 - val_loss: 0.6880\n",
            "Epoch 71/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4987 - loss: 0.7533 - val_accuracy: 0.5244 - val_loss: 0.6880\n",
            "Epoch 72/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5151 - loss: 0.7348 - val_accuracy: 0.5207 - val_loss: 0.6880\n",
            "Epoch 73/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4900 - loss: 0.7552 - val_accuracy: 0.5207 - val_loss: 0.6880\n",
            "Epoch 74/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5197 - loss: 0.7438 - val_accuracy: 0.5207 - val_loss: 0.6880\n",
            "Epoch 75/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 0.7683 - val_accuracy: 0.5207 - val_loss: 0.6880\n",
            "Epoch 76/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5073 - loss: 0.7418 - val_accuracy: 0.5207 - val_loss: 0.6881\n",
            "Epoch 77/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: 0.7352 - val_accuracy: 0.5207 - val_loss: 0.6881\n",
            "Epoch 78/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4936 - loss: 0.7425 - val_accuracy: 0.5226 - val_loss: 0.6881\n",
            "Epoch 79/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5127 - loss: 0.7374 - val_accuracy: 0.5226 - val_loss: 0.6881\n",
            "Epoch 80/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4917 - loss: 0.7558 - val_accuracy: 0.5226 - val_loss: 0.6881\n",
            "Epoch 81/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4748 - loss: 0.7384 - val_accuracy: 0.5226 - val_loss: 0.6881\n",
            "Epoch 82/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5089 - loss: 0.7393 - val_accuracy: 0.5226 - val_loss: 0.6882\n",
            "Epoch 83/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4897 - loss: 0.7446 - val_accuracy: 0.5207 - val_loss: 0.6882\n",
            "Epoch 84/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4995 - loss: 0.7330 - val_accuracy: 0.5207 - val_loss: 0.6882\n",
            "Epoch 85/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4920 - loss: 0.7290 - val_accuracy: 0.5207 - val_loss: 0.6882\n",
            "Epoch 86/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5183 - loss: 0.7381 - val_accuracy: 0.5207 - val_loss: 0.6883\n",
            "Epoch 87/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5114 - loss: 0.7353 - val_accuracy: 0.5207 - val_loss: 0.6883\n",
            "Epoch 88/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5022 - loss: 0.7190 - val_accuracy: 0.5207 - val_loss: 0.6884\n",
            "Epoch 89/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5268 - loss: 0.7228 - val_accuracy: 0.5188 - val_loss: 0.6884\n",
            "Epoch 90/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 0.7243 - val_accuracy: 0.5188 - val_loss: 0.6884\n",
            "Epoch 91/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5015 - loss: 0.7299 - val_accuracy: 0.5207 - val_loss: 0.6884\n",
            "Epoch 92/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4851 - loss: 0.7356 - val_accuracy: 0.5207 - val_loss: 0.6885\n",
            "Epoch 93/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4942 - loss: 0.7400 - val_accuracy: 0.5207 - val_loss: 0.6885\n",
            "Epoch 94/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.7240 - val_accuracy: 0.5207 - val_loss: 0.6885\n",
            "Epoch 95/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4878 - loss: 0.7391 - val_accuracy: 0.5207 - val_loss: 0.6886\n",
            "Epoch 96/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5053 - loss: 0.7315 - val_accuracy: 0.5207 - val_loss: 0.6887\n",
            "Epoch 97/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.7241 - val_accuracy: 0.5207 - val_loss: 0.6888\n",
            "Epoch 98/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: 0.7341 - val_accuracy: 0.5226 - val_loss: 0.6888\n",
            "Epoch 99/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5155 - loss: 0.7243 - val_accuracy: 0.5226 - val_loss: 0.6888\n",
            "Epoch 100/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4941 - loss: 0.7185 - val_accuracy: 0.5226 - val_loss: 0.6889\n",
            "Epoch 101/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4932 - loss: 0.7302 - val_accuracy: 0.5207 - val_loss: 0.6890\n",
            "Epoch 102/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5169 - loss: 0.7223 - val_accuracy: 0.5207 - val_loss: 0.6890\n",
            "Epoch 103/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4672 - loss: 0.7364 - val_accuracy: 0.5207 - val_loss: 0.6891\n",
            "Epoch 104/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4929 - loss: 0.7177 - val_accuracy: 0.5226 - val_loss: 0.6891\n",
            "Epoch 105/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5016 - loss: 0.7224 - val_accuracy: 0.5226 - val_loss: 0.6892\n",
            "Epoch 106/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5043 - loss: 0.7253 - val_accuracy: 0.5226 - val_loss: 0.6893\n",
            "Epoch 107/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5026 - loss: 0.7309 - val_accuracy: 0.5226 - val_loss: 0.6895\n",
            "Epoch 108/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4988 - loss: 0.7319 - val_accuracy: 0.5226 - val_loss: 0.6896\n",
            "Epoch 109/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5071 - loss: 0.7446 - val_accuracy: 0.5226 - val_loss: 0.6896\n",
            "Epoch 110/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4970 - loss: 0.7232 - val_accuracy: 0.5226 - val_loss: 0.6897\n",
            "Epoch 111/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 0.7138 - val_accuracy: 0.5226 - val_loss: 0.6897\n",
            "Epoch 112/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4847 - loss: 0.7311 - val_accuracy: 0.5226 - val_loss: 0.6897\n",
            "Epoch 113/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5180 - loss: 0.7256 - val_accuracy: 0.5226 - val_loss: 0.6897\n",
            "Epoch 114/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 0.7270 - val_accuracy: 0.5244 - val_loss: 0.6898\n",
            "Epoch 115/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4931 - loss: 0.7259 - val_accuracy: 0.5263 - val_loss: 0.6899\n",
            "Epoch 116/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5154 - loss: 0.7177 - val_accuracy: 0.5263 - val_loss: 0.6899\n",
            "Epoch 117/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 0.7123 - val_accuracy: 0.5263 - val_loss: 0.6900\n",
            "Epoch 118/400\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4955 - loss: 0.7339 - val_accuracy: 0.5282 - val_loss: 0.6900\n",
            "Epoch 118: early stopping\n",
            "Restoring model weights from the end of the best epoch: 68.\n",
            "CPU times: user 31.8 s, sys: 1.4 s, total: 33.2 s\n",
            "Wall time: 39.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# features = dirm_val_features\n",
        "# target = dirm_val_target\n",
        "# features = dirm_train_features\n",
        "# target = dirm_train_target\n",
        "features = dirm_test_features\n",
        "target = dirm_test_target\n",
        "num = len(features)\n",
        "features = features[:num]\n",
        "target = target[:num]\n",
        "\n",
        "print(len(features))\n",
        "predictions = model_7.predict(features)\n",
        "\n",
        "# target_data = np.array(target).astype('float32')\n",
        "# target_data = [x[0] for x in target_data]\n",
        "correct = 0\n",
        "predicted_classes = [1 if x >= 0.5 else 0 for x in predictions]\n",
        "for prediction_class, target_val, raw_pred in zip(predicted_classes, target, predictions):\n",
        "  # prediction_class = np.argmax(prediction)\n",
        "\n",
        "  print(f\"pred: {prediction_class}, real: {target_val}\")\n",
        "  print(f\"probability: {raw_pred}\")\n",
        "  if prediction_class == target_val:\n",
        "    correct += 1\n",
        "\n",
        "print(f\"correct: {correct/num}, {correct}/{num}\")\n",
        "# confusion_matrix = tf.math.confusion_matrix(\n",
        "#     target,\n",
        "#     predicted_classes,\n",
        "#     num_classes=3,\n",
        "#     weights=None,\n",
        "#     dtype=tf.dtypes.int32,\n",
        "#     name=None\n",
        "# )\n",
        "# confusion_matrix\n",
        "bce = keras.losses.BinaryCrossentropy()\n",
        "loss = bce(target, predictions)\n",
        "print(f\"loss {loss}\")\n",
        "plot_confusion_matrix(target, predicted_classes, [\"D\", \"U\"], \"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NkZMR6AQ06tn",
        "outputId": "6c4b5cf5-8a33-4be6-9498-437ac2fd5bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "760\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.477]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.556]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.531]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.49]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.511]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.447]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.511]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.481]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.497]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.532]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.536]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.443]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.424]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.47]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.5]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.477]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.452]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.473]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.541]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.518]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.424]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.512]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.481]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.466]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.466]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.458]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.435]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.465]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.435]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.525]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.493]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.468]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.448]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.439]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.464]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.454]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.436]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.421]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.429]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.442]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.489]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.425]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.437]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.463]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.457]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.444]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.43]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.461]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.451]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.417]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.44]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.464]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.464]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.464]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.44]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.437]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.421]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.446]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.465]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.463]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.44]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.424]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.434]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.452]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.427]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.47]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.463]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.422]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.441]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.452]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.438]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.454]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.405]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.457]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.421]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.441]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.392]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.448]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.459]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.461]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.505]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.479]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.372]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.453]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.463]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.464]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.456]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.405]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.438]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.471]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.436]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.48]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.485]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.471]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.408]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.473]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.491]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.477]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.481]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.4]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.491]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.491]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.364]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.472]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.486]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.373]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.485]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.479]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.481]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.473]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.491]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.479]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.486]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.477]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.483]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.472]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.503]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.448]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.48]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.345]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.486]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.49]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.485]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.477]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.459]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.48]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.482]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.426]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.502]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.498]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.497]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.307]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.483]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.49]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.516]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.493]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.497]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.332]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.526]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.512]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.487]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.507]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.488]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.49]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.499]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.477]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.491]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.432]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.514]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.511]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.511]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.468]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.483]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.505]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.489]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.498]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.435]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.5]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.491]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.534]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.529]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.464]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.517]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.479]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.526]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.516]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.534]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.493]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.526]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.53]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.495]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.527]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.498]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.518]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.372]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.539]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.505]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.505]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.524]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.533]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.525]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.522]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.529]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.505]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.52]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.532]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.536]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.524]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.511]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.519]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.528]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.528]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.527]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.511]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.532]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.527]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.495]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.536]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.516]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.53]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.505]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.52]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.534]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.522]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.524]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.529]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.534]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.54]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.531]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.535]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.535]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.543]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.502]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.486]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.481]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.519]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.537]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.448]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.523]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.548]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.467]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.551]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.43]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.502]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.466]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.51]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.472]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.532]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.543]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.443]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.47]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.472]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.485]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.483]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.49]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.454]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.445]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.466]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.451]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.432]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.441]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.466]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.419]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.438]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.461]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.479]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.445]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.433]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.418]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.429]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.459]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.418]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.472]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.473]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.48]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.448]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.436]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.444]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.444]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.447]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.461]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.481]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.445]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.418]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.469]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.42]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.439]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.452]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.481]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.427]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.451]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.424]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.471]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.454]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.428]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.453]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.412]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.48]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.464]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.432]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.465]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.452]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.479]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.444]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.405]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.466]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.47]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.466]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.404]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.456]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.459]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.447]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.451]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.43]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.479]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.417]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.486]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.39]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.454]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.469]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.448]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.422]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.461]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.477]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.449]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.469]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.48]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.469]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.472]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.364]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.473]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.483]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.502]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.475]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.489]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.489]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.489]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.482]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.484]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.383]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.444]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.472]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.51]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.476]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.471]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.491]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.488]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.425]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.455]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.482]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.421]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.516]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.344]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.486]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.438]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.482]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.497]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.471]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.474]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.491]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.367]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.498]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.478]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.483]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.484]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.525]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.485]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.339]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.477]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.442]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.495]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.521]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.482]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.443]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.486]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.486]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.498]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.48]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.498]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.491]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.502]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.522]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.489]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.485]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.512]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.415]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.491]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.505]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.49]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.497]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.516]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.493]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.48]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.516]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.496]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.469]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.531]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.495]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.511]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.531]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.474]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.537]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.482]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.49]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.523]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.493]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.517]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.503]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.492]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.487]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.498]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.534]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.527]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.532]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.502]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.524]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.509]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.525]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.522]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.528]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.509]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.499]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.505]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.521]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.519]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.519]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.538]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.513]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.505]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.522]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.528]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.502]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.529]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.526]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.512]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.536]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.515]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.498]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.538]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.506]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.525]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.513]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.487]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.523]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.523]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.532]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.542]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.526]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.521]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.51]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.522]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.515]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.522]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.518]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.517]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.528]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.534]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.517]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.501]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.527]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.533]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.528]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.516]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.517]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.53]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.54]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.502]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.518]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.537]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.534]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.535]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.525]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.531]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.542]\n",
            "correct: 0.4723684210526316, 359/760\n",
            "loss 0.6989993453025818\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmeyXTpJ0-1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stats dataset"
      ],
      "metadata": {
        "id": "dqWx7KIeJS3N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EC6fpAMvctf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYUvf8TUGUlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B46HJy7VE0Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "GiQw9ynuJjsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_dataset = get_dir_database(dataset.copy())\n",
        "# stats_dataset = get_small_OHE_dataset(stats_dataset)\n",
        "stats_dataset = get_odds_percent_database(stats_dataset)\n",
        "stats_dataset = get_stat_percent_database(stats_dataset)\n",
        "\n",
        "stats_dataset = stats_dataset.drop(columns=[\"home_team\", \"away_team\"])\n",
        "stats_dataset = stats_dataset.drop(stats_dataset[stats_dataset.games < 4].index)\n",
        "stats_dataset = stats_dataset.drop(stats_dataset[abs(stats_dataset[\"home_wins_rate\"] - stats_dataset[\"away_wins_rate\"]) < .5].index)\n",
        "\n",
        "\n",
        "stats_dataset = stats_dataset.drop(columns = [\"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\", \"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"DIRX\", \"DIR2\"])\n",
        "\n",
        "# stats_dataset = extreme_only[\"DIR1\"]\n",
        "# stats_dataset = extreme_only.drop(columns = [\"DIR1\"])\n",
        "curr_label = \"DIR1\"\n",
        "test_size = 42\n",
        "get_dir_dataset_stats(stats_dataset, curr_label)\n",
        "stats_dataset\n",
        "\n",
        "stats_train = stats_dataset.iloc[:-test_size]\n",
        "stats_test = stats_dataset.tail(test_size)\n",
        "\n",
        "stats_train = stats_train.sample(frac=1)\n",
        "get_dir_dataset_stats(stats_train, curr_label)\n",
        "stats_train = stats_train.groupby(curr_label).sample(n=61)\n",
        "get_dir_dataset_stats(stats_train, curr_label)\n",
        "stats_val = stats_train.groupby(curr_label).sample(frac=.2)\n",
        "get_dir_dataset_stats(stats_val, curr_label)\n",
        "stats_train = stats_train.drop(index=stats_val.index)\n",
        "get_dir_dataset_stats(stats_train, curr_label)\n",
        "stats_train = stats_train.sample(frac=1)\n",
        "stats_val = stats_val.sample(frac=1)\n",
        "\n",
        "stats_val_target, stats_val_features = get_features_and_labels(stats_val, curr_label)\n",
        "stats_train_target, stats_train_features = get_features_and_labels(stats_train, curr_label)\n",
        "stats_test_target, stats_test_features = get_features_and_labels(stats_test, curr_label)\n",
        "\n",
        "# stats_dataset.groupby([\"DIR1\"]).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvm7yqCaFSK6",
        "outputId": "33c245b0-4202-4491-dac6-751dc073e64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U% : 62.136%, 128/206; D% : 37.864%, 78/206\n",
            "U% : 62.805%, 103/164; D% : 37.195%, 61/164\n",
            "U% : 50.000%, 61/122; D% : 50.000%, 61/122\n",
            "U% : 50.000%, 12/24; D% : 50.000%, 12/24\n",
            "U% : 50.000%, 49/98; D% : 50.000%, 49/98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats_dataset = get_dir_database(dataset.copy())\n",
        "stats_dataset = get_small_OHE_dataset(stats_dataset)\n",
        "stats_dataset = get_odds_percent_database(stats_dataset)\n",
        "stats_dataset = get_stat_percent_database(stats_dataset)\n",
        "\n",
        "# stats_dataset = stats_dataset.drop(columns=[\"home_team\", \"away_team\"])\n",
        "stats_dataset = stats_dataset.drop(stats_dataset[stats_dataset.games < 4].index)\n",
        "stats_dataset = stats_dataset.drop(stats_dataset[abs(stats_dataset[\"home_wins_rate\"] - stats_dataset[\"away_wins_rate\"]) < .5].index)\n",
        "stats_train, stats_test = split_dataset(stats_dataset, True)\n",
        "# pred = []\n",
        "# diff_col = []\n",
        "# correct = 0\n",
        "# num = 0\n",
        "# total = len(stats_dataset)\n",
        "# label = \"DIR1\"\n",
        "# for index, row in stats_dataset.iterrows():\n",
        "#   diff = row[\"home_wins_rate\"] - row[\"away_wins_rate\"]\n",
        "#   if abs(diff) < .5:\n",
        "#     stats_dataset = stats_dataset.drop(index=index)\n",
        "  # else:\n",
        "  #   # print(f\"{len(diff_col)}\")\n",
        "  #   diff_col.append(diff)\n",
        "    # extreme_rows.loc[-1:] = row\n",
        "    # print(row)\n",
        "    # pd.concat([])\n",
        "\n",
        "    # num += 1\n",
        "    # pred = 0 if diff > 0 else 1\n",
        "    # print(f\"pred: {pred}, true: {row[label]}\")\n",
        "    # if pred == row[label]:\n",
        "    #   correct += 1\n",
        "\n",
        "# print(f\"correct: {format(correct/num * 100, '.3f')}%, {correct}/{num}, total {total}\")\n",
        "    # predicting winning odds go down\n",
        "# stats_train[\"DIFF1\"] = diff_col\n",
        "# # stats_train[:50]\n",
        "# stats_train.groupby([\"DIR1\"]).mean()\n",
        "# extreme_only[\"DIFF1\"] = diff_col\n",
        "# extreme_only = get_dir_database(extreme_only)\n",
        "\n",
        "stats_dataset = stats_dataset.drop(columns = [\"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"DIRX\", \"DIR2\"])\n",
        "\n",
        "stats_dataset_target = extreme_only[\"DIR1\"]\n",
        "extreme_only_features = extreme_only.drop(columns = [\"DIR1\"])\n",
        "# extreme_only.groupby([\"DIR1\"]).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "gjY_7OEtG63z",
        "outputId": "2a446af7-4045-43e5-c9aa-f24968eaa3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'extreme_only' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-328627347ce9>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mstats_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"CP1_AVG\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CPX_AVG\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CP2_AVG\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DIRX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DIR2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mextreme_only_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextreme_only\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DIR1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mextreme_only_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextreme_only\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DIR1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# extreme_only.groupby([\"DIR1\"]).mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'extreme_only' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats_db = get_dir_database(dataset.copy())\n",
        "# stats_db = get_small_OHE_dataset(stats_db)\n",
        "stats_db = get_odds_percent_database(stats_db)\n",
        "stats_db = get_stat_percent_database(stats_db)\n",
        "stats_db = stats_db.drop(stats_db[stats_db.games < 4].index)\n",
        "\n",
        "# stats_db = stats_db.drop(columns=[\"home_team\", \"away_team\"])\n",
        "stats_db.groupby([\"DIR1\"]).mean(numeric_only=True)\n",
        "correct = 0\n",
        "num = 0\n",
        "preds = []\n",
        "for index, row in stats_db.iterrows():\n",
        "  diff = row[\"home_wins_rate\"] - row[\"away_wins_rate\"]\n",
        "  if abs(diff) > .7:\n",
        "    pred = 0 if row[\"home_wins_rate\"] > row[\"away_wins_rate\"] else 1\n",
        "    preds.append(pred)\n",
        "    num += 1\n",
        "    if pred == row[\"DIR1\"]:\n",
        "      correct += 1\n",
        "  else:\n",
        "    preds.append(-1)\n",
        "\n",
        "stats_db[\"predictions\"] = preds\n",
        "print(f\"correct: {format(correct/num * 100, '.3f')}%, {correct}/{num}\")\n",
        "stats_db_diff = stats_db[(stats_db[\"predictions\"] != -1)]\n",
        "stats_db_diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "PYbxfRV2EX7z",
        "outputId": "3f7f3b6a-1d5b-40f8-e431-767d8f718d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct: 66.667%, 14/21\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        home_team      away_team  games  OP1_AVG  OPX_AVG  OP2_AVG  CP1_AVG  \\\n",
              "47         Malaga     Villarreal      4    2.568    3.177    2.784    2.840   \n",
              "52    Real Madrid         Malaga      5    1.105    9.447   21.929    1.130   \n",
              "69        Levante     Villarreal      6    4.069    3.443    1.906    4.370   \n",
              "810        Girona      Barcelona      5   11.238    6.300    1.242   12.610   \n",
              "840     Barcelona         Malaga      8    1.066   12.742   30.980    1.057   \n",
              "1194      Leganes      Barcelona      5   11.469    6.597    1.216   12.659   \n",
              "2339  Real Madrid     Villarreal      5    1.597    4.268    5.230    1.486   \n",
              "2355       Getafe  Real Sociedad      7    3.663    3.119    2.168    3.500   \n",
              "2703     Cadiz CF      Barcelona      4    7.923    4.939    1.407    9.390   \n",
              "2705  Real Madrid       Mallorca      4    1.265    5.913   10.096    1.296   \n",
              "2711    Barcelona          Elche      5    1.145    8.152   15.803    1.077   \n",
              "2756        Elche    Real Madrid      9    8.445    5.437    1.326   11.035   \n",
              "2776  Real Madrid         Girona     11    1.229    6.176   11.122    1.261   \n",
              "2808    Barcelona       Espanyol     14    1.229    6.317   10.970    1.197   \n",
              "2921        Elche      Barcelona     26    8.583    5.255    1.322   10.865   \n",
              "3084  Real Madrid  Real Sociedad      4    1.679    3.833    4.816    1.721   \n",
              "3136       Girona        Almeria      9    1.615    4.194    4.990    1.382   \n",
              "3139       Girona     Celta Vigo      9    1.891    3.475    4.073    1.717   \n",
              "3182  Real Madrid     Granada CF     14    1.154    7.590   16.117    1.165   \n",
              "3235      Almeria         Girona     19    3.889    4.043    1.795    3.716   \n",
              "3243  Real Madrid        Almeria     20    1.146    8.485   14.971    1.121   \n",
              "\n",
              "      CPX_AVG  CP2_AVG  DIR1  ...  OP1_RATE  OPX_RATE  OP2_RATE  \\\n",
              "47      3.182    2.596     1  ...  0.301090  0.372494  0.326416   \n",
              "52      9.411   19.069     1  ...  0.034020  0.290847  0.675133   \n",
              "69      3.416    1.890     1  ...  0.432045  0.365577  0.202378   \n",
              "810     6.577    1.222     1  ...  0.598403  0.335463  0.066134   \n",
              "840    15.199   33.498     0  ...  0.023801  0.284496  0.691703   \n",
              "1194    6.098    1.249     1  ...  0.594803  0.342133  0.063064   \n",
              "2339    4.734    6.401     0  ...  0.143939  0.384678  0.471384   \n",
              "2355    2.933    2.414     0  ...  0.409274  0.348492  0.242235   \n",
              "2703    5.291    1.337     1  ...  0.555260  0.346135  0.098605   \n",
              "2705    5.658   10.588     1  ...  0.073231  0.342306  0.584462   \n",
              "2711   12.500   31.174     0  ...  0.045618  0.324781  0.629602   \n",
              "2756    6.261    1.261     1  ...  0.555300  0.357509  0.087191   \n",
              "2776    6.239   11.365     1  ...  0.066336  0.333351  0.600313   \n",
              "2808    6.955   14.374     0  ...  0.066375  0.341164  0.592461   \n",
              "2921    5.406    1.307     1  ...  0.566161  0.346636  0.087203   \n",
              "3084    3.791    4.945     1  ...  0.162568  0.371127  0.466305   \n",
              "3136    5.067    7.834     0  ...  0.149551  0.388369  0.462080   \n",
              "3139    4.055    4.564     0  ...  0.200339  0.368153  0.431508   \n",
              "3182    7.985   15.659     1  ...  0.046418  0.305297  0.648284   \n",
              "3235    3.748    1.953     0  ...  0.399815  0.415647  0.184538   \n",
              "3243    9.698   21.073     0  ...  0.046582  0.344891  0.608528   \n",
              "\n",
              "      home_wins_rate  home_tie_rate  home_loss_rate  away_wins_rate  \\\n",
              "47          0.000000       0.500000        0.500000        0.750000   \n",
              "52          0.800000       0.200000        0.000000        0.000000   \n",
              "69          0.000000       0.500000        0.500000        0.833333   \n",
              "810         0.200000       0.400000        0.400000        1.000000   \n",
              "840         0.875000       0.125000        0.000000        0.000000   \n",
              "1194        0.000000       0.200000        0.800000        0.800000   \n",
              "2339        1.000000       0.200000        0.000000        0.200000   \n",
              "2355        0.000000       0.000000        1.000000        0.714286   \n",
              "2703        0.000000       0.000000        1.000000        0.750000   \n",
              "2705        1.000000       0.000000        0.000000        0.250000   \n",
              "2711        0.800000       0.200000        0.000000        0.000000   \n",
              "2756        0.000000       0.333333        0.666667        0.888889   \n",
              "2776        0.909091       0.090909        0.000000        0.181818   \n",
              "2808        0.857143       0.071429        0.071429        0.142857   \n",
              "2921        0.076923       0.269231        0.653846        0.846154   \n",
              "3084        1.000000       0.000000        0.000000        0.250000   \n",
              "3136        0.777778       0.111111        0.111111        0.000000   \n",
              "3139        0.888889       0.111111        0.111111        0.111111   \n",
              "3182        0.785714       0.142857        0.071429        0.071429   \n",
              "3235        0.000000       0.263158        0.736842        0.789474   \n",
              "3243        0.750000       0.150000        0.050000        0.000000   \n",
              "\n",
              "      away_tie_rate  away_loss_rate  predictions  \n",
              "47         0.250000        0.000000            1  \n",
              "52         0.400000        0.600000            0  \n",
              "69         0.166667        0.000000            1  \n",
              "810        0.000000        0.000000            1  \n",
              "840        0.125000        0.875000            0  \n",
              "1194       0.200000        0.000000            1  \n",
              "2339       0.800000        0.000000            0  \n",
              "2355       0.142857        0.142857            1  \n",
              "2703       0.250000        0.000000            1  \n",
              "2705       0.500000        0.250000            0  \n",
              "2711       0.200000        0.800000            0  \n",
              "2756       0.111111        0.000000            1  \n",
              "2776       0.272727        0.545455            0  \n",
              "2808       0.428571        0.428571            0  \n",
              "2921       0.076923        0.076923            1  \n",
              "3084       0.750000        0.000000            0  \n",
              "3136       0.333333        0.666667            0  \n",
              "3139       0.333333        0.666667            0  \n",
              "3182       0.285714        0.642857            0  \n",
              "3235       0.157895        0.052632            1  \n",
              "3243       0.300000        0.700000            0  \n",
              "\n",
              "[21 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d9c50d7-3f56-4044-9b54-c2a07fe08266\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>...</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Malaga</td>\n",
              "      <td>Villarreal</td>\n",
              "      <td>4</td>\n",
              "      <td>2.568</td>\n",
              "      <td>3.177</td>\n",
              "      <td>2.784</td>\n",
              "      <td>2.840</td>\n",
              "      <td>3.182</td>\n",
              "      <td>2.596</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.301090</td>\n",
              "      <td>0.372494</td>\n",
              "      <td>0.326416</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Malaga</td>\n",
              "      <td>5</td>\n",
              "      <td>1.105</td>\n",
              "      <td>9.447</td>\n",
              "      <td>21.929</td>\n",
              "      <td>1.130</td>\n",
              "      <td>9.411</td>\n",
              "      <td>19.069</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034020</td>\n",
              "      <td>0.290847</td>\n",
              "      <td>0.675133</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Levante</td>\n",
              "      <td>Villarreal</td>\n",
              "      <td>6</td>\n",
              "      <td>4.069</td>\n",
              "      <td>3.443</td>\n",
              "      <td>1.906</td>\n",
              "      <td>4.370</td>\n",
              "      <td>3.416</td>\n",
              "      <td>1.890</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.432045</td>\n",
              "      <td>0.365577</td>\n",
              "      <td>0.202378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>Girona</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>5</td>\n",
              "      <td>11.238</td>\n",
              "      <td>6.300</td>\n",
              "      <td>1.242</td>\n",
              "      <td>12.610</td>\n",
              "      <td>6.577</td>\n",
              "      <td>1.222</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.598403</td>\n",
              "      <td>0.335463</td>\n",
              "      <td>0.066134</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>Barcelona</td>\n",
              "      <td>Malaga</td>\n",
              "      <td>8</td>\n",
              "      <td>1.066</td>\n",
              "      <td>12.742</td>\n",
              "      <td>30.980</td>\n",
              "      <td>1.057</td>\n",
              "      <td>15.199</td>\n",
              "      <td>33.498</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023801</td>\n",
              "      <td>0.284496</td>\n",
              "      <td>0.691703</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>Leganes</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>5</td>\n",
              "      <td>11.469</td>\n",
              "      <td>6.597</td>\n",
              "      <td>1.216</td>\n",
              "      <td>12.659</td>\n",
              "      <td>6.098</td>\n",
              "      <td>1.249</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.594803</td>\n",
              "      <td>0.342133</td>\n",
              "      <td>0.063064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2339</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Villarreal</td>\n",
              "      <td>5</td>\n",
              "      <td>1.597</td>\n",
              "      <td>4.268</td>\n",
              "      <td>5.230</td>\n",
              "      <td>1.486</td>\n",
              "      <td>4.734</td>\n",
              "      <td>6.401</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.143939</td>\n",
              "      <td>0.384678</td>\n",
              "      <td>0.471384</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2355</th>\n",
              "      <td>Getafe</td>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>7</td>\n",
              "      <td>3.663</td>\n",
              "      <td>3.119</td>\n",
              "      <td>2.168</td>\n",
              "      <td>3.500</td>\n",
              "      <td>2.933</td>\n",
              "      <td>2.414</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.409274</td>\n",
              "      <td>0.348492</td>\n",
              "      <td>0.242235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703</th>\n",
              "      <td>Cadiz CF</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>4</td>\n",
              "      <td>7.923</td>\n",
              "      <td>4.939</td>\n",
              "      <td>1.407</td>\n",
              "      <td>9.390</td>\n",
              "      <td>5.291</td>\n",
              "      <td>1.337</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555260</td>\n",
              "      <td>0.346135</td>\n",
              "      <td>0.098605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2705</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Mallorca</td>\n",
              "      <td>4</td>\n",
              "      <td>1.265</td>\n",
              "      <td>5.913</td>\n",
              "      <td>10.096</td>\n",
              "      <td>1.296</td>\n",
              "      <td>5.658</td>\n",
              "      <td>10.588</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073231</td>\n",
              "      <td>0.342306</td>\n",
              "      <td>0.584462</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Barcelona</td>\n",
              "      <td>Elche</td>\n",
              "      <td>5</td>\n",
              "      <td>1.145</td>\n",
              "      <td>8.152</td>\n",
              "      <td>15.803</td>\n",
              "      <td>1.077</td>\n",
              "      <td>12.500</td>\n",
              "      <td>31.174</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045618</td>\n",
              "      <td>0.324781</td>\n",
              "      <td>0.629602</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2756</th>\n",
              "      <td>Elche</td>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>9</td>\n",
              "      <td>8.445</td>\n",
              "      <td>5.437</td>\n",
              "      <td>1.326</td>\n",
              "      <td>11.035</td>\n",
              "      <td>6.261</td>\n",
              "      <td>1.261</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555300</td>\n",
              "      <td>0.357509</td>\n",
              "      <td>0.087191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2776</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Girona</td>\n",
              "      <td>11</td>\n",
              "      <td>1.229</td>\n",
              "      <td>6.176</td>\n",
              "      <td>11.122</td>\n",
              "      <td>1.261</td>\n",
              "      <td>6.239</td>\n",
              "      <td>11.365</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066336</td>\n",
              "      <td>0.333351</td>\n",
              "      <td>0.600313</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808</th>\n",
              "      <td>Barcelona</td>\n",
              "      <td>Espanyol</td>\n",
              "      <td>14</td>\n",
              "      <td>1.229</td>\n",
              "      <td>6.317</td>\n",
              "      <td>10.970</td>\n",
              "      <td>1.197</td>\n",
              "      <td>6.955</td>\n",
              "      <td>14.374</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066375</td>\n",
              "      <td>0.341164</td>\n",
              "      <td>0.592461</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2921</th>\n",
              "      <td>Elche</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>26</td>\n",
              "      <td>8.583</td>\n",
              "      <td>5.255</td>\n",
              "      <td>1.322</td>\n",
              "      <td>10.865</td>\n",
              "      <td>5.406</td>\n",
              "      <td>1.307</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.566161</td>\n",
              "      <td>0.346636</td>\n",
              "      <td>0.087203</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3084</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>4</td>\n",
              "      <td>1.679</td>\n",
              "      <td>3.833</td>\n",
              "      <td>4.816</td>\n",
              "      <td>1.721</td>\n",
              "      <td>3.791</td>\n",
              "      <td>4.945</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.162568</td>\n",
              "      <td>0.371127</td>\n",
              "      <td>0.466305</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3136</th>\n",
              "      <td>Girona</td>\n",
              "      <td>Almeria</td>\n",
              "      <td>9</td>\n",
              "      <td>1.615</td>\n",
              "      <td>4.194</td>\n",
              "      <td>4.990</td>\n",
              "      <td>1.382</td>\n",
              "      <td>5.067</td>\n",
              "      <td>7.834</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149551</td>\n",
              "      <td>0.388369</td>\n",
              "      <td>0.462080</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3139</th>\n",
              "      <td>Girona</td>\n",
              "      <td>Celta Vigo</td>\n",
              "      <td>9</td>\n",
              "      <td>1.891</td>\n",
              "      <td>3.475</td>\n",
              "      <td>4.073</td>\n",
              "      <td>1.717</td>\n",
              "      <td>4.055</td>\n",
              "      <td>4.564</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200339</td>\n",
              "      <td>0.368153</td>\n",
              "      <td>0.431508</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3182</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Granada CF</td>\n",
              "      <td>14</td>\n",
              "      <td>1.154</td>\n",
              "      <td>7.590</td>\n",
              "      <td>16.117</td>\n",
              "      <td>1.165</td>\n",
              "      <td>7.985</td>\n",
              "      <td>15.659</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046418</td>\n",
              "      <td>0.305297</td>\n",
              "      <td>0.648284</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3235</th>\n",
              "      <td>Almeria</td>\n",
              "      <td>Girona</td>\n",
              "      <td>19</td>\n",
              "      <td>3.889</td>\n",
              "      <td>4.043</td>\n",
              "      <td>1.795</td>\n",
              "      <td>3.716</td>\n",
              "      <td>3.748</td>\n",
              "      <td>1.953</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.399815</td>\n",
              "      <td>0.415647</td>\n",
              "      <td>0.184538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3243</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Almeria</td>\n",
              "      <td>20</td>\n",
              "      <td>1.146</td>\n",
              "      <td>8.485</td>\n",
              "      <td>14.971</td>\n",
              "      <td>1.121</td>\n",
              "      <td>9.698</td>\n",
              "      <td>21.073</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046582</td>\n",
              "      <td>0.344891</td>\n",
              "      <td>0.608528</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d9c50d7-3f56-4044-9b54-c2a07fe08266')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d9c50d7-3f56-4044-9b54-c2a07fe08266 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d9c50d7-3f56-4044-9b54-c2a07fe08266');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b7a66bc-5fa4-47f3-8d98-3dbc9c9746f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b7a66bc-5fa4-47f3-8d98-3dbc9c9746f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b7a66bc-5fa4-47f3-8d98-3dbc9c9746f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cccaf00b-c470-42e4-8598-d80a4c79cf36\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stats_db_diff')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cccaf00b-c470-42e4-8598-d80a4c79cf36 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stats_db_diff');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stats_db_diff"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode=\"max\",\n",
        "    min_delta=0,\n",
        "    patience=100,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(stats_train_features)\n",
        "steps_per_epoch = len(stats_train_features)/32\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "model_8 = tf.keras.Sequential([\n",
        "      # normalizer,\n",
        "      layers.Dense(8, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(8, activation=tf.keras.layers.LeakyReLU()),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      # layers.Dense(8, activation=\"sigmoid\"),\n",
        "      layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_8.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CqY_g4APKTNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model_8.fit(\n",
        "    stats_train_features,\n",
        "    stats_train_target,\n",
        "    epochs=400,\n",
        "    callbacks=[early_stopping],\n",
        "    # validation_freq=5,\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_data = (stats_val_features, stats_val_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py57qCmuKapT",
        "outputId": "759a3a20-96df-41b5-adb1-ab18a75f218e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "4/4 [==============================] - 2s 81ms/step - loss: 0.8749 - accuracy: 0.5408 - val_loss: 0.6786 - val_accuracy: 0.7083\n",
            "Epoch 2/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9029 - accuracy: 0.4592 - val_loss: 0.6850 - val_accuracy: 0.5417\n",
            "Epoch 3/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7665 - accuracy: 0.5306 - val_loss: 0.6923 - val_accuracy: 0.5417\n",
            "Epoch 4/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8147 - accuracy: 0.5102 - val_loss: 0.7022 - val_accuracy: 0.5417\n",
            "Epoch 5/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7414 - accuracy: 0.5408 - val_loss: 0.7114 - val_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9165 - accuracy: 0.5204 - val_loss: 0.7252 - val_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8397 - accuracy: 0.5306 - val_loss: 0.7402 - val_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7518 - accuracy: 0.5000 - val_loss: 0.7550 - val_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8425 - accuracy: 0.5000 - val_loss: 0.7617 - val_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8006 - accuracy: 0.5612 - val_loss: 0.7612 - val_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8321 - accuracy: 0.4796 - val_loss: 0.7524 - val_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8178 - accuracy: 0.5102 - val_loss: 0.7424 - val_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.8762 - accuracy: 0.4694 - val_loss: 0.7357 - val_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7952 - accuracy: 0.5918 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7326 - accuracy: 0.5000 - val_loss: 0.7231 - val_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8164 - accuracy: 0.5510 - val_loss: 0.7171 - val_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7955 - accuracy: 0.4694 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7111 - accuracy: 0.5102 - val_loss: 0.7038 - val_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8018 - accuracy: 0.5408 - val_loss: 0.6982 - val_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8036 - accuracy: 0.4388 - val_loss: 0.6948 - val_accuracy: 0.5417\n",
            "Epoch 21/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.8737 - accuracy: 0.3980 - val_loss: 0.6933 - val_accuracy: 0.5417\n",
            "Epoch 22/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7954 - accuracy: 0.5408 - val_loss: 0.6943 - val_accuracy: 0.5417\n",
            "Epoch 23/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7931 - accuracy: 0.5102 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8699 - accuracy: 0.5204 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7465 - accuracy: 0.5510 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7539 - accuracy: 0.5000 - val_loss: 0.6918 - val_accuracy: 0.5417\n",
            "Epoch 27/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6927 - accuracy: 0.5816 - val_loss: 0.6891 - val_accuracy: 0.5417\n",
            "Epoch 28/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7972 - accuracy: 0.5510 - val_loss: 0.6875 - val_accuracy: 0.6250\n",
            "Epoch 29/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7228 - accuracy: 0.5918 - val_loss: 0.6874 - val_accuracy: 0.6667\n",
            "Epoch 30/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7732 - accuracy: 0.5408 - val_loss: 0.6873 - val_accuracy: 0.7083\n",
            "Epoch 31/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7781 - accuracy: 0.4286 - val_loss: 0.6877 - val_accuracy: 0.7083\n",
            "Epoch 32/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7284 - accuracy: 0.5102 - val_loss: 0.6891 - val_accuracy: 0.5417\n",
            "Epoch 33/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8886 - accuracy: 0.5204 - val_loss: 0.6930 - val_accuracy: 0.5417\n",
            "Epoch 34/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7531 - accuracy: 0.5816 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7767 - accuracy: 0.5204 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8232 - accuracy: 0.4592 - val_loss: 0.7023 - val_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7593 - accuracy: 0.4898 - val_loss: 0.7080 - val_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7813 - accuracy: 0.5102 - val_loss: 0.7136 - val_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8213 - accuracy: 0.4184 - val_loss: 0.7175 - val_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7325 - accuracy: 0.5204 - val_loss: 0.7202 - val_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8289 - accuracy: 0.4796 - val_loss: 0.7174 - val_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8000 - accuracy: 0.5612 - val_loss: 0.7144 - val_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7178 - accuracy: 0.5408 - val_loss: 0.7107 - val_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7913 - accuracy: 0.5204 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7621 - accuracy: 0.5000 - val_loss: 0.7016 - val_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7380 - accuracy: 0.4898 - val_loss: 0.6965 - val_accuracy: 0.5833\n",
            "Epoch 47/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7630 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5833\n",
            "Epoch 48/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8088 - accuracy: 0.4796 - val_loss: 0.6932 - val_accuracy: 0.5417\n",
            "Epoch 49/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.7471 - accuracy: 0.5510 - val_loss: 0.6933 - val_accuracy: 0.5833\n",
            "Epoch 50/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7539 - accuracy: 0.5102 - val_loss: 0.6937 - val_accuracy: 0.5833\n",
            "Epoch 51/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.7999 - accuracy: 0.4184 - val_loss: 0.6940 - val_accuracy: 0.5833\n",
            "Epoch 52/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.8549 - accuracy: 0.4184 - val_loss: 0.6937 - val_accuracy: 0.5833\n",
            "Epoch 53/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7415 - accuracy: 0.5306 - val_loss: 0.6939 - val_accuracy: 0.5833\n",
            "Epoch 54/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7523 - accuracy: 0.5510 - val_loss: 0.6933 - val_accuracy: 0.5833\n",
            "Epoch 55/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7063 - accuracy: 0.5306 - val_loss: 0.6927 - val_accuracy: 0.5833\n",
            "Epoch 56/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7350 - accuracy: 0.4898 - val_loss: 0.6925 - val_accuracy: 0.5833\n",
            "Epoch 57/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7433 - accuracy: 0.5510 - val_loss: 0.6929 - val_accuracy: 0.5833\n",
            "Epoch 58/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7212 - accuracy: 0.4592 - val_loss: 0.6935 - val_accuracy: 0.5833\n",
            "Epoch 59/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7155 - accuracy: 0.5510 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7287 - accuracy: 0.5510 - val_loss: 0.6942 - val_accuracy: 0.5417\n",
            "Epoch 61/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7123 - accuracy: 0.5408 - val_loss: 0.6937 - val_accuracy: 0.5417\n",
            "Epoch 62/400\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7159 - accuracy: 0.5306 - val_loss: 0.6933 - val_accuracy: 0.5833\n",
            "Epoch 63/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7252 - accuracy: 0.4796 - val_loss: 0.6930 - val_accuracy: 0.5833\n",
            "Epoch 64/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7871 - accuracy: 0.4796 - val_loss: 0.6927 - val_accuracy: 0.5833\n",
            "Epoch 65/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6637 - accuracy: 0.6122 - val_loss: 0.6929 - val_accuracy: 0.5417\n",
            "Epoch 66/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7407 - accuracy: 0.4694 - val_loss: 0.6934 - val_accuracy: 0.5833\n",
            "Epoch 67/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7298 - accuracy: 0.5204 - val_loss: 0.6938 - val_accuracy: 0.5833\n",
            "Epoch 68/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7599 - accuracy: 0.4388 - val_loss: 0.6950 - val_accuracy: 0.5833\n",
            "Epoch 69/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7152 - accuracy: 0.5306 - val_loss: 0.6959 - val_accuracy: 0.5417\n",
            "Epoch 70/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7397 - accuracy: 0.5612 - val_loss: 0.6960 - val_accuracy: 0.5833\n",
            "Epoch 71/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6884 - accuracy: 0.5306 - val_loss: 0.6973 - val_accuracy: 0.5417\n",
            "Epoch 72/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7221 - accuracy: 0.4796 - val_loss: 0.6972 - val_accuracy: 0.5417\n",
            "Epoch 73/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6695 - accuracy: 0.5510 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7084 - accuracy: 0.6122 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7415 - accuracy: 0.4388 - val_loss: 0.7018 - val_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7405 - accuracy: 0.5306 - val_loss: 0.7040 - val_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7668 - accuracy: 0.5000 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7458 - accuracy: 0.4898 - val_loss: 0.7083 - val_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7312 - accuracy: 0.5000 - val_loss: 0.7101 - val_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.6122 - val_loss: 0.7126 - val_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7548 - accuracy: 0.4796 - val_loss: 0.7132 - val_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7550 - accuracy: 0.5102 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7600 - accuracy: 0.5306 - val_loss: 0.7076 - val_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7401 - accuracy: 0.5102 - val_loss: 0.7051 - val_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7323 - accuracy: 0.5612 - val_loss: 0.7021 - val_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7618 - accuracy: 0.5000 - val_loss: 0.7004 - val_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7449 - accuracy: 0.4898 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7304 - accuracy: 0.5000 - val_loss: 0.6995 - val_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7541 - accuracy: 0.5102 - val_loss: 0.6991 - val_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7151 - accuracy: 0.5510 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6957 - accuracy: 0.5918 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7358 - accuracy: 0.5714 - val_loss: 0.6980 - val_accuracy: 0.5833\n",
            "Epoch 93/400\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6721 - accuracy: 0.5816 - val_loss: 0.6953 - val_accuracy: 0.5833\n",
            "Epoch 94/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7526 - accuracy: 0.5510 - val_loss: 0.6933 - val_accuracy: 0.5833\n",
            "Epoch 95/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7776 - accuracy: 0.4796 - val_loss: 0.6920 - val_accuracy: 0.5833\n",
            "Epoch 96/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7116 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5417\n",
            "Epoch 97/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6858 - accuracy: 0.5612 - val_loss: 0.6917 - val_accuracy: 0.5417\n",
            "Epoch 98/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7170 - accuracy: 0.5408 - val_loss: 0.6919 - val_accuracy: 0.5833\n",
            "Epoch 99/400\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7193 - accuracy: 0.5510 - val_loss: 0.6923 - val_accuracy: 0.5833\n",
            "Epoch 100/400\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7508 - accuracy: 0.5408 - val_loss: 0.6929 - val_accuracy: 0.5833\n",
            "Epoch 101/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.7614 - accuracy: 0.5625Restoring model weights from the end of the best epoch: 1.\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7399 - accuracy: 0.5306 - val_loss: 0.6937 - val_accuracy: 0.5417\n",
            "Epoch 101: early stopping\n",
            "CPU times: user 6.36 s, sys: 297 ms, total: 6.66 s\n",
            "Wall time: 7.02 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# features = dirm_val_features\n",
        "# target = dirm_val_target\n",
        "# features = dirm_train_features\n",
        "# target = dirm_train_target\n",
        "features = stats_test_features\n",
        "target = stats_test_target\n",
        "num = len(features)\n",
        "features = features[:num]\n",
        "target = target[:num]\n",
        "\n",
        "print(len(features))\n",
        "predictions = model_8.predict(features)\n",
        "\n",
        "# target_data = np.array(target).astype('float32')\n",
        "# target_data = [x[0] for x in target_data]\n",
        "correct = 0\n",
        "predicted_classes = [1 if x >= 0.5 else 0 for x in predictions]\n",
        "for prediction_class, target_val, raw_pred in zip(predicted_classes, target, predictions):\n",
        "  # prediction_class = np.argmax(prediction)\n",
        "\n",
        "  print(f\"pred: {prediction_class}, real: {target_val}\")\n",
        "  print(f\"probability: {raw_pred}\")\n",
        "  if prediction_class == target_val:\n",
        "    correct += 1\n",
        "\n",
        "print(f\"correct: {correct/num}, {correct}/{num}\")\n",
        "# confusion_matrix = tf.math.confusion_matrix(\n",
        "#     target,\n",
        "#     predicted_classes,\n",
        "#     num_classes=3,\n",
        "#     weights=None,\n",
        "#     dtype=tf.dtypes.int32,\n",
        "#     name=None\n",
        "# )\n",
        "# confusion_matrix\n",
        "plot_confusion_matrix(target, predicted_classes, [\"D\", \"U\"], \"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bIjKh-XRKm0h",
        "outputId": "f0d715fd-da8a-45cf-cbaa-35a04c8ad135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.541]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.538]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.517]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.492]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.481]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.52]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.542]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.539]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.521]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.483]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.488]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.474]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.528]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.465]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.471]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.477]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.452]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.528]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.526]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.452]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.467]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.511]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.508]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.45]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.507]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.514]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.462]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.494]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.49]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.457]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.504]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.499]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.46]\n",
            "pred: 0, real: 1.0\n",
            "probability: [0.454]\n",
            "pred: 1, real: 0.0\n",
            "probability: [0.519]\n",
            "pred: 1, real: 1.0\n",
            "probability: [0.505]\n",
            "pred: 0, real: 0.0\n",
            "probability: [0.449]\n",
            "correct: 0.6428571428571429, 27/42\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAHHCAYAAACyWSKnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI0ElEQVR4nO3dd3gU5drH8d+SsiSBJAQMEKR3JESqBaWrIARQsKBSBI8eLIhUOYqCihFEpSkq4IkoIhbgWCiHJhEVEQFBqSJYqQKBUEKSfd4/eLOHJQmkbDLZ2e+Ha6+LTL13dmZy536eedZhjDECAACwkRJWBwAAAOBtJDgAAMB2SHAAAIDtkOAAAADbIcEBAAC2Q4IDAABshwQHAADYDgkOAACwHRIcAABgO36T4LhcLr3yyiuKjY1VSEiIHA6HHA6HJbFk7nvv3r2W7B//40ufxbZt29SzZ09FR0crICBADodDY8aMsTqsfPGl446CGTNmjBwOh/r165ev9du0aSOHw6HExESvxlVYjh07pkceeUTVqlVTUFCQHA6H2rRpY3VYueJrx/pSAguy8u7duzVz5kytXLlSe/bs0dGjRxUaGqpq1arp2muvVa9evdSqVStvxVogzzzzjMaOHSuHw6ErrrhCERERVoeEfMr8pT548GBFRkZaGktROXz4sK6//nr9/fffKlu2rJo3b67AwEBVqVLF6tA87N27V4mJiYqMjNTgwYOtDgfFnB2v5e7du2v16tUKCQlRo0aNFBISotjYWKvDssSxY8c0adIkSbLmjzGTD+np6WbYsGEmMDDQSDKSTPXq1U3z5s1NvXr1TMmSJd3TW7VqlZ9deJXL5TLlypUzksy8efOsDsfUrVvX1K1b1/zxxx9Wh+KTMs+tPXv2FHhbvvJZTJ061UgyTZo0MadPn7Y6nBytWrXKSDJVq1a96HK+ctxRcFOnTjV169Y1jz/+eJZ5ubmWe/fuberWrWvmz59fiFF6x5YtW4wkExIS4pX7U1Fr3bq1kWT+/e9/e2V7e/bscX/GVshzBccYo9tuu00LFixQcHCwRo8erQcffFAVKlRwL3Pq1CktXrxYCQkJSkpKKlgG5gWHDh3S4cOHJUldunSxOBpp+/btVoeA/+crn8XWrVslSe3bt1fJkiUtjqbgfOW4o+AefvhhPfzww/lef/bs2V6MpnBlXqcNGzZUtWrVrA0GeW+ieumll7RgwQIFBQVp8eLFateuXZZlQkND1aNHD916660aN26cVwItiNOnT7v/HxoaamEkQP5knsOcv0DxxXVazOSl3JOSkmKioqKMJPPEE0/ku2zkcrnMe++9Zzp06GCioqJMUFCQqVSpkunVq5f5/vvvs13n3//+t5FkWrdu7f65RYsWJiwszJQuXdq0adPG/Pe///VY5/zyWHavp59+OtttZ+dipbsVK1aY7t27m4oVK5rAwEATHh5uatSoYbp3725mzZqVZXldoiy7ePFiEx8fb6Kjo01QUJApX7686datm1mxYkW2y1/YLPCf//zHtG7d2kRERJjQ0FDTokULM3fu3Bzf28WcH+u3335r4uPjTdmyZU1YWJi5+uqrzWeffeZe9q+//jIPPfSQqVKligkODjY1a9Y0zz33nElPT8+yXZfLZRYtWmQeeughc+WVV5py5cqZ4OBgExMTY3r06GGSkpKyrPP000/n6vM0xpiqVasaSWbVqlVm+/btpk+fPqZSpUomMDDQ9O3bN9v3l2nDhg0mODjYSMqxLN67d28jyTRu3NicOXMmT8d069at5t577zVVq1Y1wcHBJjIy0rRq1crMmDEjy7Hq27fvRd9zbqSmppqPP/7Y3HvvvaZhw4amTJkyxul0mqpVq5revXubH3744aLrnzp1ykyePNm0atXKREVFmeDgYFO5cmVzww03mOnTp7vff+Y1ktNr1apV7m368jXQo0cPU758eVOiRAmPc84YY1auXGl69uxpYmJiTFBQkImKijI33nijWbhw4UX38ddff5mRI0eauLg4U7p0aRMSEmJq1apl7rjjDvPJJ59ku05ej1GmZcuWmQ4dOpjw8HBTqlQp06JFC5OYmGiM8bxuzpd57fXt29ekp6ebl19+2cTGxpqQkBATGRlpOnfubNavX5/t/s5f98JpubmWL9VskpfrKdP5n+nmzZvN7bffbqKjo01wcLCpU6eOGTt2rElNTb3ocTxf5u+Q3Jz7xhT8/H7vvfdMq1atTJkyZbLd/sVs2rTJdO/e3URFRZmQkBDTsGFD8+KLL5r09PQcj3V+7iGXunedv48NGzaY0aNHm2uvvdZUqlTJfe20bdvWvP3228blcuX6/Z0vTwnOBx98YCSZEiVKmAMHDuRrh2lpaaZnz57uN3n55ZebZs2amYiICCPJBAQEmDfeeCPLeucnIf379zeSTOXKlU2TJk1MWFiYO67zbyT79u0zLVu2NM2aNXPvr2XLlu5XZvJRkARnxowZ7m1HRkaauLg406hRI/eJV6lSpSzbutjN/dFHH3XPj46ONs2bN3f3H5JknnzyySzrnH/yjx071kgy5cuXN02bNjWRkZHudadOnZrj+8vJ+esGBQWZMmXKmKZNm7rfX4kSJcwHH3xgdu3aZSpVqmScTqdp0qSJufzyy93rPvjgg1m2e+LECSPJOBwOc9lll5lGjRqZuLg493YdDoeZPn26xzqzZs0yLVu2dG+3WbNm2X6exvzvRv3888+b0NBQ43Q6TePGjU3Dhg3Nvffee8nPYtKkSUaSKVOmjPn111895r399ttGkgkLCzM7duzI0/GcN2+eO3kKCwszTZs2NdWrV3fHccMNN5hTp065lx83bpxp2bKliY6Odp/z57/n3MjsF1CiRAlToUIF07hxY3PFFVeYUqVKGUkmODg4x1+iu3fvNvXq1XPHV6VKFdO8eXMTExNjHA6Hx7F7+OGHTcOGDY0k43Q6PeJs2bKl2bBhg3u7vngNTJw40QQGBppSpUqZpk2bmjp16pgxY8YYY84l7I888oh72TJlypjGjRub8uXLu6c9/PDD2W5/8eLFJjw83P0Z1a9f3zRp0sT9x2R2/Znyc4yMMebVV1/1uF9lfpaSzNChQy+Z4Nx9993mxhtvNJJMrVq1TFxcnHE6nUY61+9k3bp1WfaZXYKTl2v5YglOXq+nTJnz33jjDVOyZEn3Z5p5LCSZHj16ZHsMs7No0SLTsmVLU7t2bSPJhIeH53juF/T8Hjx4sPv8zvz8cpvgLFq0yH28QkNDTdOmTd2f+a233prjsc7PPWTcuHE5/u5t2bKlWbRokXvZpk2bGkkmIiLC1KtXzzRr1szjs+jVq1euP4vz5SnBGTRokJFkYmNj87UzY4wZM2aM++Ce/9fxmTNnzJAhQ9xJztq1az3Wy0xCgoKCTNmyZT2qNSkpKeaWW24xkky1atWyZHuX6uiU3wQnPT3dlC1b1kgyU6ZMMWlpaR7rbNu2zUyePDnLtnK6uScmJrrf//Tp001GRoZ7Py+99JL7F8qHH37osV7myR8UFGRCQkLMnDlz3PPS0tLMgw8+aCSZUqVKmePHj+f4HrOTGWtQUJB59tln3e8xLS3N3Hvvve5fui1atDDdu3c3f//9t3vdzOTP4XCYnTt3emw3NTXVvPHGG+bPP//0mJ6enm7mzZtnQkNDTVBQkPntt99yffzOl3nRBgQEmLvuusscPXrUPe/8G97FthUfH+++MDPf944dO9wXdeZfvbm1bds2dwf8++67z6SkpLjnLVu2zJ3kP/TQQ1nWzfxr6MKKQW7s37/fvPPOOx6fjTHnrrlp06aZgIAAExUVZU6ePOkx/9SpU6Z+/frua/7Cv9APHDhgxo8fbw4ePOielttOxr54DQQEBJihQ4d6dPLOPJfGjx9vpHN/sH366ace6y9ZssSdoM6ePdtj3k8//WRCQ0ONJNOzZ88s18NPP/1kXnjhBa8cox9++MH9YMjw4cM9KhSJiYkmMDDQBAUFXTTBCQoKMtWqVfM4Fw4dOmSuvfZaI2X/UEl2Cc6Fx/Zi13JOv3QLcj2df18bMWKEx2c6Z84c9zFcuXJljnFl51K/Swp6fgcEBBin02neffdd9+85l8uVqyrywYMH3UnzbbfdZpKTk93z/vOf/5iQkBD353/hsc7vPSS3nYznzJljtmzZkmX6unXr3EljfiqweUpwbr31ViPJdOvWLc87MuZcIpL5l8qECROyXeb66683kkyXLl08pp9fAnznnXeyrLdv3z73h3NhuaywEpx9+/a5/xLKi5wu6po1axop+4qHMcbcc889RpJp2LChx/TMk1+SefbZZ7Osd/r0aXPZZZcZSeY///lPvmK9+eabs8z7+++/3TeY8uXLmxMnTmRZJjODnzRpUp72+8QTTxhJWW7u58eUmwSnQYMGWRLP3G7r8OHDplKlSkY61ySbmppqGjdu7P5LNq8yK48NGzbMtuQ6c+ZM9033r7/+8phXkATnUu6++24jybz//vse06dMmWIkmXLlyuW6YlvQBKc4XwM33nhjtvOPHDliSpUqZQICAsx3332X7TIff/yxkWTq16/vMT3zntq6dWv3L7tLye8x6tOnj5Fk2rdvn+16I0eOdL/XnBIcSdk2H3///ffuP2aOHTuW7breTnAKcj1l7jenY5H5x81jjz2WY1zZudTvEm+c3+PGjctTTJmeeeYZI8lUqFAh2ycxx40b595HXp+iyuke4o2nqJYtW2YkmY4dO+Z53TwN9Hf8+HFJUqlSpfKymtuXX36p48ePq2TJkho4cGC2ywwbNkyStHz5cp09ezbL/IiICN19991ZpleoUEHVq1eXJP3888/5ii+voqOjFRISouTkZC1atKhA29q+fbt2794tSRoyZEi2ywwfPlyS9OOPP+q3337LdpkHH3wwy7SSJUuqcePGkvJ/bO6///4s06KiotxPCvTq1Svb86JZs2YX3e+6des0atQode/eXW3atNF1112n6667Th988IEkaePGjfmKN1Pfvn0VGJi/4Z7Kli2rOXPmKCAgQAkJCeratas2btyomjVravr06XneXuY5Mnjw4GwHmezTp4+io6OVlpamZcuW5Svmi1mxYoWGDh2q+Ph4tW7d2n2sM590vPBYf/zxx5Kkf/zjH4qOjvZ6PBcq7tfAgAEDsp2+aNEipaSkqFmzZu7z/ULx8fEKCgrStm3btG/fPknSmTNn9Pnnn0uS/vWvf6lEiUvfjgtyjJYsWSJJuu+++7JdL7tr/EKNGjXS9ddfn2V648aN5XQ6ZYxxx1fYvHE9PfTQQ9lOv+aaayR593eJt87vnD6/S8k8Xvfff3+2T2I+9NBDl7xX5vUekhe//vqrxo8frzvuuEPt27d3b3vUqFH53nae7vzh4eGSpJSUlDzvSJJ27NghSapWrVqOSVLmgEhnzpzR3r17VadOHY/5tWvXznEE4vLly2vnzp06ceJEvuLLqxIlSmjYsGF69tln1blzZ8XGxqp9+/a65ppr1KpVK49H5y8l89iEhISoZs2a2S7ToEEDBQQEKCMjQ9u3b88yyFu5cuUUFRWV7brly5eXpHwfm1q1amU7PTo6Wtu3b7/ofCnrOZOenq7+/fvrnXfeueh+//7773xE+z9XXHFFgdZv3bq1nnzySY0dO1ZLly5VUFCQ3n//fZUuXTpP20lOTtb+/fslnXuENDtBQUGqV6+eDh486NXHqFNSUnTrrbdeMmm68Fhv2bJFknTttdd6LZaLKe7XQE7n0g8//CBJ2rNnj6677roc18+8b/3++++qWLGidu3apdTUVEm5P8b5PUbHjh3TwYMHJUlXXnlltuvVqFFD4eHh7j9ks3Ph/fj89xYdHa3ff/+9SO6/3rqecno/BT1XsuOt8zu/f2xkHoOczuOIiAhdfvnl2Y4unt97SG5NmTJFw4cPz7aoUZBt56mCc/nll0uSfvnllzzvSPrfyXKxX/wVK1bMsvz5wsLCclw38y8gY0y+4suPsWPHaubMmYqLi9OWLVs0adIk3XHHHYqJidENN9zgvvldSuZ7zbywshMYGKhy5cp5LH++wjw2OW0786Z9qfkX7nfixIl65513VLJkSb3yyivaunWrUlJS5HK5ZIzRrFmzJElpaWn5ivdScefFDTfc4P5/06ZNc/wr/WLO/7xyc/5788Y6bNgwLVu2TOXKldPMmTP1888/69SpUzLnmqg1evRoSVmPdeYvuqIaYdZXr4GjR49Kkg4ePKivvvoqx1fmzfvUqVOS/nd8AwICcl0Vz+8xOv8PjIsl55dK3IvL/ddb11NO76cw3kthn9/e2H9O8/J7D8mNb775Ro8++qjOnj2rhx56SOvWrdPRo0eVnp7uURFMT0/P87bzlOBk/nXy008/uf8ayIvMiycz885OZvn2/OULW06/hM938uTJHNcdMGCANm3apIMHD2rBggUaPHiwKlSooOXLl6tdu3b6888/LxlD5ns9cOBAjsukp6e7BywsqmNTWDK/62TixIkaPHiw6tevr7CwMPdnUdDKjbckJyfrnnvukXTuprd27VpNmTIlz9s5//PKzfnvrc83PT1dc+bMkXTumA8YMEA1a9ZUSEiIe5mcjnVmxfbYsWNeieVSfPUayExO+vTp477hX+yV+b1Emcc3IyMj11Xx/B6j8xOoiyXPRVX9LiirrqeCsPr8zs3+s5tXkHtIbrz99tuSpJ49e2ratGlq3ry5IiMjFRAQUOBt5ynB6dSpk6KiouRyufJ1k69Xr56kc99Xk9MFnVkWL1myZJGNBJmZFV/sg9+1a9clt3PZZZepe/fueuWVV7Rjxw5Vr15dR44c0fvvv3/JdTOPzenTp3Nsw966dasyMjIkSfXr17/kNouzPXv2SFKO31W2du3aogwnR/fff7/27t2rFi1aaN68eZKkESNG5LoylykiIsL9l+aPP/6Y7TLp6enuMrK3Pt9Dhw65r7W8HutGjRpJkr7++utc768gX2Drq9dAZrP65s2b87RenTp13H0hcnuM83uMIiMj3U0bOZ27e/bsuWjzVHFi1fVUEFaf35n7zxxt+ULJycn6448/skwvyD0kN/eDwvxdkKcEp1SpUho5cqQkacKECVq5cuVFlzfGeIxkfN111yk8PFxnzpzJsZPmSy+9JOlcs0BwcHBewsu32rVrSzp3oLNLcubMmaPk5OQ8bbN06dLuXxC5qeDUrVvX3Y/l5ZdfznaZzGMTGxurypUr5yme4iZzpM/zK3aZtm/frk8//fSS62aW+gvLjBkz9MEHHyg8PFxz585Vz5499dBDDyk1NVV33nlnjlW9nHTu3FmSNGnSpGyrhe+8844OHjyooKAgj2axgjh/RNXsjvXKlSu1YcOGbNft2bOnJGnmzJnuvypzu7/8fDa+eg106dJFISEh2rRpU546hzudTvdXx7zwwgu5ag4pyDHq2LGjJLmbfy80Y8aMXMfuLQU5X6y4ngrC6vO7U6dOkqQ333zT3ffrfK+99lq2zUAFuYecv25On/HFfhecOXNGU6dOzXa93MhTgiOd6+XdtWtXpaWlqVOnTnr66aezlAjPnDmj//znP7rqqqv05JNPuqeHhYW5e4+PGTNGCxcudM87e/asRowYoaSkJAUEBOiJJ57I51vKu9jYWFWrVs3dBnj+B7FixQoNHjxYQUFBWdbbunWrBgwYoDVr1sjlcnnMW7ZsmVasWCFJat68ea7iyDxWb7zxht544w33RetyuTR58mR3h9ynnnoq72+ymGndurWkc0+PnH9i//DDD4qPj3eXJ7OTeZNYvnx5ocW3detW97dhv/7666pRo4akc01qjRo10vbt2zVo0KA8bXPYsGEqWbKkfvzxRz3wwAMeCdLKlSs1dOhQSdIDDzyQpw7qFxMREaG4uDhJ5542Ob+56YsvvtCdd96Z43dbDRgwQA0aNNChQ4fUoUOHLE8xHDx4UC+++KIOHTrknlazZk05HA4dOnQozxUNyTevgejoaHfct912m2bPnp3lF8WRI0c0e/Zs91MymZ555hmFhoZq1apV6tWrV5ab/NatWzV+/HiPafk9RkOHDlVgYKCWLVumUaNGefSXeOeddzRx4sRs73OFqSDXshXXU0FZeX7/85//VGRkpPbt26d+/fp5NEd+9tlneu6557L9/AtyDylXrpwiIiIk5fwZZ/4ueO211/Tdd9+5px88eFA9e/bU77//nrc3er78PJeelpZmBg8ebAICAtxjH9SoUcO0aNHC1K9f3+PbxNu1a5dl3R49erjnV65c2TRv3tw9KFOJEiUuOZJxTnIaLyE3z+IvWLDAlChRwuj/BwNr0qSJqVKlipFk+vfvn+22N27c6N5uaGioadSokcfIoPr/MYMuHN8ic96lRnHNHKkyc/wOKfuvyMjN2CP5HUflYrEac+lh1HMaA2Pz5s3uEaidTqdp1KiRqVu3rvuceP7553P8vCdOnOiOq169eqZVq1amdevWHjHkNCJrbt7f6dOnTWxsrJFk+vXrl2Wdn376yYSEhBjlY/Cp80deLVWqlGnWrJmpUaOGO46cRl4tyDg4S5cudV+rYWFhpnHjxu7RXq+88kozbNiwHMcp2b17t/tzyTzHmjdvbipVqpRlJONMXbp0MdK50U0bN25sWrdubVq3bm02btzoXsZO14Ax5wZbGz58uHvZzHtIixYtTNWqVd3HKrvzefHixaZ06dLu+1+DBg1MkyZN3IOIXmok49weI2OMmTZtmnuZMmXKuD9LSWbIkCHu6+bCsW4uNpZNptx8zcOFcnMt53Yk47xcT5f6THPz+ya/6xXW+Z0bn376qXu8uNDQUNOsWTNTrVo1I8nccsstOR7rgtxDHn74Yfe5HRsb674fLF682Bhzbny8zAFFHQ6HqVOnjmncuLEJCgoyTqfTPZ5RftKVPFdwpHM9vV955RVt375dI0eOVLNmzXT8+HFt2LBBf/75p+rWrauBAwdqzZo17irG+et++OGHmjNnjtq1a6eUlBRt2rRJYWFh6tWrl9atW5er8Ri8rXv37lq6dKm7A+D27dt12WWXaebMmTmWdOvUqaNZs2bprrvuUpUqVfT7779r48aNOnv2rDp06KDZs2dr/vz5uRrfItOkSZO0aNEidenSRS6XSxs3bpTD4VC3bt20fPlyPffcc954u5aLjY3VN998o27duikkJEQ7duxQWlqaBg0apI0bN3o8TXehxx57TBMnTlRcXJx+++03JSUlafXq1dk+3pgfQ4YM0ZYtW1SnTh1NmzYty/wGDRpo8uTJks79VZTZhpwbt99+uzZu3Kh+/fopKipKmzdv1t9//63rr79eM2bM0OLFiz0673nDjTfeqFWrVqlDhw5yOBzavn27nE6nnnzySX311VcXfTKjRo0a2rBhgyZOnKhrrrlGx44d0+bNmxUQEKAbb7xRb775pmJiYjzWmT17th5++GFdfvnl+umnn7R69WqtXr06152VffEacDgcmjBhgtatW6d7771X5cuX19atW7Vx40alpaXppptu0tSpU/Xuu+9mWbdjx47atm2bhgwZonr16mnv3r3asWOHypQpo7vuukuvvfZalnXye4weeugh/fe//1X79u2Vnp6urVu3qmLFipo1a5Zeeukld1+LzA7Qha2g17IV11NBWXl+d+nSRd9++626desmp9OpH3/8UWFhYXrxxRf14Ycf5rheQe4hL774op544gnVqVNHu3btct8PMlt+wsLC9OWXX2rgwIGqWLGi9uzZo3379umWW27RunXr1L59+3y/X4cxRfhMNQCgWDp06JCio6PlcDh09OhRd9MC4KvyVcEBANjLzJkzJZ17eo7kBnZAggMAfuK9997T4sWL3Y8iS+fG4XnzzTc1duxYSdIjjzxiVXiAV+XvS3oAAD5nw4YNeumll1SqVCnVrl1bAQEB2rlzp3v8m7vuukv9+/e3OErAO0hwAMBP3H777Tp27JjWrFmjPXv2KCUlRZGRkbrxxht177336o477ijQYI1AcUInYwAAYDv0wQEAALZDE1UhSRnS1eoQgGInctr3VocAFDvpZy/9dT4FlXb4F69tK6hcDa9tqzBRwQEAALZDBQcAALtzZVx6GZshwQEAwO6M69LL2AxNVAAAwHao4AAAYHcu/6vgkOAAAGBzhiYqAAAA30cFBwAAu6OJCgAA2I4fNlGR4AAAYHd+OA4OfXAAAIDtUMEBAMDuaKICAAC244edjGmiAgAAtkMFBwAAm/PHgf5IcAAAsDuaqAAAAHwfFRwAAOyOJioAAGA7DPQHAADg+6jgAABgdzRRAQAA2/HDp6hIcAAAsDs/rODQBwcAANgOFRwAAOyOJioAAGA3xvCYOAAAgM+jggMAgN35YSdjEhwAAOzOD/vg0EQFAABshwoOAAB2RxMVAACwHb5sEwAAwPeR4AAAYHfG5b1XHiQlJSk+Pl4xMTFyOBxauHBhjsv+85//lMPh0KRJkwr2Xv8fCQ4AAHbncnnvlQcnT55UXFycXn311Ysut2DBAq1du1YxMTEFeZce6IMDAIDdebGTcWpqqlJTUz2mOZ1OOZ3OLMt26tRJnTp1uuj2/vzzTz3yyCNaunSpOnfu7LU4qeAAAIBcS0hIUEREhMcrISEhX9tyuVzq3bu3hg8friuuuMKrcVLBAQDA7rw40N+oUaM0ZMgQj2nZVW9yY/z48QoMDNSgQYO8EZoHEhwAAOzOiwlOTs1RefX9999r8uTJ2rBhgxwOhxci80QTFQAAKHJffvmlDh48qCpVqigwMFCBgYH69ddfNXToUFWrVq3A26eCAwCAzRlT/Ab66927tzp06OAx7aabblLv3r117733Fnj7JDgAANidRV+2mZKSop9//tn98549e7Rp0yZFRUWpSpUqKlu2rMfyQUFBqlChgurWrVvgfZPgAACAQrF+/Xq1bdvW/XNm5+S+ffsqMTGxUPdNggMAgN1Z9GWbbdq0kTEm18vv3bvXa/smwQEAwO4saqKyEk9RAQAA26GCAwCA3VnURGUlEhwAAOzOD5uoSHAAALA7P6zg0AcHAADYDhUcAADsjiYqAABgO36Y4NBEBQAAbIcKDgAAdueHnYxJcAAAsDuaqAAAAHwfFRwAAOyOJioAAGA7NFEBAAD4Pio4AADYHU1UAADAdvywiYoEBwAAu/PDBIc+OAAAwHao4AAAYHfGWB1BkSPBAQDA7miiAgAA8H1UcAAAsDs/rOCQ4AAAYHd+OA4OTVQAAMB2qOAAAGB3NFEBAADb8cPHxGmiAgAAtkMFBwAAu6OJCgAA2A4JDgAAsB0eEwcAAPB9VHAAALA54/K/p6hIcAAAsDs/7INDExUAALAdKjgAANidH3YyJsEBAMDu/LAPDk1UAADAdqjgAABgd37YyZgEBwAAu/PDBIcmKgAAYDtUcAAAsDvjf52MSXAAALA7mqj8W79+/eRwOORwOBQUFKTy5cvrhhtu0FtvvSWXH54cvqREjStUcsCTCn363yr18icKaHjVeTMDFNylr0KGT1FYwgcKffrfcvYaLEd4lHUBAxZ4avQQpZ/90+P145bVVoeFouAy3nv5CBKcC3Ts2FH79u3T3r17tXjxYrVt21aPPvqounTpovT0dKvDQw4cwU65/tqj1PlvZJ0Z7FSJSjWV9t95OvXyYzqT+IJKRFdSyQFPFH2ggMV+/Gm7KlW+0v1q3aa71SEBhYImqgs4nU5VqFBBklSpUiU1adJEV199tdq3b6/ExETdd999FkeI7GRs36CM7Ruyn3nmlM688ZT7RyMpdf4bCn3sZTkiy8kcO1w0QQLFQHp6hg4cOGR1GChqfjiSMRWcXGjXrp3i4uI0f/58q0OBlzhKhsm4XDKnT1odClCkateqrt/2fq+d27/W7LenqnLlGKtDQlHwwyYqKji5VK9ePW3evDnbeampqUpNTfWYlpaeIWdgQFGEhrwKDFJwl75K35gkpZ62OhqgyKxbt1H973tMO3fuVsUK0Rr95BB9sXKB4hq3U0oKyT7shQpOLhlj5HA4sp2XkJCgiIgIj9dL3/1cxBEiV0oEqGSfEZLDodSPplsdDVCklixdpY8//kxbtmzTf5etVpeuvRUZGa7besZbHRoKmXG5vPbyFSQ4ubRt2zZVr14923mjRo1ScnKyx2to81pFHCEuqUSASvYdIUdUtE6//hTVG/i95OTj2rnrF9WqVc3qUFDY/LCJigQnF1auXKktW7aoR48e2c53Op0KDw/3eNE8VcxkJjflYnR6+mjp1AmrIwIsFxYWqpo1qmrfvoNWhwJ4HX1wLpCamqr9+/crIyNDBw4c0JIlS5SQkKAuXbqoT58+VoeHnASXVIlyFd0/logqLxNTXebUCZnjR1Wy3+MqUamGzsx6Vo4SJaTSkZIkcypFyuDxf/iHCS+M1mefL9Ovv/2hmIoV9PRTQ5WR4dL78xZaHRoKmx8+RUWCc4ElS5aoYsWKCgwMVJkyZRQXF6cpU6aob9++KlGCgldxFVC5lkIeet79s7P7ucf509at0NmlcxX4/wP/hQ6b4rHe6Vf/pYzdPxZdoICFKl1eUe++86rKli2jQ4eO6Kuv16nl9fE6fPiI1aGhsPlQ05K3OIzxwy+oKAIpQ7paHQJQ7ERO+97qEIBiJ/3sn4W+j5PP3O21bYU9Ncdr2ypMVHAAALA7H3r6yVtIcAAAsDs/bKIiwQEAwO78sJMxvWYBAIDtUMEBAMDuaKICAAB240tfseAtNFEBAADboYIDAIDd0UQFAABsxw8THJqoAABAoUhKSlJ8fLxiYmLkcDi0cOFC97y0tDSNHDlSsbGxCgsLU0xMjPr06aO//vrLK/smwQEAwO6My3uvPDh58qTi4uL06quvZpl36tQpbdiwQaNHj9aGDRs0f/587dixQ127euerjmiiAgDA7rzYRJWamqrU1FSPaU6nU06nM8uynTp1UqdOnbLdTkREhJYtW+Yxbdq0aWrRooV+++03ValSpUBxUsEBAAC5lpCQoIiICI9XQkKCV7adnJwsh8OhyMjIAm+LCg4AADZnvFjBGTVqlIYMGeIxLbvqTV6dOXNGI0eOVK9evRQeHl7g7ZHgAABgd15McHJqjiqItLQ03X777TLGaPr06V7ZJgkOAAB2V4xHMs5Mbn799VetXLnSK9UbiQQHAABYJDO52bVrl1atWqWyZct6bdskOAAA2J1FA/2lpKTo559/dv+8Z88ebdq0SVFRUapYsaJ69uypDRs26LPPPlNGRob2798vSYqKilJwcHCB9k2CAwCA3VmU4Kxfv15t27Z1/5zZOblv374aM2aMPvnkE0nSlVde6bHeqlWr1KZNmwLtmwQHAAAUijZt2siYnJOri80rKBIcAABsrjATieKKBAcAALvjyzYBAAB8HxUcAADszg8rOCQ4AADYnDe/qsFX0EQFAABshwoOAAB254cVHBIcAADsrvh+FVWhIcEBAMDm6IMDAABgA1RwAACwOz+s4JDgAABgd37YB4cmKgAAYDtUcAAAsDl/7GRMggMAgN3RRAUAAOD7qOAAAGBzNFEBAAD7oYkKAADA91HBAQDA5owfVnBIcAAAsDsSHAAAYDf+WMGhDw4AALAdW1Rwjh07pnXr1ungwYNyuTzT1D59+lgUFQAAxYQfVnB8PsH59NNPdffddyslJUXh4eFyOBzueQ6HgwQHAOD3aKLyQUOHDlX//v2VkpKiY8eO6ejRo+7XkSNHrA4PAABYwOcrOH/++acGDRqk0NBQq0MBAKBYooLjg2666SatX7/e6jAAACi2jMt7L1/h8xWczp07a/jw4dq6datiY2MVFBTkMb9r164WRQYAAKzi8wnOP/7xD0nSM888k2Wew+FQRkZGUYcEAEDxYhyXXsZmfD7BufCxcAAA4MmXmpa8xef74AAAAFzIFgnO6tWrFR8fr1q1aqlWrVrq2rWrvvzyS6vDAgCgWDAuh9devsLnE5x3331XHTp0UGhoqAYNGqRBgwYpJCRE7du313vvvWd1eAAAWM4fn6JyGGOM1UEURP369XX//ffrscce85j+8ssva8aMGdq2bZslcaUM4ekt4EKR0763OgSg2Ek/+2eh7+PPa9p5bVuVvlnptW0VJp+v4Pzyyy+Kj4/PMr1r167as2ePBREBAACr+XyCU7lyZa1YsSLL9OXLl6ty5coWRAQAQPHij01UPv+Y+NChQzVo0CBt2rRJ1157rSTpq6++UmJioiZPnmxxdAAAWM+XOgd7i88nOAMHDlSFChX00ksv6YMPPpB0rl/OvHnz1K1bN4ujAwAAVvD5BEeSbrnlFt1yyy1WhwEAQLHk248T5Y8tEhwAAJAzmqh8RFRUlHbu3Kly5cqpTJkycjhy/uCOHDlShJEBAIDiwCcTnFdeeUWlS5d2//9iCQ4AAP6OCo6P6Nu3r/v//fr1sy4QAAB8gD/2wfH5cXACAgJ08ODBLNP//vtvBQQEWBARAACwmk9WcM6X0zdNpKamKjg4uIijAQCg+KGJyodMmTJFkuRwODRz5kyVKlXKPS8jI0NJSUmqV6+eVeEBAFBsGEOC4zNeeeUVSecqOK+//rpHc1RwcLCqVaum119/3arwAAAoNnzpKxa8xWcTnMwv0mzbtq3mz5+vMmXKWBwRAAAoLnw2wcm0atUqq0MAAKBYc/lhE5XPP0XVo0cPjR8/Psv0CRMm6LbbbrMgIgAAihdjHF57+QqfT3CSkpJ08803Z5neqVMnJSUlWRARAACwms83UaWkpGT7OHhQUJCOHz9uQUQAABQv/viYuM9XcGJjYzVv3rws099//301aNDAgogAAChejPHey1f4fAVn9OjRuvXWW7V79261a9dOkrRixQrNnTtXH374ocXRAQAAK/h8ghMfH6+FCxfq+eef10cffaSQkBA1atRIy5cvV+vWra0ODwAAy/ljE5XPJziS1LlzZ3Xu3DnL9B9//FENGza0ICIAAIoPHhO3gRMnTujNN99UixYtFBcXZ3U4AADAArZJcJKSktSnTx9VrFhREydOVLt27bR27VqrwwIAwHL+OA6OTzdR7d+/X4mJiZo1a5aOHz+u22+/XampqVq4cCFPUAEA8P986eknb/HZCk58fLzq1q2rzZs3a9KkSfrrr780depUq8MCAKDYcRmH116+wmcrOIsXL9agQYM0cOBA1a5d2+pwAABAMeKzFZw1a9boxIkTatq0qa666ipNmzZNhw8ftjosAACKHX/sg+OzCc7VV1+tGTNmaN++fXrggQf0/vvvKyYmRi6XS8uWLdOJEyesDhEAgGLBqpGMk5KSFB8fr5iYGDkcDi1cuPCCuIyeeuopVaxYUSEhIerQoYN27drllffsswlOprCwMPXv319r1qzRli1bNHToUL3wwguKjo5W165drQ4PAAC/dfLkScXFxenVV1/Ndv6ECRM0ZcoUvf766/r2228VFhamm266SWfOnCnwvh3G2K9vdUZGhj799FO99dZb+uSTTyyJIWUIyRVwochp31sdAlDspJ/9s9D3sf7y7l7bVuzueUpNTfWY5nQ65XQ6L7qew+HQggUL1L37uViMMYqJidHQoUM1bNgwSVJycrLKly+vxMRE3XnnnQWK02c7GV9MQECAunfv7j6IVtj+gc8XxwCvO/3Xl1aHAPglb/adSUhI0NixYz2mPf300xozZkyetrNnzx7t379fHTp0cE+LiIjQVVddpW+++YYEBwAAFJ1Ro0ZpyJAhHtMuVb3Jzv79+yVJ5cuX95hevnx597yCIMEBAMDmvDl+TW6ao4oD2lEAALA548WXt1SoUEGSdODAAY/pBw4ccM8rCBIcAABQ5KpXr64KFSpoxYoV7mnHjx/Xt99+q2uuuabA2/fJJqq8PBnFo+IAAH9n1VcspKSk6Oeff3b/vGfPHm3atElRUVGqUqWKBg8erOeee061a9dW9erVNXr0aMXExHjlISGfTHBy+8YdDocyMjIKNxgAAIo5q0YgXr9+vdq2bev+ObNzct++fZWYmKgRI0bo5MmTuv/++3Xs2DFdd911WrJkiUqWLFngfdtyHJziwJtjDgB2EbfpZatDAIqdoHI1Cn0fX1bo6bVtXb//I69tqzDRBwcAANiOTzZRXejkyZNavXq1fvvtN509e9Zj3qBBgyyKCgCA4sHId74k01t8PsHZuHGjbr75Zp06dUonT55UVFSUDh8+rNDQUEVHR5PgAAD8nssPO6P4fBPVY489pvj4eB09elQhISFau3atfv31VzVt2lQTJ060OjwAAGABn09wNm3apKFDh6pEiRIKCAhQamqqKleurAkTJuhf//qX1eEBAGA5lxxee/kKn09wgoKCVKLEubcRHR2t3377TdK5L+z6/fffrQwNAIBiwcjhtZev8Pk+OI0bN9Z3332n2rVrq3Xr1nrqqad0+PBhvfPOO2rYsKHV4QEAAAv4fAXn+eefV8WKFSVJ48aNU5kyZTRw4EAdOnRIb775psXRAQBgPZcXX77C5ys4zZo1c/8/OjpaS5YssTAaAACKH19qWvIWn09wAADAxflS5cVbfD7BqV69uhyOnDPTX375pQijAQAAxYHPJziDBw/2+DktLU0bN27UkiVLNHz4cGuCAgCgGKGC44MeffTRbKe/+uqrWr9+fRFHAwBA8eOPfXB8/imqnHTq1Ekff/yx1WEAAAAL+HwFJycfffSRoqKirA4DAADLufyvgOP7CU7jxo09OhkbY7R//34dOnRIr732moWRAQBQPPjSVyx4i88nON26dfNIcEqUKKHLLrtMbdq0Ub169SyMDAAAWMXnE5wxY8ZYHQIAAMWasToAC/h8J+OAgAAdPHgwy/S///5bAQEBFkQEAEDx4o9f1eDzCY4x2eelqampCg4OLuJoAABAceCzTVRTpkyRJDkcDs2cOVOlSpVyz8vIyFBSUhJ9cAAAkOS6yIj/duWzCc4rr7wi6VwF5/XXX/dojgoODla1atX0+uuvWxUeAADFhj/2wfHZBGfPnj2SpLZt22r+/PkqU6aMxREBAFA8+VLfGW/x2QQn06pVq6wOAQAAFDM+38m4R48eGj9+fJbpEyZM0G233WZBRAAAFC8uh/devsLnE5ykpCTdfPPNWaZ36tRJSUlJFkQEAEDx4pLDay9f4fMJTkpKSraPgwcFBen48eMWRAQAAKzm8wlObGys5s2bl2X6+++/rwYNGlgQEQAAxYvx4stX+Hwn49GjR+vWW2/V7t271a5dO0nSihUrNHfuXH344YcWRwcAgPV8qe+Mt/h8ghMfH6+FCxfq+eef10cffaSQkBA1atRIy5cvV+vWra0ODwAAWMDnExxJ6ty5szp37pxl+o8//qiGDRtaEBEAAMWHP46D4/N9cC504sQJvfnmm2rRooXi4uKsDgcAAMv5Yx8c2yQ4SUlJ6tOnjypWrKiJEyeqXbt2Wrt2rdVhAQAAC/h0E9X+/fuVmJioWbNm6fjx47r99tuVmpqqhQsX8gQVAAD/zx87GftsBSc+Pl5169bV5s2bNWnSJP3111+aOnWq1WEBAFDsuLz48hU+W8FZvHixBg0apIEDB6p27dpWhwMAQLHlS4mJt/hsBWfNmjU6ceKEmjZtqquuukrTpk3T4cOHrQ4LAAAUAz6b4Fx99dWaMWOG9u3bpwceeEDvv/++YmJi5HK5tGzZMp04ccLqEAEAKBaMw3svX+GzCU6msLAw9e/fX2vWrNGWLVs0dOhQvfDCC4qOjlbXrl2tDg8AAMv5Yx8cn09wzle3bl1NmDBBf/zxh+bOnWt1OAAAwCI+28n4YgICAtS9e3d1797d6lAAALCcL1VevMWWCQ4AAPgfXxqB2Fts1UQFAAAgUcEBAMD2/HEkYxIcAABszh/74NBEBQAAbIcKDgAANuePFRwSHAAAbM4fn6IiwQEAwOb8sZMxfXAAAIDtUMEBAMDm6IMDAABsxx/74NBEBQAAbIcKDgAANufywxoOCQ4AADbnj31waKICAAC2QwUHAACb878GKhIcAABsjyYqAAAAG6CCAwCAzfnjVzWQ4AAAYHM8Jg4AAGzH/9Ib+uAAAAAbIsEBAMDmXF585VZGRoZGjx6t6tWrKyQkRDVr1tSzzz4rY4qmnkQTFQAANmdFH5zx48dr+vTpevvtt3XFFVdo/fr1uvfeexUREaFBgwYV+v5JcAAAQK6lpqYqNTXVY5rT6ZTT6fSY9vXXX6tbt27q3LmzJKlatWqaO3eu1q1bVyRx0kQFAIDNGS++EhISFBER4fFKSEjIss9rr71WK1as0M6dOyVJP/zwg9asWaNOnToV6nvNRAUHAACb8+ZIxqNGjdKQIUM8pl1YvZGkxx9/XMePH1e9evUUEBCgjIwMjRs3TnfffbcXo8kZCQ4AAMi17JqjsvPBBx9ozpw5eu+993TFFVdo06ZNGjx4sGJiYtS3b99Cj5MEBwAAm7Oik/Hw4cP1+OOP684775QkxcbG6tdff1VCQgIJDgAAKDgrBvo7deqUSpTw7OobEBAgl6tovvqTBAcAAHhdfHy8xo0bpypVquiKK67Qxo0b9fLLL6t///5Fsn8SHAAAbK5oaiaepk6dqtGjR+vBBx/UwYMHFRMTowceeEBPPfVUkeyfBAcAAJszFjRSlS5dWpMmTdKkSZOKfN8SCQ4AALZnRQXHagz0BwAAbIcKDgAANmfFY+JWI8EBAMDm/C+9oYkKAADYEBUcAABszh+bqKjgnKdNmzYaPHhwlumJiYmKjIws8niQe6WuaqBa/35Cjda/pWZ/LFTkTVdlWSZmWC81+v4tNfl5nurMHStn9YoWRAoUnfWbtuihEU+rbde71bBlJ61I+tpj/hPPvaSGLTt5vB4Y8qRF0aIwubz48hVUcGALJUJL6tTWPTo8b7lqzRyVZX6FB29R9L1dtPexyUr9/YBiht2lOu8+rR/bPSKTmmZBxEDhO336jOrWqqFbOt+owf96Lttlrru6mZ7712Pun4OCgooqPKBQkeDAFo6v2qDjqzbkOD96QLz2TflAx/67TpK0d/BkxW1MVORNV+noJ2uKKkygSF1/TXNdf03ziy4THBSkcmWjiigiWMWKgf6sRhMVbC+4SnkFl4/S8S83u6dlnDilk5t2qlTTuhZGBljvu42b1arznepy53165sWpOpZ83OqQUAhookK+pKamKjU11WPaWZOhYEeARRHhfEGXRUqS0g8f85iedihZQZeVKfqAgGKi5dVN1aF1S1WKKa/f/9ynyW8k6p9DR2vOGy8rIID7F3wbFRwvSEhIUEREhMcr8cQuq8MCgIu6uUMbtb3+atWpWV3tW12rVyeM1Y/bduq7jZsvvTJ8ivHiP19BgnOe8PBwJScnZ5l+7NgxRURE5LjeqFGjlJyc7PHqV7p2YYaKPEg7dEySFFgu0mN60GURSjt0tOgDAoqpypUqqkxkuH77Y5/VocDL/LGJigTnPHXr1tWGDVk7qm7YsEF16tTJcT2n06nw8HCPF81TxcfZ3w7o7IEjCr+ukXtaiVIhCruyjlK+32FhZEDxsv/gIR1LPqHL6HRsOy5jvPbyFfTBOc/AgQM1bdo0DRo0SPfdd5+cTqc+//xzzZ07V59++qnV4eEiSoSWlLPa/8a1cVaOVkiD6so4dkJn/zqsg7M+VcVBt+nMnr909veDihl2l9IOHNGxpd9aGDVQuE6dOq3f/vjL/fOffx3Q9p27FRFeWhHhpfXaW3N0Q5uWKlc2Sr//+Zdefu0tVbk8Ri2vamJh1IB3kOCcp0aNGkpKStITTzyhDh066OzZs6pXr54+/PBDdezY0erwcBFhcbVU98P/jfNRecwASdLhD1Zq75Ap2v/aApUILalq4x9UQHiYUr7bpp33PMMYOLC1H7fvUv9HRrp/njD1TUlSt04dNHr4w9q5e48+Wbxcx1NOKrpclK5t0UQP/6OPgoODrQoZhcR36i7e4zDGh+pNPmT95d2tDgEoduI2vWx1CECxE1SuRqHv466qt3htW+/9usBr2ypM9MEBAAC2QxMVAAA250uPd3sLCQ4AADbnS493ewtNVAAAwHao4AAAYHMumqgAAIDd+GMfHJqoAACA7VDBAQDA5vyxkzEJDgAANuePY/qS4AAAYHP+2MmYPjgAAMB2qOAAAGBz9MEBAAC2w2PiAAAANkAFBwAAm/PHTsYkOAAA2Jw/PiZOExUAALAdKjgAANgcT1EBAADb4SkqAAAAG6CCAwCAzfEUFQAAsB1/fIqKBAcAAJvzxwoOfXAAAIDtUMEBAMDm/PEpKhIcAABszuWHfXBoogIAALZDBQcAAJvzv/oNCQ4AALbHU1QAAAA2QAUHAACb88cKDgkOAAA2548jGdNEBQAAbIcKDgAANkcTFQAAsB1GMgYAALZDHxwAAAAboIIDAIDN0QcHAADYDk1UAAAANkAFBwAAm6OJCgAA2I4/PiZOExUAALAdKjgAANicyw87GZPgAABgczRRAQAAeMmff/6pe+65R2XLllVISIhiY2O1fv36Itk3FRwAAGzOiiaqo0ePqmXLlmrbtq0WL16syy67TLt27VKZMmWKZP8kOAAA2JwVTVTjx49X5cqV9e9//9s9rXr16kW2f5qoAACwOZcxXnulpqbq+PHjHq/U1NQs+/zkk0/UrFkz3XbbbYqOjlbjxo01Y8aMInvPJDgAACDXEhISFBER4fFKSEjIstwvv/yi6dOnq3bt2lq6dKkGDhyoQYMG6e233y6SOB3GH7+gogisv7y71SEAxU7cppetDgEodoLK1Sj0fdS+rKnXtvXjH19nqdg4nU45nU6PacHBwWrWrJm+/vpr97RBgwbpu+++0zfffOO1eHJCHxwAAGzOm52Ms0tmslOxYkU1aNDAY1r9+vX18ccfey2Wi6GJCgAAeF3Lli21Y8cOj2k7d+5U1apVi2T/VHAAALA5K56ieuyxx3Tttdfq+eef1+23365169bpzTff1Jtvvlkk+yfBAQDA5oxxFfk+mzdvrgULFmjUqFF65plnVL16dU2aNEl33313keyfBAcAABSKLl26qEuXLpbsmwQHAACbc/nhd1GR4AAAYHP+OCIMT1EBAADboYIDAIDN0UQFAABsxx+bqEhwAACwOW+OZOwr6IMDAABshwoOAAA2Z8VIxlYjwQEAwOb8sQ8OTVQAAMB2qOAAAGBzPCYOAABshyYqAAAAG6CCAwCAzfnjODgkOAAA2BxNVAAAADZABQcAAJvjKSoAAGA7/thERYIDAIDN+WMnY/rgAAAA26GCAwCAzfFlmwAAwHZoogIAALABKjgAANgcT1EBAADb8cc+ODRRAQAA26GCAwCAzdFEBQAAbMcfExyaqAAAgO1QwQEAwOb8r34jOYw/1q3gN1JTU5WQkKBRo0bJ6XRaHQ5QLHBdwB+Q4MDWjh8/roiICCUnJys8PNzqcIBigesC/oA+OAAAwHZIcAAAgO2Q4AAAANshwYGtOZ1OPf3003SkBM7DdQF/QCdjAABgO1RwAACA7ZDgAAAA2yHBAQAAtkOCAwAAbIcEBwAA2A4JDgAAsB2+TRy24nK5lJiYqPnz52vv3r1yOByqXr26evbsqd69e8vhcFgdIgCgCDAODmzDGKP4+HgtWrRIcXFxqlevnowx2rZtm7Zs2aKuXbtq4cKFVocJFLkyZcpkm9xHRESoTp06GjZsmG644QYLIgMKDxUc2EZiYqKSkpK0YsUKtW3b1mPeypUr1b17d82ePVt9+vSxKELAGpMmTcp2+rFjx/T999+rS5cu+uijjxQfH1+0gQGFiAoObOPGG29Uu3bt9Pjjj2c7//nnn9fq1au1dOnSIo4MKN5efvllffTRR/r666+tDgXwGjoZwzY2b96sjh075ji/U6dO+uGHH4owIsA3dOnSRdu3b7c6DMCrSHBgG0eOHFH58uVznF++fHkdPXq0CCMCfENqaqqCg4OtDgPwKhIc2EZGRoYCA3PuVhYQEKD09PQijAjwDbNmzdKVV15pdRiAV9HJGLZhjFG/fv3kdDqznZ+amlrEEQHFw5AhQ7KdnpycrA0bNmjnzp1KSkoq4qiAwkWCA9vo27fvJZfhCSr4o40bN2Y7PTw8XDfccIPmz5+v6tWrF3FUQOHiKSoAAGA79MEBAAC2Q4IDAABshwQHAADYDgkOAACwHRIcwE/169dP3bt3d//cpk0bDR48uMjj+OKLL+RwOHTs2LEi3/eFxwCAfZDgAMVIv3795HA45HA4FBwcrFq1aumZZ54pkgEK58+fr2effTZXy1qVlCQkJCggIEAvvvhintbbu3evHA6HNm3a5DF98uTJSkxM9F6AAIoNEhygmOnYsaP27dunXbt2aejQoRozZkyOv9DPnj3rtf1GRUWpdOnSXtteYXjrrbc0YsQIvfXWW17ZXkREhCIjI72yLQDFCwkOUMw4nU5VqFBBVatW1cCBA9WhQwd98sknkv7XpDJu3DjFxMSobt26kqTff/9dt99+uyIjIxUVFaVu3bpp79697m1mZGRoyJAhioyMVNmyZTVixAhdOATWhU1UqampGjlypCpXriyn06latWpp1qxZ2rt3r9q2bStJKlOmjBwOh/r16ydJcrlcSkhIUPXq1RUSEqK4uDh99NFHHvtZtGiR6tSpo5CQELVt29YjzotZvXq1Tp8+rWeeeUbHjx/P8s3XLpdLEyZMUK1ateR0OlWlShWNGzdOktyD2DVu3FgOh0Nt2rTxOJ7nv+dBgwYpOjpaJUuW1HXXXafvvvvOPT+zcrVixQo1a9ZMoaGhuvbaa7Vjx45cvQcARYcEByjmQkJCPCo1K1as0I4dO7Rs2TJ99tlnSktL00033aTSpUvryy+/1FdffaVSpUqpY8eO7vVeeuklJSYm6q233tKaNWt05MgRLViw4KL77dOnj+bOnaspU6Zo27ZteuONN1SqVClVrlxZH3/8sSRpx44d2rdvnyZPnizpXBPS7Nmz9frrr+unn37SY489pnvuuUerV6+WdC4Ru/XWWxUfH69Nmzbpvvvu0+OPP56r4zBr1iz16tVLQUFB6tWrl2bNmuUxf9SoUXrhhRc0evRobd26Ve+99577y1fXrVsnSVq+fLn27dun+fPnZ7uPESNG6OOPP9bbb7+tDRs2qFatWrrpppt05MgRj+WeeOIJvfTSS1q/fr0CAwPVv3//XL0HAEXIACg2+vbta7p162aMMcblcplly5YZp9Nphg0b5p5fvnx5k5qa6l7nnXfeMXXr1jUul8s9LTU11YSEhJilS5caY4ypWLGimTBhgnt+Wlqaufzyy937MsaY1q1bm0cffdQYY8yOHTuMJLNs2bJs41y1apWRZI4ePeqedubMGRMaGmq+/vprj2UHDBhgevXqZYwxZtSoUaZBgwYe80eOHJllWxdKTk42ISEhZtOmTcYYYzZu3GhKlSplTpw4YYwx5vjx48bpdJoZM2Zku/6ePXuMJLNx40aP6ecf75SUFBMUFGTmzJnjnn/27FkTExPjPnaZ73v58uXuZT7//HMjyZw+fTrH+AEUPb6LCihmPvvsM5UqVUppaWlyuVy66667NGbMGPf82NhYBQcHu3/+4Ycf9PPPP2fpP3PmzBnt3r1bycnJ2rdvn6666ir3vMDAQDVr1ixLM1WmTZs2KSAgQK1bt8513D///LNOnTqlG264wWP62bNn1bhxY0nStm3bPOKQpGuuueaS2547d65q1qypuLg4SdKVV16pqlWrat68eRowYIC2bdum1NRUtW/fPtfxXmj37t1KS0tTy5Yt3dOCgoLUokULbdu2zWPZRo0auf9fsWJFSdLBgwdVpUqVfO8fgHeR4ADFTNu2bTV9+nQFBwcrJiZGgYGel2lYWJjHzykpKWratKnmzJmTZVuXXXZZvmIICQnJ8zopKSmSpM8//1yVKlXymJfTN7zn1qxZs/TTTz95HAuXy6W33npLAwYMyFe8BREUFOT+v8PhcMcDoPggwQGKmbCwMNWqVSvXyzdp0kTz5s1TdHS0wsPDs12mYsWK+vbbb9WqVStJUnp6ur7//ns1adIk2+VjY2Plcrm0evVqdejQIcv8zApSRkaGe1qDBg3kdDr122+/5Vj5qV+/vrvDdKa1a9de9P1t2bJF69ev1xdffKGoqCj39CNHjqhNmzbavn27ateurZCQEK1YsUL33XdfruK9UM2aNRUcHKyvvvpKVatWlSSlpaXpu+++s2R8IAAFQydjwMfdfffdKleunLp166Yvv/xSe/bs0RdffKFBgwbpjz/+kCQ9+uijeuGFF7Rw4UJt375dDz744EXHsKlWrZr69u2r/v37a+HChe5tfvDBB5KkqlWryuFw6LPPPtOhQ4eUkpKi0qVLa9iwYXrsscf09ttva/fu3dqwYYOmTp2qt99+W5L0z3/+U7t27dLw4cO1Y8cOvffee5cch2bWrFlq0aKFWrVqpYYNG7pfrVq1UvPmzTVr1iyVLFlSI0eO1IgRIzR79mzt3r1ba9eudXdEjo6OVkhIiJYsWaIDBw4oOTk5y37CwsI0cOBADR8+XEuWLNHWrVv1j3/8Q6dOndKAAQPy8ckAsBIJDuDjQkNDlZSUpCpVqujWW29V/fr1NWDAAJ05c8Zd0Rk6dKh69+6tvn376pprrlHp0qV1yy23XHS706dPV8+ePfXggw+qXr16+sc//qGTJ09KkipVqqSxY8fq8ccfV/ny5fXwww9Lkp599lmNHj1aCQkJql+/vjp27KjPP//c/Zh2lSpV9PHHH2vhwoWKi4vT66+/rueffz7HGM6ePat3331XPXr0yHZ+jx49NHv2bKWlpWn06NEaOnSonnrqKdWvX1933HGHDh48KOlcn6MpU6bojTfeUExMjLp165bt9l544QX16NFDvXv3VpMmTfTzzz9r6dKlKlOmzEWPFYDix2Fy6mUIAADgo6jgAAAA2yHBAQAAtkOCAwAAbIcEBwAA2A4JDgAAsB0SHAAAYDskOAAAwHZIcAAAgO2Q4AAAANshwQEAALZDggMAAGzn/wBNTbdvVqfV+gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data analysis"
      ],
      "metadata": {
        "id": "PxjFGEC4Qcep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "most movement: diff2"
      ],
      "metadata": {
        "id": "6_zRMEp4OS1t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZx1rXrXZLce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njF6ZSYraEzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_with_result = get_dataset_with_season()"
      ],
      "metadata": {
        "id": "PQxOk1tVKJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "al_dataset = get_stat_percent_database(dataset_with_result.copy())\n",
        "al_dataset = get_diff_database(al_dataset)\n",
        "al_dataset = get_odds_percent_database(al_dataset)\n",
        "al_dataset = get_odds_percent_database_closing(al_dataset)\n",
        "al_dataset = get_dir_database(al_dataset)\n",
        "al_dataset[\"MAX_DIFF\"] = get_max_diff(al_dataset)\n",
        "al_dataset = get_odds_rankings(al_dataset, True)\n",
        "al_dataset = get_odds_rankings(al_dataset, False)\n",
        "al_dataset[\"OP_SUM\"] = al_dataset[\"OP1_AVG\"] + al_dataset[\"OPX_AVG\"] + al_dataset[\"OP2_AVG\"]\n",
        "al_dataset[\"CP_SUM\"] = al_dataset[\"CP1_AVG\"] + al_dataset[\"CPX_AVG\"] + al_dataset[\"CP2_AVG\"]\n",
        "al_test = al_dataset[(al_dataset[\"season\"] == \"2023/2024\") | (al_dataset[\"season\"] == \"2022/2023\")]\n",
        "al_train = al_dataset.drop(index=al_test.index)\n",
        "al_train_lm = al_train.drop(index=al_train[al_train.games < 4].index)\n",
        "al_train"
      ],
      "metadata": {
        "id": "QXoLq8nxQjm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "0a8e2d27-6158-4252-f71a-53007493828f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           home_team      away_team  games         date     season result  \\\n",
              "0             Malaga        Sevilla      0  21 Aug 2015  2015/2016      D   \n",
              "1           Espanyol         Getafe      0  22 Aug 2015  2015/2016      H   \n",
              "2     Dep. La Coruna  Real Sociedad      0  22 Aug 2015  2015/2016      D   \n",
              "3        Atl. Madrid     Las Palmas      0  22 Aug 2015  2015/2016      H   \n",
              "4     Rayo Vallecano       Valencia      0  22 Aug 2015  2015/2016      D   \n",
              "...              ...            ...    ...          ...        ...    ...   \n",
              "2655   Real Sociedad    Atl. Madrid     37  22 May 2022  2021/2022      A   \n",
              "2656         Osasuna       Mallorca     37  22 May 2022  2021/2022      A   \n",
              "2657           Elche         Getafe     37  22 May 2022  2021/2022      H   \n",
              "2658      Granada CF       Espanyol     37  22 May 2022  2021/2022      D   \n",
              "2659       Barcelona     Villarreal     37  22 May 2022  2021/2022      A   \n",
              "\n",
              "      OP1_AVG  OPX_AVG  OP2_AVG  CP1_AVG  CPX_AVG  CP2_AVG  home_wins_rate  \\\n",
              "0       2.790    3.177    2.519    3.217    3.414    2.237        0.000000   \n",
              "1       1.884    3.356    4.140    1.994    3.245    4.134        0.000000   \n",
              "2       2.721    3.157    2.596    2.386    3.239    3.098        0.000000   \n",
              "3       1.240    5.613   12.405    1.234    5.849   15.198        0.000000   \n",
              "4       4.238    3.618    1.808    2.945    3.485    2.379        0.000000   \n",
              "...       ...      ...      ...      ...      ...      ...             ...   \n",
              "2655    2.453    3.315    2.853    2.697    3.144    2.824        0.459459   \n",
              "2656    3.499    3.526    2.177    2.997    3.238    2.504        0.324324   \n",
              "2657    3.129    2.929    2.513    3.130    2.933    2.603        0.270270   \n",
              "2658    1.754    3.863    4.736    1.445    4.722    7.145        0.216216   \n",
              "2659    2.007    4.020    3.747    1.980    3.922    3.546        0.567568   \n",
              "\n",
              "      home_tie_rate  home_loss_rate  away_wins_rate  away_tie_rate  \\\n",
              "0          0.000000        0.000000        0.000000       0.000000   \n",
              "1          0.000000        0.000000        0.000000       0.000000   \n",
              "2          0.000000        0.000000        0.000000       0.000000   \n",
              "3          0.000000        0.000000        0.000000       0.000000   \n",
              "4          0.000000        0.000000        0.000000       0.000000   \n",
              "...             ...             ...             ...            ...   \n",
              "2655       0.297297        0.243243        0.540541       0.216216   \n",
              "2656       0.297297        0.378378        0.243243       0.243243   \n",
              "2657       0.243243        0.486486        0.216216       0.405405   \n",
              "2658       0.351351        0.432432        0.270270       0.297297   \n",
              "2659       0.270270        0.162162        0.405405       0.297297   \n",
              "\n",
              "      away_loss_rate  DIFF1  DIFFX  DIFF2  OP1_RATE  OPX_RATE  OP2_RATE  \\\n",
              "0           0.000000  0.427  0.237 -0.282  0.328777  0.374381  0.296842   \n",
              "1           0.000000  0.110 -0.111 -0.006  0.200853  0.357783  0.441365   \n",
              "2           0.000000 -0.335  0.082  0.502  0.321100  0.372551  0.306349   \n",
              "3           0.000000 -0.006  0.236  2.793  0.064389  0.291463  0.644148   \n",
              "4           0.000000 -1.293 -0.133  0.571  0.438535  0.374379  0.187086   \n",
              "...              ...    ...    ...    ...       ...       ...       ...   \n",
              "2655        0.243243  0.244 -0.171 -0.029  0.284538  0.384526  0.330936   \n",
              "2656        0.513514 -0.502 -0.288  0.327  0.380243  0.383178  0.236579   \n",
              "2657        0.378378  0.001  0.004  0.090  0.365068  0.341734  0.293198   \n",
              "2658        0.432432 -0.309  0.859  2.409  0.169419  0.373129  0.457452   \n",
              "2659        0.297297 -0.027 -0.098 -0.201  0.205341  0.411295  0.383364   \n",
              "\n",
              "      CP1_RATE  CPX_RATE  CP2_RATE  DIR1  DIRX  DIR2 MAX_DIFF OP_MAX_ODD  \\\n",
              "0     0.362765  0.384980  0.252255     1     1     0        A          D   \n",
              "1     0.212739  0.346207  0.441054     1     0     0        D          A   \n",
              "2     0.273530  0.371317  0.355153     0     1     1        H          D   \n",
              "3     0.055384  0.262511  0.682106     0     1     1        H          A   \n",
              "4     0.334317  0.395618  0.270065     0     0     1        H          H   \n",
              "...        ...       ...       ...   ...   ...   ...      ...        ...   \n",
              "2655  0.311252  0.362839  0.325909     1     0     0        D          D   \n",
              "2656  0.342945  0.370523  0.286532     0     0     1        H          D   \n",
              "2657  0.361182  0.338449  0.300369     1     1     1        H          H   \n",
              "2658  0.108549  0.354718  0.536734     0     1     1        H          A   \n",
              "2659  0.209568  0.415114  0.375318     0     0     0        A          D   \n",
              "\n",
              "     OP_MID_ODD OP_MIN_ODD CP_MAX_ODD CP_MID_ODD CP_MIN_ODD  OP_SUM  CP_SUM  \n",
              "0             H          A          D          H          A   8.486   8.868  \n",
              "1             D          H          A          D          H   9.380   9.373  \n",
              "2             H          A          D          A          H   8.474   8.723  \n",
              "3             D          H          A          D          H  19.258  22.281  \n",
              "4             D          A          D          H          A   9.664   8.809  \n",
              "...         ...        ...        ...        ...        ...     ...     ...  \n",
              "2655          A          H          D          A          H   8.621   8.665  \n",
              "2656          H          A          D          H          A   9.202   8.739  \n",
              "2657          D          A          H          D          A   8.571   8.666  \n",
              "2658          D          H          A          D          H  10.353  13.312  \n",
              "2659          A          H          D          A          H   9.774   9.448  \n",
              "\n",
              "[2660 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fbb13ec-7003-4499-a855-0e776626ac66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>games</th>\n",
              "      <th>date</th>\n",
              "      <th>season</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>MAX_DIFF</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>CP_MAX_ODD</th>\n",
              "      <th>CP_MID_ODD</th>\n",
              "      <th>CP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Malaga</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>0</td>\n",
              "      <td>21 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.790</td>\n",
              "      <td>3.177</td>\n",
              "      <td>2.519</td>\n",
              "      <td>3.217</td>\n",
              "      <td>3.414</td>\n",
              "      <td>2.237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.427</td>\n",
              "      <td>0.237</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>0.328777</td>\n",
              "      <td>0.374381</td>\n",
              "      <td>0.296842</td>\n",
              "      <td>0.362765</td>\n",
              "      <td>0.384980</td>\n",
              "      <td>0.252255</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.486</td>\n",
              "      <td>8.868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Espanyol</td>\n",
              "      <td>Getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>1.884</td>\n",
              "      <td>3.356</td>\n",
              "      <td>4.140</td>\n",
              "      <td>1.994</td>\n",
              "      <td>3.245</td>\n",
              "      <td>4.134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110</td>\n",
              "      <td>-0.111</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.200853</td>\n",
              "      <td>0.357783</td>\n",
              "      <td>0.441365</td>\n",
              "      <td>0.212739</td>\n",
              "      <td>0.346207</td>\n",
              "      <td>0.441054</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>9.380</td>\n",
              "      <td>9.373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dep. La Coruna</td>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.721</td>\n",
              "      <td>3.157</td>\n",
              "      <td>2.596</td>\n",
              "      <td>2.386</td>\n",
              "      <td>3.239</td>\n",
              "      <td>3.098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.335</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.321100</td>\n",
              "      <td>0.372551</td>\n",
              "      <td>0.306349</td>\n",
              "      <td>0.273530</td>\n",
              "      <td>0.371317</td>\n",
              "      <td>0.355153</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.474</td>\n",
              "      <td>8.723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>Las Palmas</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>1.240</td>\n",
              "      <td>5.613</td>\n",
              "      <td>12.405</td>\n",
              "      <td>1.234</td>\n",
              "      <td>5.849</td>\n",
              "      <td>15.198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.236</td>\n",
              "      <td>2.793</td>\n",
              "      <td>0.064389</td>\n",
              "      <td>0.291463</td>\n",
              "      <td>0.644148</td>\n",
              "      <td>0.055384</td>\n",
              "      <td>0.262511</td>\n",
              "      <td>0.682106</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>19.258</td>\n",
              "      <td>22.281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rayo Vallecano</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>4.238</td>\n",
              "      <td>3.618</td>\n",
              "      <td>1.808</td>\n",
              "      <td>2.945</td>\n",
              "      <td>3.485</td>\n",
              "      <td>2.379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.293</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.438535</td>\n",
              "      <td>0.374379</td>\n",
              "      <td>0.187086</td>\n",
              "      <td>0.334317</td>\n",
              "      <td>0.395618</td>\n",
              "      <td>0.270065</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.664</td>\n",
              "      <td>8.809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2655</th>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>37</td>\n",
              "      <td>22 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>A</td>\n",
              "      <td>2.453</td>\n",
              "      <td>3.315</td>\n",
              "      <td>2.853</td>\n",
              "      <td>2.697</td>\n",
              "      <td>3.144</td>\n",
              "      <td>2.824</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.244</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>0.284538</td>\n",
              "      <td>0.384526</td>\n",
              "      <td>0.330936</td>\n",
              "      <td>0.311252</td>\n",
              "      <td>0.362839</td>\n",
              "      <td>0.325909</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.621</td>\n",
              "      <td>8.665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>Osasuna</td>\n",
              "      <td>Mallorca</td>\n",
              "      <td>37</td>\n",
              "      <td>22 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>A</td>\n",
              "      <td>3.499</td>\n",
              "      <td>3.526</td>\n",
              "      <td>2.177</td>\n",
              "      <td>2.997</td>\n",
              "      <td>3.238</td>\n",
              "      <td>2.504</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.288</td>\n",
              "      <td>0.327</td>\n",
              "      <td>0.380243</td>\n",
              "      <td>0.383178</td>\n",
              "      <td>0.236579</td>\n",
              "      <td>0.342945</td>\n",
              "      <td>0.370523</td>\n",
              "      <td>0.286532</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.202</td>\n",
              "      <td>8.739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2657</th>\n",
              "      <td>Elche</td>\n",
              "      <td>Getafe</td>\n",
              "      <td>37</td>\n",
              "      <td>22 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>H</td>\n",
              "      <td>3.129</td>\n",
              "      <td>2.929</td>\n",
              "      <td>2.513</td>\n",
              "      <td>3.130</td>\n",
              "      <td>2.933</td>\n",
              "      <td>2.603</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.365068</td>\n",
              "      <td>0.341734</td>\n",
              "      <td>0.293198</td>\n",
              "      <td>0.361182</td>\n",
              "      <td>0.338449</td>\n",
              "      <td>0.300369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>8.571</td>\n",
              "      <td>8.666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2658</th>\n",
              "      <td>Granada CF</td>\n",
              "      <td>Espanyol</td>\n",
              "      <td>37</td>\n",
              "      <td>22 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>D</td>\n",
              "      <td>1.754</td>\n",
              "      <td>3.863</td>\n",
              "      <td>4.736</td>\n",
              "      <td>1.445</td>\n",
              "      <td>4.722</td>\n",
              "      <td>7.145</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>-0.309</td>\n",
              "      <td>0.859</td>\n",
              "      <td>2.409</td>\n",
              "      <td>0.169419</td>\n",
              "      <td>0.373129</td>\n",
              "      <td>0.457452</td>\n",
              "      <td>0.108549</td>\n",
              "      <td>0.354718</td>\n",
              "      <td>0.536734</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>10.353</td>\n",
              "      <td>13.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2659</th>\n",
              "      <td>Barcelona</td>\n",
              "      <td>Villarreal</td>\n",
              "      <td>37</td>\n",
              "      <td>22 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>A</td>\n",
              "      <td>2.007</td>\n",
              "      <td>4.020</td>\n",
              "      <td>3.747</td>\n",
              "      <td>1.980</td>\n",
              "      <td>3.922</td>\n",
              "      <td>3.546</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.201</td>\n",
              "      <td>0.205341</td>\n",
              "      <td>0.411295</td>\n",
              "      <td>0.383364</td>\n",
              "      <td>0.209568</td>\n",
              "      <td>0.415114</td>\n",
              "      <td>0.375318</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>9.774</td>\n",
              "      <td>9.448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2660 rows × 39 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fbb13ec-7003-4499-a855-0e776626ac66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8fbb13ec-7003-4499-a855-0e776626ac66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8fbb13ec-7003-4499-a855-0e776626ac66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51959061-5145-476e-8f1a-5b29f824b684\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51959061-5145-476e-8f1a-5b29f824b684')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51959061-5145-476e-8f1a-5b29f824b684 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fe38e20e-e56d-4e61-ab55-c0bc2c4c350c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('al_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fe38e20e-e56d-4e61-ab55-c0bc2c4c350c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('al_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "al_train"
            }
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "ypJmSnBW7YZ9",
        "outputId": "fb221ba7-3de4-4d3e-a9e7-bff2d2440511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           home_team      away_team  games         date     season result  \\\n",
              "0             Malaga        Sevilla      0  21 Aug 2015  2015/2016      D   \n",
              "1           Espanyol         Getafe      0  22 Aug 2015  2015/2016      H   \n",
              "2     Dep. La Coruna  Real Sociedad      0  22 Aug 2015  2015/2016      D   \n",
              "3        Atl. Madrid     Las Palmas      0  22 Aug 2015  2015/2016      H   \n",
              "4     Rayo Vallecano       Valencia      0  22 Aug 2015  2015/2016      D   \n",
              "...              ...            ...    ...          ...        ...    ...   \n",
              "3415     Real Madrid          Betis     37  25 May 2024  2023/2024      D   \n",
              "3416         Sevilla      Barcelona     37  26 May 2024  2023/2024      A   \n",
              "3417          Getafe       Mallorca     37  26 May 2024  2023/2024      A   \n",
              "3418      Las Palmas         Alaves     37  26 May 2024  2023/2024      D   \n",
              "3419      Celta Vigo       Valencia     37  26 May 2024  2023/2024      D   \n",
              "\n",
              "      OP1_AVG  OPX_AVG  OP2_AVG  CP1_AVG  CPX_AVG  CP2_AVG  home_wins_rate  \\\n",
              "0       2.790    3.177    2.519    3.217    3.414    2.237        0.000000   \n",
              "1       1.884    3.356    4.140    1.994    3.245    4.134        0.000000   \n",
              "2       2.721    3.157    2.596    2.386    3.239    3.098        0.000000   \n",
              "3       1.240    5.613   12.405    1.234    5.849   15.198        0.000000   \n",
              "4       4.238    3.618    1.808    2.945    3.485    2.379        0.000000   \n",
              "...       ...      ...      ...      ...      ...      ...             ...   \n",
              "3415    1.314    5.714    7.809    1.219    7.152   11.637        0.783784   \n",
              "3416    3.341    3.939    1.954    4.479    4.244    1.692        0.270270   \n",
              "3417    2.250    3.304    3.124    2.330    3.162    3.284        0.270270   \n",
              "3418    2.313    3.401    2.947    2.342    3.450    3.020        0.270270   \n",
              "3419    1.861    3.684    3.929    1.932    3.670    3.847        0.270270   \n",
              "\n",
              "      home_tie_rate  home_loss_rate  away_wins_rate  away_tie_rate  \\\n",
              "0          0.000000        0.000000        0.000000       0.000000   \n",
              "1          0.000000        0.000000        0.000000       0.000000   \n",
              "2          0.000000        0.000000        0.000000       0.000000   \n",
              "3          0.000000        0.000000        0.000000       0.000000   \n",
              "4          0.000000        0.000000        0.000000       0.000000   \n",
              "...             ...             ...             ...            ...   \n",
              "3415       0.189189        0.027027        0.378378       0.378378   \n",
              "3416       0.297297        0.432432        0.675676       0.189189   \n",
              "3417       0.351351        0.378378        0.189189       0.432432   \n",
              "3418       0.243243        0.486486        0.324324       0.243243   \n",
              "3419       0.270270        0.459459        0.351351       0.243243   \n",
              "\n",
              "      away_loss_rate  DIFF1  DIFFX  DIFF2  OP1_RATE  OPX_RATE  OP2_RATE  \\\n",
              "0           0.000000  0.427  0.237 -0.282  0.328777  0.374381  0.296842   \n",
              "1           0.000000  0.110 -0.111 -0.006  0.200853  0.357783  0.441365   \n",
              "2           0.000000 -0.335  0.082  0.502  0.321100  0.372551  0.306349   \n",
              "3           0.000000 -0.006  0.236  2.793  0.064389  0.291463  0.644148   \n",
              "4           0.000000 -1.293 -0.133  0.571  0.438535  0.374379  0.187086   \n",
              "...              ...    ...    ...    ...       ...       ...       ...   \n",
              "3415        0.243243 -0.095  1.438  3.828  0.088562  0.385118  0.526319   \n",
              "3416        0.135135  1.138  0.305 -0.262  0.361815  0.426576  0.211609   \n",
              "3417        0.378378  0.080 -0.142  0.160  0.259276  0.380733  0.359991   \n",
              "3418        0.432432  0.029  0.049  0.073  0.267059  0.392680  0.340261   \n",
              "3419        0.405405  0.071 -0.014 -0.082  0.196432  0.388854  0.414714   \n",
              "\n",
              "      CP1_RATE  CPX_RATE  CP2_RATE  DIR1  DIRX  DIR2 MAX_DIFF OP_MAX_ODD  \\\n",
              "0     0.362765  0.384980  0.252255     1     1     0        A          D   \n",
              "1     0.212739  0.346207  0.441054     1     0     0        D          A   \n",
              "2     0.273530  0.371317  0.355153     0     1     1        H          D   \n",
              "3     0.055384  0.262511  0.682106     0     1     1        H          A   \n",
              "4     0.334317  0.395618  0.270065     0     0     1        H          H   \n",
              "...        ...       ...       ...   ...   ...   ...      ...        ...   \n",
              "3415  0.060926  0.357457  0.581617     0     1     1        H          A   \n",
              "3416  0.430053  0.407489  0.162458     1     1     0        A          D   \n",
              "3417  0.265497  0.360301  0.374202     1     0     1        D          D   \n",
              "3418  0.265774  0.391512  0.342714     1     1     1        H          D   \n",
              "3419  0.204466  0.388401  0.407133     1     0     0        A          A   \n",
              "\n",
              "     OP_MID_ODD OP_MIN_ODD CP_MAX_ODD CP_MID_ODD CP_MIN_ODD  OP_SUM  CP_SUM  \n",
              "0             H          A          D          H          A   8.486   8.868  \n",
              "1             D          H          A          D          H   9.380   9.373  \n",
              "2             H          A          D          A          H   8.474   8.723  \n",
              "3             D          H          A          D          H  19.258  22.281  \n",
              "4             D          A          D          H          A   9.664   8.809  \n",
              "...         ...        ...        ...        ...        ...     ...     ...  \n",
              "3415          D          H          A          D          H  14.837  20.008  \n",
              "3416          H          A          H          D          A   9.234  10.415  \n",
              "3417          A          H          A          D          H   8.678   8.776  \n",
              "3418          A          H          D          A          H   8.661   8.812  \n",
              "3419          D          H          A          D          H   9.474   9.449  \n",
              "\n",
              "[3420 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-978e23d7-dfbb-4e97-90e2-cedab7b12426\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>games</th>\n",
              "      <th>date</th>\n",
              "      <th>season</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>MAX_DIFF</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>CP_MAX_ODD</th>\n",
              "      <th>CP_MID_ODD</th>\n",
              "      <th>CP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Malaga</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>0</td>\n",
              "      <td>21 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.790</td>\n",
              "      <td>3.177</td>\n",
              "      <td>2.519</td>\n",
              "      <td>3.217</td>\n",
              "      <td>3.414</td>\n",
              "      <td>2.237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.427</td>\n",
              "      <td>0.237</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>0.328777</td>\n",
              "      <td>0.374381</td>\n",
              "      <td>0.296842</td>\n",
              "      <td>0.362765</td>\n",
              "      <td>0.384980</td>\n",
              "      <td>0.252255</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.486</td>\n",
              "      <td>8.868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Espanyol</td>\n",
              "      <td>Getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>1.884</td>\n",
              "      <td>3.356</td>\n",
              "      <td>4.140</td>\n",
              "      <td>1.994</td>\n",
              "      <td>3.245</td>\n",
              "      <td>4.134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110</td>\n",
              "      <td>-0.111</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.200853</td>\n",
              "      <td>0.357783</td>\n",
              "      <td>0.441365</td>\n",
              "      <td>0.212739</td>\n",
              "      <td>0.346207</td>\n",
              "      <td>0.441054</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>9.380</td>\n",
              "      <td>9.373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dep. La Coruna</td>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.721</td>\n",
              "      <td>3.157</td>\n",
              "      <td>2.596</td>\n",
              "      <td>2.386</td>\n",
              "      <td>3.239</td>\n",
              "      <td>3.098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.335</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.321100</td>\n",
              "      <td>0.372551</td>\n",
              "      <td>0.306349</td>\n",
              "      <td>0.273530</td>\n",
              "      <td>0.371317</td>\n",
              "      <td>0.355153</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.474</td>\n",
              "      <td>8.723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>Las Palmas</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>1.240</td>\n",
              "      <td>5.613</td>\n",
              "      <td>12.405</td>\n",
              "      <td>1.234</td>\n",
              "      <td>5.849</td>\n",
              "      <td>15.198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.236</td>\n",
              "      <td>2.793</td>\n",
              "      <td>0.064389</td>\n",
              "      <td>0.291463</td>\n",
              "      <td>0.644148</td>\n",
              "      <td>0.055384</td>\n",
              "      <td>0.262511</td>\n",
              "      <td>0.682106</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>19.258</td>\n",
              "      <td>22.281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rayo Vallecano</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>0</td>\n",
              "      <td>22 Aug 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>4.238</td>\n",
              "      <td>3.618</td>\n",
              "      <td>1.808</td>\n",
              "      <td>2.945</td>\n",
              "      <td>3.485</td>\n",
              "      <td>2.379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.293</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.438535</td>\n",
              "      <td>0.374379</td>\n",
              "      <td>0.187086</td>\n",
              "      <td>0.334317</td>\n",
              "      <td>0.395618</td>\n",
              "      <td>0.270065</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.664</td>\n",
              "      <td>8.809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Betis</td>\n",
              "      <td>37</td>\n",
              "      <td>25 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>D</td>\n",
              "      <td>1.314</td>\n",
              "      <td>5.714</td>\n",
              "      <td>7.809</td>\n",
              "      <td>1.219</td>\n",
              "      <td>7.152</td>\n",
              "      <td>11.637</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>1.438</td>\n",
              "      <td>3.828</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.385118</td>\n",
              "      <td>0.526319</td>\n",
              "      <td>0.060926</td>\n",
              "      <td>0.357457</td>\n",
              "      <td>0.581617</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>14.837</td>\n",
              "      <td>20.008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>Sevilla</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>A</td>\n",
              "      <td>3.341</td>\n",
              "      <td>3.939</td>\n",
              "      <td>1.954</td>\n",
              "      <td>4.479</td>\n",
              "      <td>4.244</td>\n",
              "      <td>1.692</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.138</td>\n",
              "      <td>0.305</td>\n",
              "      <td>-0.262</td>\n",
              "      <td>0.361815</td>\n",
              "      <td>0.426576</td>\n",
              "      <td>0.211609</td>\n",
              "      <td>0.430053</td>\n",
              "      <td>0.407489</td>\n",
              "      <td>0.162458</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>9.234</td>\n",
              "      <td>10.415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>Getafe</td>\n",
              "      <td>Mallorca</td>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>A</td>\n",
              "      <td>2.250</td>\n",
              "      <td>3.304</td>\n",
              "      <td>3.124</td>\n",
              "      <td>2.330</td>\n",
              "      <td>3.162</td>\n",
              "      <td>3.284</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.080</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.259276</td>\n",
              "      <td>0.380733</td>\n",
              "      <td>0.359991</td>\n",
              "      <td>0.265497</td>\n",
              "      <td>0.360301</td>\n",
              "      <td>0.374202</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>8.678</td>\n",
              "      <td>8.776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>Las Palmas</td>\n",
              "      <td>Alaves</td>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>D</td>\n",
              "      <td>2.313</td>\n",
              "      <td>3.401</td>\n",
              "      <td>2.947</td>\n",
              "      <td>2.342</td>\n",
              "      <td>3.450</td>\n",
              "      <td>3.020</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.073</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.392680</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>0.265774</td>\n",
              "      <td>0.391512</td>\n",
              "      <td>0.342714</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.661</td>\n",
              "      <td>8.812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3419</th>\n",
              "      <td>Celta Vigo</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>D</td>\n",
              "      <td>1.861</td>\n",
              "      <td>3.684</td>\n",
              "      <td>3.929</td>\n",
              "      <td>1.932</td>\n",
              "      <td>3.670</td>\n",
              "      <td>3.847</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.071</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.196432</td>\n",
              "      <td>0.388854</td>\n",
              "      <td>0.414714</td>\n",
              "      <td>0.204466</td>\n",
              "      <td>0.388401</td>\n",
              "      <td>0.407133</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>9.474</td>\n",
              "      <td>9.449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3420 rows × 39 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-978e23d7-dfbb-4e97-90e2-cedab7b12426')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-978e23d7-dfbb-4e97-90e2-cedab7b12426 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-978e23d7-dfbb-4e97-90e2-cedab7b12426');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8bf8cfda-8548-4193-a39b-8018d9b8ee47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bf8cfda-8548-4193-a39b-8018d9b8ee47')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8bf8cfda-8548-4193-a39b-8018d9b8ee47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a6deb894-2ae8-4b25-8cf3-c47e53e74346\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('al_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a6deb894-2ae8-4b25-8cf3-c47e53e74346 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('al_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "al_dataset"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "fl8KVwwd5G-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# op_odds = zip(al_dataset[\"OP_MAX_ODD\"], al_dataset[\"OP_MID_ODD\"], al_dataset[\"OP_MIN_ODD\"])\n",
        "# cp_odds = zip(al_dataset[\"CP_MAX_ODD\"], al_dataset[\"CP_MID_ODD\"], al_dataset[\"CP_MIN_ODD\"])\n",
        "no_change = al_dataset[al_dataset[\"OP_MAX_ODD\"] == al_dataset[\"CP_MAX_ODD\"]]\n",
        "no_change = no_change[no_change[\"OP_MID_ODD\"] == no_change[\"CP_MID_ODD\"]]\n",
        "no_change = no_change[no_change[\"OP_MIN_ODD\"] == no_change[\"CP_MIN_ODD\"]]\n",
        "print(f\"no change len {format(len(no_change)/len(al_dataset) * 100, '.3f')}% {len(no_change)}/{len(al_dataset)}%\")\n",
        "change_dataset = al_dataset.drop(index=no_change.index)\n",
        "change_dataset.describe()\n",
        "# print(no_change.describe())"
      ],
      "metadata": {
        "id": "jITDRrJRePVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "b6f4a189-dbf6-4e66-f8bf-b3be4872a0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change len 80.906% 2767/3420%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games     OP1_AVG     OPX_AVG     OP2_AVG     CP1_AVG     CPX_AVG  \\\n",
              "count  653.000000  653.000000  653.000000  653.000000  653.000000  653.000000   \n",
              "mean    18.549770    2.673859    3.276124    2.813077    2.763692    3.283118   \n",
              "std     11.283004    0.534516    0.235531    0.496217    0.624274    0.307018   \n",
              "min      0.000000    1.642000    2.798000    1.368000    1.335000    2.617000   \n",
              "25%      9.000000    2.347000    3.139000    2.490000    2.330000    3.102000   \n",
              "50%     18.000000    2.603000    3.235000    2.782000    2.658000    3.234000   \n",
              "75%     29.000000    2.890000    3.369000    3.121000    3.101000    3.410000   \n",
              "max     37.000000    8.520000    5.120000    5.134000    7.751000    6.015000   \n",
              "\n",
              "          CP2_AVG  home_wins_rate  home_tie_rate  home_loss_rate  \\\n",
              "count  653.000000      653.000000     653.000000      653.000000   \n",
              "mean     2.896738        0.277694       0.276823        0.418440   \n",
              "std      0.626248        0.170409       0.162676        0.191980   \n",
              "min      1.400000        0.000000       0.000000        0.000000   \n",
              "25%      2.442000        0.166667       0.192308        0.333333   \n",
              "50%      2.859000        0.272727       0.272727        0.428571   \n",
              "75%      3.282000        0.357143       0.351351        0.516129   \n",
              "max      7.763000        1.000000       1.000000        1.000000   \n",
              "\n",
              "       away_wins_rate  away_tie_rate  away_loss_rate       DIFF1       DIFFX  \\\n",
              "count      653.000000     653.000000      653.000000  653.000000  653.000000   \n",
              "mean         0.369235       0.282492        0.323379    0.089833    0.006994   \n",
              "std          0.197682       0.185818        0.192321    0.551165    0.187518   \n",
              "min          0.000000       0.000000        0.000000   -5.405001   -1.607000   \n",
              "25%          0.250000       0.185185        0.200000   -0.202000   -0.089000   \n",
              "50%          0.363636       0.263158        0.333333    0.069000   -0.005000   \n",
              "75%          0.500000       0.357143        0.432432    0.390000    0.076000   \n",
              "max          1.000000       2.000000        1.333333    4.139000    1.551000   \n",
              "\n",
              "            DIFF2    OP1_RATE    OPX_RATE    OP2_RATE    CP1_RATE    CPX_RATE  \\\n",
              "count  653.000000  653.000000  653.000000  653.000000  653.000000  653.000000   \n",
              "mean     0.083662    0.304943    0.373633    0.321424    0.309192    0.366754   \n",
              "std      0.491244    0.052519    0.015463    0.053954    0.063021    0.021376   \n",
              "min     -2.087000    0.156232    0.313941    0.091151    0.088335    0.297522   \n",
              "25%     -0.268000    0.270270    0.364896    0.289821    0.264874    0.354030   \n",
              "50%      0.060000    0.303524    0.372875    0.325802    0.306014    0.365704   \n",
              "75%      0.371000    0.337349    0.382542    0.360512    0.355576    0.379461   \n",
              "max      3.359000    0.567697    0.426576    0.480577    0.550620    0.436419   \n",
              "\n",
              "         CP2_RATE        DIR1        DIRX        DIR2      OP_SUM      CP_SUM  \n",
              "count  653.000000  653.000000  653.000000  653.000000  653.000000  653.000000  \n",
              "mean     0.324054    0.542113    0.462481    0.531394    8.763060    8.943548  \n",
              "std      0.063407    0.498605    0.498973    0.499396    0.416539    0.510368  \n",
              "min      0.099192    0.000000    0.000000    0.000000    8.438000    8.561000  \n",
              "25%      0.279152    0.000000    0.000000    0.000000    8.558000    8.684000  \n",
              "50%      0.329096    1.000000    0.000000    1.000000    8.634000    8.792000  \n",
              "75%      0.372093    1.000000    1.000000    1.000000    8.834000    9.027000  \n",
              "max      0.513664    1.000000    1.000000    1.000000   15.008000   15.113000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e6c11aa-3dff-49c1-9325-f87ea8686bff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "      <td>653.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>18.549770</td>\n",
              "      <td>2.673859</td>\n",
              "      <td>3.276124</td>\n",
              "      <td>2.813077</td>\n",
              "      <td>2.763692</td>\n",
              "      <td>3.283118</td>\n",
              "      <td>2.896738</td>\n",
              "      <td>0.277694</td>\n",
              "      <td>0.276823</td>\n",
              "      <td>0.418440</td>\n",
              "      <td>0.369235</td>\n",
              "      <td>0.282492</td>\n",
              "      <td>0.323379</td>\n",
              "      <td>0.089833</td>\n",
              "      <td>0.006994</td>\n",
              "      <td>0.083662</td>\n",
              "      <td>0.304943</td>\n",
              "      <td>0.373633</td>\n",
              "      <td>0.321424</td>\n",
              "      <td>0.309192</td>\n",
              "      <td>0.366754</td>\n",
              "      <td>0.324054</td>\n",
              "      <td>0.542113</td>\n",
              "      <td>0.462481</td>\n",
              "      <td>0.531394</td>\n",
              "      <td>8.763060</td>\n",
              "      <td>8.943548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.283004</td>\n",
              "      <td>0.534516</td>\n",
              "      <td>0.235531</td>\n",
              "      <td>0.496217</td>\n",
              "      <td>0.624274</td>\n",
              "      <td>0.307018</td>\n",
              "      <td>0.626248</td>\n",
              "      <td>0.170409</td>\n",
              "      <td>0.162676</td>\n",
              "      <td>0.191980</td>\n",
              "      <td>0.197682</td>\n",
              "      <td>0.185818</td>\n",
              "      <td>0.192321</td>\n",
              "      <td>0.551165</td>\n",
              "      <td>0.187518</td>\n",
              "      <td>0.491244</td>\n",
              "      <td>0.052519</td>\n",
              "      <td>0.015463</td>\n",
              "      <td>0.053954</td>\n",
              "      <td>0.063021</td>\n",
              "      <td>0.021376</td>\n",
              "      <td>0.063407</td>\n",
              "      <td>0.498605</td>\n",
              "      <td>0.498973</td>\n",
              "      <td>0.499396</td>\n",
              "      <td>0.416539</td>\n",
              "      <td>0.510368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.642000</td>\n",
              "      <td>2.798000</td>\n",
              "      <td>1.368000</td>\n",
              "      <td>1.335000</td>\n",
              "      <td>2.617000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.405001</td>\n",
              "      <td>-1.607000</td>\n",
              "      <td>-2.087000</td>\n",
              "      <td>0.156232</td>\n",
              "      <td>0.313941</td>\n",
              "      <td>0.091151</td>\n",
              "      <td>0.088335</td>\n",
              "      <td>0.297522</td>\n",
              "      <td>0.099192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.438000</td>\n",
              "      <td>8.561000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.347000</td>\n",
              "      <td>3.139000</td>\n",
              "      <td>2.490000</td>\n",
              "      <td>2.330000</td>\n",
              "      <td>3.102000</td>\n",
              "      <td>2.442000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.202000</td>\n",
              "      <td>-0.089000</td>\n",
              "      <td>-0.268000</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.364896</td>\n",
              "      <td>0.289821</td>\n",
              "      <td>0.264874</td>\n",
              "      <td>0.354030</td>\n",
              "      <td>0.279152</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.558000</td>\n",
              "      <td>8.684000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>2.603000</td>\n",
              "      <td>3.235000</td>\n",
              "      <td>2.782000</td>\n",
              "      <td>2.658000</td>\n",
              "      <td>3.234000</td>\n",
              "      <td>2.859000</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.069000</td>\n",
              "      <td>-0.005000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.303524</td>\n",
              "      <td>0.372875</td>\n",
              "      <td>0.325802</td>\n",
              "      <td>0.306014</td>\n",
              "      <td>0.365704</td>\n",
              "      <td>0.329096</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.634000</td>\n",
              "      <td>8.792000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>2.890000</td>\n",
              "      <td>3.369000</td>\n",
              "      <td>3.121000</td>\n",
              "      <td>3.101000</td>\n",
              "      <td>3.410000</td>\n",
              "      <td>3.282000</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>0.337349</td>\n",
              "      <td>0.382542</td>\n",
              "      <td>0.360512</td>\n",
              "      <td>0.355576</td>\n",
              "      <td>0.379461</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.834000</td>\n",
              "      <td>9.027000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>8.520000</td>\n",
              "      <td>5.120000</td>\n",
              "      <td>5.134000</td>\n",
              "      <td>7.751000</td>\n",
              "      <td>6.015000</td>\n",
              "      <td>7.763000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.139000</td>\n",
              "      <td>1.551000</td>\n",
              "      <td>3.359000</td>\n",
              "      <td>0.567697</td>\n",
              "      <td>0.426576</td>\n",
              "      <td>0.480577</td>\n",
              "      <td>0.550620</td>\n",
              "      <td>0.436419</td>\n",
              "      <td>0.513664</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.008000</td>\n",
              "      <td>15.113000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e6c11aa-3dff-49c1-9325-f87ea8686bff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e6c11aa-3dff-49c1-9325-f87ea8686bff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e6c11aa-3dff-49c1-9325-f87ea8686bff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93c3840c-076c-4e13-84d5-f6410535aaf2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93c3840c-076c-4e13-84d5-f6410535aaf2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93c3840c-076c-4e13-84d5-f6410535aaf2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_change.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "0bE4rstC4Tgu",
        "outputId": "9aaafc05-70fe-4957-c6e4-08a8b5310231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             games      OP1_AVG      OPX_AVG      OP2_AVG      CP1_AVG  \\\n",
              "count  2767.000000  2767.000000  2767.000000  2767.000000  2767.000000   \n",
              "mean     18.488254     2.645905     4.126351     5.156853     2.747189   \n",
              "std      10.893711     1.976919     1.583578     4.699931     2.263262   \n",
              "min       0.000000     1.039000     2.794000     1.100000     1.031000   \n",
              "25%       9.000000     1.594000     3.298500     2.517500     1.580500   \n",
              "50%      19.000000     2.001000     3.561000     3.871000     1.998000   \n",
              "75%      28.000000     2.825500     4.263000     5.674500     2.920500   \n",
              "max      37.000000    20.314000    16.556000    39.494000    26.781000   \n",
              "\n",
              "           CPX_AVG      CP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "count  2767.000000  2767.000000     2767.000000    2767.000000   \n",
              "mean      4.227743     5.406997        0.366349       0.269691   \n",
              "std       1.791913     4.930371        0.219157       0.160043   \n",
              "min       2.682000     1.083000        0.000000       0.000000   \n",
              "25%       3.302500     2.549500        0.222222       0.181818   \n",
              "50%       3.630000     4.066000        0.333333       0.257143   \n",
              "75%       4.393000     6.125000        0.500000       0.347826   \n",
              "max      21.078000    43.927000        2.000000       1.000000   \n",
              "\n",
              "       home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  \\\n",
              "count     2767.000000     2767.000000    2767.000000     2767.000000   \n",
              "mean         0.339199        0.349628       0.270195        0.354487   \n",
              "std          0.206374        0.215746       0.156410        0.205221   \n",
              "min          0.000000        0.000000       0.000000        0.000000   \n",
              "25%          0.193548        0.206897       0.185185        0.214286   \n",
              "50%          0.347826        0.323529       0.260870        0.370370   \n",
              "75%          0.466667        0.486486       0.347826        0.500000   \n",
              "max          2.000000        1.000000       1.000000        1.000000   \n",
              "\n",
              "             DIFF1        DIFFX        DIFF2     OP1_RATE     OPX_RATE  \\\n",
              "count  2767.000000  2767.000000  2767.000000  2767.000000  2767.000000   \n",
              "mean      0.101285     0.101392     0.250144     0.245422     0.354458   \n",
              "std       0.692392     0.570382     1.442723     0.141537     0.026985   \n",
              "min      -4.759000    -2.987000    -9.798002     0.018200     0.183238   \n",
              "25%      -0.076000    -0.111500    -0.132500     0.142634     0.341029   \n",
              "50%       0.022000     0.033000     0.075000     0.217520     0.358477   \n",
              "75%       0.156500     0.225000     0.514000     0.328322     0.372263   \n",
              "max      12.504001     7.787999    15.370999     0.653980     0.436047   \n",
              "\n",
              "          OP2_RATE     CP1_RATE     CPX_RATE     CP2_RATE         DIR1  \\\n",
              "count  2767.000000  2767.000000  2767.000000  2767.000000  2767.000000   \n",
              "mean      0.400121     0.245511     0.348810     0.405679     0.560535   \n",
              "std       0.152886     0.147748     0.028980     0.158479     0.496412   \n",
              "min       0.035008     0.015672     0.231372     0.027096     0.000000   \n",
              "25%       0.293213     0.135333     0.331508     0.292647     0.000000   \n",
              "50%       0.420122     0.211904     0.350204     0.432014     1.000000   \n",
              "75%       0.506404     0.334907     0.369129     0.522364     1.000000   \n",
              "max       0.778794     0.687905     0.446842     0.724476     1.000000   \n",
              "\n",
              "              DIRX         DIR2       OP_SUM       CP_SUM  \n",
              "count  2767.000000  2767.000000  2767.000000  2767.000000  \n",
              "mean      0.566317     0.590170    11.929109    12.381929  \n",
              "std       0.495672     0.491891     5.770773     6.212287  \n",
              "min       0.000000     0.000000     8.446000     8.571000  \n",
              "25%       0.000000     0.000000     8.949500     9.105500  \n",
              "50%       1.000000     1.000000     9.841000    10.241000  \n",
              "75%       1.000000     1.000000    12.161500    12.759000  \n",
              "max       1.000000     1.000000    57.089000    66.040000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81cf29cd-9ca7-40ff-be06-dfe542725d14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "      <td>2767.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>18.488254</td>\n",
              "      <td>2.645905</td>\n",
              "      <td>4.126351</td>\n",
              "      <td>5.156853</td>\n",
              "      <td>2.747189</td>\n",
              "      <td>4.227743</td>\n",
              "      <td>5.406997</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.269691</td>\n",
              "      <td>0.339199</td>\n",
              "      <td>0.349628</td>\n",
              "      <td>0.270195</td>\n",
              "      <td>0.354487</td>\n",
              "      <td>0.101285</td>\n",
              "      <td>0.101392</td>\n",
              "      <td>0.250144</td>\n",
              "      <td>0.245422</td>\n",
              "      <td>0.354458</td>\n",
              "      <td>0.400121</td>\n",
              "      <td>0.245511</td>\n",
              "      <td>0.348810</td>\n",
              "      <td>0.405679</td>\n",
              "      <td>0.560535</td>\n",
              "      <td>0.566317</td>\n",
              "      <td>0.590170</td>\n",
              "      <td>11.929109</td>\n",
              "      <td>12.381929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.893711</td>\n",
              "      <td>1.976919</td>\n",
              "      <td>1.583578</td>\n",
              "      <td>4.699931</td>\n",
              "      <td>2.263262</td>\n",
              "      <td>1.791913</td>\n",
              "      <td>4.930371</td>\n",
              "      <td>0.219157</td>\n",
              "      <td>0.160043</td>\n",
              "      <td>0.206374</td>\n",
              "      <td>0.215746</td>\n",
              "      <td>0.156410</td>\n",
              "      <td>0.205221</td>\n",
              "      <td>0.692392</td>\n",
              "      <td>0.570382</td>\n",
              "      <td>1.442723</td>\n",
              "      <td>0.141537</td>\n",
              "      <td>0.026985</td>\n",
              "      <td>0.152886</td>\n",
              "      <td>0.147748</td>\n",
              "      <td>0.028980</td>\n",
              "      <td>0.158479</td>\n",
              "      <td>0.496412</td>\n",
              "      <td>0.495672</td>\n",
              "      <td>0.491891</td>\n",
              "      <td>5.770773</td>\n",
              "      <td>6.212287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.039000</td>\n",
              "      <td>2.794000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>1.031000</td>\n",
              "      <td>2.682000</td>\n",
              "      <td>1.083000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.759000</td>\n",
              "      <td>-2.987000</td>\n",
              "      <td>-9.798002</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.183238</td>\n",
              "      <td>0.035008</td>\n",
              "      <td>0.015672</td>\n",
              "      <td>0.231372</td>\n",
              "      <td>0.027096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.446000</td>\n",
              "      <td>8.571000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.594000</td>\n",
              "      <td>3.298500</td>\n",
              "      <td>2.517500</td>\n",
              "      <td>1.580500</td>\n",
              "      <td>3.302500</td>\n",
              "      <td>2.549500</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.193548</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>-0.076000</td>\n",
              "      <td>-0.111500</td>\n",
              "      <td>-0.132500</td>\n",
              "      <td>0.142634</td>\n",
              "      <td>0.341029</td>\n",
              "      <td>0.293213</td>\n",
              "      <td>0.135333</td>\n",
              "      <td>0.331508</td>\n",
              "      <td>0.292647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.949500</td>\n",
              "      <td>9.105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>2.001000</td>\n",
              "      <td>3.561000</td>\n",
              "      <td>3.871000</td>\n",
              "      <td>1.998000</td>\n",
              "      <td>3.630000</td>\n",
              "      <td>4.066000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>0.033000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.217520</td>\n",
              "      <td>0.358477</td>\n",
              "      <td>0.420122</td>\n",
              "      <td>0.211904</td>\n",
              "      <td>0.350204</td>\n",
              "      <td>0.432014</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.841000</td>\n",
              "      <td>10.241000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>2.825500</td>\n",
              "      <td>4.263000</td>\n",
              "      <td>5.674500</td>\n",
              "      <td>2.920500</td>\n",
              "      <td>4.393000</td>\n",
              "      <td>6.125000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.514000</td>\n",
              "      <td>0.328322</td>\n",
              "      <td>0.372263</td>\n",
              "      <td>0.506404</td>\n",
              "      <td>0.334907</td>\n",
              "      <td>0.369129</td>\n",
              "      <td>0.522364</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.161500</td>\n",
              "      <td>12.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>20.314000</td>\n",
              "      <td>16.556000</td>\n",
              "      <td>39.494000</td>\n",
              "      <td>26.781000</td>\n",
              "      <td>21.078000</td>\n",
              "      <td>43.927000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.504001</td>\n",
              "      <td>7.787999</td>\n",
              "      <td>15.370999</td>\n",
              "      <td>0.653980</td>\n",
              "      <td>0.436047</td>\n",
              "      <td>0.778794</td>\n",
              "      <td>0.687905</td>\n",
              "      <td>0.446842</td>\n",
              "      <td>0.724476</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.089000</td>\n",
              "      <td>66.040000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81cf29cd-9ca7-40ff-be06-dfe542725d14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81cf29cd-9ca7-40ff-be06-dfe542725d14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81cf29cd-9ca7-40ff-be06-dfe542725d14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a6756bf6-433d-4146-8bcf-5a101b11aa25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6756bf6-433d-4146-8bcf-5a101b11aa25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a6756bf6-433d-4146-8bcf-5a101b11aa25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_dataset.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "EMFD-BJd5ir8",
        "outputId": "b3f61142-6037-4605-8b02-171d1cf18df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games      OP1_AVG      OPX_AVG      OP2_AVG      CP1_AVG  \\\n",
              "count  3420.00000  3420.000000  3420.000000  3420.000000  3420.000000   \n",
              "mean     18.50000     2.651242     3.964012     4.709343     2.750340   \n",
              "std      10.96746     1.793426     1.466646     4.332006     2.053872   \n",
              "min       0.00000     1.039000     2.794000     1.100000     1.031000   \n",
              "25%       9.00000     1.689750     3.246750     2.510000     1.668000   \n",
              "50%      18.50000     2.158500     3.456500     3.451000     2.171000   \n",
              "75%      28.00000     2.856250     4.020250     5.053000     3.000250   \n",
              "max      37.00000    20.314000    16.556000    39.494000    26.781000   \n",
              "\n",
              "           CPX_AVG      CP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "count  3420.000000  3420.000000     3420.000000    3420.000000   \n",
              "mean      4.047380     4.927699        0.349422       0.271052   \n",
              "std       1.659382     4.551301        0.213562       0.160550   \n",
              "min       2.617000     1.083000        0.000000       0.000000   \n",
              "25%       3.238000     2.503750        0.214286       0.181818   \n",
              "50%       3.510000     3.575500        0.333333       0.259259   \n",
              "75%       4.140000     5.487000        0.478261       0.348370   \n",
              "max      21.078000    43.927000        2.000000       1.000000   \n",
              "\n",
              "       home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  \\\n",
              "count     3420.000000     3420.000000    3420.000000     3420.000000   \n",
              "mean         0.354329        0.353372       0.272543        0.348547   \n",
              "std          0.206045        0.212528       0.162479        0.203162   \n",
              "min          0.000000        0.000000       0.000000        0.000000   \n",
              "25%          0.217098        0.216216       0.185185        0.210526   \n",
              "50%          0.363636        0.333333       0.260870        0.360000   \n",
              "75%          0.483871        0.489865       0.348370        0.473684   \n",
              "max          2.000000        1.000000       2.000000        1.333333   \n",
              "\n",
              "             DIFF1        DIFFX        DIFF2     OP1_RATE     OPX_RATE  \\\n",
              "count  3420.000000  3420.000000  3420.000000  3420.000000  3420.000000   \n",
              "mean      0.099098     0.083368     0.218356     0.256786     0.358119   \n",
              "std       0.667679     0.520847     1.316895     0.131454     0.026297   \n",
              "min      -5.405001    -2.987000    -9.798002     0.018200     0.183238   \n",
              "25%      -0.094000    -0.104000    -0.160000     0.160720     0.345257   \n",
              "50%       0.024500     0.019000     0.073500     0.243408     0.362394   \n",
              "75%       0.194000     0.192000     0.463000     0.333314     0.375248   \n",
              "max      12.504001     7.787999    15.370999     0.653980     0.436047   \n",
              "\n",
              "          OP2_RATE     CP1_RATE     CPX_RATE     CP2_RATE         DIR1  \\\n",
              "count  3420.000000  3420.000000  3420.000000  3420.000000  3420.000000   \n",
              "mean      0.385095     0.257670     0.352236     0.390094     0.557018   \n",
              "std       0.142906     0.138001     0.028571     0.148711     0.496811   \n",
              "min       0.035008     0.015672     0.231372     0.027096     0.000000   \n",
              "25%       0.292130     0.152161     0.335569     0.286756     0.000000   \n",
              "50%       0.388060     0.240112     0.354473     0.395215     1.000000   \n",
              "75%       0.480615     0.344749     0.371225     0.500249     1.000000   \n",
              "max       0.778794     0.687905     0.446842     0.724476     1.000000   \n",
              "\n",
              "              DIRX         DIR2       OP_SUM       CP_SUM  \n",
              "count  3420.000000  3420.000000  3420.000000  3420.000000  \n",
              "mean      0.546491     0.578947    11.324597    11.725420  \n",
              "std       0.497907     0.493800     5.340737     5.753103  \n",
              "min       0.000000     0.000000     8.438000     8.561000  \n",
              "25%       0.000000     0.000000     8.735000     8.877750  \n",
              "50%       1.000000     1.000000     9.356500     9.665500  \n",
              "75%       1.000000     1.000000    11.358250    11.855250  \n",
              "max       1.000000     1.000000    57.089000    66.040000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-162a16c3-2ceb-4887-a591-dbdda37d0866\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3420.00000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "      <td>3420.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>18.50000</td>\n",
              "      <td>2.651242</td>\n",
              "      <td>3.964012</td>\n",
              "      <td>4.709343</td>\n",
              "      <td>2.750340</td>\n",
              "      <td>4.047380</td>\n",
              "      <td>4.927699</td>\n",
              "      <td>0.349422</td>\n",
              "      <td>0.271052</td>\n",
              "      <td>0.354329</td>\n",
              "      <td>0.353372</td>\n",
              "      <td>0.272543</td>\n",
              "      <td>0.348547</td>\n",
              "      <td>0.099098</td>\n",
              "      <td>0.083368</td>\n",
              "      <td>0.218356</td>\n",
              "      <td>0.256786</td>\n",
              "      <td>0.358119</td>\n",
              "      <td>0.385095</td>\n",
              "      <td>0.257670</td>\n",
              "      <td>0.352236</td>\n",
              "      <td>0.390094</td>\n",
              "      <td>0.557018</td>\n",
              "      <td>0.546491</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>11.324597</td>\n",
              "      <td>11.725420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.96746</td>\n",
              "      <td>1.793426</td>\n",
              "      <td>1.466646</td>\n",
              "      <td>4.332006</td>\n",
              "      <td>2.053872</td>\n",
              "      <td>1.659382</td>\n",
              "      <td>4.551301</td>\n",
              "      <td>0.213562</td>\n",
              "      <td>0.160550</td>\n",
              "      <td>0.206045</td>\n",
              "      <td>0.212528</td>\n",
              "      <td>0.162479</td>\n",
              "      <td>0.203162</td>\n",
              "      <td>0.667679</td>\n",
              "      <td>0.520847</td>\n",
              "      <td>1.316895</td>\n",
              "      <td>0.131454</td>\n",
              "      <td>0.026297</td>\n",
              "      <td>0.142906</td>\n",
              "      <td>0.138001</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.148711</td>\n",
              "      <td>0.496811</td>\n",
              "      <td>0.497907</td>\n",
              "      <td>0.493800</td>\n",
              "      <td>5.340737</td>\n",
              "      <td>5.753103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.039000</td>\n",
              "      <td>2.794000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>1.031000</td>\n",
              "      <td>2.617000</td>\n",
              "      <td>1.083000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.405001</td>\n",
              "      <td>-2.987000</td>\n",
              "      <td>-9.798002</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.183238</td>\n",
              "      <td>0.035008</td>\n",
              "      <td>0.015672</td>\n",
              "      <td>0.231372</td>\n",
              "      <td>0.027096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.438000</td>\n",
              "      <td>8.561000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.00000</td>\n",
              "      <td>1.689750</td>\n",
              "      <td>3.246750</td>\n",
              "      <td>2.510000</td>\n",
              "      <td>1.668000</td>\n",
              "      <td>3.238000</td>\n",
              "      <td>2.503750</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.217098</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>-0.094000</td>\n",
              "      <td>-0.104000</td>\n",
              "      <td>-0.160000</td>\n",
              "      <td>0.160720</td>\n",
              "      <td>0.345257</td>\n",
              "      <td>0.292130</td>\n",
              "      <td>0.152161</td>\n",
              "      <td>0.335569</td>\n",
              "      <td>0.286756</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.735000</td>\n",
              "      <td>8.877750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>18.50000</td>\n",
              "      <td>2.158500</td>\n",
              "      <td>3.456500</td>\n",
              "      <td>3.451000</td>\n",
              "      <td>2.171000</td>\n",
              "      <td>3.510000</td>\n",
              "      <td>3.575500</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.259259</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.024500</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.073500</td>\n",
              "      <td>0.243408</td>\n",
              "      <td>0.362394</td>\n",
              "      <td>0.388060</td>\n",
              "      <td>0.240112</td>\n",
              "      <td>0.354473</td>\n",
              "      <td>0.395215</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.356500</td>\n",
              "      <td>9.665500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>28.00000</td>\n",
              "      <td>2.856250</td>\n",
              "      <td>4.020250</td>\n",
              "      <td>5.053000</td>\n",
              "      <td>3.000250</td>\n",
              "      <td>4.140000</td>\n",
              "      <td>5.487000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.348370</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>0.489865</td>\n",
              "      <td>0.348370</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.194000</td>\n",
              "      <td>0.192000</td>\n",
              "      <td>0.463000</td>\n",
              "      <td>0.333314</td>\n",
              "      <td>0.375248</td>\n",
              "      <td>0.480615</td>\n",
              "      <td>0.344749</td>\n",
              "      <td>0.371225</td>\n",
              "      <td>0.500249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.358250</td>\n",
              "      <td>11.855250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.00000</td>\n",
              "      <td>20.314000</td>\n",
              "      <td>16.556000</td>\n",
              "      <td>39.494000</td>\n",
              "      <td>26.781000</td>\n",
              "      <td>21.078000</td>\n",
              "      <td>43.927000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>12.504001</td>\n",
              "      <td>7.787999</td>\n",
              "      <td>15.370999</td>\n",
              "      <td>0.653980</td>\n",
              "      <td>0.436047</td>\n",
              "      <td>0.778794</td>\n",
              "      <td>0.687905</td>\n",
              "      <td>0.446842</td>\n",
              "      <td>0.724476</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.089000</td>\n",
              "      <td>66.040000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-162a16c3-2ceb-4887-a591-dbdda37d0866')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-162a16c3-2ceb-4887-a591-dbdda37d0866 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-162a16c3-2ceb-4887-a591-dbdda37d0866');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-afb7ae7b-8399-4b0c-ac6f-d6552ecff61d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afb7ae7b-8399-4b0c-ac6f-d6552ecff61d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-afb7ae7b-8399-4b0c-ac6f-d6552ecff61d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_odds_from_symbol(dataset, comp_label, is_opening):\n",
        "  odds_label_pref = \"OP\" if is_opening else \"CP\"\n",
        "  odds_list = []\n",
        "  for index, row in dataset.iterrows():\n",
        "    symbol = row[comp_label]\n",
        "    if symbol == \"H\":\n",
        "      odds_list.append(row[f\"{odds_label_pref}1_AVG\"])\n",
        "    elif symbol == \"D\":\n",
        "      odds_list.append(row[f\"{odds_label_pref}X_AVG\"])\n",
        "    elif symbol == \"A\":\n",
        "      odds_list.append(row[f\"{odds_label_pref}2_AVG\"])\n",
        "    else:\n",
        "      ValueError(\"invalid symbol\")\n",
        "  return odds_list"
      ],
      "metadata": {
        "id": "O6EAp0xEOrpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = al_dataset[abs(al_dataset[\"DIFF2\"]) > 1]\n",
        "outliers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "DZYRYxIFNEZ2",
        "outputId": "a7a9b9c6-b0d7-45d6-e90f-44b9712d1873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          home_team       away_team  games result  OP1_AVG  OPX_AVG  OP2_AVG  \\\n",
              "3       Atl. Madrid      Las Palmas      0      H    1.240    5.613   12.405   \n",
              "13       Celta Vigo  Rayo Vallecano      1      H    1.660    3.777    5.021   \n",
              "14      Real Madrid           Betis      1      H    1.100    9.495   24.668   \n",
              "18       Las Palmas         Levante      1      D    2.041    3.257    3.745   \n",
              "34    Real Sociedad        Espanyol      3      A    2.058    3.320    3.684   \n",
              "...             ...             ...    ...    ...      ...      ...      ...   \n",
              "3401     Ath Bilbao         Sevilla     36      H    1.676    3.923    4.775   \n",
              "3402    Atl. Madrid         Osasuna     36      A    1.349    5.130    8.142   \n",
              "3407       Mallorca         Almeria     36      D    1.641    3.705    5.390   \n",
              "3410         Girona      Granada CF     37      H    1.241    6.417    9.689   \n",
              "3415    Real Madrid           Betis     37      D    1.314    5.714    7.809   \n",
              "\n",
              "      CP1_AVG  CPX_AVG  CP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "3       1.234    5.849   15.198        0.000000       0.000000   \n",
              "13      1.489    4.412    6.712        1.000000       0.000000   \n",
              "14      1.095   11.006   22.170        0.000000       1.000000   \n",
              "18      1.804    3.436    4.847        0.000000       0.000000   \n",
              "34      1.794    3.577    4.745        0.000000       0.666667   \n",
              "...       ...      ...      ...             ...            ...   \n",
              "3401    1.559    4.200    5.818        0.472222       0.305556   \n",
              "3402    1.312    5.400   10.012        0.638889       0.111111   \n",
              "3407    1.382    4.531    9.230        0.194444       0.416667   \n",
              "3410    1.215    7.136   11.819        0.648649       0.162162   \n",
              "3415    1.219    7.152   11.637        0.783784       0.189189   \n",
              "\n",
              "      home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  DIFF1  \\\n",
              "3           0.000000        0.000000       0.000000        0.000000 -0.006   \n",
              "13          0.000000        0.000000       1.000000        0.000000 -0.171   \n",
              "14          0.000000        0.000000       1.000000        0.000000 -0.005   \n",
              "18          1.000000        0.000000       0.000000        1.000000 -0.237   \n",
              "34          0.333333        0.333333       0.000000        0.666667 -0.264   \n",
              "...              ...             ...            ...             ...    ...   \n",
              "3401        0.222222        0.277778       0.305556        0.416667 -0.117   \n",
              "3402        0.250000        0.305556       0.222222        0.472222 -0.037   \n",
              "3407        0.388889        0.055556       0.305556        0.638889 -0.259   \n",
              "3410        0.189189        0.108108       0.243243        0.648649 -0.026   \n",
              "3415        0.027027        0.378378       0.378378        0.243243 -0.095   \n",
              "\n",
              "      DIFFX     DIFF2  OP1_RATE  OPX_RATE  OP2_RATE  CP1_RATE  CPX_RATE  \\\n",
              "3     0.236  2.793000  0.064389  0.291463  0.644148  0.055384  0.262511   \n",
              "13    0.635  1.691000  0.158730  0.361159  0.480111  0.118053  0.349798   \n",
              "14    1.511 -2.497999  0.031194  0.269262  0.699543  0.031951  0.321146   \n",
              "18    0.179  1.102000  0.225699  0.360168  0.414132  0.178844  0.340636   \n",
              "34    0.257  1.061000  0.227102  0.366365  0.406533  0.177343  0.353598   \n",
              "...     ...       ...       ...       ...       ...       ...       ...   \n",
              "3401  0.277  1.043000  0.161558  0.378157  0.460285  0.134664  0.362788   \n",
              "3402  0.270  1.870000  0.092265  0.350865  0.556870  0.078450  0.322889   \n",
              "3407  0.826  3.840000  0.152850  0.345101  0.502049  0.091263  0.299214   \n",
              "3410  0.719  2.130000  0.071540  0.369920  0.558540  0.060238  0.353793   \n",
              "3415  1.438  3.828000  0.088562  0.385118  0.526319  0.060926  0.357457   \n",
              "\n",
              "      CP2_RATE  DIR1  DIRX  DIR2 MAX_DIFF OP_MAX_ODD OP_MID_ODD OP_MIN_ODD  \\\n",
              "3     0.682106     0     1     1        H          A          D          H   \n",
              "13    0.532149     0     1     1        H          A          D          H   \n",
              "14    0.646903     0     1     0        A          A          D          H   \n",
              "18    0.480519     0     1     1        H          A          D          H   \n",
              "34    0.469059     0     1     1        H          A          D          H   \n",
              "...        ...   ...   ...   ...      ...        ...        ...        ...   \n",
              "3401  0.502548     0     1     1        H          A          D          H   \n",
              "3402  0.598661     0     1     1        H          A          D          H   \n",
              "3407  0.609523     0     1     1        H          A          D          H   \n",
              "3410  0.585969     0     1     1        H          A          D          H   \n",
              "3415  0.581617     0     1     1        H          A          D          H   \n",
              "\n",
              "     CP_MAX_ODD CP_MID_ODD CP_MIN_ODD  OP_SUM  CP_SUM  \n",
              "3             A          D          H  19.258  22.281  \n",
              "13            A          D          H  10.458  12.613  \n",
              "14            A          D          H  35.263  34.271  \n",
              "18            A          D          H   9.043  10.087  \n",
              "34            A          D          H   9.062  10.116  \n",
              "...         ...        ...        ...     ...     ...  \n",
              "3401          A          D          H  10.374  11.577  \n",
              "3402          A          D          H  14.621  16.724  \n",
              "3407          A          D          H  10.736  15.143  \n",
              "3410          A          D          H  17.347  20.170  \n",
              "3415          A          D          H  14.837  20.008  \n",
              "\n",
              "[602 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99b6c8f6-6d16-45a9-9b4d-1143c5872305\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>games</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>MAX_DIFF</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>CP_MAX_ODD</th>\n",
              "      <th>CP_MID_ODD</th>\n",
              "      <th>CP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>Las Palmas</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>1.240</td>\n",
              "      <td>5.613</td>\n",
              "      <td>12.405</td>\n",
              "      <td>1.234</td>\n",
              "      <td>5.849</td>\n",
              "      <td>15.198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.236</td>\n",
              "      <td>2.793000</td>\n",
              "      <td>0.064389</td>\n",
              "      <td>0.291463</td>\n",
              "      <td>0.644148</td>\n",
              "      <td>0.055384</td>\n",
              "      <td>0.262511</td>\n",
              "      <td>0.682106</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>19.258</td>\n",
              "      <td>22.281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Celta Vigo</td>\n",
              "      <td>Rayo Vallecano</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>1.660</td>\n",
              "      <td>3.777</td>\n",
              "      <td>5.021</td>\n",
              "      <td>1.489</td>\n",
              "      <td>4.412</td>\n",
              "      <td>6.712</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>0.635</td>\n",
              "      <td>1.691000</td>\n",
              "      <td>0.158730</td>\n",
              "      <td>0.361159</td>\n",
              "      <td>0.480111</td>\n",
              "      <td>0.118053</td>\n",
              "      <td>0.349798</td>\n",
              "      <td>0.532149</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>10.458</td>\n",
              "      <td>12.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Betis</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>1.100</td>\n",
              "      <td>9.495</td>\n",
              "      <td>24.668</td>\n",
              "      <td>1.095</td>\n",
              "      <td>11.006</td>\n",
              "      <td>22.170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>1.511</td>\n",
              "      <td>-2.497999</td>\n",
              "      <td>0.031194</td>\n",
              "      <td>0.269262</td>\n",
              "      <td>0.699543</td>\n",
              "      <td>0.031951</td>\n",
              "      <td>0.321146</td>\n",
              "      <td>0.646903</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>35.263</td>\n",
              "      <td>34.271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Las Palmas</td>\n",
              "      <td>Levante</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>2.041</td>\n",
              "      <td>3.257</td>\n",
              "      <td>3.745</td>\n",
              "      <td>1.804</td>\n",
              "      <td>3.436</td>\n",
              "      <td>4.847</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.237</td>\n",
              "      <td>0.179</td>\n",
              "      <td>1.102000</td>\n",
              "      <td>0.225699</td>\n",
              "      <td>0.360168</td>\n",
              "      <td>0.414132</td>\n",
              "      <td>0.178844</td>\n",
              "      <td>0.340636</td>\n",
              "      <td>0.480519</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>9.043</td>\n",
              "      <td>10.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>Espanyol</td>\n",
              "      <td>3</td>\n",
              "      <td>A</td>\n",
              "      <td>2.058</td>\n",
              "      <td>3.320</td>\n",
              "      <td>3.684</td>\n",
              "      <td>1.794</td>\n",
              "      <td>3.577</td>\n",
              "      <td>4.745</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-0.264</td>\n",
              "      <td>0.257</td>\n",
              "      <td>1.061000</td>\n",
              "      <td>0.227102</td>\n",
              "      <td>0.366365</td>\n",
              "      <td>0.406533</td>\n",
              "      <td>0.177343</td>\n",
              "      <td>0.353598</td>\n",
              "      <td>0.469059</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>9.062</td>\n",
              "      <td>10.116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>Ath Bilbao</td>\n",
              "      <td>Sevilla</td>\n",
              "      <td>36</td>\n",
              "      <td>H</td>\n",
              "      <td>1.676</td>\n",
              "      <td>3.923</td>\n",
              "      <td>4.775</td>\n",
              "      <td>1.559</td>\n",
              "      <td>4.200</td>\n",
              "      <td>5.818</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>-0.117</td>\n",
              "      <td>0.277</td>\n",
              "      <td>1.043000</td>\n",
              "      <td>0.161558</td>\n",
              "      <td>0.378157</td>\n",
              "      <td>0.460285</td>\n",
              "      <td>0.134664</td>\n",
              "      <td>0.362788</td>\n",
              "      <td>0.502548</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>10.374</td>\n",
              "      <td>11.577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3402</th>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>Osasuna</td>\n",
              "      <td>36</td>\n",
              "      <td>A</td>\n",
              "      <td>1.349</td>\n",
              "      <td>5.130</td>\n",
              "      <td>8.142</td>\n",
              "      <td>1.312</td>\n",
              "      <td>5.400</td>\n",
              "      <td>10.012</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>0.270</td>\n",
              "      <td>1.870000</td>\n",
              "      <td>0.092265</td>\n",
              "      <td>0.350865</td>\n",
              "      <td>0.556870</td>\n",
              "      <td>0.078450</td>\n",
              "      <td>0.322889</td>\n",
              "      <td>0.598661</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>14.621</td>\n",
              "      <td>16.724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3407</th>\n",
              "      <td>Mallorca</td>\n",
              "      <td>Almeria</td>\n",
              "      <td>36</td>\n",
              "      <td>D</td>\n",
              "      <td>1.641</td>\n",
              "      <td>3.705</td>\n",
              "      <td>5.390</td>\n",
              "      <td>1.382</td>\n",
              "      <td>4.531</td>\n",
              "      <td>9.230</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>-0.259</td>\n",
              "      <td>0.826</td>\n",
              "      <td>3.840000</td>\n",
              "      <td>0.152850</td>\n",
              "      <td>0.345101</td>\n",
              "      <td>0.502049</td>\n",
              "      <td>0.091263</td>\n",
              "      <td>0.299214</td>\n",
              "      <td>0.609523</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>10.736</td>\n",
              "      <td>15.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3410</th>\n",
              "      <td>Girona</td>\n",
              "      <td>Granada CF</td>\n",
              "      <td>37</td>\n",
              "      <td>H</td>\n",
              "      <td>1.241</td>\n",
              "      <td>6.417</td>\n",
              "      <td>9.689</td>\n",
              "      <td>1.215</td>\n",
              "      <td>7.136</td>\n",
              "      <td>11.819</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>-0.026</td>\n",
              "      <td>0.719</td>\n",
              "      <td>2.130000</td>\n",
              "      <td>0.071540</td>\n",
              "      <td>0.369920</td>\n",
              "      <td>0.558540</td>\n",
              "      <td>0.060238</td>\n",
              "      <td>0.353793</td>\n",
              "      <td>0.585969</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>17.347</td>\n",
              "      <td>20.170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>Betis</td>\n",
              "      <td>37</td>\n",
              "      <td>D</td>\n",
              "      <td>1.314</td>\n",
              "      <td>5.714</td>\n",
              "      <td>7.809</td>\n",
              "      <td>1.219</td>\n",
              "      <td>7.152</td>\n",
              "      <td>11.637</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>-0.095</td>\n",
              "      <td>1.438</td>\n",
              "      <td>3.828000</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.385118</td>\n",
              "      <td>0.526319</td>\n",
              "      <td>0.060926</td>\n",
              "      <td>0.357457</td>\n",
              "      <td>0.581617</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>14.837</td>\n",
              "      <td>20.008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>602 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99b6c8f6-6d16-45a9-9b4d-1143c5872305')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99b6c8f6-6d16-45a9-9b4d-1143c5872305 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99b6c8f6-6d16-45a9-9b4d-1143c5872305');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13518c65-9ddc-4a2a-8425-074bb21626b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13518c65-9ddc-4a2a-8425-074bb21626b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13518c65-9ddc-4a2a-8425-074bb21626b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_417d4d77-d740-4379-98fd-484099ab9927\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('outliers')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_417d4d77-d740-4379-98fd-484099ab9927 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('outliers');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "outliers"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_dataset_chosen = al_dataset.copy()\n",
        "al_dataset_chosen[\"CHOSEN\"] = get_odds_from_symbol(al_dataset, \"MAX_DIFF\", False)\n",
        "al_dataset_chosen\n",
        "al_dataset_chosen[\"WINNINGS\"] = al_dataset_chosen.apply(lambda x: (x[\"CHOSEN\"] - 1) if x[\"result\"] == x[\"MAX_DIFF\"] else -1, axis=1)\n",
        "al_dataset_chosen[\"WINNINGS\"].sum() / len(al_dataset_chosen)\n",
        "al_dataset_chosen.groupby([\"MAX_DIFF\"]).mean(numeric_only=True)\n",
        "# al_dataset_wins = al_dataset_chosen[al_dataset_chosen[\"result\"] == al_dataset_chosen[\"MAX_DIFF\"]]\n",
        "# al_dataset_losses = al_dataset_chosen[al_dataset_chosen[\"result\"] != al_dataset_chosen[\"MAX_DIFF\"]]\n",
        "\n",
        "al_dataset_chosen.groupby([\"result\"]).mean(numeric_only=True)\n",
        "al_dataset_chosen.mean(numeric_only=True)\n",
        "# print(f\"wins: {format(len(al_dataset_wins)/len(al_dataset) * 100, '.3f')}% {len(al_dataset_wins)}/{len(al_dataset)}%\")\n",
        "# al_dataset_wins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "IhgLx2jgNYA4",
        "outputId": "a8d9923e-e286-486e-f282-0c6e89bb8c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "games             18.500000\n",
              "OP1_AVG            2.651242\n",
              "OPX_AVG            3.964012\n",
              "OP2_AVG            4.709343\n",
              "CP1_AVG            2.750340\n",
              "CPX_AVG            4.047380\n",
              "CP2_AVG            4.927699\n",
              "home_wins_rate     0.349422\n",
              "home_tie_rate      0.271052\n",
              "home_loss_rate     0.354329\n",
              "away_wins_rate     0.353372\n",
              "away_tie_rate      0.272543\n",
              "away_loss_rate     0.348547\n",
              "DIFF1              0.099098\n",
              "DIFFX              0.083368\n",
              "DIFF2              0.218356\n",
              "OP1_RATE           0.256786\n",
              "OPX_RATE           0.358119\n",
              "OP2_RATE           0.385095\n",
              "CP1_RATE           0.257670\n",
              "CPX_RATE           0.352236\n",
              "CP2_RATE           0.390094\n",
              "DIR1               0.557018\n",
              "DIRX               0.546491\n",
              "DIR2               0.578947\n",
              "OP_SUM            11.324597\n",
              "CP_SUM            11.725420\n",
              "CHOSEN             3.276699\n",
              "WINNINGS          -0.061042\n",
              "dtype: float64"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>18.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OP1_AVG</th>\n",
              "      <td>2.651242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OPX_AVG</th>\n",
              "      <td>3.964012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OP2_AVG</th>\n",
              "      <td>4.709343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP1_AVG</th>\n",
              "      <td>2.750340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CPX_AVG</th>\n",
              "      <td>4.047380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP2_AVG</th>\n",
              "      <td>4.927699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_wins_rate</th>\n",
              "      <td>0.349422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_tie_rate</th>\n",
              "      <td>0.271052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home_loss_rate</th>\n",
              "      <td>0.354329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_wins_rate</th>\n",
              "      <td>0.353372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_tie_rate</th>\n",
              "      <td>0.272543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>away_loss_rate</th>\n",
              "      <td>0.348547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIFF1</th>\n",
              "      <td>0.099098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIFFX</th>\n",
              "      <td>0.083368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIFF2</th>\n",
              "      <td>0.218356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OP1_RATE</th>\n",
              "      <td>0.256786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OPX_RATE</th>\n",
              "      <td>0.358119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OP2_RATE</th>\n",
              "      <td>0.385095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP1_RATE</th>\n",
              "      <td>0.257670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CPX_RATE</th>\n",
              "      <td>0.352236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP2_RATE</th>\n",
              "      <td>0.390094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIR1</th>\n",
              "      <td>0.557018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIRX</th>\n",
              "      <td>0.546491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIR2</th>\n",
              "      <td>0.578947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OP_SUM</th>\n",
              "      <td>11.324597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP_SUM</th>\n",
              "      <td>11.725420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHOSEN</th>\n",
              "      <td>3.276699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WINNINGS</th>\n",
              "      <td>-0.061042</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_percent(smaller_dataset, total_dataset):\n",
        "  print(f\"wins: {format(len(smaller_dataset)/len(total_dataset) * 100, '.3f')}% {len(smaller_dataset)}/{len(total_dataset)}\")"
      ],
      "metadata": {
        "id": "_Hi5zVNXVNHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "al_dataset_wins = al_dataset_chosen[al_dataset_chosen[\"result\"] == \"A\"]\n",
        "# al_dataset_wins = al_dataset_chosen\n",
        "print_percent(al_dataset_wins[al_dataset_wins[\"result\"] == al_dataset_wins[\"MAX_DIFF\"]], al_dataset_wins)\n",
        "al_dataset_wins[\"WINNINGS\"].sum() / len(al_dataset_wins[\"WINNINGS\"])\n",
        "al_dataset_wins[al_dataset_wins[\"result\"] == al_dataset_wins[\"MAX_DIFF\"]].describe()\n",
        "# len(al_dataset_wins[al_dataset_wins[\"result\"] != al_dataset_wins[\"MAX_DIFF\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "LQbNd1lSTPj-",
        "outputId": "8e4011de-c4ee-4695-f172-aea9f55efd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wins: 45.803% 442/965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games     OP1_AVG     OPX_AVG     OP2_AVG     CP1_AVG     CPX_AVG  \\\n",
              "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
              "mean    19.036199    3.929948    3.807536    2.871706    4.698412    3.997287   \n",
              "std     11.643166    2.767938    1.078713    2.370493    3.643575    1.395253   \n",
              "min      0.000000    1.062000    2.798000    1.100000    1.076000    2.754000   \n",
              "25%      8.000000    2.253500    3.233500    1.780000    2.523750    3.252250   \n",
              "50%     19.000000    2.973000    3.415000    2.410000    3.528000    3.491500   \n",
              "75%     29.750000    4.567250    3.931750    3.234000    5.550750    4.141500   \n",
              "max     37.000000   20.314000   12.499000   34.673000   26.781000   12.227000   \n",
              "\n",
              "          CP2_AVG  home_wins_rate  home_tie_rate  home_loss_rate  \\\n",
              "count  442.000000      442.000000     442.000000      442.000000   \n",
              "mean     2.610075        0.289756       0.271918        0.413355   \n",
              "std      2.115827        0.200317       0.159780        0.195150   \n",
              "min      1.083000        0.000000       0.000000        0.000000   \n",
              "25%      1.632750        0.171675       0.189189        0.321717   \n",
              "50%      2.167000        0.285714       0.264706        0.416667   \n",
              "75%      2.908500        0.377534       0.333333        0.500000   \n",
              "max     30.331000        2.000000       1.000000        1.000000   \n",
              "\n",
              "       away_wins_rate  away_tie_rate  away_loss_rate       DIFF1       DIFFX  \\\n",
              "count      442.000000     442.000000      442.000000  442.000000  442.000000   \n",
              "mean         0.449338       0.258477        0.260869    0.768464    0.189751   \n",
              "std          0.235246       0.182264        0.191634    1.186381    0.508520   \n",
              "min          0.000000       0.000000        0.000000   -0.027000   -0.993000   \n",
              "25%          0.281250       0.166667        0.107384    0.216000   -0.022000   \n",
              "50%          0.444444       0.250000        0.250000    0.431500    0.076000   \n",
              "75%          0.628571       0.333333        0.400000    0.887000    0.274750   \n",
              "max          1.000000       2.000000        1.000000   12.504001    4.765000   \n",
              "\n",
              "            DIFF2    OP1_RATE    OPX_RATE    OP2_RATE    CP1_RATE    CPX_RATE  \\\n",
              "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
              "mean    -0.261631    0.355791    0.363926    0.280284    0.390327    0.359109   \n",
              "std      0.371981    0.132872    0.023972    0.131282    0.134341    0.026724   \n",
              "min     -4.342001    0.022018    0.259133    0.035008    0.024952    0.271688   \n",
              "25%     -0.335750    0.257762    0.349535    0.176736    0.290725    0.341504   \n",
              "50%     -0.159500    0.344557    0.366765    0.279046    0.389700    0.361452   \n",
              "75%     -0.065750    0.449507    0.379548    0.367370    0.494703    0.377827   \n",
              "max      0.034000    0.653980    0.426897    0.718850    0.685321    0.432582   \n",
              "\n",
              "         CP2_RATE        DIR1        DIRX        DIR2      OP_SUM      CP_SUM  \\\n",
              "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
              "mean     0.250565    0.993213    0.690045    0.040724   10.609190   11.305774   \n",
              "std      0.129223    0.082198    0.462999    0.197874    3.838654    4.765759   \n",
              "min      0.027096    0.000000    0.000000    0.000000    8.468000    8.591000   \n",
              "25%      0.146537    1.000000    0.000000    0.000000    8.695000    8.847250   \n",
              "50%      0.240981    1.000000    1.000000    0.000000    9.153000    9.418000   \n",
              "75%      0.334416    1.000000    1.000000    0.000000   10.740500   11.487250   \n",
              "max      0.703360    1.000000    1.000000    1.000000   48.234000   43.123000   \n",
              "\n",
              "           CHOSEN    WINNINGS  \n",
              "count  442.000000  442.000000  \n",
              "mean     2.610075    1.610075  \n",
              "std      2.115827    2.115827  \n",
              "min      1.083000    0.083000  \n",
              "25%      1.632750    0.632750  \n",
              "50%      2.167000    1.167000  \n",
              "75%      2.908500    1.908500  \n",
              "max     30.331000   29.331000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff7038aa-13fd-441c-a63a-5f9353586a26\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "      <th>CHOSEN</th>\n",
              "      <th>WINNINGS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "      <td>442.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>19.036199</td>\n",
              "      <td>3.929948</td>\n",
              "      <td>3.807536</td>\n",
              "      <td>2.871706</td>\n",
              "      <td>4.698412</td>\n",
              "      <td>3.997287</td>\n",
              "      <td>2.610075</td>\n",
              "      <td>0.289756</td>\n",
              "      <td>0.271918</td>\n",
              "      <td>0.413355</td>\n",
              "      <td>0.449338</td>\n",
              "      <td>0.258477</td>\n",
              "      <td>0.260869</td>\n",
              "      <td>0.768464</td>\n",
              "      <td>0.189751</td>\n",
              "      <td>-0.261631</td>\n",
              "      <td>0.355791</td>\n",
              "      <td>0.363926</td>\n",
              "      <td>0.280284</td>\n",
              "      <td>0.390327</td>\n",
              "      <td>0.359109</td>\n",
              "      <td>0.250565</td>\n",
              "      <td>0.993213</td>\n",
              "      <td>0.690045</td>\n",
              "      <td>0.040724</td>\n",
              "      <td>10.609190</td>\n",
              "      <td>11.305774</td>\n",
              "      <td>2.610075</td>\n",
              "      <td>1.610075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.643166</td>\n",
              "      <td>2.767938</td>\n",
              "      <td>1.078713</td>\n",
              "      <td>2.370493</td>\n",
              "      <td>3.643575</td>\n",
              "      <td>1.395253</td>\n",
              "      <td>2.115827</td>\n",
              "      <td>0.200317</td>\n",
              "      <td>0.159780</td>\n",
              "      <td>0.195150</td>\n",
              "      <td>0.235246</td>\n",
              "      <td>0.182264</td>\n",
              "      <td>0.191634</td>\n",
              "      <td>1.186381</td>\n",
              "      <td>0.508520</td>\n",
              "      <td>0.371981</td>\n",
              "      <td>0.132872</td>\n",
              "      <td>0.023972</td>\n",
              "      <td>0.131282</td>\n",
              "      <td>0.134341</td>\n",
              "      <td>0.026724</td>\n",
              "      <td>0.129223</td>\n",
              "      <td>0.082198</td>\n",
              "      <td>0.462999</td>\n",
              "      <td>0.197874</td>\n",
              "      <td>3.838654</td>\n",
              "      <td>4.765759</td>\n",
              "      <td>2.115827</td>\n",
              "      <td>2.115827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062000</td>\n",
              "      <td>2.798000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>1.076000</td>\n",
              "      <td>2.754000</td>\n",
              "      <td>1.083000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.027000</td>\n",
              "      <td>-0.993000</td>\n",
              "      <td>-4.342001</td>\n",
              "      <td>0.022018</td>\n",
              "      <td>0.259133</td>\n",
              "      <td>0.035008</td>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.271688</td>\n",
              "      <td>0.027096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.468000</td>\n",
              "      <td>8.591000</td>\n",
              "      <td>1.083000</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.253500</td>\n",
              "      <td>3.233500</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>2.523750</td>\n",
              "      <td>3.252250</td>\n",
              "      <td>1.632750</td>\n",
              "      <td>0.171675</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.321717</td>\n",
              "      <td>0.281250</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.107384</td>\n",
              "      <td>0.216000</td>\n",
              "      <td>-0.022000</td>\n",
              "      <td>-0.335750</td>\n",
              "      <td>0.257762</td>\n",
              "      <td>0.349535</td>\n",
              "      <td>0.176736</td>\n",
              "      <td>0.290725</td>\n",
              "      <td>0.341504</td>\n",
              "      <td>0.146537</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.695000</td>\n",
              "      <td>8.847250</td>\n",
              "      <td>1.632750</td>\n",
              "      <td>0.632750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>2.973000</td>\n",
              "      <td>3.415000</td>\n",
              "      <td>2.410000</td>\n",
              "      <td>3.528000</td>\n",
              "      <td>3.491500</td>\n",
              "      <td>2.167000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>-0.159500</td>\n",
              "      <td>0.344557</td>\n",
              "      <td>0.366765</td>\n",
              "      <td>0.279046</td>\n",
              "      <td>0.389700</td>\n",
              "      <td>0.361452</td>\n",
              "      <td>0.240981</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.153000</td>\n",
              "      <td>9.418000</td>\n",
              "      <td>2.167000</td>\n",
              "      <td>1.167000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.750000</td>\n",
              "      <td>4.567250</td>\n",
              "      <td>3.931750</td>\n",
              "      <td>3.234000</td>\n",
              "      <td>5.550750</td>\n",
              "      <td>4.141500</td>\n",
              "      <td>2.908500</td>\n",
              "      <td>0.377534</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.887000</td>\n",
              "      <td>0.274750</td>\n",
              "      <td>-0.065750</td>\n",
              "      <td>0.449507</td>\n",
              "      <td>0.379548</td>\n",
              "      <td>0.367370</td>\n",
              "      <td>0.494703</td>\n",
              "      <td>0.377827</td>\n",
              "      <td>0.334416</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.740500</td>\n",
              "      <td>11.487250</td>\n",
              "      <td>2.908500</td>\n",
              "      <td>1.908500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>20.314000</td>\n",
              "      <td>12.499000</td>\n",
              "      <td>34.673000</td>\n",
              "      <td>26.781000</td>\n",
              "      <td>12.227000</td>\n",
              "      <td>30.331000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.504001</td>\n",
              "      <td>4.765000</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>0.653980</td>\n",
              "      <td>0.426897</td>\n",
              "      <td>0.718850</td>\n",
              "      <td>0.685321</td>\n",
              "      <td>0.432582</td>\n",
              "      <td>0.703360</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>48.234000</td>\n",
              "      <td>43.123000</td>\n",
              "      <td>30.331000</td>\n",
              "      <td>29.331000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff7038aa-13fd-441c-a63a-5f9353586a26')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff7038aa-13fd-441c-a63a-5f9353586a26 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff7038aa-13fd-441c-a63a-5f9353586a26');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f27b1f12-eae7-44a2-ba86-cbd8fe570c8e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f27b1f12-eae7-44a2-ba86-cbd8fe570c8e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f27b1f12-eae7-44a2-ba86-cbd8fe570c8e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_dataset_losses.groupby([\"result\"]).mean(numeric_only=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "z_6zZp0vTQeA",
        "outputId": "fd694fa7-2aa2-4c18-e4a9-bfc6ea4fafd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games   OP1_AVG   OPX_AVG   OP2_AVG   CP1_AVG   CPX_AVG   CP2_AVG  \\\n",
              "result                                                                          \n",
              "A       17.946463  3.278243  3.683294  3.212033  3.073587  3.678392  3.591512   \n",
              "D       18.113798  2.671179  3.716465  4.052202  2.733661  3.796156  4.217403   \n",
              "H       18.685714  2.155384  4.262846  6.139701  2.352517  4.106727  5.591175   \n",
              "\n",
              "        home_wins_rate  home_tie_rate  home_loss_rate  away_wins_rate  \\\n",
              "result                                                                  \n",
              "A             0.300487       0.295383        0.374764        0.389131   \n",
              "D             0.332780       0.266961        0.370782        0.351762   \n",
              "H             0.385629       0.262801        0.327681        0.320911   \n",
              "\n",
              "        away_tie_rate  away_loss_rate     DIFF1     DIFFX     DIFF2  OP1_RATE  \\\n",
              "result                                                                          \n",
              "A            0.270419        0.307145 -0.204656 -0.004902  0.379480  0.315630   \n",
              "D            0.276977        0.341292  0.062482  0.079691  0.165201  0.268036   \n",
              "H            0.281495        0.378815  0.197133 -0.156119 -0.548526  0.209191   \n",
              "\n",
              "        OPX_RATE  OP2_RATE  CP1_RATE  CPX_RATE  CP2_RATE      DIR1      DIRX  \\\n",
              "result                                                                         \n",
              "A       0.365171  0.319199  0.299479  0.358069  0.342452  0.315488  0.449331   \n",
              "D       0.361191  0.370773  0.267629  0.357490  0.374881  0.490754  0.625889   \n",
              "H       0.350363  0.440446  0.227221  0.347373  0.425406  0.932919  0.273292   \n",
              "\n",
              "            DIR2     OP_SUM     CP_SUM    CHOSEN  WINNINGS  \n",
              "result                                                      \n",
              "A       0.929254  10.173570  10.343491  3.470130      -1.0  \n",
              "D       0.533428  10.439846  10.747220  3.398708      -1.0  \n",
              "H       0.249689  12.557930  12.050419  5.846234      -1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05c53945-c835-498c-a57c-30144c27249b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "      <th>CHOSEN</th>\n",
              "      <th>WINNINGS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>result</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>17.946463</td>\n",
              "      <td>3.278243</td>\n",
              "      <td>3.683294</td>\n",
              "      <td>3.212033</td>\n",
              "      <td>3.073587</td>\n",
              "      <td>3.678392</td>\n",
              "      <td>3.591512</td>\n",
              "      <td>0.300487</td>\n",
              "      <td>0.295383</td>\n",
              "      <td>0.374764</td>\n",
              "      <td>0.389131</td>\n",
              "      <td>0.270419</td>\n",
              "      <td>0.307145</td>\n",
              "      <td>-0.204656</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.379480</td>\n",
              "      <td>0.315630</td>\n",
              "      <td>0.365171</td>\n",
              "      <td>0.319199</td>\n",
              "      <td>0.299479</td>\n",
              "      <td>0.358069</td>\n",
              "      <td>0.342452</td>\n",
              "      <td>0.315488</td>\n",
              "      <td>0.449331</td>\n",
              "      <td>0.929254</td>\n",
              "      <td>10.173570</td>\n",
              "      <td>10.343491</td>\n",
              "      <td>3.470130</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <td>18.113798</td>\n",
              "      <td>2.671179</td>\n",
              "      <td>3.716465</td>\n",
              "      <td>4.052202</td>\n",
              "      <td>2.733661</td>\n",
              "      <td>3.796156</td>\n",
              "      <td>4.217403</td>\n",
              "      <td>0.332780</td>\n",
              "      <td>0.266961</td>\n",
              "      <td>0.370782</td>\n",
              "      <td>0.351762</td>\n",
              "      <td>0.276977</td>\n",
              "      <td>0.341292</td>\n",
              "      <td>0.062482</td>\n",
              "      <td>0.079691</td>\n",
              "      <td>0.165201</td>\n",
              "      <td>0.268036</td>\n",
              "      <td>0.361191</td>\n",
              "      <td>0.370773</td>\n",
              "      <td>0.267629</td>\n",
              "      <td>0.357490</td>\n",
              "      <td>0.374881</td>\n",
              "      <td>0.490754</td>\n",
              "      <td>0.625889</td>\n",
              "      <td>0.533428</td>\n",
              "      <td>10.439846</td>\n",
              "      <td>10.747220</td>\n",
              "      <td>3.398708</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H</th>\n",
              "      <td>18.685714</td>\n",
              "      <td>2.155384</td>\n",
              "      <td>4.262846</td>\n",
              "      <td>6.139701</td>\n",
              "      <td>2.352517</td>\n",
              "      <td>4.106727</td>\n",
              "      <td>5.591175</td>\n",
              "      <td>0.385629</td>\n",
              "      <td>0.262801</td>\n",
              "      <td>0.327681</td>\n",
              "      <td>0.320911</td>\n",
              "      <td>0.281495</td>\n",
              "      <td>0.378815</td>\n",
              "      <td>0.197133</td>\n",
              "      <td>-0.156119</td>\n",
              "      <td>-0.548526</td>\n",
              "      <td>0.209191</td>\n",
              "      <td>0.350363</td>\n",
              "      <td>0.440446</td>\n",
              "      <td>0.227221</td>\n",
              "      <td>0.347373</td>\n",
              "      <td>0.425406</td>\n",
              "      <td>0.932919</td>\n",
              "      <td>0.273292</td>\n",
              "      <td>0.249689</td>\n",
              "      <td>12.557930</td>\n",
              "      <td>12.050419</td>\n",
              "      <td>5.846234</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05c53945-c835-498c-a57c-30144c27249b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05c53945-c835-498c-a57c-30144c27249b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05c53945-c835-498c-a57c-30144c27249b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b98edde3-e691-430f-bf41-10155b0bedf7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b98edde3-e691-430f-bf41-10155b0bedf7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b98edde3-e691-430f-bf41-10155b0bedf7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_train.groupby(\"result\").mean(numeric_only=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "D8-Pza3tDPOU",
        "outputId": "e4dc5439-aecf-4322-bac7-337974f7c8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games   OP1_AVG   OPX_AVG   OP2_AVG   CP1_AVG   CPX_AVG   CP2_AVG  \\\n",
              "result                                                                          \n",
              "A       18.601333  3.710344  3.796363  3.090235  3.948796  3.895621  3.183715   \n",
              "D       17.578348  2.682573  3.709729  4.059583  2.744900  3.737160  4.193751   \n",
              "H       18.972682  2.090060  4.355593  6.399324  2.114389  4.474548  6.710561   \n",
              "\n",
              "        home_wins_rate  home_tie_rate  home_loss_rate  away_wins_rate  \\\n",
              "result                                                                  \n",
              "A             0.294785       0.289920        0.391768        0.408081   \n",
              "D             0.331249       0.279318        0.361176        0.351869   \n",
              "H             0.387183       0.267947        0.320937        0.313560   \n",
              "\n",
              "        away_tie_rate  away_loss_rate     DIFF1     DIFFX     DIFF2  OP1_RATE  \\\n",
              "result                                                                          \n",
              "A            0.274988        0.287433  0.238452  0.099259  0.093480  0.337100   \n",
              "D            0.279615        0.335665  0.062328  0.027430  0.134168  0.269667   \n",
              "H            0.281142        0.386681  0.024329  0.118955  0.311238  0.200978   \n",
              "\n",
              "        OPX_RATE  OP2_RATE  CP1_RATE  CPX_RATE  CP2_RATE      DIR1      DIRX  \\\n",
              "result                                                                         \n",
              "A       0.362904  0.299996  0.342952  0.357915  0.299133  0.606667  0.581333   \n",
              "D       0.360314  0.370019  0.270857  0.354317  0.374826  0.559829  0.504274   \n",
              "H       0.351147  0.447876  0.197344  0.346737  0.455919  0.501656  0.580298   \n",
              "\n",
              "            DIR2     OP_SUM     CP_SUM  \n",
              "result                                  \n",
              "A       0.529333  10.596941  11.028132  \n",
              "D       0.575499  10.451885  10.675811  \n",
              "H       0.601821  12.844977  13.299498  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-954f3089-24ba-436c-8233-01340b075bd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>result</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>18.601333</td>\n",
              "      <td>3.710344</td>\n",
              "      <td>3.796363</td>\n",
              "      <td>3.090235</td>\n",
              "      <td>3.948796</td>\n",
              "      <td>3.895621</td>\n",
              "      <td>3.183715</td>\n",
              "      <td>0.294785</td>\n",
              "      <td>0.289920</td>\n",
              "      <td>0.391768</td>\n",
              "      <td>0.408081</td>\n",
              "      <td>0.274988</td>\n",
              "      <td>0.287433</td>\n",
              "      <td>0.238452</td>\n",
              "      <td>0.099259</td>\n",
              "      <td>0.093480</td>\n",
              "      <td>0.337100</td>\n",
              "      <td>0.362904</td>\n",
              "      <td>0.299996</td>\n",
              "      <td>0.342952</td>\n",
              "      <td>0.357915</td>\n",
              "      <td>0.299133</td>\n",
              "      <td>0.606667</td>\n",
              "      <td>0.581333</td>\n",
              "      <td>0.529333</td>\n",
              "      <td>10.596941</td>\n",
              "      <td>11.028132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <td>17.578348</td>\n",
              "      <td>2.682573</td>\n",
              "      <td>3.709729</td>\n",
              "      <td>4.059583</td>\n",
              "      <td>2.744900</td>\n",
              "      <td>3.737160</td>\n",
              "      <td>4.193751</td>\n",
              "      <td>0.331249</td>\n",
              "      <td>0.279318</td>\n",
              "      <td>0.361176</td>\n",
              "      <td>0.351869</td>\n",
              "      <td>0.279615</td>\n",
              "      <td>0.335665</td>\n",
              "      <td>0.062328</td>\n",
              "      <td>0.027430</td>\n",
              "      <td>0.134168</td>\n",
              "      <td>0.269667</td>\n",
              "      <td>0.360314</td>\n",
              "      <td>0.370019</td>\n",
              "      <td>0.270857</td>\n",
              "      <td>0.354317</td>\n",
              "      <td>0.374826</td>\n",
              "      <td>0.559829</td>\n",
              "      <td>0.504274</td>\n",
              "      <td>0.575499</td>\n",
              "      <td>10.451885</td>\n",
              "      <td>10.675811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H</th>\n",
              "      <td>18.972682</td>\n",
              "      <td>2.090060</td>\n",
              "      <td>4.355593</td>\n",
              "      <td>6.399324</td>\n",
              "      <td>2.114389</td>\n",
              "      <td>4.474548</td>\n",
              "      <td>6.710561</td>\n",
              "      <td>0.387183</td>\n",
              "      <td>0.267947</td>\n",
              "      <td>0.320937</td>\n",
              "      <td>0.313560</td>\n",
              "      <td>0.281142</td>\n",
              "      <td>0.386681</td>\n",
              "      <td>0.024329</td>\n",
              "      <td>0.118955</td>\n",
              "      <td>0.311238</td>\n",
              "      <td>0.200978</td>\n",
              "      <td>0.351147</td>\n",
              "      <td>0.447876</td>\n",
              "      <td>0.197344</td>\n",
              "      <td>0.346737</td>\n",
              "      <td>0.455919</td>\n",
              "      <td>0.501656</td>\n",
              "      <td>0.580298</td>\n",
              "      <td>0.601821</td>\n",
              "      <td>12.844977</td>\n",
              "      <td>13.299498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-954f3089-24ba-436c-8233-01340b075bd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-954f3089-24ba-436c-8233-01340b075bd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-954f3089-24ba-436c-8233-01340b075bd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7853910b-1d6f-4abf-9116-d063f585da68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7853910b-1d6f-4abf-9116-d063f585da68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7853910b-1d6f-4abf-9116-d063f585da68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_percent_str(str_label, small_num, total):\n",
        "  if total != 0:\n",
        "    print(f\"{str_label}: {format(small_num/total * 100, '.3f')}%      {format(small_num, '.3f')}/{total}\")\n",
        "  else:\n",
        "    print(f\"{str_label}: invalid%      {small_num}/{total}\")"
      ],
      "metadata": {
        "id": "xBZPJuaPI81i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_odds_rates(dataset, is_opening):\n",
        "  pref = \"OP\" if is_opening else \"CP\"\n",
        "  rate1 = dataset[f\"{pref}1_RATE\"].mean()\n",
        "  rateX = dataset[f\"{pref}X_RATE\"].mean()\n",
        "  rate2 = dataset[f\"{pref}2_RATE\"].mean()\n",
        "  print(f\"{pref} odds rate: {format(rate1, '.3f')}, {format(rateX, '.3f')}, {format(rate2, '.3f')}\")"
      ],
      "metadata": {
        "id": "KWDvP0uUKgfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_min_max_mid_rates(dataset, lm_dataset, result, label, is_opening):\n",
        "  pref = \"OP\" if is_opening else \"CP\"\n",
        "  count = len(lm_dataset)\n",
        "  max_num = len(lm_dataset[lm_dataset[f\"{pref}_MAX_ODD\"] == result])\n",
        "  mid_num = len(lm_dataset[lm_dataset[f\"{pref}_MID_ODD\"] == result])\n",
        "  min_num = len(lm_dataset[lm_dataset[f\"{pref}_MIN_ODD\"] == result])\n",
        "\n",
        "  total_result_maxs = len(dataset[dataset[f\"{pref}_MAX_ODD\"] == result])\n",
        "  total_result_mids = len(dataset[dataset[f\"{pref}_MID_ODD\"] == result])\n",
        "  total_result_mins = len(dataset[dataset[f\"{pref}_MIN_ODD\"] == result])\n",
        "  dataset_len = len(dataset)\n",
        "  print(f\"stats data for {pref}\")\n",
        "  # when H wins, how often is it max/mid/min\n",
        "  print_percent_str(f\"when {result} wins, rate of maxs\", max_num, count)\n",
        "  print_percent_str(f\"when {result} wins, rate of mids\", mid_num, count)\n",
        "  print_percent_str(f\"when {result} wins, rate of mins\", min_num, count)\n",
        "\n",
        "  # how often is H max/mid/min in general (not necessarily when it wins)\n",
        "  print_percent_str(f\"{result} rate of maxs in dataset\", total_result_maxs, dataset_len)\n",
        "  print_percent_str(f\"{result} rate of mids in dataset\", total_result_mids, dataset_len)\n",
        "  print_percent_str(f\"{result} rate of mins in dataset\", total_result_mins, dataset_len)\n",
        "\n",
        "  # how often does H win as max/mid/min\n",
        "  print_percent_str(f\"{result} rate of wins as max\", max_num, total_result_maxs)\n",
        "  print_percent_str(f\"{result} rate of wins as mid\", mid_num, total_result_mids)\n",
        "  print_percent_str(f\"{result} rate of wins as min\", min_num, total_result_mins)\n",
        "\n",
        "  # winning average max/mid/min odds\n",
        "  max_win_odds = lm_dataset[lm_dataset[f\"{pref}_MAX_ODD\"] == result][label].mean()\n",
        "  mid_win_odds = lm_dataset[lm_dataset[f\"{pref}_MID_ODD\"] == result][label].mean()\n",
        "  min_win_odds = lm_dataset[lm_dataset[f\"{pref}_MIN_ODD\"] == result][label].mean()\n",
        "  print(f\"when {result} wins as max, avg odds: {format(max_win_odds, '.3f')}\")\n",
        "  print(f\"when {result} wins as mid, avg odds: {format(mid_win_odds, '.3f')}\")\n",
        "  print(f\"when {result} wins as min, avg odds: {format(min_win_odds, '.3f')}\")\n",
        "\n",
        "  # dataset average max/mid/min odds\n",
        "  max_odds = dataset[dataset[f\"{pref}_MAX_ODD\"] == result][label].mean()\n",
        "  mid_odds = dataset[dataset[f\"{pref}_MID_ODD\"] == result][label].mean()\n",
        "  min_odds = dataset[dataset[f\"{pref}_MIN_ODD\"] == result][label].mean()\n",
        "  print(f\"when {result} is max, avg odds: {format(max_odds, '.3f')}\")\n",
        "  print(f\"when {result} is mid, avg odds: {format(mid_odds, '.3f')}\")\n",
        "  print(f\"when {result} is min, avg odds: {format(min_odds, '.3f')}\")\n",
        "\n",
        "  # ev\n",
        "  max_win_rate = max_num / total_result_maxs if total_result_maxs != 0 else 0\n",
        "  mid_win_rate = mid_num / total_result_mids if total_result_mids != 0 else 0\n",
        "  min_win_rate = min_num / total_result_mins if total_result_mins != 0 else 0\n",
        "  print(f\"EV for {result} as max = {format(max_win_rate * max_win_odds, '.3f')}\")\n",
        "  print(f\"EV for {result} as mid = {format(mid_win_rate * mid_win_odds, '.3f')}\")\n",
        "  print(f\"EV for {result} as min = {format(min_win_rate * min_win_odds, '.3f')}\")"
      ],
      "metadata": {
        "id": "UetmIYmaYQg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VI4XsT-kcJ8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home info\n",
        "# odds\n",
        "\n",
        "def print_result_stats(result):\n",
        "  if result == \"H\":\n",
        "    label = \"OP1_AVG\"\n",
        "  elif result == \"D\":\n",
        "    label = \"OPX_AVG\"\n",
        "  else:\n",
        "    label = \"OP2_AVG\"\n",
        "\n",
        "  al_train_lm = al_train.drop(index=al_train[al_train.games < 4].index)\n",
        "  al_stat = al_train_lm[al_train_lm[\"result\"] == result]\n",
        "  mean = al_stat[label].mean()\n",
        "  std = al_stat[label].std()\n",
        "  op1_odds_rate = al_stat[\"OP1_RATE\"].mean()\n",
        "  opx_odds_rate = al_stat[\"OPX_RATE\"].mean()\n",
        "  op2_odds_rate = al_stat[\"OP2_RATE\"].mean()\n",
        "\n",
        "  hwr, hdr, hlr = al_stat[\"home_wins_rate\"].mean(), al_stat[\"home_tie_rate\"].mean(), al_stat[\"home_loss_rate\"].mean()\n",
        "  awr, adr, alr = al_stat[\"away_wins_rate\"].mean(), al_stat[\"away_tie_rate\"].mean(), al_stat[\"away_loss_rate\"].mean()\n",
        "\n",
        "  print(f\"{result} win stats: \")\n",
        "  print(f\"{label} mean: {(format(mean, '.3f'))}, std: {format(std, '.3f')}\")\n",
        "  # print(f\"op odds rates: {format(op1_odds_rate, '.3f')}, {format(opx_odds_rate, '.3f')}, {format(op2_odds_rate, '.3f')}\")\n",
        "  print_odds_rates(al_stat, True)\n",
        "  print_odds_rates(al_stat, False)\n",
        "  print(f\"home win rates: {format(hwr, '.3f')}, {format(hdr, '.3f')}, {format(hlr, '.3f')}\")\n",
        "  print(f\"away win rates: {format(awr, '.3f')}, {format(adr, '.3f')}, {format(alr, '.3f')}\")\n",
        "  # when H wins, how often is it max/mid/min\n",
        "  print_min_max_mid_rates(al_train_lm, al_stat, result, label, True)\n",
        "  print_min_max_mid_rates(al_train_lm, al_stat, result, label, False)\n"
      ],
      "metadata": {
        "id": "VpmmAvhbEY4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print_result_stats(\"H\")\n",
        "print(\"\")\n",
        "print_result_stats(\"D\")\n",
        "print(\"\")\n",
        "print_result_stats(\"A\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihonXCdPNRKx",
        "outputId": "da2ebe03-274d-4222-9764-8ae059217a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H win stats: \n",
            "OP1_AVG mean: 2.100, std: 1.135\n",
            "OP odds rate: 0.202, 0.352, 0.447\n",
            "CP odds rate: 0.198, 0.347, 0.455\n",
            "home win rates: 0.395, 0.274, 0.328\n",
            "away win rates: 0.325, 0.282, 0.393\n",
            "stats data for OP\n",
            "when H wins, rate of maxs: 8.590%      95/1106\n",
            "when H wins, rate of mids: 6.510%      72/1106\n",
            "when H wins, rate of mins: 84.901%      939/1106\n",
            "H rate of maxs in dataset: 18.487%      440/2380\n",
            "H rate of mids in dataset: 10.672%      254/2380\n",
            "H rate of mins in dataset: 70.840%      1686/2380\n",
            "H rate of wins as max: 21.591%      95/440\n",
            "H rate of wins as mid: 28.346%      72/254\n",
            "H rate of wins as min: 55.694%      939/1686\n",
            "when H wins as max, avg odds: 4.855\n",
            "when H wins as mid, avg odds: 2.932\n",
            "when H wins as min, avg odds: 1.758\n",
            "when H is max, avg odds: 5.660\n",
            "when H is mid, avg odds: 2.950\n",
            "when H is min, avg odds: 1.874\n",
            "EV for H as max = 1.048\n",
            "EV for H as mid = 0.831\n",
            "EV for H as min = 0.979\n",
            "stats data for CP\n",
            "when H wins, rate of maxs: 9.313%      103/1106\n",
            "when H wins, rate of mids: 5.244%      58/1106\n",
            "when H wins, rate of mins: 85.443%      945/1106\n",
            "H rate of maxs in dataset: 20.882%      497/2380\n",
            "H rate of mids in dataset: 8.950%      213/2380\n",
            "H rate of mins in dataset: 70.168%      1670/2380\n",
            "H rate of wins as max: 20.724%      103/497\n",
            "H rate of wins as mid: 27.230%      58/213\n",
            "H rate of wins as min: 56.587%      945/1670\n",
            "when H wins as max, avg odds: 4.577\n",
            "when H wins as mid, avg odds: 3.004\n",
            "when H wins as min, avg odds: 1.775\n",
            "when H is max, avg odds: 5.282\n",
            "when H is mid, avg odds: 2.946\n",
            "when H is min, avg odds: 1.884\n",
            "EV for H as max = 0.948\n",
            "EV for H as mid = 0.818\n",
            "EV for H as min = 1.004\n",
            "\n",
            "D win stats: \n",
            "OPX_AVG mean: 3.696, std: 1.059\n",
            "OP odds rate: 0.269, 0.361, 0.370\n",
            "CP odds rate: 0.270, 0.355, 0.375\n",
            "home win rates: 0.344, 0.280, 0.379\n",
            "away win rates: 0.360, 0.286, 0.353\n",
            "stats data for OP\n",
            "when D wins, rate of maxs: 31.774%      197/620\n",
            "when D wins, rate of mids: 68.226%      423/620\n",
            "when D wins, rate of mins: 0.000%      0/620\n",
            "D rate of maxs in dataset: 26.050%      620/2380\n",
            "D rate of mids in dataset: 73.950%      1760/2380\n",
            "D rate of mins in dataset: 0.000%      0/2380\n",
            "D rate of wins as max: 31.774%      197/620\n",
            "D rate of wins as mid: 24.034%      423/1760\n",
            "D rate of wins as min: invalid%      0/0\n",
            "when D wins as max, avg odds: 3.257\n",
            "when D wins as mid, avg odds: 3.901\n",
            "when D wins as min, avg odds: nan\n",
            "when D is max, avg odds: 3.276\n",
            "when D is mid, avg odds: 4.286\n",
            "when D is min, avg odds: nan\n",
            "EV for D as max = 1.035\n",
            "EV for D as mid = 0.938\n",
            "EV for D as min = nan\n",
            "stats data for CP\n",
            "when D wins, rate of maxs: 25.161%      156/620\n",
            "when D wins, rate of mids: 74.355%      461/620\n",
            "when D wins, rate of mins: 0.484%      3/620\n",
            "D rate of maxs in dataset: 21.639%      515/2380\n",
            "D rate of mids in dataset: 78.109%      1859/2380\n",
            "D rate of mins in dataset: 0.252%      6/2380\n",
            "D rate of wins as max: 30.291%      156/515\n",
            "D rate of wins as mid: 24.798%      461/1859\n",
            "D rate of wins as min: 50.000%      3/6\n",
            "when D wins as max, avg odds: 3.300\n",
            "when D wins as mid, avg odds: 3.835\n",
            "when D wins as min, avg odds: 3.015\n",
            "when D is max, avg odds: 3.320\n",
            "when D is mid, avg odds: 4.221\n",
            "when D is min, avg odds: 2.984\n",
            "EV for D as max = 1.000\n",
            "EV for D as mid = 0.951\n",
            "EV for D as min = 1.508\n",
            "\n",
            "A win stats: \n",
            "OP2_AVG mean: 3.071, std: 2.163\n",
            "OP odds rate: 0.337, 0.363, 0.300\n",
            "CP odds rate: 0.344, 0.359, 0.297\n",
            "home win rates: 0.310, 0.286, 0.404\n",
            "away win rates: 0.429, 0.272, 0.298\n",
            "stats data for OP\n",
            "when A wins, rate of maxs: 31.040%      203/654\n",
            "when A wins, rate of mids: 17.737%      116/654\n",
            "when A wins, rate of mins: 51.223%      335/654\n",
            "A rate of maxs in dataset: 55.462%      1320/2380\n",
            "A rate of mids in dataset: 15.378%      366/2380\n",
            "A rate of mins in dataset: 29.160%      694/2380\n",
            "A rate of wins as max: 15.379%      203/1320\n",
            "A rate of wins as mid: 31.694%      116/366\n",
            "A rate of wins as min: 48.271%      335/694\n",
            "when A wins as max, avg odds: 5.041\n",
            "when A wins as mid, avg odds: 2.994\n",
            "when A wins as min, avg odds: 1.905\n",
            "when A is max, avg odds: 6.825\n",
            "when A is mid, avg odds: 2.987\n",
            "when A is min, avg odds: 2.012\n",
            "EV for A as max = 0.775\n",
            "EV for A as mid = 0.949\n",
            "EV for A as min = 0.919\n",
            "stats data for CP\n",
            "when A wins, rate of maxs: 32.110%      210/654\n",
            "when A wins, rate of mids: 14.526%      95/654\n",
            "when A wins, rate of mins: 53.364%      349/654\n",
            "A rate of maxs in dataset: 57.479%      1368/2380\n",
            "A rate of mids in dataset: 12.941%      308/2380\n",
            "A rate of mins in dataset: 29.580%      704/2380\n",
            "A rate of wins as max: 15.351%      210/1368\n",
            "A rate of wins as mid: 30.844%      95/308\n",
            "A rate of wins as min: 49.574%      349/704\n",
            "when A wins as max, avg odds: 4.922\n",
            "when A wins as mid, avg odds: 3.028\n",
            "when A wins as min, avg odds: 1.970\n",
            "when A is max, avg odds: 6.666\n",
            "when A is mid, avg odds: 3.000\n",
            "when A is min, avg odds: 2.068\n",
            "EV for A as max = 0.756\n",
            "EV for A as mid = 0.934\n",
            "EV for A as min = 0.976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_min_wins = al_train_lm[(al_train_lm[\"OP_MIN_ODD\"] == \"H\") & (al_train_lm[\"result\"] == \"H\")]\n",
        "h_min_wins.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "wpqo13u0iT9o",
        "outputId": "90baa96a-f757-4fbc-c10b-82dfb152ed74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games     OP1_AVG     OPX_AVG     OP2_AVG     CP1_AVG     CPX_AVG  \\\n",
              "count  939.000000  939.000000  939.000000  939.000000  939.000000  939.000000   \n",
              "mean    20.617678    1.757667    4.474911    7.061887    1.761368    4.600190   \n",
              "std      9.634567    0.425774    2.086045    5.875901    0.450670    2.344339   \n",
              "min      4.000000    1.039000    2.835000    2.617000    1.031000    2.807000   \n",
              "25%     12.000000    1.403000    3.335500    3.646500    1.405000    3.352000   \n",
              "50%     21.000000    1.739000    3.664000    4.849000    1.692000    3.765000   \n",
              "75%     29.000000    2.071000    4.561000    7.711000    2.070000    4.675000   \n",
              "max     37.000000    3.130000   16.556000   39.494000    3.247000   21.078000   \n",
              "\n",
              "          CP2_AVG  home_wins_rate  home_tie_rate  home_loss_rate  \\\n",
              "count  939.000000      939.000000     939.000000      939.000000   \n",
              "mean     7.396805        0.419271       0.271578        0.306457   \n",
              "std      6.097533        0.181235       0.118563        0.169828   \n",
              "min      2.297000        0.000000       0.000000        0.000000   \n",
              "25%      3.826000        0.285714       0.191392        0.171429   \n",
              "50%      5.332000        0.400000       0.258065        0.312500   \n",
              "75%      8.204500        0.571429       0.342857        0.411765   \n",
              "max     43.927000        1.000000       0.800000        1.000000   \n",
              "\n",
              "       away_wins_rate  away_tie_rate  away_loss_rate       DIFF1       DIFFX  \\\n",
              "count      939.000000     939.000000      939.000000  939.000000  939.000000   \n",
              "mean         0.296579       0.284853        0.420341    0.003702    0.125279   \n",
              "std          0.136180       0.121297        0.148084    0.182266    0.718536   \n",
              "min          0.000000       0.000000        0.000000   -1.655000   -2.987000   \n",
              "25%          0.200000       0.205882        0.333333   -0.086000   -0.112000   \n",
              "50%          0.285714       0.277778        0.411765    0.000000    0.047000   \n",
              "75%          0.375000       0.355991        0.516129    0.081500    0.245000   \n",
              "max          0.800000       0.833333        1.000000    0.818000    7.787999   \n",
              "\n",
              "            DIFF2    OP1_RATE    OPX_RATE    OP2_RATE    CP1_RATE    CPX_RATE  \\\n",
              "count  939.000000  939.000000  939.000000  939.000000  939.000000  939.000000   \n",
              "mean     0.334918    0.166291    0.348515    0.485194    0.162140    0.344084   \n",
              "std      1.927719    0.078773    0.029997    0.102366    0.080618    0.030858   \n",
              "min     -9.798002    0.018200    0.183238    0.302929    0.015672    0.231372   \n",
              "25%     -0.270000    0.102242    0.333607    0.401576    0.098028    0.326713   \n",
              "50%      0.239000    0.171055    0.354536    0.472869    0.157758    0.346920   \n",
              "75%      0.881000    0.229396    0.369008    0.559632    0.224452    0.365943   \n",
              "max     15.147000    0.315869    0.409112    0.778794    0.371086    0.416406   \n",
              "\n",
              "         CP2_RATE        DIR1        DIRX        DIR2      OP_SUM      CP_SUM  \n",
              "count  939.000000  939.000000  939.000000  939.000000  939.000000  939.000000  \n",
              "mean     0.493776    0.498403    0.576145    0.608094   13.294464   13.758363  \n",
              "std      0.101692    0.500264    0.494431    0.488436    7.617723    8.085048  \n",
              "min      0.258235    0.000000    0.000000    0.000000    8.472000    8.584000  \n",
              "25%      0.414652    0.000000    0.000000    0.000000    9.055000    9.231000  \n",
              "50%      0.490581    0.000000    1.000000    1.000000   10.218000   10.774000  \n",
              "75%      0.567058    1.000000    1.000000    1.000000   13.717000   14.423000  \n",
              "max      0.724476    1.000000    1.000000    1.000000   57.089000   66.040000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd055bfd-af52-4fa5-87e9-2b88a456d469\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>939.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.617678</td>\n",
              "      <td>1.757667</td>\n",
              "      <td>4.474911</td>\n",
              "      <td>7.061887</td>\n",
              "      <td>1.761368</td>\n",
              "      <td>4.600190</td>\n",
              "      <td>7.396805</td>\n",
              "      <td>0.419271</td>\n",
              "      <td>0.271578</td>\n",
              "      <td>0.306457</td>\n",
              "      <td>0.296579</td>\n",
              "      <td>0.284853</td>\n",
              "      <td>0.420341</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.125279</td>\n",
              "      <td>0.334918</td>\n",
              "      <td>0.166291</td>\n",
              "      <td>0.348515</td>\n",
              "      <td>0.485194</td>\n",
              "      <td>0.162140</td>\n",
              "      <td>0.344084</td>\n",
              "      <td>0.493776</td>\n",
              "      <td>0.498403</td>\n",
              "      <td>0.576145</td>\n",
              "      <td>0.608094</td>\n",
              "      <td>13.294464</td>\n",
              "      <td>13.758363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.634567</td>\n",
              "      <td>0.425774</td>\n",
              "      <td>2.086045</td>\n",
              "      <td>5.875901</td>\n",
              "      <td>0.450670</td>\n",
              "      <td>2.344339</td>\n",
              "      <td>6.097533</td>\n",
              "      <td>0.181235</td>\n",
              "      <td>0.118563</td>\n",
              "      <td>0.169828</td>\n",
              "      <td>0.136180</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0.148084</td>\n",
              "      <td>0.182266</td>\n",
              "      <td>0.718536</td>\n",
              "      <td>1.927719</td>\n",
              "      <td>0.078773</td>\n",
              "      <td>0.029997</td>\n",
              "      <td>0.102366</td>\n",
              "      <td>0.080618</td>\n",
              "      <td>0.030858</td>\n",
              "      <td>0.101692</td>\n",
              "      <td>0.500264</td>\n",
              "      <td>0.494431</td>\n",
              "      <td>0.488436</td>\n",
              "      <td>7.617723</td>\n",
              "      <td>8.085048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.039000</td>\n",
              "      <td>2.835000</td>\n",
              "      <td>2.617000</td>\n",
              "      <td>1.031000</td>\n",
              "      <td>2.807000</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.655000</td>\n",
              "      <td>-2.987000</td>\n",
              "      <td>-9.798002</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.183238</td>\n",
              "      <td>0.302929</td>\n",
              "      <td>0.015672</td>\n",
              "      <td>0.231372</td>\n",
              "      <td>0.258235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.472000</td>\n",
              "      <td>8.584000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.403000</td>\n",
              "      <td>3.335500</td>\n",
              "      <td>3.646500</td>\n",
              "      <td>1.405000</td>\n",
              "      <td>3.352000</td>\n",
              "      <td>3.826000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.191392</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.086000</td>\n",
              "      <td>-0.112000</td>\n",
              "      <td>-0.270000</td>\n",
              "      <td>0.102242</td>\n",
              "      <td>0.333607</td>\n",
              "      <td>0.401576</td>\n",
              "      <td>0.098028</td>\n",
              "      <td>0.326713</td>\n",
              "      <td>0.414652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.055000</td>\n",
              "      <td>9.231000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.739000</td>\n",
              "      <td>3.664000</td>\n",
              "      <td>4.849000</td>\n",
              "      <td>1.692000</td>\n",
              "      <td>3.765000</td>\n",
              "      <td>5.332000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.258065</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>0.239000</td>\n",
              "      <td>0.171055</td>\n",
              "      <td>0.354536</td>\n",
              "      <td>0.472869</td>\n",
              "      <td>0.157758</td>\n",
              "      <td>0.346920</td>\n",
              "      <td>0.490581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.218000</td>\n",
              "      <td>10.774000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>2.071000</td>\n",
              "      <td>4.561000</td>\n",
              "      <td>7.711000</td>\n",
              "      <td>2.070000</td>\n",
              "      <td>4.675000</td>\n",
              "      <td>8.204500</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.355991</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.081500</td>\n",
              "      <td>0.245000</td>\n",
              "      <td>0.881000</td>\n",
              "      <td>0.229396</td>\n",
              "      <td>0.369008</td>\n",
              "      <td>0.559632</td>\n",
              "      <td>0.224452</td>\n",
              "      <td>0.365943</td>\n",
              "      <td>0.567058</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.717000</td>\n",
              "      <td>14.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>16.556000</td>\n",
              "      <td>39.494000</td>\n",
              "      <td>3.247000</td>\n",
              "      <td>21.078000</td>\n",
              "      <td>43.927000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.818000</td>\n",
              "      <td>7.787999</td>\n",
              "      <td>15.147000</td>\n",
              "      <td>0.315869</td>\n",
              "      <td>0.409112</td>\n",
              "      <td>0.778794</td>\n",
              "      <td>0.371086</td>\n",
              "      <td>0.416406</td>\n",
              "      <td>0.724476</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.089000</td>\n",
              "      <td>66.040000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd055bfd-af52-4fa5-87e9-2b88a456d469')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd055bfd-af52-4fa5-87e9-2b88a456d469 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd055bfd-af52-4fa5-87e9-2b88a456d469');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef17d2e8-6558-4725-a25b-3f242ed16871\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef17d2e8-6558-4725-a25b-3f242ed16871')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef17d2e8-6558-4725-a25b-3f242ed16871 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_min_losses = al_train_lm[(al_train_lm[\"OP_MIN_ODD\"] == \"H\") & (al_train_lm[\"result\"] != \"H\")]\n",
        "h_min_losses.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "VPB_gbpXixP7",
        "outputId": "f66e748f-4b61-41c0-f1a8-963659d5d94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games     OP1_AVG     OPX_AVG     OP2_AVG     CP1_AVG     CPX_AVG  \\\n",
              "count  747.000000  747.000000  747.000000  747.000000  747.000000  747.000000   \n",
              "mean    20.188755    2.020149    3.680079    4.646356    2.074507    3.718825   \n",
              "std     10.043230    0.396575    1.073355    3.125086    0.480771    1.170411   \n",
              "min      4.000000    1.064000    2.794000    2.580000    1.078000    2.747000   \n",
              "25%     11.000000    1.738500    3.210500    3.088500    1.723000    3.181000   \n",
              "50%     20.000000    2.048000    3.375000    3.721000    2.051000    3.386000   \n",
              "75%     29.000000    2.349000    3.673500    4.778000    2.416000    3.779500   \n",
              "max     37.000000    2.759000   12.750000   33.132000    3.534000   12.941000   \n",
              "\n",
              "          CP2_AVG  home_wins_rate  home_tie_rate  home_loss_rate  \\\n",
              "count  747.000000      747.000000     747.000000      747.000000   \n",
              "mean     4.822689        0.356934       0.280780        0.362942   \n",
              "std      3.191656        0.170648       0.136301        0.163938   \n",
              "min      2.167000        0.000000       0.000000        0.000000   \n",
              "25%      3.157000        0.250000       0.194444        0.250000   \n",
              "50%      3.846000        0.333333       0.269231        0.368421   \n",
              "75%      5.142500        0.460499       0.352941        0.473684   \n",
              "max     26.467000        1.000000       1.000000        0.857143   \n",
              "\n",
              "       away_wins_rate  away_tie_rate  away_loss_rate       DIFF1       DIFFX  \\\n",
              "count      747.000000     747.000000      747.000000  747.000000  747.000000   \n",
              "mean         0.305574       0.295074        0.402712    0.054359    0.038746   \n",
              "std          0.138910       0.123163        0.151199    0.217508    0.353679   \n",
              "min          0.000000       0.000000        0.000000   -0.731000   -2.211000   \n",
              "25%          0.213203       0.217391        0.315789   -0.078000   -0.112000   \n",
              "50%          0.285714       0.285714        0.400000    0.027000    0.005000   \n",
              "75%          0.380131       0.367544        0.500000    0.162500    0.135000   \n",
              "max          0.818182       0.833333        1.000000    0.966000    2.838000   \n",
              "\n",
              "            DIFF2    OP1_RATE    OPX_RATE    OP2_RATE    CP1_RATE    CPX_RATE  \\\n",
              "count  747.000000  747.000000  747.000000  747.000000  747.000000  747.000000   \n",
              "mean     0.176333    0.214233    0.360859    0.424907    0.216199    0.354668   \n",
              "std      1.065814    0.068614    0.022227    0.083418    0.077593    0.025197   \n",
              "min     -7.905001    0.022664    0.271589    0.293482    0.026626    0.270783   \n",
              "25%     -0.217000    0.171463    0.349600    0.356752    0.162861    0.338967   \n",
              "50%      0.083000    0.225600    0.364114    0.410270    0.221884    0.355923   \n",
              "75%      0.482500    0.270650    0.375314    0.469417    0.275152    0.371356   \n",
              "max     10.993000    0.325162    0.424738    0.705747    0.393783    0.434332   \n",
              "\n",
              "         CP2_RATE        DIR1        DIRX        DIR2      OP_SUM      CP_SUM  \n",
              "count  747.000000  747.000000  747.000000  747.000000  747.000000  747.000000  \n",
              "mean     0.429133    0.570281    0.508701    0.568942   10.346584   10.616021  \n",
              "std      0.091180    0.495368    0.500259    0.495556    3.894428    3.998926  \n",
              "min      0.239500    0.000000    0.000000    0.000000    8.450000    8.571000  \n",
              "25%      0.359896    0.000000    0.000000    0.000000    8.680500    8.786000  \n",
              "50%      0.416121    1.000000    1.000000    1.000000    9.083000    9.234000  \n",
              "75%      0.489524    1.000000    1.000000    1.000000   10.151500   10.572000  \n",
              "max      0.697768    1.000000    1.000000    1.000000   46.946000   40.486000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19eb065d-c637-421a-8bfc-6347aa0b2627\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "      <td>747.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.188755</td>\n",
              "      <td>2.020149</td>\n",
              "      <td>3.680079</td>\n",
              "      <td>4.646356</td>\n",
              "      <td>2.074507</td>\n",
              "      <td>3.718825</td>\n",
              "      <td>4.822689</td>\n",
              "      <td>0.356934</td>\n",
              "      <td>0.280780</td>\n",
              "      <td>0.362942</td>\n",
              "      <td>0.305574</td>\n",
              "      <td>0.295074</td>\n",
              "      <td>0.402712</td>\n",
              "      <td>0.054359</td>\n",
              "      <td>0.038746</td>\n",
              "      <td>0.176333</td>\n",
              "      <td>0.214233</td>\n",
              "      <td>0.360859</td>\n",
              "      <td>0.424907</td>\n",
              "      <td>0.216199</td>\n",
              "      <td>0.354668</td>\n",
              "      <td>0.429133</td>\n",
              "      <td>0.570281</td>\n",
              "      <td>0.508701</td>\n",
              "      <td>0.568942</td>\n",
              "      <td>10.346584</td>\n",
              "      <td>10.616021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.043230</td>\n",
              "      <td>0.396575</td>\n",
              "      <td>1.073355</td>\n",
              "      <td>3.125086</td>\n",
              "      <td>0.480771</td>\n",
              "      <td>1.170411</td>\n",
              "      <td>3.191656</td>\n",
              "      <td>0.170648</td>\n",
              "      <td>0.136301</td>\n",
              "      <td>0.163938</td>\n",
              "      <td>0.138910</td>\n",
              "      <td>0.123163</td>\n",
              "      <td>0.151199</td>\n",
              "      <td>0.217508</td>\n",
              "      <td>0.353679</td>\n",
              "      <td>1.065814</td>\n",
              "      <td>0.068614</td>\n",
              "      <td>0.022227</td>\n",
              "      <td>0.083418</td>\n",
              "      <td>0.077593</td>\n",
              "      <td>0.025197</td>\n",
              "      <td>0.091180</td>\n",
              "      <td>0.495368</td>\n",
              "      <td>0.500259</td>\n",
              "      <td>0.495556</td>\n",
              "      <td>3.894428</td>\n",
              "      <td>3.998926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.064000</td>\n",
              "      <td>2.794000</td>\n",
              "      <td>2.580000</td>\n",
              "      <td>1.078000</td>\n",
              "      <td>2.747000</td>\n",
              "      <td>2.167000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.731000</td>\n",
              "      <td>-2.211000</td>\n",
              "      <td>-7.905001</td>\n",
              "      <td>0.022664</td>\n",
              "      <td>0.271589</td>\n",
              "      <td>0.293482</td>\n",
              "      <td>0.026626</td>\n",
              "      <td>0.270783</td>\n",
              "      <td>0.239500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.450000</td>\n",
              "      <td>8.571000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.738500</td>\n",
              "      <td>3.210500</td>\n",
              "      <td>3.088500</td>\n",
              "      <td>1.723000</td>\n",
              "      <td>3.181000</td>\n",
              "      <td>3.157000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.213203</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>-0.078000</td>\n",
              "      <td>-0.112000</td>\n",
              "      <td>-0.217000</td>\n",
              "      <td>0.171463</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.356752</td>\n",
              "      <td>0.162861</td>\n",
              "      <td>0.338967</td>\n",
              "      <td>0.359896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.680500</td>\n",
              "      <td>8.786000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.048000</td>\n",
              "      <td>3.375000</td>\n",
              "      <td>3.721000</td>\n",
              "      <td>2.051000</td>\n",
              "      <td>3.386000</td>\n",
              "      <td>3.846000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.027000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.083000</td>\n",
              "      <td>0.225600</td>\n",
              "      <td>0.364114</td>\n",
              "      <td>0.410270</td>\n",
              "      <td>0.221884</td>\n",
              "      <td>0.355923</td>\n",
              "      <td>0.416121</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.083000</td>\n",
              "      <td>9.234000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>2.349000</td>\n",
              "      <td>3.673500</td>\n",
              "      <td>4.778000</td>\n",
              "      <td>2.416000</td>\n",
              "      <td>3.779500</td>\n",
              "      <td>5.142500</td>\n",
              "      <td>0.460499</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.380131</td>\n",
              "      <td>0.367544</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.162500</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.270650</td>\n",
              "      <td>0.375314</td>\n",
              "      <td>0.469417</td>\n",
              "      <td>0.275152</td>\n",
              "      <td>0.371356</td>\n",
              "      <td>0.489524</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.151500</td>\n",
              "      <td>10.572000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>2.759000</td>\n",
              "      <td>12.750000</td>\n",
              "      <td>33.132000</td>\n",
              "      <td>3.534000</td>\n",
              "      <td>12.941000</td>\n",
              "      <td>26.467000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>2.838000</td>\n",
              "      <td>10.993000</td>\n",
              "      <td>0.325162</td>\n",
              "      <td>0.424738</td>\n",
              "      <td>0.705747</td>\n",
              "      <td>0.393783</td>\n",
              "      <td>0.434332</td>\n",
              "      <td>0.697768</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>46.946000</td>\n",
              "      <td>40.486000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19eb065d-c637-421a-8bfc-6347aa0b2627')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19eb065d-c637-421a-8bfc-6347aa0b2627 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19eb065d-c637-421a-8bfc-6347aa0b2627');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f633d58-df72-4fd1-ba0d-b36539a1831a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f633d58-df72-4fd1-ba0d-b36539a1831a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f633d58-df72-4fd1-ba0d-b36539a1831a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_train_lm_pwr = al_train_lm.copy()\n",
        "al_train_lm_pwr[\"HOME_POWER\"] = (al_train_lm[\"home_wins_rate\"] * 2 + al_train_lm[\"home_tie_rate\"]) / (al_train_lm[\"away_wins_rate\"] * 2 + al_train_lm[\"away_tie_rate\"])\n",
        "al_train_lm_pwr[\"HOME_POWER\"] = [10 if x > 10 else x for x in al_train_lm_pwr[\"HOME_POWER\"]]\n",
        "al_train_lm_pwr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "dlNuLp9hl7V1",
        "outputId": "5af0b0f8-28c4-445d-da92-eb2939cb0290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           home_team      away_team  games result  OP1_AVG  OPX_AVG  OP2_AVG  \\\n",
              "40        Granada CF  Real Sociedad      4      A    2.528    3.115    2.900   \n",
              "41          Espanyol       Valencia      4      H    3.329    3.263    2.187   \n",
              "42       Atl. Madrid         Getafe      4      H    1.244    5.543   13.128   \n",
              "43    Rayo Vallecano          Gijon      4      H    2.113    3.384    3.412   \n",
              "44           Levante          Eibar      4      D    2.382    3.094    3.138   \n",
              "...              ...            ...    ...    ...      ...      ...      ...   \n",
              "2655   Real Sociedad    Atl. Madrid     37      A    2.453    3.315    2.853   \n",
              "2656         Osasuna       Mallorca     37      A    3.499    3.526    2.177   \n",
              "2657           Elche         Getafe     37      H    3.129    2.929    2.513   \n",
              "2658      Granada CF       Espanyol     37      D    1.754    3.863    4.736   \n",
              "2659       Barcelona     Villarreal     37      A    2.007    4.020    3.747   \n",
              "\n",
              "      CP1_AVG  CPX_AVG  CP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "40      2.539    3.125    2.978        0.250000       0.000000   \n",
              "41      3.115    3.299    2.343        0.500000       0.000000   \n",
              "42      1.331    4.873   11.233        0.750000       0.000000   \n",
              "43      2.142    3.415    3.433        0.250000       0.250000   \n",
              "44      2.367    3.020    3.368        0.000000       0.500000   \n",
              "...       ...      ...      ...             ...            ...   \n",
              "2655    2.697    3.144    2.824        0.459459       0.297297   \n",
              "2656    2.997    3.238    2.504        0.324324       0.297297   \n",
              "2657    3.130    2.933    2.603        0.270270       0.243243   \n",
              "2658    1.445    4.722    7.145        0.216216       0.351351   \n",
              "2659    1.980    3.922    3.546        0.567568       0.270270   \n",
              "\n",
              "      home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  DIFF1  \\\n",
              "40          0.750000        0.000000       0.500000        0.500000  0.011   \n",
              "41          0.500000        0.250000       0.750000        0.000000 -0.214   \n",
              "42          0.250000        0.250000       0.000000        0.750000  0.087   \n",
              "43          0.500000        0.250000       0.500000        0.250000  0.029   \n",
              "44          0.500000        0.500000       0.250000        0.250000 -0.015   \n",
              "...              ...             ...            ...             ...    ...   \n",
              "2655        0.243243        0.540541       0.216216        0.243243  0.244   \n",
              "2656        0.378378        0.243243       0.243243        0.513514 -0.502   \n",
              "2657        0.486486        0.216216       0.405405        0.378378  0.001   \n",
              "2658        0.432432        0.270270       0.297297        0.432432 -0.309   \n",
              "2659        0.162162        0.405405       0.297297        0.297297 -0.027   \n",
              "\n",
              "      DIFFX  DIFF2  OP1_RATE  OPX_RATE  OP2_RATE  CP1_RATE  CPX_RATE  \\\n",
              "40    0.010  0.078  0.295915  0.364626  0.339459  0.293798  0.361606   \n",
              "41    0.036  0.156  0.379200  0.371682  0.249117  0.355715  0.376727   \n",
              "42   -0.670 -1.895  0.062465  0.278333  0.659202  0.076332  0.279463   \n",
              "43    0.031  0.021  0.237176  0.379841  0.382983  0.238265  0.379867   \n",
              "44   -0.074  0.230  0.276527  0.359183  0.364291  0.270360  0.344946   \n",
              "...     ...    ...       ...       ...       ...       ...       ...   \n",
              "2655 -0.171 -0.029  0.284538  0.384526  0.330936  0.311252  0.362839   \n",
              "2656 -0.288  0.327  0.380243  0.383178  0.236579  0.342945  0.370523   \n",
              "2657  0.004  0.090  0.365068  0.341734  0.293198  0.361182  0.338449   \n",
              "2658  0.859  2.409  0.169419  0.373129  0.457452  0.108549  0.354718   \n",
              "2659 -0.098 -0.201  0.205341  0.411295  0.383364  0.209568  0.415114   \n",
              "\n",
              "      CP2_RATE  DIR1  DIRX  DIR2 MAX_DIFF OP_MAX_ODD OP_MID_ODD OP_MIN_ODD  \\\n",
              "40    0.344596     1     1     1        D          D          A          H   \n",
              "41    0.267557     0     1     1        H          H          D          A   \n",
              "42    0.644205     1     0     0        A          A          D          H   \n",
              "43    0.381869     1     1     1        A          A          D          H   \n",
              "44    0.384694     0     0     1        D          A          D          H   \n",
              "...        ...   ...   ...   ...      ...        ...        ...        ...   \n",
              "2655  0.325909     1     0     0        D          D          A          H   \n",
              "2656  0.286532     0     0     1        H          D          H          A   \n",
              "2657  0.300369     1     1     1        H          H          D          A   \n",
              "2658  0.536734     0     1     1        H          A          D          H   \n",
              "2659  0.375318     0     0     0        A          D          A          H   \n",
              "\n",
              "     CP_MAX_ODD CP_MID_ODD CP_MIN_ODD  OP_SUM  CP_SUM  HOME_POWER  \n",
              "40            D          A          H   8.543   8.642    1.000000  \n",
              "41            D          H          A   8.779   8.757    0.800000  \n",
              "42            A          D          H  19.915  17.437    3.000000  \n",
              "43            A          D          H   8.909   8.990    0.750000  \n",
              "44            A          D          H   8.614   8.755    0.400000  \n",
              "...         ...        ...        ...     ...     ...         ...  \n",
              "2655          D          A          H   8.621   8.665    0.937500  \n",
              "2656          D          H          A   9.202   8.739    1.296296  \n",
              "2657          H          D          A   8.571   8.666    0.935484  \n",
              "2658          A          D          H  10.353  13.312    0.935484  \n",
              "2659          D          A          H   9.774   9.448    1.268293  \n",
              "\n",
              "[2380 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64a6712d-d89c-4c97-8362-dbd038cc136f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>games</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>MAX_DIFF</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>CP_MAX_ODD</th>\n",
              "      <th>CP_MID_ODD</th>\n",
              "      <th>CP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Granada CF</td>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>4</td>\n",
              "      <td>A</td>\n",
              "      <td>2.528</td>\n",
              "      <td>3.115</td>\n",
              "      <td>2.900</td>\n",
              "      <td>2.539</td>\n",
              "      <td>3.125</td>\n",
              "      <td>2.978</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.295915</td>\n",
              "      <td>0.364626</td>\n",
              "      <td>0.339459</td>\n",
              "      <td>0.293798</td>\n",
              "      <td>0.361606</td>\n",
              "      <td>0.344596</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.543</td>\n",
              "      <td>8.642</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Espanyol</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>4</td>\n",
              "      <td>H</td>\n",
              "      <td>3.329</td>\n",
              "      <td>3.263</td>\n",
              "      <td>2.187</td>\n",
              "      <td>3.115</td>\n",
              "      <td>3.299</td>\n",
              "      <td>2.343</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.214</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.156</td>\n",
              "      <td>0.379200</td>\n",
              "      <td>0.371682</td>\n",
              "      <td>0.249117</td>\n",
              "      <td>0.355715</td>\n",
              "      <td>0.376727</td>\n",
              "      <td>0.267557</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.779</td>\n",
              "      <td>8.757</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>Getafe</td>\n",
              "      <td>4</td>\n",
              "      <td>H</td>\n",
              "      <td>1.244</td>\n",
              "      <td>5.543</td>\n",
              "      <td>13.128</td>\n",
              "      <td>1.331</td>\n",
              "      <td>4.873</td>\n",
              "      <td>11.233</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>-0.670</td>\n",
              "      <td>-1.895</td>\n",
              "      <td>0.062465</td>\n",
              "      <td>0.278333</td>\n",
              "      <td>0.659202</td>\n",
              "      <td>0.076332</td>\n",
              "      <td>0.279463</td>\n",
              "      <td>0.644205</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>19.915</td>\n",
              "      <td>17.437</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Rayo Vallecano</td>\n",
              "      <td>Gijon</td>\n",
              "      <td>4</td>\n",
              "      <td>H</td>\n",
              "      <td>2.113</td>\n",
              "      <td>3.384</td>\n",
              "      <td>3.412</td>\n",
              "      <td>2.142</td>\n",
              "      <td>3.415</td>\n",
              "      <td>3.433</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.237176</td>\n",
              "      <td>0.379841</td>\n",
              "      <td>0.382983</td>\n",
              "      <td>0.238265</td>\n",
              "      <td>0.379867</td>\n",
              "      <td>0.381869</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>8.909</td>\n",
              "      <td>8.990</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Levante</td>\n",
              "      <td>Eibar</td>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>2.382</td>\n",
              "      <td>3.094</td>\n",
              "      <td>3.138</td>\n",
              "      <td>2.367</td>\n",
              "      <td>3.020</td>\n",
              "      <td>3.368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.015</td>\n",
              "      <td>-0.074</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.276527</td>\n",
              "      <td>0.359183</td>\n",
              "      <td>0.364291</td>\n",
              "      <td>0.270360</td>\n",
              "      <td>0.344946</td>\n",
              "      <td>0.384694</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>8.614</td>\n",
              "      <td>8.755</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2655</th>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>37</td>\n",
              "      <td>A</td>\n",
              "      <td>2.453</td>\n",
              "      <td>3.315</td>\n",
              "      <td>2.853</td>\n",
              "      <td>2.697</td>\n",
              "      <td>3.144</td>\n",
              "      <td>2.824</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.244</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>-0.029</td>\n",
              "      <td>0.284538</td>\n",
              "      <td>0.384526</td>\n",
              "      <td>0.330936</td>\n",
              "      <td>0.311252</td>\n",
              "      <td>0.362839</td>\n",
              "      <td>0.325909</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.621</td>\n",
              "      <td>8.665</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>Osasuna</td>\n",
              "      <td>Mallorca</td>\n",
              "      <td>37</td>\n",
              "      <td>A</td>\n",
              "      <td>3.499</td>\n",
              "      <td>3.526</td>\n",
              "      <td>2.177</td>\n",
              "      <td>2.997</td>\n",
              "      <td>3.238</td>\n",
              "      <td>2.504</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.288</td>\n",
              "      <td>0.327</td>\n",
              "      <td>0.380243</td>\n",
              "      <td>0.383178</td>\n",
              "      <td>0.236579</td>\n",
              "      <td>0.342945</td>\n",
              "      <td>0.370523</td>\n",
              "      <td>0.286532</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.202</td>\n",
              "      <td>8.739</td>\n",
              "      <td>1.296296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2657</th>\n",
              "      <td>Elche</td>\n",
              "      <td>Getafe</td>\n",
              "      <td>37</td>\n",
              "      <td>H</td>\n",
              "      <td>3.129</td>\n",
              "      <td>2.929</td>\n",
              "      <td>2.513</td>\n",
              "      <td>3.130</td>\n",
              "      <td>2.933</td>\n",
              "      <td>2.603</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.365068</td>\n",
              "      <td>0.341734</td>\n",
              "      <td>0.293198</td>\n",
              "      <td>0.361182</td>\n",
              "      <td>0.338449</td>\n",
              "      <td>0.300369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>8.571</td>\n",
              "      <td>8.666</td>\n",
              "      <td>0.935484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2658</th>\n",
              "      <td>Granada CF</td>\n",
              "      <td>Espanyol</td>\n",
              "      <td>37</td>\n",
              "      <td>D</td>\n",
              "      <td>1.754</td>\n",
              "      <td>3.863</td>\n",
              "      <td>4.736</td>\n",
              "      <td>1.445</td>\n",
              "      <td>4.722</td>\n",
              "      <td>7.145</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>-0.309</td>\n",
              "      <td>0.859</td>\n",
              "      <td>2.409</td>\n",
              "      <td>0.169419</td>\n",
              "      <td>0.373129</td>\n",
              "      <td>0.457452</td>\n",
              "      <td>0.108549</td>\n",
              "      <td>0.354718</td>\n",
              "      <td>0.536734</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>10.353</td>\n",
              "      <td>13.312</td>\n",
              "      <td>0.935484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2659</th>\n",
              "      <td>Barcelona</td>\n",
              "      <td>Villarreal</td>\n",
              "      <td>37</td>\n",
              "      <td>A</td>\n",
              "      <td>2.007</td>\n",
              "      <td>4.020</td>\n",
              "      <td>3.747</td>\n",
              "      <td>1.980</td>\n",
              "      <td>3.922</td>\n",
              "      <td>3.546</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.201</td>\n",
              "      <td>0.205341</td>\n",
              "      <td>0.411295</td>\n",
              "      <td>0.383364</td>\n",
              "      <td>0.209568</td>\n",
              "      <td>0.415114</td>\n",
              "      <td>0.375318</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>9.774</td>\n",
              "      <td>9.448</td>\n",
              "      <td>1.268293</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2380 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64a6712d-d89c-4c97-8362-dbd038cc136f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64a6712d-d89c-4c97-8362-dbd038cc136f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64a6712d-d89c-4c97-8362-dbd038cc136f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-703aab10-7f86-4314-a3da-d9e31532ccfc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-703aab10-7f86-4314-a3da-d9e31532ccfc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-703aab10-7f86-4314-a3da-d9e31532ccfc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c73857ac-5f86-4beb-adc3-4575cb1bef67\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('al_train_lm_pwr')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c73857ac-5f86-4beb-adc3-4575cb1bef67 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('al_train_lm_pwr');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "al_train_lm_pwr"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_train_lm_pwr[(al_train_lm_pwr[\"OP_MAX_ODD\"] == \"H\") & (al_train_lm_pwr[\"result\"] == \"H\")].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "R3s1kCLhUzBn",
        "outputId": "933e45d5-4aee-4d3c-fd73-e62c517de3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           games    OP1_AVG    OPX_AVG    OP2_AVG    CP1_AVG    CPX_AVG  \\\n",
              "count  95.000000  95.000000  95.000000  95.000000  95.000000  95.000000   \n",
              "mean   20.252632   4.854674   3.792674   1.870642   5.088905   3.895095   \n",
              "std    10.445368   1.979819   0.778149   0.351101   2.392722   0.874993   \n",
              "min     4.000000   2.899000   2.867000   1.215000   2.110000   2.825000   \n",
              "25%    10.500000   3.531500   3.340500   1.583500   3.435500   3.328000   \n",
              "50%    20.000000   3.996000   3.517000   1.895000   4.276000   3.631000   \n",
              "75%    29.000000   5.530000   4.033000   2.103500   5.840000   4.112500   \n",
              "max    37.000000  11.567000   6.804000   2.709000  15.277000   7.005000   \n",
              "\n",
              "         CP2_AVG  home_wins_rate  home_tie_rate  home_loss_rate  \\\n",
              "count  95.000000       95.000000      95.000000       95.000000   \n",
              "mean    1.910337        0.266885       0.272595        0.459068   \n",
              "std     0.428294        0.150599       0.105943        0.139394   \n",
              "min     1.211000        0.000000       0.000000        0.000000   \n",
              "25%     1.584000        0.166667       0.200000        0.400000   \n",
              "50%     1.857000        0.250000       0.266667        0.450000   \n",
              "75%     2.175000        0.344952       0.348913        0.533333   \n",
              "max     3.203000        0.750000       0.500000        0.833333   \n",
              "\n",
              "       away_wins_rate  away_tie_rate  away_loss_rate      DIFF1      DIFFX  \\\n",
              "count       95.000000      95.000000       95.000000  95.000000  95.000000   \n",
              "mean         0.536969       0.266676        0.185607   0.234232   0.102421   \n",
              "std          0.169907       0.119354        0.137888   1.237000   0.393249   \n",
              "min          0.000000       0.000000        0.000000  -3.400001  -0.915000   \n",
              "25%          0.422648       0.200000        0.076923  -0.320500  -0.084500   \n",
              "50%          0.571429       0.250000        0.166667   0.172000   0.067000   \n",
              "75%          0.653125       0.333333        0.274295   0.790500   0.193000   \n",
              "max          1.000000       0.750000        0.513514   6.103001   1.949000   \n",
              "\n",
              "           DIFF2   OP1_RATE   OPX_RATE   OP2_RATE   CP1_RATE   CPX_RATE  \\\n",
              "count  95.000000  95.000000  95.000000  95.000000  95.000000  95.000000   \n",
              "mean    0.039695   0.447128   0.362517   0.190355   0.448902   0.360519   \n",
              "std     0.248401   0.069970   0.021213   0.062427   0.082710   0.028205   \n",
              "min    -0.402000   0.341756   0.303671   0.062034   0.228157   0.256214   \n",
              "25%    -0.096500   0.394616   0.349805   0.140696   0.383719   0.342958   \n",
              "50%     0.000000   0.424866   0.365577   0.200524   0.444508   0.362733   \n",
              "75%     0.133500   0.487884   0.376302   0.234417   0.505593   0.379352   \n",
              "max     1.247000   0.601972   0.403014   0.318369   0.687905   0.436419   \n",
              "\n",
              "        CP2_RATE       DIR1       DIRX       DIR2     OP_SUM     CP_SUM  \\\n",
              "count  95.000000  95.000000  95.000000  95.000000  95.000000  95.000000   \n",
              "mean    0.190579   0.610526   0.631579   0.484211  10.517989  10.894337   \n",
              "std     0.071118   0.490218   0.484935   0.502402   2.420756   2.852541   \n",
              "min     0.055881   0.000000   0.000000   0.000000   8.446000   8.622000   \n",
              "25%     0.136283   0.000000   0.000000   0.000000   8.979000   9.122000   \n",
              "50%     0.190608   1.000000   1.000000   0.000000   9.540000   9.732000   \n",
              "75%     0.241048   1.000000   1.000000   1.000000  11.260500  11.625000   \n",
              "max     0.367485   1.000000   1.000000   1.000000  19.586000  22.208000   \n",
              "\n",
              "       HOME_POWER  \n",
              "count   95.000000  \n",
              "mean     0.623223  \n",
              "std      0.220330  \n",
              "min      0.000000  \n",
              "25%      0.500000  \n",
              "50%      0.575000  \n",
              "75%      0.776190  \n",
              "max      1.185185  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88d8b34b-c262-4843-9721-33cbad6cbdc5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>95.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.252632</td>\n",
              "      <td>4.854674</td>\n",
              "      <td>3.792674</td>\n",
              "      <td>1.870642</td>\n",
              "      <td>5.088905</td>\n",
              "      <td>3.895095</td>\n",
              "      <td>1.910337</td>\n",
              "      <td>0.266885</td>\n",
              "      <td>0.272595</td>\n",
              "      <td>0.459068</td>\n",
              "      <td>0.536969</td>\n",
              "      <td>0.266676</td>\n",
              "      <td>0.185607</td>\n",
              "      <td>0.234232</td>\n",
              "      <td>0.102421</td>\n",
              "      <td>0.039695</td>\n",
              "      <td>0.447128</td>\n",
              "      <td>0.362517</td>\n",
              "      <td>0.190355</td>\n",
              "      <td>0.448902</td>\n",
              "      <td>0.360519</td>\n",
              "      <td>0.190579</td>\n",
              "      <td>0.610526</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.484211</td>\n",
              "      <td>10.517989</td>\n",
              "      <td>10.894337</td>\n",
              "      <td>0.623223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.445368</td>\n",
              "      <td>1.979819</td>\n",
              "      <td>0.778149</td>\n",
              "      <td>0.351101</td>\n",
              "      <td>2.392722</td>\n",
              "      <td>0.874993</td>\n",
              "      <td>0.428294</td>\n",
              "      <td>0.150599</td>\n",
              "      <td>0.105943</td>\n",
              "      <td>0.139394</td>\n",
              "      <td>0.169907</td>\n",
              "      <td>0.119354</td>\n",
              "      <td>0.137888</td>\n",
              "      <td>1.237000</td>\n",
              "      <td>0.393249</td>\n",
              "      <td>0.248401</td>\n",
              "      <td>0.069970</td>\n",
              "      <td>0.021213</td>\n",
              "      <td>0.062427</td>\n",
              "      <td>0.082710</td>\n",
              "      <td>0.028205</td>\n",
              "      <td>0.071118</td>\n",
              "      <td>0.490218</td>\n",
              "      <td>0.484935</td>\n",
              "      <td>0.502402</td>\n",
              "      <td>2.420756</td>\n",
              "      <td>2.852541</td>\n",
              "      <td>0.220330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.899000</td>\n",
              "      <td>2.867000</td>\n",
              "      <td>1.215000</td>\n",
              "      <td>2.110000</td>\n",
              "      <td>2.825000</td>\n",
              "      <td>1.211000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.400001</td>\n",
              "      <td>-0.915000</td>\n",
              "      <td>-0.402000</td>\n",
              "      <td>0.341756</td>\n",
              "      <td>0.303671</td>\n",
              "      <td>0.062034</td>\n",
              "      <td>0.228157</td>\n",
              "      <td>0.256214</td>\n",
              "      <td>0.055881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.446000</td>\n",
              "      <td>8.622000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.500000</td>\n",
              "      <td>3.531500</td>\n",
              "      <td>3.340500</td>\n",
              "      <td>1.583500</td>\n",
              "      <td>3.435500</td>\n",
              "      <td>3.328000</td>\n",
              "      <td>1.584000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.422648</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>-0.320500</td>\n",
              "      <td>-0.084500</td>\n",
              "      <td>-0.096500</td>\n",
              "      <td>0.394616</td>\n",
              "      <td>0.349805</td>\n",
              "      <td>0.140696</td>\n",
              "      <td>0.383719</td>\n",
              "      <td>0.342958</td>\n",
              "      <td>0.136283</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.979000</td>\n",
              "      <td>9.122000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>3.996000</td>\n",
              "      <td>3.517000</td>\n",
              "      <td>1.895000</td>\n",
              "      <td>4.276000</td>\n",
              "      <td>3.631000</td>\n",
              "      <td>1.857000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.172000</td>\n",
              "      <td>0.067000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424866</td>\n",
              "      <td>0.365577</td>\n",
              "      <td>0.200524</td>\n",
              "      <td>0.444508</td>\n",
              "      <td>0.362733</td>\n",
              "      <td>0.190608</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.540000</td>\n",
              "      <td>9.732000</td>\n",
              "      <td>0.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.530000</td>\n",
              "      <td>4.033000</td>\n",
              "      <td>2.103500</td>\n",
              "      <td>5.840000</td>\n",
              "      <td>4.112500</td>\n",
              "      <td>2.175000</td>\n",
              "      <td>0.344952</td>\n",
              "      <td>0.348913</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.653125</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.274295</td>\n",
              "      <td>0.790500</td>\n",
              "      <td>0.193000</td>\n",
              "      <td>0.133500</td>\n",
              "      <td>0.487884</td>\n",
              "      <td>0.376302</td>\n",
              "      <td>0.234417</td>\n",
              "      <td>0.505593</td>\n",
              "      <td>0.379352</td>\n",
              "      <td>0.241048</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.260500</td>\n",
              "      <td>11.625000</td>\n",
              "      <td>0.776190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>11.567000</td>\n",
              "      <td>6.804000</td>\n",
              "      <td>2.709000</td>\n",
              "      <td>15.277000</td>\n",
              "      <td>7.005000</td>\n",
              "      <td>3.203000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>6.103001</td>\n",
              "      <td>1.949000</td>\n",
              "      <td>1.247000</td>\n",
              "      <td>0.601972</td>\n",
              "      <td>0.403014</td>\n",
              "      <td>0.318369</td>\n",
              "      <td>0.687905</td>\n",
              "      <td>0.436419</td>\n",
              "      <td>0.367485</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>19.586000</td>\n",
              "      <td>22.208000</td>\n",
              "      <td>1.185185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88d8b34b-c262-4843-9721-33cbad6cbdc5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88d8b34b-c262-4843-9721-33cbad6cbdc5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88d8b34b-c262-4843-9721-33cbad6cbdc5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3917713c-f716-4a5c-9aae-d7b3057ce37e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3917713c-f716-4a5c-9aae-d7b3057ce37e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3917713c-f716-4a5c-9aae-d7b3057ce37e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_train_lm_pwr[(al_train_lm_pwr[\"OP_MAX_ODD\"] == \"H\") & (al_train_lm_pwr[\"result\"] != \"H\")].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "xKfvqnBLVjQ7",
        "outputId": "12e426f5-64ec-42f4-eaac-f788a29c466b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            games     OP1_AVG     OPX_AVG     OP2_AVG     CP1_AVG     CPX_AVG  \\\n",
              "count  345.000000  345.000000  345.000000  345.000000  345.000000  345.000000   \n",
              "mean    20.971014    5.882377    4.140745    1.738609    6.280974    4.288243   \n",
              "std      9.530201    2.952309    1.145622    0.350733    3.691432    1.465097   \n",
              "min      4.000000    2.990000    2.819000    1.100000    2.567000    2.744000   \n",
              "25%     13.000000    3.748000    3.338000    1.462000    3.881000    3.339000   \n",
              "50%     21.000000    4.919000    3.722000    1.725000    5.122000    3.785000   \n",
              "75%     29.000000    6.889000    4.591000    2.040000    7.203000    4.707000   \n",
              "max     37.000000   20.314000   10.007000    2.587000   26.781000   12.227000   \n",
              "\n",
              "          CP2_AVG  home_wins_rate  home_tie_rate  home_loss_rate  \\\n",
              "count  345.000000      345.000000     345.000000      345.000000   \n",
              "mean     1.757545        0.276192       0.291154        0.434384   \n",
              "std      0.388384        0.127305       0.117563        0.146472   \n",
              "min      1.083000        0.000000       0.000000        0.000000   \n",
              "25%      1.445000        0.200000       0.214286        0.333333   \n",
              "50%      1.707000        0.269231       0.291667        0.428571   \n",
              "75%      2.049000        0.357143       0.375000        0.513514   \n",
              "max      2.861000        0.750000       0.777778        1.000000   \n",
              "\n",
              "       away_wins_rate  away_tie_rate  away_loss_rate       DIFF1       DIFFX  \\\n",
              "count      345.000000     345.000000      345.000000  345.000000  345.000000   \n",
              "mean         0.570144       0.247692        0.171289    0.398597    0.147499   \n",
              "std          0.147119       0.109834        0.114712    1.670232    0.647351   \n",
              "min          0.000000       0.000000        0.000000   -5.405001   -1.741000   \n",
              "25%          0.470588       0.166667        0.090909   -0.299000   -0.122000   \n",
              "50%          0.588235       0.230769        0.160000    0.208000    0.069000   \n",
              "75%          0.666667       0.307692        0.241379    0.838000    0.277000   \n",
              "max          1.000000       0.750000        0.615385   12.504001    4.765000   \n",
              "\n",
              "            DIFF2    OP1_RATE    OPX_RATE    OP2_RATE    CP1_RATE    CPX_RATE  \\\n",
              "count  345.000000  345.000000  345.000000  345.000000  345.000000  345.000000   \n",
              "mean     0.018936    0.478544    0.355728    0.165728    0.484225    0.351976   \n",
              "std      0.185135    0.076399    0.023011    0.065409    0.081003    0.026967   \n",
              "min     -0.739000    0.351806    0.294805    0.035008    0.294990    0.282854   \n",
              "25%     -0.072000    0.409274    0.338413    0.114351    0.416546    0.334739   \n",
              "50%      0.006000    0.475979    0.359837    0.169243    0.483635    0.353581   \n",
              "75%      0.092000    0.534100    0.373632    0.223580    0.545516    0.371726   \n",
              "max      0.947000    0.653980    0.404983    0.304496    0.685321    0.420736   \n",
              "\n",
              "         CP2_RATE        DIR1        DIRX        DIR2      OP_SUM      CP_SUM  \\\n",
              "count  345.000000  345.000000  345.000000  345.000000  345.000000  345.000000   \n",
              "mean     0.163800    0.614493    0.602899    0.513043   11.761730   12.326762   \n",
              "std      0.069679    0.487422    0.490008    0.500556    3.774616    4.820136   \n",
              "min      0.027096    0.000000    0.000000    0.000000    8.496000    8.619000   \n",
              "25%      0.107988    0.000000    0.000000    0.000000    9.129000    9.319000   \n",
              "50%      0.160652    1.000000    1.000000    1.000000   10.295000   10.683000   \n",
              "75%      0.221377    1.000000    1.000000    1.000000   12.757000   13.299000   \n",
              "max      0.328775    1.000000    1.000000    1.000000   31.421000   39.969000   \n",
              "\n",
              "       HOME_POWER  \n",
              "count  345.000000  \n",
              "mean     0.622441  \n",
              "std      0.205517  \n",
              "min      0.000000  \n",
              "25%      0.500000  \n",
              "50%      0.608696  \n",
              "75%      0.730769  \n",
              "max      1.666667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-891377a8-68ea-4bd3-9a9b-60bb81037700\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>DIFF1</th>\n",
              "      <th>DIFFX</th>\n",
              "      <th>DIFF2</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>CP1_RATE</th>\n",
              "      <th>CPX_RATE</th>\n",
              "      <th>CP2_RATE</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>345.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.971014</td>\n",
              "      <td>5.882377</td>\n",
              "      <td>4.140745</td>\n",
              "      <td>1.738609</td>\n",
              "      <td>6.280974</td>\n",
              "      <td>4.288243</td>\n",
              "      <td>1.757545</td>\n",
              "      <td>0.276192</td>\n",
              "      <td>0.291154</td>\n",
              "      <td>0.434384</td>\n",
              "      <td>0.570144</td>\n",
              "      <td>0.247692</td>\n",
              "      <td>0.171289</td>\n",
              "      <td>0.398597</td>\n",
              "      <td>0.147499</td>\n",
              "      <td>0.018936</td>\n",
              "      <td>0.478544</td>\n",
              "      <td>0.355728</td>\n",
              "      <td>0.165728</td>\n",
              "      <td>0.484225</td>\n",
              "      <td>0.351976</td>\n",
              "      <td>0.163800</td>\n",
              "      <td>0.614493</td>\n",
              "      <td>0.602899</td>\n",
              "      <td>0.513043</td>\n",
              "      <td>11.761730</td>\n",
              "      <td>12.326762</td>\n",
              "      <td>0.622441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.530201</td>\n",
              "      <td>2.952309</td>\n",
              "      <td>1.145622</td>\n",
              "      <td>0.350733</td>\n",
              "      <td>3.691432</td>\n",
              "      <td>1.465097</td>\n",
              "      <td>0.388384</td>\n",
              "      <td>0.127305</td>\n",
              "      <td>0.117563</td>\n",
              "      <td>0.146472</td>\n",
              "      <td>0.147119</td>\n",
              "      <td>0.109834</td>\n",
              "      <td>0.114712</td>\n",
              "      <td>1.670232</td>\n",
              "      <td>0.647351</td>\n",
              "      <td>0.185135</td>\n",
              "      <td>0.076399</td>\n",
              "      <td>0.023011</td>\n",
              "      <td>0.065409</td>\n",
              "      <td>0.081003</td>\n",
              "      <td>0.026967</td>\n",
              "      <td>0.069679</td>\n",
              "      <td>0.487422</td>\n",
              "      <td>0.490008</td>\n",
              "      <td>0.500556</td>\n",
              "      <td>3.774616</td>\n",
              "      <td>4.820136</td>\n",
              "      <td>0.205517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.990000</td>\n",
              "      <td>2.819000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>2.567000</td>\n",
              "      <td>2.744000</td>\n",
              "      <td>1.083000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.405001</td>\n",
              "      <td>-1.741000</td>\n",
              "      <td>-0.739000</td>\n",
              "      <td>0.351806</td>\n",
              "      <td>0.294805</td>\n",
              "      <td>0.035008</td>\n",
              "      <td>0.294990</td>\n",
              "      <td>0.282854</td>\n",
              "      <td>0.027096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.496000</td>\n",
              "      <td>8.619000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.748000</td>\n",
              "      <td>3.338000</td>\n",
              "      <td>1.462000</td>\n",
              "      <td>3.881000</td>\n",
              "      <td>3.339000</td>\n",
              "      <td>1.445000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>-0.299000</td>\n",
              "      <td>-0.122000</td>\n",
              "      <td>-0.072000</td>\n",
              "      <td>0.409274</td>\n",
              "      <td>0.338413</td>\n",
              "      <td>0.114351</td>\n",
              "      <td>0.416546</td>\n",
              "      <td>0.334739</td>\n",
              "      <td>0.107988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.129000</td>\n",
              "      <td>9.319000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>4.919000</td>\n",
              "      <td>3.722000</td>\n",
              "      <td>1.725000</td>\n",
              "      <td>5.122000</td>\n",
              "      <td>3.785000</td>\n",
              "      <td>1.707000</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.069000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.475979</td>\n",
              "      <td>0.359837</td>\n",
              "      <td>0.169243</td>\n",
              "      <td>0.483635</td>\n",
              "      <td>0.353581</td>\n",
              "      <td>0.160652</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.295000</td>\n",
              "      <td>10.683000</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>6.889000</td>\n",
              "      <td>4.591000</td>\n",
              "      <td>2.040000</td>\n",
              "      <td>7.203000</td>\n",
              "      <td>4.707000</td>\n",
              "      <td>2.049000</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.092000</td>\n",
              "      <td>0.534100</td>\n",
              "      <td>0.373632</td>\n",
              "      <td>0.223580</td>\n",
              "      <td>0.545516</td>\n",
              "      <td>0.371726</td>\n",
              "      <td>0.221377</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.757000</td>\n",
              "      <td>13.299000</td>\n",
              "      <td>0.730769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>20.314000</td>\n",
              "      <td>10.007000</td>\n",
              "      <td>2.587000</td>\n",
              "      <td>26.781000</td>\n",
              "      <td>12.227000</td>\n",
              "      <td>2.861000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>12.504001</td>\n",
              "      <td>4.765000</td>\n",
              "      <td>0.947000</td>\n",
              "      <td>0.653980</td>\n",
              "      <td>0.404983</td>\n",
              "      <td>0.304496</td>\n",
              "      <td>0.685321</td>\n",
              "      <td>0.420736</td>\n",
              "      <td>0.328775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.421000</td>\n",
              "      <td>39.969000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-891377a8-68ea-4bd3-9a9b-60bb81037700')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-891377a8-68ea-4bd3-9a9b-60bb81037700 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-891377a8-68ea-4bd3-9a9b-60bb81037700');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f24dc058-61a9-41ed-8ba5-2c9814075fcf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f24dc058-61a9-41ed-8ba5-2c9814075fcf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f24dc058-61a9-41ed-8ba5-2c9814075fcf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_filter = al_train_lm_pwr[((al_train_lm_pwr[\"OP_MIN_ODD\"] == \"H\") & (al_train_lm_pwr[\"HOME_POWER\"] > 3))]\n",
        "al_filter\n",
        "filter_odds = al_filter[al_filter[\"result\"] == \"H\"][\"OP1_AVG\"].mean()\n",
        "num_correct = len(al_filter[al_filter[\"result\"] == \"H\"])\n",
        "total = len(al_filter)\n",
        "win_percent = num_correct / total\n",
        "print_percent_str(\"\", num_correct, total)\n",
        "print(f\"odds: {filter_odds}\")\n",
        "print(f\"ev = {filter_odds * win_percent}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw-VqxeWVxPl",
        "outputId": "98b070af-6f4e-450e-aaf3-3f6be8f4794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": 70.588%      24/34\n",
            "odds: 1.4215833333333334\n",
            "ev = 1.0034705882352943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "al_mv = al_train_lm[(al_train_lm[\"OP_MIN_ODD\"] == \"H\") & (al_train_lm[\"CP1_AVG\"] > al_train_lm[\"OP1_AVG\"])]\n",
        "mv_correct = al_mv[al_mv[\"result\"] == \"H\"]\n",
        "mv_odds = mv_correct[\"CP1_AVG\"].mean()\n",
        "num_correct = len(mv_correct)\n",
        "total = len(al_mv)\n",
        "win_percent = num_correct / total\n",
        "print_percent_str(\"\", num_correct, total)\n",
        "print(f\"odds: {mv_odds}\")\n",
        "print(f\"ev = {mv_odds * win_percent}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWgsvbQ9Ma2Z",
        "outputId": "f0c49e88-c157-49fe-9bde-8c6e7d9b7d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": 52.349%      468/894\n",
            "odds: 1.8509123931623932\n",
            "ev = 0.968934004474273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def examine_changes(dataset, label, is_opening):\n",
        "  symbols =[\"OP_MAX_ODD\", \"OP_MID_ODD\", \"OP_MIN_ODD\"]\n",
        "  pref = \"OP\" if is_opening else \"CP\"\n",
        "  if label == \"H\":\n",
        "    odds_suffix = \"1_AVG\"\n",
        "    diff_label = \"DIFF1\"\n",
        "  elif label == \"D\":\n",
        "    odds_suffix = \"X_AVG\"\n",
        "    diff_label = \"DIFFX\"\n",
        "  else:\n",
        "      odds_suffix = \"2_AVG\"\n",
        "      diff_label = \"DIFF2\"\n",
        "\n",
        "  for symbol in symbols:\n",
        "    ds_lim = dataset[dataset[symbol] == label]\n",
        "    increases = ds_lim[ds_lim[diff_label] >= 0]\n",
        "    decreases = ds_lim[ds_lim[diff_label] < 0]\n",
        "    increase_wins = increases[increases[\"result\"] == label]\n",
        "    decrease_wins = decreases[decreases[\"result\"] == label]\n",
        "    odds_label = f\"{pref}{odds_suffix}\"\n",
        "    increase_winning_odds = increase_wins[f\"{pref}{odds_suffix}\"].mean()\n",
        "    decrease_winning_odds = decrease_wins[f\"{pref}{odds_suffix}\"].mean()\n",
        "    avg_winning_odds = (increase_winning_odds + decrease_winning_odds)/2\n",
        "    increase_win_rate = len(increase_wins) / len(increases) if len(increases) > 0 else 0\n",
        "    decrease_win_rate = len(decrease_wins) / len(decreases) if len(decreases) > 0 else 0\n",
        "    total_win_rate = (len(increase_wins) + len(decrease_wins)) / len(ds_lim) if len(ds_lim) > 0 else 0\n",
        "\n",
        "    print(f\"{symbol} stats for {label}\")\n",
        "    print_percent_str(\"num increases\", len(increases), len(ds_lim))\n",
        "    print_percent_str(\"num decreases\", len(decreases), len(ds_lim))\n",
        "    print_percent_str(\"total wins\", len(increase_wins) + len(decrease_wins), len(ds_lim))\n",
        "    print(f\"total winning avg odds: {format(avg_winning_odds, '.3f')}\")\n",
        "    print(f\"total winning ev: {format(calculate_ev_math(total_win_rate, avg_winning_odds), '.3f')}\")\n",
        "    # print(f\"ev: {format(calculate_ev(ds_lim, odds_label, label), '.3f')}\")\n",
        "    print_percent_str(\"increases wins\", len(increase_wins), len(increases))\n",
        "    print(f\"increase winning avg odds: {format(increase_winning_odds, '.3f')}\")\n",
        "    print(f\"increase winning ev: {format(calculate_ev_math(increase_win_rate, increase_winning_odds), '.3f')}\")\n",
        "    # print(f\"ev: {format(calculate_ev(increases, odds_label, label), '.3f')}\")\n",
        "    print_percent_str(\"decreases wins\", len(decrease_wins), len(decreases))\n",
        "    print(f\"decrease winning avg odds: {format(decrease_winning_odds, '.3f')}\")\n",
        "    print(f\"decrease winning ev: {format(calculate_ev_math(decrease_win_rate, decrease_winning_odds), '.3f')}\")\n",
        "    # print(f\"ev: {format(calculate_ev(decreases, odds_label, label), '.3f')}\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "  # dataset_max = dataset[dataset[\"OP_MAX_ODD\"] == label]\n",
        "  # dataset_mid = dataset[dataset[\"OP_MID_ODD\"] == label]\n",
        "  # dataset_min = dataset[dataset[\"OP_MIN_ODD\"] == label]\n",
        "\n",
        "  # max_increases = dataset_max[dataset_max[\"DIFF1\"] >= 0]\n",
        "  # max_decreases = dataset_max[dataset_max[\"DIFF1\"] <= 0]"
      ],
      "metadata": {
        "id": "fS-A8PGDO6wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVsi4-cyuHUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examine_changes(al_train_lm, \"H\", True)\n",
        "examine_changes(al_train_lm, \"H\", False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn0OpyTgmrvQ",
        "outputId": "7dda1b4d-e574-4e91-f840-30543092be80",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OP_MAX_ODD stats for H\n",
            "num increases: 61.364%      270/440\n",
            "num decreases: 38.636%      170/440\n",
            "total wins: 21.591%      95/440\n",
            "total winning avg odds: 4.845\n",
            "total winning ev: 0.046\n",
            "increases wins: 21.481%      58/270\n",
            "increase winning avg odds: 4.889\n",
            "increase winning ev: 0.050\n",
            "decreases wins: 21.765%      37/170\n",
            "decrease winning avg odds: 4.801\n",
            "decrease winning ev: 0.045\n",
            "\n",
            "\n",
            "OP_MID_ODD stats for H\n",
            "num increases: 57.087%      145/254\n",
            "num decreases: 42.913%      109/254\n",
            "total wins: 28.346%      72/254\n",
            "total winning avg odds: 2.931\n",
            "total winning ev: -0.169\n",
            "increases wins: 25.517%      37/145\n",
            "increase winning avg odds: 2.967\n",
            "increase winning ev: -0.243\n",
            "decreases wins: 32.110%      35/109\n",
            "decrease winning avg odds: 2.895\n",
            "decrease winning ev: -0.070\n",
            "\n",
            "\n",
            "OP_MIN_ODD stats for H\n",
            "num increases: 53.381%      900/1686\n",
            "num decreases: 46.619%      786/1686\n",
            "total wins: 55.694%      939/1686\n",
            "total winning avg odds: 1.758\n",
            "total winning ev: -0.021\n",
            "increases wins: 52.556%      473/900\n",
            "increase winning avg odds: 1.721\n",
            "increase winning ev: -0.096\n",
            "decreases wins: 59.288%      466/786\n",
            "decrease winning avg odds: 1.795\n",
            "decrease winning ev: 0.064\n",
            "\n",
            "\n",
            "OP_MAX_ODD stats for H\n",
            "num increases: 61.364%      270/440\n",
            "num decreases: 38.636%      170/440\n",
            "total wins: 21.591%      95/440\n",
            "total winning avg odds: 4.908\n",
            "total winning ev: 0.060\n",
            "increases wins: 21.481%      58/270\n",
            "increase winning avg odds: 5.726\n",
            "increase winning ev: 0.230\n",
            "decreases wins: 21.765%      37/170\n",
            "decrease winning avg odds: 4.091\n",
            "decrease winning ev: -0.110\n",
            "\n",
            "\n",
            "OP_MID_ODD stats for H\n",
            "num increases: 57.087%      145/254\n",
            "num decreases: 42.913%      109/254\n",
            "total wins: 28.346%      72/254\n",
            "total winning avg odds: 2.941\n",
            "total winning ev: -0.166\n",
            "increases wins: 25.517%      37/145\n",
            "increase winning avg odds: 3.289\n",
            "increase winning ev: -0.161\n",
            "decreases wins: 32.110%      35/109\n",
            "decrease winning avg odds: 2.593\n",
            "decrease winning ev: -0.167\n",
            "\n",
            "\n",
            "OP_MIN_ODD stats for H\n",
            "num increases: 53.381%      900/1686\n",
            "num decreases: 46.619%      786/1686\n",
            "total wins: 55.694%      939/1686\n",
            "total winning avg odds: 1.761\n",
            "total winning ev: -0.019\n",
            "increases wins: 52.556%      473/900\n",
            "increase winning avg odds: 1.847\n",
            "increase winning ev: -0.029\n",
            "decreases wins: 59.288%      466/786\n",
            "decrease winning avg odds: 1.674\n",
            "decrease winning ev: -0.007\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "best times to bet:\n",
        "\n",
        "H:\n",
        "* max: 4.5% returns on OP, 6% on CP\n",
        "  * increase:\n",
        "      * OP: 5%\n",
        "      * CP: 23%\n",
        "  * decrease:\n",
        "      * OP: 4.5%\n",
        "      * CP: -11%\n",
        "* mid: -17% on OP, -16.6% on CP\n",
        "  * increase:\n",
        "      * OP: -24.3%\n",
        "      * CP: -16.1%\n",
        "  * decrease:\n",
        "      * OP: -7%\n",
        "      * CP: -16.7%\n",
        "* min: -2.1% on OP, -1.9 on CP\n",
        "  * increase:\n",
        "      * OP: -9.6%\n",
        "      * CP: -2.9%\n",
        "  * decrease:\n",
        "      * OP: 6.4%\n",
        "      * CP: -0.7%\n",
        "\n",
        "H strategy:\n",
        "* max: bet on opening increase/decrease and closing increase\n",
        "* mid: don't bet\n",
        "* min: bet on opening decrease\n",
        "\n",
        "D:\n",
        "\n",
        "* max: 3.4% for OP, 4.17% for CP\n",
        "    * increase:\n",
        "      * OP: -3%\n",
        "      * CP: 0.78%\n",
        "    * decrease:\n",
        "      * OP: 12%\n",
        "      * CP: 9.167%\n",
        "* mid: -6.26% for OP,\n",
        "    * increase:\n",
        "      * OP: -18.85%\n",
        "      * CP: -12.35%\n",
        "    * decrease:\n",
        "      * OP: 10.26%\n",
        "      * CP: 3.8%\n",
        "* min: doesnt happen\n",
        "\n",
        "D strategy:\n",
        "* max: bet on opening/closing decrease\n",
        "* mid: bet on opening decrease (risky) or closing decrease (safer)\n",
        "* min: doesn't happen\n",
        "\n",
        "A:\n",
        "\n",
        "* max: -23% on OP, -21.135%\n",
        "    * increase:\n",
        "      * OP: -19%\n",
        "      * CP: -7.89%\n",
        "    * decrease:\n",
        "      * OP: -27%\n",
        "      * CP: -34%\n",
        "* mid: -5.12% for OP, -3.34%\n",
        "    * increase:\n",
        "      * OP: -14%\n",
        "      * CP: -4%\n",
        "    * decrease:\n",
        "      * OP: 7%\n",
        "      * CP: -1.3%\n",
        "* min: -8.06% for OP, -8%\n",
        "    * increase:\n",
        "      * OP: -16.35%\n",
        "      * CP: -9.36%\n",
        "    * decrease:\n",
        "      * OP: 1.1%\n",
        "      * CP: -7%\n",
        "\n",
        "A strategy:\n",
        "* max: dont bet\n",
        "* mid: dont bet\n",
        "* min: dont bet\n"
      ],
      "metadata": {
        "id": "MMgr2dBlNACN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "at what frequency does each result occur?\n",
        "* H: 1208/2660, 45.4%\n",
        "* D: 702/2660, 26.3%\n",
        "* A: 750/2660, 28.1%\n",
        "\n",
        "what are the odds when each result wins?\n",
        "Home:\n",
        "* OP: 2.09, std 1.1\n",
        "* odds rates: 0.200978\t0.351147 0.447876\n",
        "* home win rates: 0.387183\t0.267947\t0.320937\n",
        "* away win rates: 0.313560\t0.281142\t0.386681\n",
        "\n",
        "which of max/mid/min are each result's odds when they win?"
      ],
      "metadata": {
        "id": "suYbJdhrDZ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_ev(dataset, is_opening):\n",
        "  earnings = 0\n",
        "  op1_ev = 0\n",
        "  opx_ev = 0\n",
        "  op2_ev = 0\n",
        "  for index, row in dataset.iterrows():\n",
        "      op1_result = (row[\"OP1_AVG\"] - 1) if row[\"result\"] == \"H\" else -1\n",
        "      opx_result = (row[\"OPX_AVG\"] - 1) if row[\"result\"] == \"D\" else -1\n",
        "      op2_result = (row[\"OP2_AVG\"] - 1) if row[\"result\"] == \"A\" else -1\n",
        "      op1_ev += op1_result\n",
        "      opx_ev += opx_result\n",
        "      op2_ev += op2_result\n",
        "      earnings += op1_result + opx_result + op2_result\n",
        "  print(f\"total earnings: {earnings}/{len(dataset)}, {earnings/len(dataset)}\")\n",
        "  print(f\"op1_ev: {op1_ev}\")\n",
        "  print(f\"opx_ev: {opx_ev}\")\n",
        "  print(f\"op2_ev: {op2_ev}\")"
      ],
      "metadata": {
        "id": "2lYV1qFvmKge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_all_ev(al_train_lm, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVvMfbfrm-ho",
        "outputId": "699cb011-b73c-4867-a21d-73b7ea09eeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total earnings: -516.8730000000006/2380, -0.21717352941176496\n",
            "op1_ev: -57.26000000000002\n",
            "opx_ev: -88.348\n",
            "op2_ev: -371.26500000000016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minh_lm = al_train_lm[al_train_lm[\"OP_MIN_ODD\"] == \"H\"]\n",
        "minh_lm\n"
      ],
      "metadata": {
        "id": "PKjaSHjasOMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trends analysis"
      ],
      "metadata": {
        "id": "E1eeDAFsBL8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def examine_trends(dataset):\n",
        "  diff_label = \"DIFF1\"\n",
        "  label = \"H\"\n",
        "  num_a = dataset[\"OP_MAX_ODD\"].value_counts()[\"A\"]\n",
        "  num_d = dataset[\"OP_MAX_ODD\"].value_counts()[\"D\"]\n",
        "  total_len = len(dataset)\n",
        "  print_percent_str(\"max odd is a\", num_a, total_len)\n",
        "  print_percent_str(\"max odd is d\", num_d, total_len)\n",
        "\n",
        "  increases = dataset[dataset[diff_label] >= 0]\n",
        "  decreases = dataset[dataset[diff_label] < 0]\n",
        "  print_percent_str(\"num increases\", len(increases), total_len)\n",
        "  print_percent_str(\"num decreases\", len(decreases), total_len)\n",
        "  print(\"\")\n",
        "\n",
        "  num_a_increases = increases[\"OP_MAX_ODD\"].value_counts()[\"A\"]\n",
        "  num_d_increases = increases[\"OP_MAX_ODD\"].value_counts()[\"D\"]\n",
        "  print_percent_str(\"num a increases / increases\", num_a_increases, len(increases))\n",
        "  print_percent_str(\"num d increases / increases\", num_d_increases, len(increases))\n",
        "\n",
        "  num_a_decreases = decreases[\"OP_MAX_ODD\"].value_counts()[\"A\"]\n",
        "  num_d_decreases = decreases[\"OP_MAX_ODD\"].value_counts()[\"D\"]\n",
        "  print_percent_str(\"num a decreases / decreases\", num_a_decreases, len(decreases))\n",
        "  print_percent_str(\"num d decreases / decreases\", num_d_decreases, len(decreases))\n",
        "  print(\"\")\n",
        "  # number of times a is an increase / d is an increase\n",
        "  print_percent_str(\"num a increases / total a's\", num_a_increases, num_a)\n",
        "  print_percent_str(\"num d increases / total d's\", num_d_increases, num_d)\n",
        "  print_percent_str(\"num a decreases / total a's\", num_a_decreases, num_a)\n",
        "  print_percent_str(\"num d decreases / total d's\", num_d_decreases, num_d)\n",
        "\n",
        "  adh = dataset[dataset[\"OP_MAX_ODD\"] == \"A\"]\n",
        "  dah = dataset[dataset[\"OP_MAX_ODD\"] == \"D\"]\n",
        "  # return adh\n",
        "  # ev when A D H\n",
        "  evA = calculate_ev(adh, \"OP1_AVG\", label)\n",
        "  evD = calculate_ev(dah, \"OP1_AVG\", label)\n",
        "  print(f\"evA: {format(evA, '.3f')}\")\n",
        "  print(f\"evD: {format(evD, '.3f')}\")\n",
        "\n",
        "\n",
        "  # ev when D A H\n",
        "\n",
        "  # increase_wins = increases[increases[\"result\"] == label]\n",
        "  # decrease_wins = decreases[decreases[\"result\"] == label]\n",
        "  # increase_num ="
      ],
      "metadata": {
        "id": "h_fuY6D-scHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_odd_label_from_symbol(symbol, is_opening):\n",
        "  if symbol == \"H\":\n",
        "    return \"OP1_AVG\" if is_opening else \"CP1_AVG\"\n",
        "  elif symbol == \"D\":\n",
        "    return \"OPX_AVG\" if is_opening else \"CPX_AVG\"\n",
        "  else:\n",
        "    return \"OP2_AVG\" if is_opening else \"CP2_AVG\""
      ],
      "metadata": {
        "id": "e9JWijiW3pe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def examine_combos(dataset, limit_to_profitable):\n",
        "  for max_symbol, mid_symbol, min_symbol in itertools.permutations([\"H\", \"D\", \"A\"]):\n",
        "    ds = dataset[(dataset[\"OP_MAX_ODD\"] == max_symbol) & (dataset[\"OP_MID_ODD\"] == mid_symbol) & (dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "    print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} frequency\", len(ds), len(dataset))\n",
        "    # add increases and increases\n",
        "    if (len(ds) == 0):\n",
        "      print(f\"no len for {[max_symbol, mid_symbol, min_symbol]}\")\n",
        "      continue\n",
        "\n",
        "    for symbol in [max_symbol, mid_symbol, min_symbol]:\n",
        "      if symbol == \"H\":\n",
        "        diff = \"DIFF1\"\n",
        "      elif symbol == \"D\":\n",
        "        diff = \"DIFFX\"\n",
        "      else:\n",
        "        diff = \"DIFF2\"\n",
        "      increases = ds[ds[diff] > 0]\n",
        "      decreases = ds[ds[diff] <= 0]\n",
        "      print(\"\")\n",
        "      print(f\"{max_symbol} {mid_symbol} {min_symbol} for {symbol}\")\n",
        "      print_percent_str(f\"num increase / total\", len(increases), len(dataset))\n",
        "      print_percent_str(f\"num increase / odds\", len(increases), len(ds))\n",
        "      print_percent_str(f\"num decrease / total\", len(decreases), len(dataset))\n",
        "      print_percent_str(f\"num decrease / odds\", len(decreases), len(ds))\n",
        "      op_was_profitable = True\n",
        "      for is_opening in [True, False]:\n",
        "        print(\"\")\n",
        "        oc_str = \"OP\" if is_opening else \"CP\"\n",
        "        odds_label = get_odd_label_from_symbol(symbol, is_opening)\n",
        "        ev = calculate_ev(ds, odds_label, symbol)\n",
        "        increase_ev = calculate_ev(increases, odds_label, symbol)\n",
        "        decrease_ev = calculate_ev(decreases, odds_label, symbol)\n",
        "        if (((not is_opening and not op_was_profitable) or is_opening) and limit_to_profitable and (increase_ev < 0 and decrease_ev < 0)):\n",
        "          print(f\"{max_symbol} {mid_symbol} {min_symbol} for {symbol}, {oc_str} not profitable\")\n",
        "          if (is_opening):\n",
        "            op_was_profitable = False\n",
        "          continue;\n",
        "        print(f\"ev for {oc_str}: {format(ev * 100, '.2f')}%\")\n",
        "        print(f\"increase ev for {oc_str} = {format(increase_ev * 100, '.2f')}%\")\n",
        "        print(f\"decrease ev for {oc_str} = {format(decrease_ev * 100, '.2f')}%\")\n",
        "        print(\"\")\n",
        "        print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} win freq for {symbol}\", len(ds[ds[\"result\"] == symbol]), len(ds))\n",
        "\n",
        "        print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} increase wins/increases\", len(increases[increases[\"result\"] == symbol]), len(increases))\n",
        "        print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} increase wins/odds\", len(increases[increases[\"result\"] == symbol]), len(ds))\n",
        "\n",
        "        print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} decrease wins/decreases\", len(decreases[decreases[\"result\"] == symbol]), len(decreases))\n",
        "        print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} decrease wins/odds\", len(decreases[decreases[\"result\"] == symbol]), len(ds))\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"\")\n"
      ],
      "metadata": {
        "id": "erwmCKnK3EK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_profitable_combos(dataset, only_profitable):\n",
        "  season = dataset[\"season\"].iloc[0]\n",
        "  print(f\"season: {season}\")\n",
        "  combo_rows = []\n",
        "\n",
        "  for max_symbol, mid_symbol, min_symbol in itertools.permutations([\"H\", \"D\", \"A\"]):\n",
        "    ds = dataset[(dataset[\"OP_MAX_ODD\"] == max_symbol) & (dataset[\"OP_MID_ODD\"] == mid_symbol) & (dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "    print_percent_str(f\"{max_symbol} {mid_symbol} {min_symbol} frequency\", len(ds), len(dataset))\n",
        "    # add increases and increases\n",
        "    if (len(ds) == 0):\n",
        "      print(f\"no len for {[max_symbol, mid_symbol, min_symbol]}\")\n",
        "      continue\n",
        "\n",
        "    for symbol in [max_symbol, mid_symbol, min_symbol]:\n",
        "      if symbol == \"H\":\n",
        "        diff = \"DIFF1\"\n",
        "      elif symbol == \"D\":\n",
        "        diff = \"DIFFX\"\n",
        "      else:\n",
        "        diff = \"DIFF2\"\n",
        "      increases = ds[ds[diff] > 0]\n",
        "      decreases = ds[ds[diff] <= 0]\n",
        "\n",
        "      ds_wins = len(ds[ds[\"result\"] == symbol])\n",
        "      print(f\"{max_symbol} {mid_symbol} {min_symbol} for {symbol}\")\n",
        "      for is_opening in [True, False]:\n",
        "        oc_str = \"OP\" if is_opening else \"CP\"\n",
        "        # print(\"\")\n",
        "        odds_label = get_odd_label_from_symbol(symbol, is_opening)\n",
        "        ev = calculate_ev(ds, odds_label, symbol)\n",
        "        # print(f\"ev for {oc_str}: {format(ev * 100, '.2f')}%\")\n",
        "        for is_increase in [True, False]:\n",
        "          inc_dec_str = \"increasing\" if True else \"decreasing\"\n",
        "          dir_ds = increases if is_increase else decreases\n",
        "          dir_ev = calculate_ev(dir_ds, odds_label, symbol)\n",
        "          # print(f\" ev for {inc_dec_str} = {format(dir_ev * 100, '.2f')}%\")\n",
        "\n",
        "          dir_wins = len(dir_ds[dir_ds[\"result\"] == symbol])\n",
        "          if (only_profitable and dir_ev < 0):\n",
        "            continue;\n",
        "          combo_stat = get_combo_stat(\n",
        "              season=season,\n",
        "              max_symbol=max_symbol,\n",
        "              mid_symbol=mid_symbol,\n",
        "              min_symbol=min_symbol,\n",
        "              symbol=symbol,\n",
        "              is_opening=is_opening,\n",
        "              is_increase=is_increase,\n",
        "              bd_ds=ds,\n",
        "              bd_ev=ev,\n",
        "              bd_wins=ds_wins,\n",
        "              dir_ds=dir_ds,\n",
        "              dir_ev=dir_ev,\n",
        "              dir_wins=dir_wins)\n",
        "          combo_rows.append(combo_stat)\n",
        "\n",
        "  return combo_rows\n",
        "\n",
        "def get_combo_stat(season, max_symbol, mid_symbol, min_symbol, symbol, is_opening, is_increase, bd_ds, bd_ev, bd_wins, dir_ds, dir_ev, dir_wins):\n",
        "    return {\n",
        "        \"combo_key\": f\"{max_symbol},{mid_symbol},{min_symbol};s:{symbol};o:{is_opening};i:{is_increase}\",\n",
        "        \"season\": season,\n",
        "        \"max_symbol\": max_symbol,\n",
        "        \"mid_symbol\": mid_symbol,\n",
        "        \"min_symbol\": min_symbol,\n",
        "        \"current_symbol\": symbol,\n",
        "        \"is_opening\": is_opening,\n",
        "        \"is_increase\": is_increase,\n",
        "        \"ds_is_empty\": (len(bd_ds) == 0),\n",
        "        # \"bd_ds\": bd_ds, # both dirs (increase + decrease but still only opening or closing)\n",
        "        \"bd_ev\": bd_ev,\n",
        "        \"bd_wins\": bd_wins,\n",
        "        \"bd_len\": len(bd_ds),\n",
        "        # \"dir_ds\": dir_ds,\n",
        "        \"dir_ev\": dir_ev,\n",
        "        \"dir_of_bd\": len(dir_ds)/len(bd_ds),\n",
        "        \"dir_wins\": dir_wins,\n",
        "        \"dir_len\": len(dir_ds),\n",
        "        \"profitable\": dir_ev > 0\n",
        "      }\n",
        "\n",
        "def print_combo_stat(combo_stat):\n",
        "  print(f\"combo_key: {combo_stat['combo_key']} \")\n",
        "  print(f\"bd_ev: {combo_stat['bd_ev']}; dir_ev: {combo_stat['dir_ev']}\")\n",
        "  print(f\"bd_wins: {combo_stat['bd_wins']}; dir_wins: {combo_stat['dir_wins']}\")\n"
      ],
      "metadata": {
        "id": "A5dp5yjg-bP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine_trends(minh_lm)\n",
        "examine_combos(al_train_lm, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4keLpfa05yfD",
        "outputId": "02d2c636-95f8-4085-b662-ac4658d9d9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H D A frequency: 18.487%      440.000/2380\n",
            "\n",
            "H D A for H\n",
            "num increase / total: 11.345%      270.000/2380\n",
            "num increase / odds: 61.364%      270.000/440\n",
            "num decrease / total: 7.143%      170.000/2380\n",
            "num decrease / odds: 38.636%      170.000/440\n",
            "\n",
            "ev for OP: 4.82%\n",
            "increase ev for OP = 5.03%\n",
            "decrease ev for OP = 4.49%\n",
            "\n",
            "H D A win freq for H: 21.591%      95.000/440\n",
            "H D A increase wins/increases: 21.481%      58.000/270\n",
            "H D A increase wins/odds: 13.182%      58.000/440\n",
            "H D A decrease wins/decreases: 21.765%      37.000/170\n",
            "H D A decrease wins/odds: 8.409%      37.000/440\n",
            "\n",
            "ev for CP: 9.87%\n",
            "increase ev for CP = 22.99%\n",
            "decrease ev for CP = -10.96%\n",
            "\n",
            "H D A win freq for H: 21.591%      95.000/440\n",
            "H D A increase wins/increases: 21.481%      58.000/270\n",
            "H D A increase wins/odds: 13.182%      58.000/440\n",
            "H D A decrease wins/decreases: 21.765%      37.000/170\n",
            "H D A decrease wins/odds: 8.409%      37.000/440\n",
            "\n",
            "H D A for D\n",
            "num increase / total: 11.261%      268.000/2380\n",
            "num increase / odds: 60.909%      268.000/440\n",
            "num decrease / total: 7.227%      172.000/2380\n",
            "num decrease / odds: 39.091%      172.000/440\n",
            "\n",
            "ev for OP: -3.81%\n",
            "increase ev for OP = -19.43%\n",
            "decrease ev for OP = 20.55%\n",
            "\n",
            "H D A win freq for D: 25.227%      111.000/440\n",
            "H D A increase wins/increases: 20.896%      56.000/268\n",
            "H D A increase wins/odds: 12.727%      56.000/440\n",
            "H D A decrease wins/decreases: 31.977%      55.000/172\n",
            "H D A decrease wins/odds: 12.500%      55.000/440\n",
            "\n",
            "ev for CP: -2.64%\n",
            "increase ev for CP = -12.59%\n",
            "decrease ev for CP = 12.86%\n",
            "\n",
            "H D A win freq for D: 25.227%      111.000/440\n",
            "H D A increase wins/increases: 20.896%      56.000/268\n",
            "H D A increase wins/odds: 12.727%      56.000/440\n",
            "H D A decrease wins/decreases: 31.977%      55.000/172\n",
            "H D A decrease wins/odds: 12.500%      55.000/440\n",
            "\n",
            "H D A for A\n",
            "num increase / total: 9.370%      223.000/2380\n",
            "num increase / odds: 50.682%      223.000/440\n",
            "num decrease / total: 9.118%      217.000/2380\n",
            "num decrease / odds: 49.318%      217.000/440\n",
            "\n",
            "H D A for A, OP not profitable\n",
            "\n",
            "H D A for A, CP not profitable\n",
            "\n",
            "\n",
            "H A D frequency: 0.000%      0.000/2380\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 10.672%      254.000/2380\n",
            "\n",
            "D H A for D\n",
            "num increase / total: 6.597%      157.000/2380\n",
            "num increase / odds: 61.811%      157.000/254\n",
            "num decrease / total: 4.076%      97.000/2380\n",
            "num decrease / odds: 38.189%      97.000/254\n",
            "\n",
            "ev for OP: 4.54%\n",
            "increase ev for OP = -11.57%\n",
            "decrease ev for OP = 30.63%\n",
            "\n",
            "D H A win freq for D: 31.890%      81.000/254\n",
            "D H A increase wins/increases: 26.752%      42.000/157\n",
            "D H A increase wins/odds: 16.535%      42.000/254\n",
            "D H A decrease wins/decreases: 40.206%      39.000/97\n",
            "D H A decrease wins/odds: 15.354%      39.000/254\n",
            "\n",
            "ev for CP: 6.03%\n",
            "increase ev for CP = -7.28%\n",
            "decrease ev for CP = 27.57%\n",
            "\n",
            "D H A win freq for D: 31.890%      81.000/254\n",
            "D H A increase wins/increases: 26.752%      42.000/157\n",
            "D H A increase wins/odds: 16.535%      42.000/254\n",
            "D H A decrease wins/decreases: 40.206%      39.000/97\n",
            "D H A decrease wins/odds: 15.354%      39.000/254\n",
            "\n",
            "D H A for H\n",
            "num increase / total: 6.008%      143.000/2380\n",
            "num increase / odds: 56.299%      143.000/254\n",
            "num decrease / total: 4.664%      111.000/2380\n",
            "num decrease / odds: 43.701%      111.000/254\n",
            "\n",
            "D H A for H, OP not profitable\n",
            "\n",
            "D H A for H, CP not profitable\n",
            "\n",
            "D H A for A\n",
            "num increase / total: 5.714%      136.000/2380\n",
            "num increase / odds: 53.543%      136.000/254\n",
            "num decrease / total: 4.958%      118.000/2380\n",
            "num decrease / odds: 46.457%      118.000/254\n",
            "\n",
            "ev for OP: -3.94%\n",
            "increase ev for OP = -16.44%\n",
            "decrease ev for OP = 10.48%\n",
            "\n",
            "D H A win freq for A: 39.764%      101.000/254\n",
            "D H A increase wins/increases: 34.559%      47.000/136\n",
            "D H A increase wins/odds: 18.504%      47.000/254\n",
            "D H A decrease wins/decreases: 45.763%      54.000/118\n",
            "D H A decrease wins/odds: 21.260%      54.000/254\n",
            "\n",
            "ev for CP: -4.82%\n",
            "increase ev for CP = -8.51%\n",
            "decrease ev for CP = -0.58%\n",
            "\n",
            "D H A win freq for A: 39.764%      101.000/254\n",
            "D H A increase wins/increases: 34.559%      47.000/136\n",
            "D H A increase wins/odds: 18.504%      47.000/254\n",
            "D H A decrease wins/decreases: 45.763%      54.000/118\n",
            "D H A decrease wins/odds: 21.260%      54.000/254\n",
            "\n",
            "\n",
            "D A H frequency: 15.378%      366.000/2380\n",
            "\n",
            "D A H for D\n",
            "num increase / total: 8.067%      192.000/2380\n",
            "num increase / odds: 52.459%      192.000/366\n",
            "num decrease / total: 7.311%      174.000/2380\n",
            "num decrease / odds: 47.541%      174.000/366\n",
            "\n",
            "ev for OP: 2.76%\n",
            "increase ev for OP = 5.58%\n",
            "decrease ev for OP = -0.35%\n",
            "\n",
            "D A H win freq for D: 31.694%      116.000/366\n",
            "D A H increase wins/increases: 32.292%      62.000/192\n",
            "D A H increase wins/odds: 16.940%      62.000/366\n",
            "D A H decrease wins/decreases: 31.034%      54.000/174\n",
            "D A H decrease wins/odds: 14.754%      54.000/366\n",
            "\n",
            "ev for CP: 3.28%\n",
            "increase ev for CP = 8.95%\n",
            "decrease ev for CP = -2.97%\n",
            "\n",
            "D A H win freq for D: 31.694%      116.000/366\n",
            "D A H increase wins/increases: 32.292%      62.000/192\n",
            "D A H increase wins/odds: 16.940%      62.000/366\n",
            "D A H decrease wins/decreases: 31.034%      54.000/174\n",
            "D A H decrease wins/odds: 14.754%      54.000/366\n",
            "\n",
            "D A H for A\n",
            "num increase / total: 8.908%      212.000/2380\n",
            "num increase / odds: 57.923%      212.000/366\n",
            "num decrease / total: 6.471%      154.000/2380\n",
            "num decrease / odds: 42.077%      154.000/366\n",
            "\n",
            "ev for OP: -5.10%\n",
            "increase ev for OP = -14.55%\n",
            "decrease ev for OP = 7.92%\n",
            "\n",
            "D A H win freq for A: 31.694%      116.000/366\n",
            "D A H increase wins/increases: 28.302%      60.000/212\n",
            "D A H increase wins/odds: 16.393%      60.000/366\n",
            "D A H decrease wins/decreases: 36.364%      56.000/154\n",
            "D A H decrease wins/odds: 15.301%      56.000/366\n",
            "\n",
            "ev for CP: -2.97%\n",
            "increase ev for CP = -4.18%\n",
            "decrease ev for CP = -1.31%\n",
            "\n",
            "D A H win freq for A: 31.694%      116.000/366\n",
            "D A H increase wins/increases: 28.302%      60.000/212\n",
            "D A H increase wins/odds: 16.393%      60.000/366\n",
            "D A H decrease wins/decreases: 36.364%      56.000/154\n",
            "D A H decrease wins/odds: 15.301%      56.000/366\n",
            "\n",
            "D A H for H\n",
            "num increase / total: 8.151%      194.000/2380\n",
            "num increase / odds: 53.005%      194.000/366\n",
            "num decrease / total: 7.227%      172.000/2380\n",
            "num decrease / odds: 46.995%      172.000/366\n",
            "\n",
            "ev for OP: -11.95%\n",
            "increase ev for OP = -25.99%\n",
            "decrease ev for OP = 3.88%\n",
            "\n",
            "D A H win freq for H: 36.612%      134.000/366\n",
            "D A H increase wins/increases: 30.412%      59.000/194\n",
            "D A H increase wins/odds: 16.120%      59.000/366\n",
            "D A H decrease wins/decreases: 43.605%      75.000/172\n",
            "D A H decrease wins/odds: 20.492%      75.000/366\n",
            "\n",
            "ev for CP: -12.41%\n",
            "increase ev for CP = -19.57%\n",
            "decrease ev for CP = -4.33%\n",
            "\n",
            "D A H win freq for H: 36.612%      134.000/366\n",
            "D A H increase wins/increases: 30.412%      59.000/194\n",
            "D A H increase wins/odds: 16.120%      59.000/366\n",
            "D A H decrease wins/decreases: 43.605%      75.000/172\n",
            "D A H decrease wins/odds: 20.492%      75.000/366\n",
            "\n",
            "\n",
            "A H D frequency: 0.000%      0.000/2380\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 55.462%      1320.000/2380\n",
            "\n",
            "A D H for A\n",
            "num increase / total: 32.941%      784.000/2380\n",
            "num increase / odds: 59.394%      784.000/1320\n",
            "num decrease / total: 22.521%      536.000/2380\n",
            "num decrease / odds: 40.606%      536.000/1320\n",
            "\n",
            "A D H for A, OP not profitable\n",
            "\n",
            "A D H for A, CP not profitable\n",
            "\n",
            "A D H for D\n",
            "num increase / total: 30.630%      729.000/2380\n",
            "num increase / odds: 55.227%      729.000/1320\n",
            "num decrease / total: 24.832%      591.000/2380\n",
            "num decrease / odds: 44.773%      591.000/1320\n",
            "\n",
            "ev for OP: -7.06%\n",
            "increase ev for OP = -18.53%\n",
            "decrease ev for OP = 7.08%\n",
            "\n",
            "A D H win freq for D: 23.636%      312.000/1320\n",
            "A D H increase wins/increases: 21.125%      154.000/729\n",
            "A D H increase wins/odds: 11.667%      154.000/1320\n",
            "A D H decrease wins/decreases: 26.734%      158.000/591\n",
            "A D H decrease wins/odds: 11.970%      158.000/1320\n",
            "\n",
            "ev for CP: -6.26%\n",
            "increase ev for CP = -12.14%\n",
            "decrease ev for CP = 0.98%\n",
            "\n",
            "A D H win freq for D: 23.636%      312.000/1320\n",
            "A D H increase wins/increases: 21.125%      154.000/729\n",
            "A D H increase wins/odds: 11.667%      154.000/1320\n",
            "A D H decrease wins/decreases: 26.734%      158.000/591\n",
            "A D H decrease wins/odds: 11.970%      158.000/1320\n",
            "\n",
            "A D H for H\n",
            "num increase / total: 29.412%      700.000/2380\n",
            "num increase / odds: 53.030%      700.000/1320\n",
            "num decrease / total: 26.050%      620.000/2380\n",
            "num decrease / odds: 46.970%      620.000/1320\n",
            "\n",
            "ev for OP: 0.62%\n",
            "increase ev for OP = -5.31%\n",
            "decrease ev for OP = 7.32%\n",
            "\n",
            "A D H win freq for H: 60.985%      805.000/1320\n",
            "A D H increase wins/increases: 58.429%      409.000/700\n",
            "A D H increase wins/odds: 30.985%      409.000/1320\n",
            "A D H decrease wins/decreases: 63.871%      396.000/620\n",
            "A D H decrease wins/odds: 30.000%      396.000/1320\n",
            "\n",
            "ev for CP: 1.01%\n",
            "increase ev for CP = 1.46%\n",
            "decrease ev for CP = 0.51%\n",
            "\n",
            "A D H win freq for H: 60.985%      805.000/1320\n",
            "A D H increase wins/increases: 58.429%      409.000/700\n",
            "A D H increase wins/odds: 30.985%      409.000/1320\n",
            "A D H decrease wins/decreases: 63.871%      396.000/620\n",
            "A D H decrease wins/odds: 30.000%      396.000/1320\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def examine_combos_over_seasons(dataset_list, only_profitable):\n",
        "  combo_rows = []\n",
        "  for dataset in dataset_list:\n",
        "    combo_rows = combo_rows + get_profitable_combos(dataset, only_profitable)\n",
        "  return pd.DataFrame.from_dict(combo_rows).sort_values(\"combo_key\").reset_index(drop=True)\n",
        "\n",
        "def split_dataset_by_season(dataset):\n",
        "  return [v for k, v in dataset.groupby('season')]"
      ],
      "metadata": {
        "id": "mwtzuMdYlyUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list = split_dataset_by_season(al_train_lm)\n",
        "len(dataset_list)\n",
        "# single_ds = dataset_list[:2]\n",
        "profit_combos = examine_combos_over_seasons(dataset_list, False)\n",
        "profit_combos\n",
        "\n",
        "\n",
        "\n",
        "# profit_combos.groupby(\"combo_key\")\n",
        "# single_ds\n",
        "# pcs = get_profitable_combos(single_ds)\n",
        "# pc_df = pd.DataFrame.from_dict(pcs)\n",
        "# pc_df\n",
        "# print(len(pcs))\n",
        "# pcs[next(iter(pcs))]\n",
        "# print_combo_stat(next(iter(pcs))[0])\n",
        "# combo_dict = examine_combos_over_seasons(dataset_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "o3vwpYHGsv6F",
        "outputId": "5c845b47-a787-4167-99bd-1edcd70dd820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "season: 2015/2016\n",
            "H D A frequency: 18.235%      62/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 8.529%      29/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 18.824%      64/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 54.412%      185/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n",
            "season: 2016/2017\n",
            "H D A frequency: 18.529%      63/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 10.294%      35/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 15.882%      54/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 55.294%      188/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n",
            "season: 2017/2018\n",
            "H D A frequency: 16.176%      55/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 9.706%      33/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 16.765%      57/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 57.353%      195/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n",
            "season: 2018/2019\n",
            "H D A frequency: 14.706%      50/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 12.353%      42/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 18.235%      62/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 54.706%      186/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n",
            "season: 2019/2020\n",
            "H D A frequency: 17.353%      59/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 10.588%      36/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 13.235%      45/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 58.824%      200/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n",
            "season: 2020/2021\n",
            "H D A frequency: 24.118%      82/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 11.176%      38/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 10.588%      36/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 54.118%      184/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n",
            "season: 2021/2022\n",
            "H D A frequency: 20.294%      69/340\n",
            "H D A for H\n",
            "H D A for D\n",
            "H D A for A\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 12.059%      41/340\n",
            "D H A for D\n",
            "D H A for H\n",
            "D H A for A\n",
            "D A H frequency: 14.118%      48/340\n",
            "D A H for D\n",
            "D A H for A\n",
            "D A H for H\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 53.529%      182/340\n",
            "A D H for A\n",
            "A D H for D\n",
            "A D H for H\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     combo_key     season max_symbol mid_symbol min_symbol  \\\n",
              "0    A,D,H;s:A;o:False;i:False  2017/2018          A          D          H   \n",
              "1    A,D,H;s:A;o:False;i:False  2018/2019          A          D          H   \n",
              "2    A,D,H;s:A;o:False;i:False  2020/2021          A          D          H   \n",
              "3    A,D,H;s:A;o:False;i:False  2016/2017          A          D          H   \n",
              "4    A,D,H;s:A;o:False;i:False  2015/2016          A          D          H   \n",
              "..                         ...        ...        ...        ...        ...   \n",
              "331    H,D,A;s:H;o:True;i:True  2019/2020          H          D          A   \n",
              "332    H,D,A;s:H;o:True;i:True  2017/2018          H          D          A   \n",
              "333    H,D,A;s:H;o:True;i:True  2020/2021          H          D          A   \n",
              "334    H,D,A;s:H;o:True;i:True  2018/2019          H          D          A   \n",
              "335    H,D,A;s:H;o:True;i:True  2015/2016          H          D          A   \n",
              "\n",
              "    current_symbol  is_opening  is_increase  ds_is_empty     bd_ev  bd_wins  \\\n",
              "0                A       False        False        False -0.061877       34   \n",
              "1                A       False        False        False -0.003683       30   \n",
              "2                A       False        False        False -0.109272       28   \n",
              "3                A       False        False        False -0.490324       21   \n",
              "4                A       False        False        False -0.260049       29   \n",
              "..             ...         ...          ...          ...       ...      ...   \n",
              "331              H        True         True        False  0.084373       14   \n",
              "332              H        True         True        False  0.149345       12   \n",
              "333              H        True         True        False -0.317512       13   \n",
              "334              H        True         True        False  0.314160       13   \n",
              "335              H        True         True        False  0.264468       16   \n",
              "\n",
              "     bd_len    dir_ev  dir_of_bd  dir_wins  dir_len  profitable  \n",
              "0       195 -0.191646   0.405128        15       79       False  \n",
              "1       186 -0.337716   0.435484        11       81       False  \n",
              "2       184 -0.311261   0.478261        14       88       False  \n",
              "3       188 -0.576213   0.398936         8       75       False  \n",
              "4       185 -0.169341   0.443243        14       82       False  \n",
              "..      ...       ...        ...       ...      ...         ...  \n",
              "331      59  0.029024   0.694915        10       41        True  \n",
              "332      55  0.209231   0.472727         6       26        True  \n",
              "333      82 -0.283323   0.756098        11       62       False  \n",
              "334      50  0.488000   0.540000         7       27        True  \n",
              "335      62  0.226583   0.580645         8       36        True  \n",
              "\n",
              "[336 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a4c577c-4cb6-45ea-b7bc-8612b65710e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combo_key</th>\n",
              "      <th>season</th>\n",
              "      <th>max_symbol</th>\n",
              "      <th>mid_symbol</th>\n",
              "      <th>min_symbol</th>\n",
              "      <th>current_symbol</th>\n",
              "      <th>is_opening</th>\n",
              "      <th>is_increase</th>\n",
              "      <th>ds_is_empty</th>\n",
              "      <th>bd_ev</th>\n",
              "      <th>bd_wins</th>\n",
              "      <th>bd_len</th>\n",
              "      <th>dir_ev</th>\n",
              "      <th>dir_of_bd</th>\n",
              "      <th>dir_wins</th>\n",
              "      <th>dir_len</th>\n",
              "      <th>profitable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A,D,H;s:A;o:False;i:False</td>\n",
              "      <td>2017/2018</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.061877</td>\n",
              "      <td>34</td>\n",
              "      <td>195</td>\n",
              "      <td>-0.191646</td>\n",
              "      <td>0.405128</td>\n",
              "      <td>15</td>\n",
              "      <td>79</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A,D,H;s:A;o:False;i:False</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.003683</td>\n",
              "      <td>30</td>\n",
              "      <td>186</td>\n",
              "      <td>-0.337716</td>\n",
              "      <td>0.435484</td>\n",
              "      <td>11</td>\n",
              "      <td>81</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A,D,H;s:A;o:False;i:False</td>\n",
              "      <td>2020/2021</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.109272</td>\n",
              "      <td>28</td>\n",
              "      <td>184</td>\n",
              "      <td>-0.311261</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>14</td>\n",
              "      <td>88</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A,D,H;s:A;o:False;i:False</td>\n",
              "      <td>2016/2017</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.490324</td>\n",
              "      <td>21</td>\n",
              "      <td>188</td>\n",
              "      <td>-0.576213</td>\n",
              "      <td>0.398936</td>\n",
              "      <td>8</td>\n",
              "      <td>75</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A,D,H;s:A;o:False;i:False</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.260049</td>\n",
              "      <td>29</td>\n",
              "      <td>185</td>\n",
              "      <td>-0.169341</td>\n",
              "      <td>0.443243</td>\n",
              "      <td>14</td>\n",
              "      <td>82</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>2019/2020</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.084373</td>\n",
              "      <td>14</td>\n",
              "      <td>59</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>2017/2018</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.149345</td>\n",
              "      <td>12</td>\n",
              "      <td>55</td>\n",
              "      <td>0.209231</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>6</td>\n",
              "      <td>26</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>2020/2021</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.317512</td>\n",
              "      <td>13</td>\n",
              "      <td>82</td>\n",
              "      <td>-0.283323</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>11</td>\n",
              "      <td>62</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.314160</td>\n",
              "      <td>13</td>\n",
              "      <td>50</td>\n",
              "      <td>0.488000</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.264468</td>\n",
              "      <td>16</td>\n",
              "      <td>62</td>\n",
              "      <td>0.226583</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>8</td>\n",
              "      <td>36</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>336 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a4c577c-4cb6-45ea-b7bc-8612b65710e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a4c577c-4cb6-45ea-b7bc-8612b65710e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a4c577c-4cb6-45ea-b7bc-8612b65710e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4362b8f-1398-4fbb-b781-589cc189eee2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4362b8f-1398-4fbb-b781-589cc189eee2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4362b8f-1398-4fbb-b781-589cc189eee2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_078e790d-56a1-4164-afb6-05abbee12b99\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('profit_combos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_078e790d-56a1-4164-afb6-05abbee12b99 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('profit_combos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "profit_combos",
              "summary": "{\n  \"name\": \"profit_combos\",\n  \"rows\": 336,\n  \"fields\": [\n    {\n      \"column\": \"combo_key\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 48,\n        \"samples\": [\n          \"D,H,A;s:A;o:True;i:True\",\n          \"H,D,A;s:D;o:False;i:False\",\n          \"D,H,A;s:A;o:True;i:False\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"2017/2018\",\n          \"2018/2019\",\n          \"2019/2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A\",\n          \"D\",\n          \"H\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mid_symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"D\",\n          \"A\",\n          \"H\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"A\",\n          \"H\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"current_symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A\",\n          \"D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_opening\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_increase\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ds_is_empty\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bd_ev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16130641402037224,\n        \"min\": -0.517031914893617,\n        \"max\": 0.3754600000000002,\n        \"num_unique_values\": 168,\n        \"samples\": [\n          -0.22267741935483867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bd_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 8,\n        \"max\": 130,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bd_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61,\n        \"min\": 29,\n        \"max\": 200,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dir_ev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2679468038474841,\n        \"min\": -0.8027818181818182,\n        \"max\": 0.9463000000000001,\n        \"num_unique_values\": 336,\n        \"samples\": [\n          0.004377551020408039\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dir_of_bd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10996541537393452,\n        \"min\": 0.23170731707317074,\n        \"max\": 0.7682926829268293,\n        \"num_unique_values\": 141,\n        \"samples\": [\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dir_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 2,\n        \"max\": 66,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dir_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 7,\n        \"max\": 127,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"profitable\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "B9UJgwgawsbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = profit_combos.groupby([\"combo_key\", \"profitable\"])\n",
        "grouped_describe = grouped.describe().reset_index()\n",
        "grouped_describe.columns.tolist()\n",
        "kept_rows = grouped_describe[(grouped_describe[\"profitable\"] == True) & (grouped_describe[\"bd_ev\"][\"count\"] >= 5)]\n",
        "kept_rows\n",
        "grouped_describe[grouped_describe[\"combo_key\"].isin(kept_rows[\"combo_key\"])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "6ctugFmWtzLe",
        "outputId": "106a6e00-9442-48f9-cef0-301c4f8e6446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    combo_key profitable bd_ev                                \\\n",
              "                                         count      mean       std       min   \n",
              "18   A,D,H;s:H;o:True;i:False       True   7.0  0.006827  0.056452 -0.065744   \n",
              "31   D,A,H;s:D;o:False;i:True      False   2.0 -0.098464  0.141261 -0.198351   \n",
              "32   D,A,H;s:D;o:False;i:True       True   5.0  0.089327  0.099877 -0.066593   \n",
              "35    D,A,H;s:D;o:True;i:True      False   2.0 -0.102370  0.135911 -0.198474   \n",
              "36    D,A,H;s:D;o:True;i:True       True   5.0  0.083550  0.099342 -0.080000   \n",
              "41   D,A,H;s:H;o:True;i:False      False   2.0 -0.214738  0.043138 -0.245241   \n",
              "42   D,A,H;s:H;o:True;i:False       True   5.0 -0.062863  0.156319 -0.268081   \n",
              "48   D,H,A;s:A;o:True;i:False      False   1.0 -0.161789       NaN -0.161789   \n",
              "49   D,H,A;s:A;o:True;i:False       True   6.0 -0.024959  0.148114 -0.233828   \n",
              "52  D,H,A;s:D;o:False;i:False      False   1.0 -0.060771       NaN -0.060771   \n",
              "53  D,H,A;s:D;o:False;i:False       True   6.0  0.076937  0.140098 -0.150455   \n",
              "56   D,H,A;s:D;o:True;i:False      False   1.0 -0.066800       NaN -0.066800   \n",
              "57   D,H,A;s:D;o:True;i:False       True   6.0  0.060173  0.139933 -0.184364   \n",
              "85   H,D,A;s:H;o:False;i:True      False   1.0 -0.185976       NaN -0.185976   \n",
              "86   H,D,A;s:H;o:False;i:True       True   6.0  0.171301  0.153922  0.008492   \n",
              "87   H,D,A;s:H;o:True;i:False      False   2.0 -0.165081  0.215570 -0.317512   \n",
              "88   H,D,A;s:H;o:True;i:False       True   5.0  0.170382  0.116702  0.039565   \n",
              "89    H,D,A;s:H;o:True;i:True      False   2.0 -0.138973  0.252492 -0.317512   \n",
              "90    H,D,A;s:H;o:True;i:True       True   5.0  0.159939  0.132590 -0.012651   \n",
              "\n",
              "                                           bd_wins                        \\\n",
              "         25%       50%       75%       max   count        mean       std   \n",
              "18 -0.029027 -0.009177  0.042923  0.094920     7.0  115.000000  9.183318   \n",
              "31 -0.148408 -0.098464 -0.048521  0.001422     2.0   14.000000  0.000000   \n",
              "32  0.049729  0.125891  0.163661  0.173944     5.0   17.600000  4.159327   \n",
              "35 -0.150422 -0.102370 -0.054318 -0.006267     2.0   14.000000  0.000000   \n",
              "36  0.063250  0.118688  0.154565  0.161250     5.0   17.600000  4.159327   \n",
              "41 -0.229989 -0.214738 -0.199486 -0.184234     2.0   19.500000  3.535534   \n",
              "42 -0.191188  0.012722  0.056719  0.075511     5.0   19.000000  3.937004   \n",
              "48 -0.161789 -0.161789 -0.161789 -0.161789     1.0   13.000000       NaN   \n",
              "49 -0.114189 -0.024600  0.077290  0.166073     6.0   14.666667  3.559026   \n",
              "52 -0.060771 -0.060771 -0.060771 -0.060771     1.0   10.000000       NaN   \n",
              "53  0.019388  0.090878  0.182861  0.221238     6.0   11.833333  2.483277   \n",
              "56 -0.066800 -0.066800 -0.066800 -0.066800     1.0   10.000000       NaN   \n",
              "57  0.019368  0.083685  0.167461  0.184714     6.0   11.833333  2.483277   \n",
              "85 -0.185976 -0.185976 -0.185976 -0.185976     1.0   13.000000       NaN   \n",
              "86  0.059697  0.127113  0.296080  0.375460     6.0   13.666667  2.065591   \n",
              "87 -0.241297 -0.165081 -0.088866 -0.012651     2.0   12.000000  1.414214   \n",
              "88  0.084373  0.149345  0.264468  0.314160     5.0   14.200000  1.788854   \n",
              "89 -0.228243 -0.138973 -0.049704  0.039565     2.0   14.500000  2.121320   \n",
              "90  0.084373  0.149345  0.264468  0.314160     5.0   13.200000  1.923538   \n",
              "\n",
              "                                        bd_len                                \\\n",
              "      min     25%    50%     75%    max  count        mean        std    min   \n",
              "18  101.0  111.00  114.0  119.00  130.0    7.0  188.571429   6.528327  182.0   \n",
              "31   14.0   14.00   14.0   14.00   14.0    2.0   51.000000   8.485281   45.0   \n",
              "32   13.0   15.00   16.0   22.00   22.0    5.0   52.800000  11.366618   36.0   \n",
              "35   14.0   14.00   14.0   14.00   14.0    2.0   51.000000   8.485281   45.0   \n",
              "36   13.0   15.00   16.0   22.00   22.0    5.0   52.800000  11.366618   36.0   \n",
              "41   17.0   18.25   19.5   20.75   22.0    2.0   59.000000   7.071068   54.0   \n",
              "42   15.0   16.00   19.0   20.00   25.0    5.0   49.600000  10.212737   36.0   \n",
              "48   13.0   13.00   13.0   13.00   13.0    1.0   38.000000        NaN   38.0   \n",
              "49    9.0   14.00   14.5   15.75   20.0    6.0   36.000000   4.898979   29.0   \n",
              "52   10.0   10.00   10.0   10.00   10.0    1.0   35.000000        NaN   35.0   \n",
              "53    8.0   10.50   12.5   13.00   15.0    6.0   36.500000   4.929503   29.0   \n",
              "56   10.0   10.00   10.0   10.00   10.0    1.0   35.000000        NaN   35.0   \n",
              "57    8.0   10.50   12.5   13.00   15.0    6.0   36.500000   4.929503   29.0   \n",
              "85   13.0   13.00   13.0   13.00   13.0    1.0   82.000000        NaN   82.0   \n",
              "86   11.0   12.25   13.5   15.50   16.0    6.0   59.666667   6.623192   50.0   \n",
              "87   11.0   11.50   12.0   12.50   13.0    2.0   72.500000  13.435029   63.0   \n",
              "88   12.0   13.00   14.0   16.00   16.0    5.0   59.000000   7.176350   50.0   \n",
              "89   13.0   13.75   14.5   15.25   16.0    2.0   75.500000   9.192388   69.0   \n",
              "90   11.0   12.00   13.0   14.00   16.0    5.0   57.800000   5.357238   50.0   \n",
              "\n",
              "                                 dir_ev                                \\\n",
              "       25%    50%     75%    max  count      mean       std       min   \n",
              "18  184.50  186.0  191.50  200.0    7.0  0.074350  0.056626  0.004378   \n",
              "31   48.00   51.0   54.00   57.0    2.0 -0.174447  0.164622 -0.290853   \n",
              "32   48.00   54.0   62.00   64.0    5.0  0.173847  0.188714  0.028625   \n",
              "35   48.00   51.0   54.00   57.0    2.0 -0.197262  0.155817 -0.307441   \n",
              "36   48.00   54.0   62.00   64.0    5.0  0.134042  0.194140  0.000708   \n",
              "41   56.50   59.0   61.50   64.0    2.0 -0.190152  0.177977 -0.316000   \n",
              "42   45.00   48.0   57.00   62.0    5.0  0.155734  0.121313  0.028467   \n",
              "48   38.00   38.0   38.00   38.0    1.0 -0.151350       NaN -0.151350   \n",
              "49   33.50   35.5   39.75   42.0    6.0  0.156158  0.166742  0.009286   \n",
              "52   35.00   35.0   35.00   35.0    1.0 -0.065941       NaN -0.065941   \n",
              "53   33.75   37.0   40.25   42.0    6.0  0.422251  0.295839  0.017920   \n",
              "56   35.00   35.0   35.00   35.0    1.0 -0.047235       NaN -0.047235   \n",
              "57   33.75   37.0   40.25   42.0    6.0  0.453246  0.300585  0.054480   \n",
              "85   82.00   82.0   82.00   82.0    1.0 -0.067371       NaN -0.067371   \n",
              "86   56.00   60.5   62.75   69.0    6.0  0.338305  0.216398  0.006974   \n",
              "87   67.75   72.5   77.25   82.0    2.0 -0.410146  0.018886 -0.423500   \n",
              "88   55.00   59.0   62.00   69.0    5.0  0.201855  0.098154  0.095655   \n",
              "89   72.25   75.5   78.75   82.0    2.0 -0.212879  0.099622 -0.283323   \n",
              "90   55.00   59.0   62.00   63.0    5.0  0.235316  0.163780  0.029024   \n",
              "\n",
              "                                           dir_of_bd                      \\\n",
              "         25%       50%       75%       max     count      mean       std   \n",
              "18  0.032670  0.087248  0.095709  0.172066       7.0  0.469134  0.055431   \n",
              "31 -0.232650 -0.174447 -0.116244 -0.058042       2.0  0.564912  0.044659   \n",
              "32  0.064250  0.068500  0.224711  0.483147       5.0  0.506205  0.116348   \n",
              "35 -0.252352 -0.197262 -0.142173 -0.087083       2.0  0.564912  0.044659   \n",
              "36  0.008227  0.013125  0.200974  0.447176       5.0  0.506205  0.116348   \n",
              "41 -0.253076 -0.190152 -0.127227 -0.064303       2.0  0.452257  0.089616   \n",
              "42  0.039833  0.182269  0.213714  0.314389       5.0  0.470780  0.094717   \n",
              "48 -0.151350 -0.151350 -0.151350 -0.151350       1.0  0.526316       NaN   \n",
              "49  0.061672  0.107108  0.172525  0.472588       6.0  0.455422  0.066512   \n",
              "52 -0.065941 -0.065941 -0.065941 -0.065941       1.0  0.485714       NaN   \n",
              "53  0.317800  0.365750  0.528812  0.899100       6.0  0.357914  0.142616   \n",
              "56 -0.047235 -0.047235 -0.047235 -0.047235       1.0  0.485714       NaN   \n",
              "57  0.337307  0.392464  0.559250  0.946300       6.0  0.357914  0.142616   \n",
              "85 -0.067371 -0.067371 -0.067371 -0.067371       1.0  0.756098       NaN   \n",
              "86  0.266653  0.323519  0.441079  0.647852       6.0  0.578759  0.074896   \n",
              "87 -0.416823 -0.410146 -0.403469 -0.396792       2.0  0.312427  0.096909   \n",
              "88  0.110087  0.210444  0.276167  0.316923       5.0  0.429299  0.080777   \n",
              "89 -0.248101 -0.212879 -0.177658 -0.142436       2.0  0.660657  0.134973   \n",
              "90  0.209231  0.223744  0.226583  0.488000       5.0  0.581467  0.083408   \n",
              "\n",
              "                                                     dir_wins             \\\n",
              "         min       25%       50%       75%       max    count       mean   \n",
              "18  0.380435  0.436719  0.484043  0.503782  0.538462      7.0  56.571429   \n",
              "31  0.533333  0.549123  0.564912  0.580702  0.596491      2.0   7.000000   \n",
              "32  0.333333  0.444444  0.548387  0.593750  0.611111      5.0   9.600000   \n",
              "35  0.533333  0.549123  0.564912  0.580702  0.596491      2.0   7.000000   \n",
              "36  0.333333  0.444444  0.548387  0.593750  0.611111      5.0   9.600000   \n",
              "41  0.388889  0.420573  0.452257  0.483941  0.515625      2.0   9.500000   \n",
              "42  0.388889  0.400000  0.456140  0.483871  0.625000      5.0  11.200000   \n",
              "48  0.526316  0.526316  0.526316  0.526316  0.526316      1.0   7.000000   \n",
              "49  0.361111  0.418118  0.455665  0.495690  0.545455      6.0   7.833333   \n",
              "52  0.485714  0.485714  0.485714  0.485714  0.485714      1.0   5.000000   \n",
              "53  0.241379  0.268797  0.294372  0.409091  0.609756      6.0   5.666667   \n",
              "56  0.485714  0.485714  0.485714  0.485714  0.485714      1.0   5.000000   \n",
              "57  0.241379  0.268797  0.294372  0.409091  0.609756      6.0   5.666667   \n",
              "85  0.756098  0.756098  0.756098  0.756098  0.756098      1.0  11.000000   \n",
              "86  0.472727  0.546304  0.572931  0.609447  0.694915      6.0   7.833333   \n",
              "87  0.243902  0.278165  0.312427  0.346690  0.380952      2.0   2.000000   \n",
              "88  0.305085  0.419355  0.434783  0.460000  0.527273      5.0   6.600000   \n",
              "89  0.565217  0.612937  0.660657  0.708378  0.756098      2.0   9.000000   \n",
              "90  0.472727  0.540000  0.580645  0.619048  0.694915      5.0   8.000000   \n",
              "\n",
              "                                             dir_len                        \\\n",
              "         std   min    25%   50%    75%   max   count       mean        std   \n",
              "18  8.829065  42.0  52.50  59.0  62.00  66.0     7.0  88.571429  11.759495   \n",
              "31  0.000000   7.0   7.00   7.0   7.00   7.0     2.0  29.000000   7.071068   \n",
              "32  4.560702   5.0   7.00   7.0  14.00  15.0     5.0  26.800000   9.011104   \n",
              "35  0.000000   7.0   7.00   7.0   7.00   7.0     2.0  29.000000   7.071068   \n",
              "36  4.560702   5.0   7.00   7.0  14.00  15.0     5.0  26.800000   9.011104   \n",
              "41  4.949747   6.0   7.75   9.5  11.25  13.0     2.0  27.000000   8.485281   \n",
              "42  2.683282   7.0  10.00  13.0  13.00  13.0     5.0  23.600000   7.266361   \n",
              "48       NaN   7.0   7.00   7.0   7.00   7.0     1.0  20.000000        NaN   \n",
              "49  1.722401   6.0   6.25   8.0   9.00  10.0     6.0  16.333333   2.943920   \n",
              "52       NaN   5.0   5.00   5.0   5.00   5.0     1.0  17.000000        NaN   \n",
              "53  1.861899   3.0   4.50   6.0   6.75   8.0     6.0  13.333333   6.439462   \n",
              "56       NaN   5.0   5.00   5.0   5.00   5.0     1.0  17.000000        NaN   \n",
              "57  1.861899   3.0   4.50   6.0   6.75   8.0     6.0  13.333333   6.439462   \n",
              "85       NaN  11.0  11.00  11.0  11.00  11.0     1.0  62.000000        NaN   \n",
              "86  1.471960   6.0   7.00   7.5   8.75  10.0     6.0  34.666667   6.531973   \n",
              "87  0.000000   2.0   2.00   2.0   2.00   2.0     2.0  22.000000   2.828427   \n",
              "88  1.949359   4.0   6.00   6.0   8.00   9.0     5.0  25.200000   4.868265   \n",
              "89  2.828427   7.0   8.00   9.0  10.00  11.0     2.0  50.500000  16.263456   \n",
              "90  1.581139   6.0   7.00   8.0   9.00  10.0     5.0  33.800000   6.906519   \n",
              "\n",
              "                                     \n",
              "     min    25%   50%    75%    max  \n",
              "18  70.0  81.00  91.0  98.00  101.0  \n",
              "31  24.0  26.50  29.0  31.50   34.0  \n",
              "32  16.0  22.00  24.0  34.00   38.0  \n",
              "35  24.0  26.50  29.0  31.50   34.0  \n",
              "36  16.0  22.00  24.0  34.00   38.0  \n",
              "41  21.0  24.00  27.0  30.00   33.0  \n",
              "42  14.0  18.00  26.0  30.00   30.0  \n",
              "48  20.0  20.00  20.0  20.00   20.0  \n",
              "49  13.0  14.25  16.0  17.75   21.0  \n",
              "52  17.0  17.00  17.0  17.00   17.0  \n",
              "53   7.0  10.00  11.0  15.00   25.0  \n",
              "56  17.0  17.00  17.0  17.00   17.0  \n",
              "57   7.0  10.00  11.0  15.00   25.0  \n",
              "85  62.0  62.00  62.0  62.00   62.0  \n",
              "86  26.0  29.25  37.5  39.00   41.0  \n",
              "87  20.0  21.00  22.0  23.00   24.0  \n",
              "88  18.0  23.00  26.0  29.00   30.0  \n",
              "89  39.0  44.75  50.5  56.25   62.0  \n",
              "90  26.0  27.00  36.0  39.00   41.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8da47e14-e1f6-4b99-b29f-1570800afafa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>combo_key</th>\n",
              "      <th>profitable</th>\n",
              "      <th colspan=\"8\" halign=\"left\">bd_ev</th>\n",
              "      <th colspan=\"8\" halign=\"left\">bd_wins</th>\n",
              "      <th colspan=\"8\" halign=\"left\">bd_len</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dir_ev</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dir_of_bd</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dir_wins</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dir_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A,D,H;s:H;o:True;i:False</td>\n",
              "      <td>True</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.006827</td>\n",
              "      <td>0.056452</td>\n",
              "      <td>-0.065744</td>\n",
              "      <td>-0.029027</td>\n",
              "      <td>-0.009177</td>\n",
              "      <td>0.042923</td>\n",
              "      <td>0.094920</td>\n",
              "      <td>7.0</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>9.183318</td>\n",
              "      <td>101.0</td>\n",
              "      <td>111.00</td>\n",
              "      <td>114.0</td>\n",
              "      <td>119.00</td>\n",
              "      <td>130.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>188.571429</td>\n",
              "      <td>6.528327</td>\n",
              "      <td>182.0</td>\n",
              "      <td>184.50</td>\n",
              "      <td>186.0</td>\n",
              "      <td>191.50</td>\n",
              "      <td>200.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.074350</td>\n",
              "      <td>0.056626</td>\n",
              "      <td>0.004378</td>\n",
              "      <td>0.032670</td>\n",
              "      <td>0.087248</td>\n",
              "      <td>0.095709</td>\n",
              "      <td>0.172066</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.469134</td>\n",
              "      <td>0.055431</td>\n",
              "      <td>0.380435</td>\n",
              "      <td>0.436719</td>\n",
              "      <td>0.484043</td>\n",
              "      <td>0.503782</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>7.0</td>\n",
              "      <td>56.571429</td>\n",
              "      <td>8.829065</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.50</td>\n",
              "      <td>59.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>66.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>88.571429</td>\n",
              "      <td>11.759495</td>\n",
              "      <td>70.0</td>\n",
              "      <td>81.00</td>\n",
              "      <td>91.0</td>\n",
              "      <td>98.00</td>\n",
              "      <td>101.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>D,A,H;s:D;o:False;i:True</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.098464</td>\n",
              "      <td>0.141261</td>\n",
              "      <td>-0.198351</td>\n",
              "      <td>-0.148408</td>\n",
              "      <td>-0.098464</td>\n",
              "      <td>-0.048521</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>8.485281</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>51.0</td>\n",
              "      <td>54.00</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.174447</td>\n",
              "      <td>0.164622</td>\n",
              "      <td>-0.290853</td>\n",
              "      <td>-0.232650</td>\n",
              "      <td>-0.174447</td>\n",
              "      <td>-0.116244</td>\n",
              "      <td>-0.058042</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.564912</td>\n",
              "      <td>0.044659</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.549123</td>\n",
              "      <td>0.564912</td>\n",
              "      <td>0.580702</td>\n",
              "      <td>0.596491</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>7.071068</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.50</td>\n",
              "      <td>29.0</td>\n",
              "      <td>31.50</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>D,A,H;s:D;o:False;i:True</td>\n",
              "      <td>True</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.089327</td>\n",
              "      <td>0.099877</td>\n",
              "      <td>-0.066593</td>\n",
              "      <td>0.049729</td>\n",
              "      <td>0.125891</td>\n",
              "      <td>0.163661</td>\n",
              "      <td>0.173944</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.600000</td>\n",
              "      <td>4.159327</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>11.366618</td>\n",
              "      <td>36.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>54.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.173847</td>\n",
              "      <td>0.188714</td>\n",
              "      <td>0.028625</td>\n",
              "      <td>0.064250</td>\n",
              "      <td>0.068500</td>\n",
              "      <td>0.224711</td>\n",
              "      <td>0.483147</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.506205</td>\n",
              "      <td>0.116348</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>4.560702</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>26.800000</td>\n",
              "      <td>9.011104</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>34.00</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>D,A,H;s:D;o:True;i:True</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.102370</td>\n",
              "      <td>0.135911</td>\n",
              "      <td>-0.198474</td>\n",
              "      <td>-0.150422</td>\n",
              "      <td>-0.102370</td>\n",
              "      <td>-0.054318</td>\n",
              "      <td>-0.006267</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>8.485281</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>51.0</td>\n",
              "      <td>54.00</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.197262</td>\n",
              "      <td>0.155817</td>\n",
              "      <td>-0.307441</td>\n",
              "      <td>-0.252352</td>\n",
              "      <td>-0.197262</td>\n",
              "      <td>-0.142173</td>\n",
              "      <td>-0.087083</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.564912</td>\n",
              "      <td>0.044659</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.549123</td>\n",
              "      <td>0.564912</td>\n",
              "      <td>0.580702</td>\n",
              "      <td>0.596491</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>7.071068</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.50</td>\n",
              "      <td>29.0</td>\n",
              "      <td>31.50</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>D,A,H;s:D;o:True;i:True</td>\n",
              "      <td>True</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.083550</td>\n",
              "      <td>0.099342</td>\n",
              "      <td>-0.080000</td>\n",
              "      <td>0.063250</td>\n",
              "      <td>0.118688</td>\n",
              "      <td>0.154565</td>\n",
              "      <td>0.161250</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.600000</td>\n",
              "      <td>4.159327</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>11.366618</td>\n",
              "      <td>36.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>54.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.134042</td>\n",
              "      <td>0.194140</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.008227</td>\n",
              "      <td>0.013125</td>\n",
              "      <td>0.200974</td>\n",
              "      <td>0.447176</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.506205</td>\n",
              "      <td>0.116348</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>4.560702</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>26.800000</td>\n",
              "      <td>9.011104</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>34.00</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>D,A,H;s:H;o:True;i:False</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.214738</td>\n",
              "      <td>0.043138</td>\n",
              "      <td>-0.245241</td>\n",
              "      <td>-0.229989</td>\n",
              "      <td>-0.214738</td>\n",
              "      <td>-0.199486</td>\n",
              "      <td>-0.184234</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.5</td>\n",
              "      <td>20.75</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7.071068</td>\n",
              "      <td>54.0</td>\n",
              "      <td>56.50</td>\n",
              "      <td>59.0</td>\n",
              "      <td>61.50</td>\n",
              "      <td>64.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.190152</td>\n",
              "      <td>0.177977</td>\n",
              "      <td>-0.316000</td>\n",
              "      <td>-0.253076</td>\n",
              "      <td>-0.190152</td>\n",
              "      <td>-0.127227</td>\n",
              "      <td>-0.064303</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.452257</td>\n",
              "      <td>0.089616</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.420573</td>\n",
              "      <td>0.452257</td>\n",
              "      <td>0.483941</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>4.949747</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.75</td>\n",
              "      <td>9.5</td>\n",
              "      <td>11.25</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>8.485281</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24.00</td>\n",
              "      <td>27.0</td>\n",
              "      <td>30.00</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>D,A,H;s:H;o:True;i:False</td>\n",
              "      <td>True</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.062863</td>\n",
              "      <td>0.156319</td>\n",
              "      <td>-0.268081</td>\n",
              "      <td>-0.191188</td>\n",
              "      <td>0.012722</td>\n",
              "      <td>0.056719</td>\n",
              "      <td>0.075511</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.937004</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>49.600000</td>\n",
              "      <td>10.212737</td>\n",
              "      <td>36.0</td>\n",
              "      <td>45.00</td>\n",
              "      <td>48.0</td>\n",
              "      <td>57.00</td>\n",
              "      <td>62.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.155734</td>\n",
              "      <td>0.121313</td>\n",
              "      <td>0.028467</td>\n",
              "      <td>0.039833</td>\n",
              "      <td>0.182269</td>\n",
              "      <td>0.213714</td>\n",
              "      <td>0.314389</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.470780</td>\n",
              "      <td>0.094717</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.456140</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>2.683282</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>7.266361</td>\n",
              "      <td>14.0</td>\n",
              "      <td>18.00</td>\n",
              "      <td>26.0</td>\n",
              "      <td>30.00</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>D,H,A;s:A;o:True;i:False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.161789</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.161789</td>\n",
              "      <td>-0.161789</td>\n",
              "      <td>-0.161789</td>\n",
              "      <td>-0.161789</td>\n",
              "      <td>-0.161789</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.0</td>\n",
              "      <td>38.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>38.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.151350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.151350</td>\n",
              "      <td>-0.151350</td>\n",
              "      <td>-0.151350</td>\n",
              "      <td>-0.151350</td>\n",
              "      <td>-0.151350</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>D,H,A;s:A;o:True;i:False</td>\n",
              "      <td>True</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.024959</td>\n",
              "      <td>0.148114</td>\n",
              "      <td>-0.233828</td>\n",
              "      <td>-0.114189</td>\n",
              "      <td>-0.024600</td>\n",
              "      <td>0.077290</td>\n",
              "      <td>0.166073</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.666667</td>\n",
              "      <td>3.559026</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.75</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>4.898979</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.50</td>\n",
              "      <td>35.5</td>\n",
              "      <td>39.75</td>\n",
              "      <td>42.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.156158</td>\n",
              "      <td>0.166742</td>\n",
              "      <td>0.009286</td>\n",
              "      <td>0.061672</td>\n",
              "      <td>0.107108</td>\n",
              "      <td>0.172525</td>\n",
              "      <td>0.472588</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.455422</td>\n",
              "      <td>0.066512</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.418118</td>\n",
              "      <td>0.455665</td>\n",
              "      <td>0.495690</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.833333</td>\n",
              "      <td>1.722401</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.25</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.333333</td>\n",
              "      <td>2.943920</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.25</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.75</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>D,H,A;s:D;o:False;i:False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.060771</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.060771</td>\n",
              "      <td>-0.060771</td>\n",
              "      <td>-0.060771</td>\n",
              "      <td>-0.060771</td>\n",
              "      <td>-0.060771</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.00</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.00</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.065941</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.065941</td>\n",
              "      <td>-0.065941</td>\n",
              "      <td>-0.065941</td>\n",
              "      <td>-0.065941</td>\n",
              "      <td>-0.065941</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>D,H,A;s:D;o:False;i:False</td>\n",
              "      <td>True</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.076937</td>\n",
              "      <td>0.140098</td>\n",
              "      <td>-0.150455</td>\n",
              "      <td>0.019388</td>\n",
              "      <td>0.090878</td>\n",
              "      <td>0.182861</td>\n",
              "      <td>0.221238</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.833333</td>\n",
              "      <td>2.483277</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.50</td>\n",
              "      <td>12.5</td>\n",
              "      <td>13.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>4.929503</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.75</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.25</td>\n",
              "      <td>42.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.422251</td>\n",
              "      <td>0.295839</td>\n",
              "      <td>0.017920</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.365750</td>\n",
              "      <td>0.528812</td>\n",
              "      <td>0.899100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.357914</td>\n",
              "      <td>0.142616</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.268797</td>\n",
              "      <td>0.294372</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>1.861899</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.75</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.439462</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>D,H,A;s:D;o:True;i:False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.066800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.066800</td>\n",
              "      <td>-0.066800</td>\n",
              "      <td>-0.066800</td>\n",
              "      <td>-0.066800</td>\n",
              "      <td>-0.066800</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.00</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.00</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.047235</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.047235</td>\n",
              "      <td>-0.047235</td>\n",
              "      <td>-0.047235</td>\n",
              "      <td>-0.047235</td>\n",
              "      <td>-0.047235</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>D,H,A;s:D;o:True;i:False</td>\n",
              "      <td>True</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.060173</td>\n",
              "      <td>0.139933</td>\n",
              "      <td>-0.184364</td>\n",
              "      <td>0.019368</td>\n",
              "      <td>0.083685</td>\n",
              "      <td>0.167461</td>\n",
              "      <td>0.184714</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.833333</td>\n",
              "      <td>2.483277</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.50</td>\n",
              "      <td>12.5</td>\n",
              "      <td>13.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>4.929503</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.75</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.25</td>\n",
              "      <td>42.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.453246</td>\n",
              "      <td>0.300585</td>\n",
              "      <td>0.054480</td>\n",
              "      <td>0.337307</td>\n",
              "      <td>0.392464</td>\n",
              "      <td>0.559250</td>\n",
              "      <td>0.946300</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.357914</td>\n",
              "      <td>0.142616</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.268797</td>\n",
              "      <td>0.294372</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>1.861899</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.75</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.439462</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>H,D,A;s:H;o:False;i:True</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.185976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.185976</td>\n",
              "      <td>-0.185976</td>\n",
              "      <td>-0.185976</td>\n",
              "      <td>-0.185976</td>\n",
              "      <td>-0.185976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.067371</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.067371</td>\n",
              "      <td>-0.067371</td>\n",
              "      <td>-0.067371</td>\n",
              "      <td>-0.067371</td>\n",
              "      <td>-0.067371</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>H,D,A;s:H;o:False;i:True</td>\n",
              "      <td>True</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.171301</td>\n",
              "      <td>0.153922</td>\n",
              "      <td>0.008492</td>\n",
              "      <td>0.059697</td>\n",
              "      <td>0.127113</td>\n",
              "      <td>0.296080</td>\n",
              "      <td>0.375460</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>2.065591</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.25</td>\n",
              "      <td>13.5</td>\n",
              "      <td>15.50</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>59.666667</td>\n",
              "      <td>6.623192</td>\n",
              "      <td>50.0</td>\n",
              "      <td>56.00</td>\n",
              "      <td>60.5</td>\n",
              "      <td>62.75</td>\n",
              "      <td>69.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.338305</td>\n",
              "      <td>0.216398</td>\n",
              "      <td>0.006974</td>\n",
              "      <td>0.266653</td>\n",
              "      <td>0.323519</td>\n",
              "      <td>0.441079</td>\n",
              "      <td>0.647852</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.578759</td>\n",
              "      <td>0.074896</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>0.546304</td>\n",
              "      <td>0.572931</td>\n",
              "      <td>0.609447</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.833333</td>\n",
              "      <td>1.471960</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>7.5</td>\n",
              "      <td>8.75</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>34.666667</td>\n",
              "      <td>6.531973</td>\n",
              "      <td>26.0</td>\n",
              "      <td>29.25</td>\n",
              "      <td>37.5</td>\n",
              "      <td>39.00</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>H,D,A;s:H;o:True;i:False</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.165081</td>\n",
              "      <td>0.215570</td>\n",
              "      <td>-0.317512</td>\n",
              "      <td>-0.241297</td>\n",
              "      <td>-0.165081</td>\n",
              "      <td>-0.088866</td>\n",
              "      <td>-0.012651</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.50</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.50</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>13.435029</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.75</td>\n",
              "      <td>72.5</td>\n",
              "      <td>77.25</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.410146</td>\n",
              "      <td>0.018886</td>\n",
              "      <td>-0.423500</td>\n",
              "      <td>-0.416823</td>\n",
              "      <td>-0.410146</td>\n",
              "      <td>-0.403469</td>\n",
              "      <td>-0.396792</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.312427</td>\n",
              "      <td>0.096909</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.278165</td>\n",
              "      <td>0.312427</td>\n",
              "      <td>0.346690</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>23.00</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>H,D,A;s:H;o:True;i:False</td>\n",
              "      <td>True</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.170382</td>\n",
              "      <td>0.116702</td>\n",
              "      <td>0.039565</td>\n",
              "      <td>0.084373</td>\n",
              "      <td>0.149345</td>\n",
              "      <td>0.264468</td>\n",
              "      <td>0.314160</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.200000</td>\n",
              "      <td>1.788854</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7.176350</td>\n",
              "      <td>50.0</td>\n",
              "      <td>55.00</td>\n",
              "      <td>59.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>69.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.201855</td>\n",
              "      <td>0.098154</td>\n",
              "      <td>0.095655</td>\n",
              "      <td>0.110087</td>\n",
              "      <td>0.210444</td>\n",
              "      <td>0.276167</td>\n",
              "      <td>0.316923</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.429299</td>\n",
              "      <td>0.080777</td>\n",
              "      <td>0.305085</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>1.949359</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.200000</td>\n",
              "      <td>4.868265</td>\n",
              "      <td>18.0</td>\n",
              "      <td>23.00</td>\n",
              "      <td>26.0</td>\n",
              "      <td>29.00</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>False</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.138973</td>\n",
              "      <td>0.252492</td>\n",
              "      <td>-0.317512</td>\n",
              "      <td>-0.228243</td>\n",
              "      <td>-0.138973</td>\n",
              "      <td>-0.049704</td>\n",
              "      <td>0.039565</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>2.121320</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.75</td>\n",
              "      <td>14.5</td>\n",
              "      <td>15.25</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>75.500000</td>\n",
              "      <td>9.192388</td>\n",
              "      <td>69.0</td>\n",
              "      <td>72.25</td>\n",
              "      <td>75.5</td>\n",
              "      <td>78.75</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.212879</td>\n",
              "      <td>0.099622</td>\n",
              "      <td>-0.283323</td>\n",
              "      <td>-0.248101</td>\n",
              "      <td>-0.212879</td>\n",
              "      <td>-0.177658</td>\n",
              "      <td>-0.142436</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.660657</td>\n",
              "      <td>0.134973</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.612937</td>\n",
              "      <td>0.660657</td>\n",
              "      <td>0.708378</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.500000</td>\n",
              "      <td>16.263456</td>\n",
              "      <td>39.0</td>\n",
              "      <td>44.75</td>\n",
              "      <td>50.5</td>\n",
              "      <td>56.25</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>H,D,A;s:H;o:True;i:True</td>\n",
              "      <td>True</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.159939</td>\n",
              "      <td>0.132590</td>\n",
              "      <td>-0.012651</td>\n",
              "      <td>0.084373</td>\n",
              "      <td>0.149345</td>\n",
              "      <td>0.264468</td>\n",
              "      <td>0.314160</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.200000</td>\n",
              "      <td>1.923538</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>57.800000</td>\n",
              "      <td>5.357238</td>\n",
              "      <td>50.0</td>\n",
              "      <td>55.00</td>\n",
              "      <td>59.0</td>\n",
              "      <td>62.00</td>\n",
              "      <td>63.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.235316</td>\n",
              "      <td>0.163780</td>\n",
              "      <td>0.029024</td>\n",
              "      <td>0.209231</td>\n",
              "      <td>0.223744</td>\n",
              "      <td>0.226583</td>\n",
              "      <td>0.488000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.581467</td>\n",
              "      <td>0.083408</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.581139</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>33.800000</td>\n",
              "      <td>6.906519</td>\n",
              "      <td>26.0</td>\n",
              "      <td>27.00</td>\n",
              "      <td>36.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8da47e14-e1f6-4b99-b29f-1570800afafa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8da47e14-e1f6-4b99-b29f-1570800afafa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8da47e14-e1f6-4b99-b29f-1570800afafa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5ef029a-41c7-4642-a21c-d5f0fc8120b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5ef029a-41c7-4642-a21c-d5f0fc8120b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5ef029a-41c7-4642-a21c-d5f0fc8120b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examine_combos(dataset_list[0], True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L4Hq_jAuqaUX",
        "outputId": "01e69958-ed75-40b9-bf77-bd7f28cf9822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H D A frequency: 18.235%      62/340\n",
            "\n",
            "H D A for H\n",
            "num increase / total: 10.588%      36/340\n",
            "num increase / odds: 58.065%      36/62\n",
            "num decrease / total: 7.647%      26/340\n",
            "num decrease / odds: 41.935%      26/62\n",
            "\n",
            "ev for OP: 26.45%\n",
            "increase ev for OP = 22.66%\n",
            "decrease ev for OP = 31.69%\n",
            "\n",
            "H D A win freq for H: 25.806%      16/62\n",
            "H D A increase wins/increases: 22.222%      8/36\n",
            "H D A increase wins/odds: 12.903%      8/62\n",
            "H D A decrease wins/decreases: 30.769%      8/26\n",
            "H D A decrease wins/odds: 12.903%      8/62\n",
            "\n",
            "ev for CP: 33.14%\n",
            "increase ev for CP = 47.97%\n",
            "decrease ev for CP = 12.60%\n",
            "\n",
            "H D A win freq for H: 25.806%      16/62\n",
            "H D A increase wins/increases: 22.222%      8/36\n",
            "H D A increase wins/odds: 12.903%      8/62\n",
            "H D A decrease wins/decreases: 30.769%      8/26\n",
            "H D A decrease wins/odds: 12.903%      8/62\n",
            "\n",
            "H D A for D\n",
            "num increase / total: 10.294%      35/340\n",
            "num increase / odds: 56.452%      35/62\n",
            "num decrease / total: 7.941%      27/340\n",
            "num decrease / odds: 43.548%      27/62\n",
            "\n",
            "H D A for D, OP not profitable\n",
            "\n",
            "ev for CP: -2.94%\n",
            "increase ev for CP = 0.46%\n",
            "decrease ev for CP = -7.34%\n",
            "\n",
            "H D A win freq for D: 22.581%      14/62\n",
            "H D A increase wins/increases: 22.857%      8/35\n",
            "H D A increase wins/odds: 12.903%      8/62\n",
            "H D A decrease wins/decreases: 22.222%      6/27\n",
            "H D A decrease wins/odds: 9.677%      6/62\n",
            "\n",
            "H D A for A\n",
            "num increase / total: 9.706%      33/340\n",
            "num increase / odds: 53.226%      33/62\n",
            "num decrease / total: 8.529%      29/340\n",
            "num decrease / odds: 46.774%      29/62\n",
            "\n",
            "H D A for A, OP not profitable\n",
            "\n",
            "H D A for A, CP not profitable\n",
            "\n",
            "\n",
            "H A D frequency: 0.000%      0/340\n",
            "no len for ['H', 'A', 'D']\n",
            "D H A frequency: 8.529%      29/340\n",
            "\n",
            "D H A for D\n",
            "num increase / total: 6.471%      22/340\n",
            "num increase / odds: 75.862%      22/29\n",
            "num decrease / total: 2.059%      7/340\n",
            "num decrease / odds: 24.138%      7/29\n",
            "\n",
            "ev for OP: 13.73%\n",
            "increase ev for OP = 5.97%\n",
            "decrease ev for OP = 38.14%\n",
            "\n",
            "D H A win freq for D: 34.483%      10/29\n",
            "D H A increase wins/increases: 31.818%      7/22\n",
            "D H A increase wins/odds: 24.138%      7/29\n",
            "D H A decrease wins/decreases: 42.857%      3/7\n",
            "D H A decrease wins/odds: 10.345%      3/29\n",
            "\n",
            "ev for CP: 15.59%\n",
            "increase ev for CP = 8.90%\n",
            "decrease ev for CP = 36.60%\n",
            "\n",
            "D H A win freq for D: 34.483%      10/29\n",
            "D H A increase wins/increases: 31.818%      7/22\n",
            "D H A increase wins/odds: 24.138%      7/29\n",
            "D H A decrease wins/decreases: 42.857%      3/7\n",
            "D H A decrease wins/odds: 10.345%      3/29\n",
            "\n",
            "D H A for H\n",
            "num increase / total: 4.118%      14/340\n",
            "num increase / odds: 48.276%      14/29\n",
            "num decrease / total: 4.412%      15/340\n",
            "num decrease / odds: 51.724%      15/29\n",
            "\n",
            "ev for OP: 0.49%\n",
            "increase ev for OP = -36.61%\n",
            "decrease ev for OP = 35.13%\n",
            "\n",
            "D H A win freq for H: 34.483%      10/29\n",
            "D H A increase wins/increases: 21.429%      3/14\n",
            "D H A increase wins/odds: 10.345%      3/29\n",
            "D H A decrease wins/decreases: 46.667%      7/15\n",
            "D H A decrease wins/odds: 24.138%      7/29\n",
            "\n",
            "ev for CP: -5.51%\n",
            "increase ev for CP = -33.45%\n",
            "decrease ev for CP = 20.57%\n",
            "\n",
            "D H A win freq for H: 34.483%      10/29\n",
            "D H A increase wins/increases: 21.429%      3/14\n",
            "D H A increase wins/odds: 10.345%      3/29\n",
            "D H A decrease wins/decreases: 46.667%      7/15\n",
            "D H A decrease wins/odds: 24.138%      7/29\n",
            "\n",
            "D H A for A\n",
            "num increase / total: 4.412%      15/340\n",
            "num increase / odds: 51.724%      15/29\n",
            "num decrease / total: 4.118%      14/340\n",
            "num decrease / odds: 48.276%      14/29\n",
            "\n",
            "ev for OP: -23.38%\n",
            "increase ev for OP = -50.47%\n",
            "decrease ev for OP = 5.64%\n",
            "\n",
            "D H A win freq for A: 31.034%      9/29\n",
            "D H A increase wins/increases: 20.000%      3/15\n",
            "D H A increase wins/odds: 10.345%      3/29\n",
            "D H A decrease wins/decreases: 42.857%      6/14\n",
            "D H A decrease wins/odds: 20.690%      6/29\n",
            "\n",
            "ev for CP: -23.39%\n",
            "increase ev for CP = -44.79%\n",
            "decrease ev for CP = -0.46%\n",
            "\n",
            "D H A win freq for A: 31.034%      9/29\n",
            "D H A increase wins/increases: 20.000%      3/15\n",
            "D H A increase wins/odds: 10.345%      3/29\n",
            "D H A decrease wins/decreases: 42.857%      6/14\n",
            "D H A decrease wins/odds: 20.690%      6/29\n",
            "\n",
            "\n",
            "D A H frequency: 18.824%      64/340\n",
            "\n",
            "D A H for D\n",
            "num increase / total: 11.176%      38/340\n",
            "num increase / odds: 59.375%      38/64\n",
            "num decrease / total: 7.647%      26/340\n",
            "num decrease / odds: 40.625%      26/64\n",
            "\n",
            "ev for OP: 11.87%\n",
            "increase ev for OP = 20.10%\n",
            "decrease ev for OP = -0.16%\n",
            "\n",
            "D A H win freq for D: 34.375%      22/64\n",
            "D A H increase wins/increases: 36.842%      14/38\n",
            "D A H increase wins/odds: 21.875%      14/64\n",
            "D A H decrease wins/decreases: 30.769%      8/26\n",
            "D A H decrease wins/odds: 12.500%      8/64\n",
            "\n",
            "ev for CP: 12.59%\n",
            "increase ev for CP = 22.47%\n",
            "decrease ev for CP = -1.85%\n",
            "\n",
            "D A H win freq for D: 34.375%      22/64\n",
            "D A H increase wins/increases: 36.842%      14/38\n",
            "D A H increase wins/odds: 21.875%      14/64\n",
            "D A H decrease wins/decreases: 30.769%      8/26\n",
            "D A H decrease wins/odds: 12.500%      8/64\n",
            "\n",
            "D A H for A\n",
            "num increase / total: 12.647%      43/340\n",
            "num increase / odds: 67.188%      43/64\n",
            "num decrease / total: 6.176%      21/340\n",
            "num decrease / odds: 32.812%      21/64\n",
            "\n",
            "ev for OP: -5.52%\n",
            "increase ev for OP = -8.43%\n",
            "decrease ev for OP = 0.43%\n",
            "\n",
            "D A H win freq for A: 31.250%      20/64\n",
            "D A H increase wins/increases: 30.233%      13/43\n",
            "D A H increase wins/odds: 20.312%      13/64\n",
            "D A H decrease wins/decreases: 33.333%      7/21\n",
            "D A H decrease wins/odds: 10.938%      7/64\n",
            "\n",
            "ev for CP: -4.06%\n",
            "increase ev for CP = -0.44%\n",
            "decrease ev for CP = -11.46%\n",
            "\n",
            "D A H win freq for A: 31.250%      20/64\n",
            "D A H increase wins/increases: 30.233%      13/43\n",
            "D A H increase wins/odds: 20.312%      13/64\n",
            "D A H decrease wins/decreases: 33.333%      7/21\n",
            "D A H decrease wins/odds: 10.938%      7/64\n",
            "\n",
            "D A H for H\n",
            "num increase / total: 9.118%      31/340\n",
            "num increase / odds: 48.438%      31/64\n",
            "num decrease / total: 9.706%      33/340\n",
            "num decrease / odds: 51.562%      33/64\n",
            "\n",
            "D A H for H, OP not profitable\n",
            "\n",
            "D A H for H, CP not profitable\n",
            "\n",
            "\n",
            "A H D frequency: 0.000%      0/340\n",
            "no len for ['A', 'H', 'D']\n",
            "A D H frequency: 54.412%      185/340\n",
            "\n",
            "A D H for A\n",
            "num increase / total: 30.294%      103/340\n",
            "num increase / odds: 55.676%      103/185\n",
            "num decrease / total: 24.118%      82/340\n",
            "num decrease / odds: 44.324%      82/185\n",
            "\n",
            "A D H for A, OP not profitable\n",
            "\n",
            "A D H for A, CP not profitable\n",
            "\n",
            "A D H for D\n",
            "num increase / total: 33.529%      114/340\n",
            "num increase / odds: 61.622%      114/185\n",
            "num decrease / total: 20.882%      71/340\n",
            "num decrease / odds: 38.378%      71/185\n",
            "\n",
            "ev for OP: -23.97%\n",
            "increase ev for OP = -40.71%\n",
            "decrease ev for OP = 2.90%\n",
            "\n",
            "A D H win freq for D: 18.378%      34/185\n",
            "A D H increase wins/increases: 15.789%      18/114\n",
            "A D H increase wins/odds: 9.730%      18/185\n",
            "A D H decrease wins/decreases: 22.535%      16/71\n",
            "A D H decrease wins/odds: 8.649%      16/185\n",
            "\n",
            "ev for CP: -23.82%\n",
            "increase ev for CP = -37.96%\n",
            "decrease ev for CP = -1.12%\n",
            "\n",
            "A D H win freq for D: 18.378%      34/185\n",
            "A D H increase wins/increases: 15.789%      18/114\n",
            "A D H increase wins/odds: 9.730%      18/185\n",
            "A D H decrease wins/decreases: 22.535%      16/71\n",
            "A D H decrease wins/odds: 8.649%      16/185\n",
            "\n",
            "A D H for H\n",
            "num increase / total: 29.412%      100/340\n",
            "num increase / odds: 54.054%      100/185\n",
            "num decrease / total: 25.000%      85/340\n",
            "num decrease / odds: 45.946%      85/185\n",
            "\n",
            "ev for OP: 3.83%\n",
            "increase ev for OP = -1.58%\n",
            "decrease ev for OP = 10.19%\n",
            "\n",
            "A D H win freq for H: 65.946%      122/185\n",
            "A D H increase wins/increases: 63.000%      63/100\n",
            "A D H increase wins/odds: 34.054%      63/185\n",
            "A D H decrease wins/decreases: 69.412%      59/85\n",
            "A D H decrease wins/odds: 31.892%      59/185\n",
            "\n",
            "ev for CP: 4.18%\n",
            "increase ev for CP = 3.24%\n",
            "decrease ev for CP = 5.29%\n",
            "\n",
            "A D H win freq for H: 65.946%      122/185\n",
            "A D H increase wins/increases: 63.000%      63/100\n",
            "A D H increase wins/odds: 34.054%      63/185\n",
            "A D H decrease wins/decreases: 69.412%      59/85\n",
            "A D H decrease wins/odds: 31.892%      59/185\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attempt_simple_investments(dataset):\n",
        "\n",
        "  # from combo analysis\n",
        "  profitable_combos = [\n",
        "    {\"combo\": (\"A\", \"D\", \"H\"), \"symbol\": \"H\", \"odds\": [\"OP\"], \"is_increase\": False},\n",
        "    {\"combo\": (\"A\", \"D\", \"H\"), \"symbol\": \"H\", \"odds\": [\"OP\"], \"is_increase\": True},\n",
        "    {\"combo\": (\"A\", \"D\", \"H\"), \"symbol\": \"H\", \"odds\": [\"CP\"], \"is_increase\": True},\n",
        "\n",
        "    # {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"D\", \"odds\": [\"OP\"], \"is_increase\": True},\n",
        "    # {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"D\", \"odds\": [\"OP\"], \"is_increase\": False},\n",
        "\n",
        "    {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"H\", \"odds\": [\"OP\"], \"is_increase\": False},\n",
        "    {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"H\", \"odds\": [\"OP\"], \"is_increase\": True},\n",
        "    {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"H\", \"odds\": [\"CP\"], \"is_increase\": True},\n",
        "\n",
        "    {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"A\", \"odds\": [\"OP\"], \"is_increase\": False},\n",
        "    {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"A\", \"odds\": [\"OP\"], \"is_increase\": True},\n",
        "    {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"A\", \"odds\": [\"CP\"], \"is_increase\": True},\n",
        "\n",
        "    {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"D\", \"odds\": [\"OP\"], \"is_increase\": False},\n",
        "    {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"D\", \"odds\": [\"OP\"], \"is_increase\": True},\n",
        "    {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"D\", \"odds\": [\"CP\"], \"is_increase\": True},\n",
        "\n",
        "    {\"combo\": (\"H\", \"D\", \"A\"), \"symbol\": \"H\", \"odds\": [\"OP\"], \"is_increase\": False},\n",
        "    {\"combo\": (\"H\", \"D\", \"A\"), \"symbol\": \"H\", \"odds\": [\"OP\"], \"is_increase\": True},\n",
        "    {\"combo\": (\"H\", \"D\", \"A\"), \"symbol\": \"H\", \"odds\": [\"CP\"], \"is_increase\": True},\n",
        "    ]\n",
        "      # profitable_combos = [\n",
        "  #     {\"combo\": (\"H\", \"D\", \"A\"), \"symbol\": \"H\", \"odds\": [\"OP\", \"CP\"]},\n",
        "  #     {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"D\", \"odds\": [\"OP\", \"CP\"]},\n",
        "  #     {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"D\", \"odds\": [\"OP\", \"CP\"]},\n",
        "  #     {\"combo\": (\"A\", \"D\", \"H\"), \"symbol\": \"H\",\"odds\": [\"OP\", \"CP\"]}]\n",
        "  # no prediction combos\n",
        "  # profitable_combos = [\n",
        "  #   {\"combo\": (\"H\", \"D\", \"A\"), \"symbol\": \"H\", \"odds\": [\"CP\"], \"is_increase\": True},\n",
        "  #   {\"combo\": (\"H\", \"D\", \"A\"), \"symbol\": \"D\", \"odds\": [\"CP\"], \"is_increase\": False},\n",
        "  #   {\"combo\": (\"D\", \"H\", \"A\"), \"symbol\": \"D\", \"odds\": [\"CP\"], \"is_increase\": False},\n",
        "  #   {\"combo\": (\"D\", \"A\", \"H\"), \"symbol\": \"D\", \"odds\": [\"CP\"], \"is_increase\": True}]\n",
        "  total_ev = 0\n",
        "  total_investments = 0\n",
        "  total_winnings = 0\n",
        "  total_bd_ev = 0\n",
        "  for combo_dict in profitable_combos:\n",
        "    max_symbol, mid_symbol, min_symbol = combo_dict[\"combo\"]\n",
        "    symbol = combo_dict[\"symbol\"]\n",
        "    odds = combo_dict[\"odds\"]\n",
        "    is_increasing = combo_dict[\"is_increase\"]\n",
        "\n",
        "    ds = dataset[(dataset[\"OP_MAX_ODD\"] == max_symbol) & (dataset[\"OP_MID_ODD\"] == mid_symbol) & (dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "\n",
        "    if symbol == \"H\":\n",
        "      diff = \"DIFF1\"\n",
        "      odds_label = \"OP1_AVG\"\n",
        "    elif symbol == \"D\":\n",
        "      diff = \"DIFFX\"\n",
        "      odds_label = \"OPX_AVG\"\n",
        "    else:\n",
        "      diff = \"DIFF2\"\n",
        "      odds_label = \"OP2_AVG\"\n",
        "\n",
        "    bd_ev = calculate_ev(ds, odds_label, symbol)\n",
        "\n",
        "    # increases = ds[ds[diff] > 0]\n",
        "    # decreases = ds[ds[diff] <= 0]\n",
        "\n",
        "    if is_increasing:\n",
        "      ds = ds[ds[diff] > 0]\n",
        "    else:\n",
        "      ds = ds[ds[diff] <= 0]\n",
        "\n",
        "    # print(f\"{[max_symbol, mid_symbol, min_symbol]} evs\")\n",
        "    print(combo_dict)\n",
        "    print_percent_str(f\"num {[max_symbol, mid_symbol, min_symbol]}\", len(ds), len(dataset))\n",
        "    for odd in odds:\n",
        "      num_invested = len(ds)\n",
        "      is_opening = True if odd == \"OP\" else False\n",
        "      odds_label = get_odd_label_from_symbol(symbol, is_opening)\n",
        "      ev = calculate_ev(ds, odds_label, symbol)\n",
        "      winnings = calculate_winnings(ds, odds_label, symbol)\n",
        "      print(f\"ev for {odd} = {format(ev, '.3f')}, bd_ev {format(bd_ev, '.3f')}\")\n",
        "      print_percent_str(f\"winnings for {odd}\", winnings, num_invested)\n",
        "      total_ev += ev * num_invested\n",
        "      total_investments += num_invested\n",
        "      total_winnings += winnings\n",
        "      total_bd_ev += bd_ev/2\n",
        "    print(\"\")\n",
        "  print(\"\")\n",
        "  total_ev = total_ev / total_investments\n",
        "  print(f\"total ev: {format(total_ev * 100, '.3f')}%\")\n",
        "  print_percent_str(\"total winnings\", total_winnings, total_investments)\n",
        "  print_percent_str(\"num invested in\", total_investments, len(dataset))\n",
        "  print_percent_str(\"bd_ev\", total_bd_ev, len(combo_dict)/2)\n"
      ],
      "metadata": {
        "id": "4QawIbG57FuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "al_test_lm = al_test.drop(index=al_test[al_test.games < 4].index)"
      ],
      "metadata": {
        "id": "UmMexy_uhBTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attempt_simple_investments(al_test_lm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZlxbHRDf0zE",
        "outputId": "bf4b3a09-3edf-4158-9f34-3eaaca00e5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'combo': ('A', 'D', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['A', 'D', 'H']: 24.853%      169.000/680\n",
            "ev for OP = 0.013, bd_ev 0.035\n",
            "winnings for OP: 1.254%      2.119/169\n",
            "\n",
            "{'combo': ('A', 'D', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['A', 'D', 'H']: 29.265%      199.000/680\n",
            "ev for OP = 0.054, bd_ev 0.035\n",
            "winnings for OP: 5.447%      10.839/199\n",
            "\n",
            "{'combo': ('A', 'D', 'H'), 'symbol': 'H', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['A', 'D', 'H']: 29.265%      199.000/680\n",
            "ev for CP = 0.123, bd_ev 0.035\n",
            "winnings for CP: 12.290%      24.458/199\n",
            "\n",
            "{'combo': ('D', 'A', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['D', 'A', 'H']: 7.059%      48.000/680\n",
            "ev for OP = -0.153, bd_ev -0.132\n",
            "winnings for OP: -15.302%      -7.345/48\n",
            "\n",
            "{'combo': ('D', 'A', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['D', 'A', 'H']: 9.412%      64.000/680\n",
            "ev for OP = -0.116, bd_ev -0.132\n",
            "winnings for OP: -11.559%      -7.398/64\n",
            "\n",
            "{'combo': ('D', 'A', 'H'), 'symbol': 'H', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['D', 'A', 'H']: 9.412%      64.000/680\n",
            "ev for CP = -0.040, bd_ev -0.132\n",
            "winnings for CP: -3.959%      -2.534/64\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'A', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['D', 'H', 'A']: 6.176%      42.000/680\n",
            "ev for OP = 0.219, bd_ev 0.000\n",
            "winnings for OP: 21.855%      9.179/42\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'A', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 7.941%      54.000/680\n",
            "ev for OP = -0.169, bd_ev 0.000\n",
            "winnings for OP: -16.943%      -9.149/54\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'A', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 7.941%      54.000/680\n",
            "ev for CP = -0.113, bd_ev 0.000\n",
            "winnings for CP: -11.276%      -6.089/54\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'D', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['D', 'H', 'A']: 8.382%      57.000/680\n",
            "ev for OP = -0.061, bd_ev -0.059\n",
            "winnings for OP: -6.054%      -3.451/57\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'D', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 5.735%      39.000/680\n",
            "ev for OP = -0.057, bd_ev -0.059\n",
            "winnings for OP: -5.682%      -2.216/39\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'D', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 5.735%      39.000/680\n",
            "ev for CP = -0.011, bd_ev -0.059\n",
            "winnings for CP: -1.095%      -0.427/39\n",
            "\n",
            "{'combo': ('H', 'D', 'A'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['H', 'D', 'A']: 3.971%      27.000/680\n",
            "ev for OP = 0.561, bd_ev -0.070\n",
            "winnings for OP: 56.107%      15.149/27\n",
            "\n",
            "{'combo': ('H', 'D', 'A'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['H', 'D', 'A']: 11.324%      77.000/680\n",
            "ev for OP = -0.291, bd_ev -0.070\n",
            "winnings for OP: -29.088%      -22.398/77\n",
            "\n",
            "{'combo': ('H', 'D', 'A'), 'symbol': 'H', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['H', 'D', 'A']: 11.324%      77.000/680\n",
            "ev for CP = -0.198, bd_ev -0.070\n",
            "winnings for CP: -19.777%      -15.228/77\n",
            "\n",
            "\n",
            "total ev: -1.199%\n",
            "total winnings: -1.199%      -14.491/1209\n",
            "num invested in: 177.794%      1209.000/680\n",
            "bd_ev: -16.863%      -0.337/2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attempt_simple_investments(al_train_lm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrTyGTqo_dDs",
        "outputId": "e1cf116a-6dbb-47c8-f336-d5ee2c56ea8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'combo': ('A', 'D', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['A', 'D', 'H']: 26.050%      620.000/2380\n",
            "ev for OP = 0.073, bd_ev 0.006\n",
            "winnings for OP: 7.315%      45.354/620\n",
            "\n",
            "{'combo': ('A', 'D', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['A', 'D', 'H']: 29.412%      700.000/2380\n",
            "ev for OP = -0.053, bd_ev 0.006\n",
            "winnings for OP: -5.309%      -37.162/700\n",
            "\n",
            "{'combo': ('A', 'D', 'H'), 'symbol': 'H', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['A', 'D', 'H']: 29.412%      700.000/2380\n",
            "ev for CP = 0.015, bd_ev 0.006\n",
            "winnings for CP: 1.457%      10.197/700\n",
            "\n",
            "{'combo': ('D', 'A', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['D', 'A', 'H']: 7.227%      172.000/2380\n",
            "ev for OP = 0.039, bd_ev -0.120\n",
            "winnings for OP: 3.884%      6.681/172\n",
            "\n",
            "{'combo': ('D', 'A', 'H'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['D', 'A', 'H']: 8.151%      194.000/2380\n",
            "ev for OP = -0.260, bd_ev -0.120\n",
            "winnings for OP: -25.992%      -50.424/194\n",
            "\n",
            "{'combo': ('D', 'A', 'H'), 'symbol': 'H', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['D', 'A', 'H']: 8.151%      194.000/2380\n",
            "ev for CP = -0.196, bd_ev -0.120\n",
            "winnings for CP: -19.572%      -37.970/194\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'A', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['D', 'H', 'A']: 4.958%      118.000/2380\n",
            "ev for OP = 0.105, bd_ev -0.039\n",
            "winnings for OP: 10.483%      12.370/118\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'A', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 5.714%      136.000/2380\n",
            "ev for OP = -0.164, bd_ev -0.039\n",
            "winnings for OP: -16.445%      -22.365/136\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'A', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 5.714%      136.000/2380\n",
            "ev for CP = -0.085, bd_ev -0.039\n",
            "winnings for CP: -8.509%      -11.572/136\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'D', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['D', 'H', 'A']: 4.076%      97.000/2380\n",
            "ev for OP = 0.306, bd_ev 0.045\n",
            "winnings for OP: 30.627%      29.708/97\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'D', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 6.597%      157.000/2380\n",
            "ev for OP = -0.116, bd_ev 0.045\n",
            "winnings for OP: -11.571%      -18.167/157\n",
            "\n",
            "{'combo': ('D', 'H', 'A'), 'symbol': 'D', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['D', 'H', 'A']: 6.597%      157.000/2380\n",
            "ev for CP = -0.073, bd_ev 0.045\n",
            "winnings for CP: -7.278%      -11.427/157\n",
            "\n",
            "{'combo': ('H', 'D', 'A'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': False}\n",
            "num ['H', 'D', 'A']: 7.143%      170.000/2380\n",
            "ev for OP = 0.045, bd_ev 0.048\n",
            "winnings for OP: 4.486%      7.626/170\n",
            "\n",
            "{'combo': ('H', 'D', 'A'), 'symbol': 'H', 'odds': ['OP'], 'is_increase': True}\n",
            "num ['H', 'D', 'A']: 11.345%      270.000/2380\n",
            "ev for OP = 0.050, bd_ev 0.048\n",
            "winnings for OP: 5.025%      13.568/270\n",
            "\n",
            "{'combo': ('H', 'D', 'A'), 'symbol': 'H', 'odds': ['CP'], 'is_increase': True}\n",
            "num ['H', 'D', 'A']: 11.345%      270.000/2380\n",
            "ev for CP = 0.230, bd_ev 0.048\n",
            "winnings for CP: 22.995%      62.086/270\n",
            "\n",
            "\n",
            "total ev: -0.037%\n",
            "total winnings: -0.037%      -1.497/4091\n",
            "num invested in: 171.891%      4091.000/2380\n",
            "bd_ev: -4.429%      -0.089/2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADH H EV: 2% OPTIMAL:47%\n",
        "DAH D EV: 5.2% OPTIMAL: 52.4%\n",
        "DAH D EV: -22.107% OPTIMAL: 47%\n",
        "DHA D EV: -6% OPTIMAL: 46.4%"
      ],
      "metadata": {
        "id": "Pd4o8qspmZia"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErMGtQzm-aZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plotting ##"
      ],
      "metadata": {
        "id": "YXzirde3Em24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GwwO3IeKGAeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_with_result = get_dataset_with_season()"
      ],
      "metadata": {
        "id": "HpthEWWLFGJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_dataset = get_stat_percent_database(dataset_with_result.copy())\n",
        "pl_dataset = get_diff_database(pl_dataset)\n",
        "pl_dataset = get_odds_percent_database(pl_dataset)\n",
        "pl_dataset = get_odds_percent_database_closing(pl_dataset)\n",
        "pl_dataset = get_dir_database(pl_dataset)\n",
        "pl_dataset[\"MAX_DIFF\"] = get_max_diff(pl_dataset)\n",
        "pl_dataset = get_odds_rankings(pl_dataset, True)\n",
        "pl_dataset = get_odds_rankings(pl_dataset, False)\n",
        "pl_dataset[\"OP_SUM\"] = pl_dataset[\"OP1_AVG\"] + pl_dataset[\"OPX_AVG\"] + pl_dataset[\"OP2_AVG\"]\n",
        "pl_dataset[\"CP_SUM\"] = pl_dataset[\"CP1_AVG\"] + pl_dataset[\"CPX_AVG\"] + pl_dataset[\"CP2_AVG\"]\n",
        "pl_dataset[\"HOME_POWER\"] = (pl_dataset[\"home_wins_rate\"] * 2 + pl_dataset[\"home_tie_rate\"]) / (pl_dataset[\"away_wins_rate\"] * 2 + pl_dataset[\"away_tie_rate\"])\n",
        "pl_dataset[\"HOME_POWER\"] = [10 if x > 10 else x for x in pl_dataset[\"HOME_POWER\"]]\n",
        "max_symbol = \"D\"\n",
        "mid_symbol = \"H\"\n",
        "min_symbol = \"A\"\n",
        "pl_dataset = pl_dataset.drop(index=pl_dataset[pl_dataset[\"games\"] < 4].index)\n",
        "pl_dataset = pl_dataset[(pl_dataset[\"OP_MAX_ODD\"] == max_symbol) & (pl_dataset[\"OP_MID_ODD\"] == mid_symbol) & (pl_dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "pl_test = pl_dataset[(pl_dataset[\"season\"] == \"2023/2024\") | (pl_dataset[\"season\"] == \"2022/2023\")]\n",
        "pl_train = pl_dataset.drop(index=pl_test.index)\n",
        "pl_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "AD4EjQjgE8U5",
        "outputId": "670245df-465a-45b6-d29f-4e8c78008d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           home_team      away_team  games         date     season result  \\\n",
              "53        Villarreal    Atl. Madrid      5  26 Sep 2015  2015/2016      H   \n",
              "66       Atl. Madrid    Real Madrid      6  04 Oct 2015  2015/2016      D   \n",
              "78    Dep. La Coruna     Ath Bilbao      7  18 Oct 2015  2015/2016      D   \n",
              "92     Real Sociedad     Celta Vigo      9  31 Oct 2015  2015/2016      A   \n",
              "99             Betis     Ath Bilbao      9  01 Nov 2015  2015/2016      A   \n",
              "...              ...            ...    ...          ...        ...    ...   \n",
              "2619          Getafe          Betis     33  02 May 2022  2021/2022      D   \n",
              "2620         Levante  Real Sociedad     34  06 May 2022  2021/2022      H   \n",
              "2622           Betis      Barcelona     34  07 May 2022  2021/2022      A   \n",
              "2630        Valencia          Betis     35  10 May 2022  2021/2022      A   \n",
              "2656         Osasuna       Mallorca     37  22 May 2022  2021/2022      A   \n",
              "\n",
              "      OP1_AVG  OPX_AVG  OP2_AVG  CP1_AVG  ...  MAX_DIFF  OP_MAX_ODD  \\\n",
              "53      3.109    3.178    2.357    2.693  ...         H           D   \n",
              "66      2.787    3.280    2.515    3.143  ...         A           D   \n",
              "78      2.763    3.055    2.670    2.878  ...         A           D   \n",
              "92      2.816    3.229    2.513    2.530  ...         H           D   \n",
              "99      2.828    3.207    2.519    3.394  ...         A           D   \n",
              "...       ...      ...      ...      ...  ...       ...         ...   \n",
              "2619    2.816    3.120    2.584    2.895  ...         D           D   \n",
              "2620    3.177    3.447    2.183    3.362  ...         A           D   \n",
              "2622    3.511    3.609    1.991    3.003  ...         H           D   \n",
              "2630    2.921    3.286    2.453    3.411  ...         A           D   \n",
              "2656    3.499    3.526    2.177    2.997  ...         H           D   \n",
              "\n",
              "      OP_MID_ODD  OP_MIN_ODD  CP_MAX_ODD  CP_MID_ODD  CP_MIN_ODD  OP_SUM  \\\n",
              "53             H           A           D           A           H   8.644   \n",
              "66             H           A           D           H           A   8.582   \n",
              "78             H           A           D           H           A   8.488   \n",
              "92             H           A           D           A           H   8.558   \n",
              "99             H           A           H           D           A   8.554   \n",
              "...          ...         ...         ...         ...         ...     ...   \n",
              "2619           H           A           D           H           A   8.520   \n",
              "2620           H           A           D           H           A   8.807   \n",
              "2622           H           A           D           H           A   9.111   \n",
              "2630           H           A           H           D           A   8.660   \n",
              "2656           H           A           D           H           A   9.202   \n",
              "\n",
              "      CP_SUM  HOME_POWER  \n",
              "53     8.570    1.125000  \n",
              "66     8.750    0.800000  \n",
              "78     8.595    1.800000  \n",
              "92     8.654    0.538462  \n",
              "99     8.891    1.125000  \n",
              "...      ...         ...  \n",
              "2619   8.661    0.675000  \n",
              "2620   9.029    0.512195  \n",
              "2622   8.975    0.872340  \n",
              "2630   8.978    0.829268  \n",
              "2656   8.739    1.296296  \n",
              "\n",
              "[254 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3820f3e-ead0-4aa6-afcf-9d81c5006a19\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>games</th>\n",
              "      <th>date</th>\n",
              "      <th>season</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>...</th>\n",
              "      <th>MAX_DIFF</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>CP_MAX_ODD</th>\n",
              "      <th>CP_MID_ODD</th>\n",
              "      <th>CP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>CP_SUM</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Villarreal</td>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>5</td>\n",
              "      <td>26 Sep 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>3.109</td>\n",
              "      <td>3.178</td>\n",
              "      <td>2.357</td>\n",
              "      <td>2.693</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.644</td>\n",
              "      <td>8.570</td>\n",
              "      <td>1.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Atl. Madrid</td>\n",
              "      <td>Real Madrid</td>\n",
              "      <td>6</td>\n",
              "      <td>04 Oct 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.787</td>\n",
              "      <td>3.280</td>\n",
              "      <td>2.515</td>\n",
              "      <td>3.143</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.582</td>\n",
              "      <td>8.750</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Dep. La Coruna</td>\n",
              "      <td>Ath Bilbao</td>\n",
              "      <td>7</td>\n",
              "      <td>18 Oct 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.763</td>\n",
              "      <td>3.055</td>\n",
              "      <td>2.670</td>\n",
              "      <td>2.878</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.488</td>\n",
              "      <td>8.595</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>Celta Vigo</td>\n",
              "      <td>9</td>\n",
              "      <td>31 Oct 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>A</td>\n",
              "      <td>2.816</td>\n",
              "      <td>3.229</td>\n",
              "      <td>2.513</td>\n",
              "      <td>2.530</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.558</td>\n",
              "      <td>8.654</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Betis</td>\n",
              "      <td>Ath Bilbao</td>\n",
              "      <td>9</td>\n",
              "      <td>01 Nov 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>A</td>\n",
              "      <td>2.828</td>\n",
              "      <td>3.207</td>\n",
              "      <td>2.519</td>\n",
              "      <td>3.394</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>8.554</td>\n",
              "      <td>8.891</td>\n",
              "      <td>1.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>Getafe</td>\n",
              "      <td>Betis</td>\n",
              "      <td>33</td>\n",
              "      <td>02 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>D</td>\n",
              "      <td>2.816</td>\n",
              "      <td>3.120</td>\n",
              "      <td>2.584</td>\n",
              "      <td>2.895</td>\n",
              "      <td>...</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.520</td>\n",
              "      <td>8.661</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2620</th>\n",
              "      <td>Levante</td>\n",
              "      <td>Real Sociedad</td>\n",
              "      <td>34</td>\n",
              "      <td>06 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>H</td>\n",
              "      <td>3.177</td>\n",
              "      <td>3.447</td>\n",
              "      <td>2.183</td>\n",
              "      <td>3.362</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.807</td>\n",
              "      <td>9.029</td>\n",
              "      <td>0.512195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2622</th>\n",
              "      <td>Betis</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>34</td>\n",
              "      <td>07 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>A</td>\n",
              "      <td>3.511</td>\n",
              "      <td>3.609</td>\n",
              "      <td>1.991</td>\n",
              "      <td>3.003</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.111</td>\n",
              "      <td>8.975</td>\n",
              "      <td>0.872340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2630</th>\n",
              "      <td>Valencia</td>\n",
              "      <td>Betis</td>\n",
              "      <td>35</td>\n",
              "      <td>10 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>A</td>\n",
              "      <td>2.921</td>\n",
              "      <td>3.286</td>\n",
              "      <td>2.453</td>\n",
              "      <td>3.411</td>\n",
              "      <td>...</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>8.660</td>\n",
              "      <td>8.978</td>\n",
              "      <td>0.829268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>Osasuna</td>\n",
              "      <td>Mallorca</td>\n",
              "      <td>37</td>\n",
              "      <td>22 May 2022</td>\n",
              "      <td>2021/2022</td>\n",
              "      <td>A</td>\n",
              "      <td>3.499</td>\n",
              "      <td>3.526</td>\n",
              "      <td>2.177</td>\n",
              "      <td>2.997</td>\n",
              "      <td>...</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.202</td>\n",
              "      <td>8.739</td>\n",
              "      <td>1.296296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3820f3e-ead0-4aa6-afcf-9d81c5006a19')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3820f3e-ead0-4aa6-afcf-9d81c5006a19 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3820f3e-ead0-4aa6-afcf-9d81c5006a19');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e3517a9-ec24-4acd-9719-6e14d6815bf4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e3517a9-ec24-4acd-9719-6e14d6815bf4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e3517a9-ec24-4acd-9719-6e14d6815bf4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_012ad42f-5b61-45d8-8a9b-71be6fc3f574\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pl_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_012ad42f-5b61-45d8-8a9b-71be6fc3f574 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pl_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pl_train"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import axes3d"
      ],
      "metadata": {
        "id": "VlRgpfOwJCWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 'combo': ('D', 'H', 'A'), 'symbol': 'D',\n",
        "\n",
        "symbol = \"D\"\n",
        "label = \"DIRX\"\n",
        "color_col = pl_train[label].apply(lambda x: 'g' if x == 1 else 'r')\n",
        "plt.scatter(pl_train[\"OPX_AVG\"], pl_train[\"HOME_POWER\"], c=color_col)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "0r71L7kjEojh",
        "outputId": "0f7386f0-4e1c-4948-9eab-5b4a5a3b54f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACkYklEQVR4nOzdd3xT1fvA8c9N0gltoYxSoOwle++hgIADQYagspcMAcHJ1/Vz4gAHMgVkCAjIlCkbZMqWvTe07JaWriT398ehiyZpWtqmheftqy9pcu/NSZrkPvec5zxH03VdRwghhBDCRQyuboAQQgghnmwSjAghhBDCpSQYEUIIIYRLSTAihBBCCJeSYEQIIYQQLiXBiBBCCCFcSoIRIYQQQriUBCNCCCGEcCmTqxvgDKvVytWrV/Hx8UHTNFc3RwghhBBO0HWde/fuUbBgQQwG+/0f2SIYuXr1KkFBQa5uhhBCCCHS4NKlSxQuXNju/dkiGPHx8QHUk/H19XVxa4QQQgjhjLCwMIKCguLP4/Zki2AkbmjG19dXghEhhBAim0kpxUISWIUQQgjhUhKMCCGEEMKlJBgRQgghhEtJMCKEEEIIl5JgRAghhBAuJcGIEEIIIVxKghEhhBBCuJQEI0IIIYRwqWxR9EyI7ODW/VusP7eeaHM0VQtUpVJAJVc3SQghsoVU9YyMHDmSWrVq4ePjQ/78+Wnbti0nTpxwuM/06dPRNC3Jj6en5yM1WoisJMYSw5BVQyj4Q0E6LehEtyXdqDyxMvWn1ufUrVOubp4QQmR5qQpGNm/ezKBBg9i5cydr164lNjaWFi1aEBER4XA/X19frl27Fv9z4cKFR2q0EFmFrut0W9yNcbvHEWOJSXLfv1f+pf5v9bkSdsVFrRNCiOwhVcM0q1evTvL79OnTyZ8/P3v37qVx48Z299M0jQIFCqSthUJkYbuv7mbekXk277PoFu5E3mHU9lH82OrHTG6ZEEJkH4+UwBoaGgqAv7+/w+3Cw8MpWrQoQUFBtGnThiNHjjjcPjo6mrCwsCQ/QmRFMw/OxGSwH9NbdAu/HfgNXdczsVVCCJG9pDkYsVqtvPXWWzRo0ICKFSva3a5s2bL89ttvLF26lFmzZmG1Wqlfvz6XL1+2u8/IkSPx8/OL/wkKCkprM4XIUMHhwVisFofbhEWHEWuNzaQWCSFE9qPpabxkGzBgAKtWrWLr1q0ULlzY6f1iY2N56qmnePXVV/niiy9sbhMdHU10dHT872FhYQQFBREaGoqvr29amitEhhiyaggT9kzAbDXb3SaXZy7uvH8nE1slhBBZQ1hYGH5+fimev9PUM/Lmm2+yfPlyNm7cmKpABMDNzY1q1apx+vRpu9t4eHjg6+ub5EeIrKhH1R4OAxGjZqRPtT6Z2CIhhMh+UhWM6LrOm2++yeLFi9mwYQPFixdP9QNaLBYOHTpEYGBgqvcVIqupHlidHlV6oKElu89kMBGQM4C367/tgpYJIUT2kapgZNCgQcyaNYs5c+bg4+NDcHAwwcHBREZGxm/TrVs3RowYEf/7559/zpo1azh79iz79u2jS5cuXLhwgT595GpRPB6mvDSFEQ1HkMMtR5Lbnyn2DDt676BATplJJoQQjqRqau+ECRMAePrpp5PcPm3aNHr06AHAxYsXMRgSYpw7d+7Qt29fgoODyZ07NzVq1GD79u2UL1/+0VouRBZhNBj5qtlXjGg0gn8u/EOUOYrKAZUp6V/S1U0TQohsIc0JrJnJ2QQYIYQQQmQdGZrAKoQQQgiRXiQYEUIIIYRLSTAihBBCCJeSYEQIIYQQLiXBiBBCCCFcSoIRIYQQQriUBCNCCCGEcCkJRoQQQgjhUhKMCCGEEMKlJBgRQgghhEtJMCKEEEIIl5JgRAghhBAuJcGIEEIIIVxKghEhhBBCuJQEI0IIIYRwKQlGhBBCCOFSEowIIYQQwqUkGBFCCCGES0kwIoQQQgiXkmBECCGEEC4lwYgQQgghXEqCESGEEEK4lAQjQgghhHApCUaEEEII4VISjAghhBDCpSQYEUIIIYRLSTAihBBCCJeSYEQIIYQQLiXBiBBCCCFcSoIRIYQQQriUBCNCCCGEcCkJRoQQQgjhUhKMCCGEEMKlJBgRQgghhEtJMCKEEEIIl5JgRAghhBAuJcGIEEIIIVxKghEhhBBCuJQEI0IIIYRwKQlGhBBCCOFSEowIIYQQwqUkGBFCCCGES0kwIoQQQgiXkmBECCGEEC4lwYgQQgghXEqCESGEEEK4lAQjQgghhHApCUaEEEII4VISjAghhBDCpSQYEUIIIYRLSTAihBBCCJeSYEQIIYQQLiXBiBBCCCFcSoIRIYQQQriUBCNCCCGEcCkJRoQQQgjhUhKMCCGEEMKlUhWMjBw5klq1auHj40P+/Plp27YtJ06cSHG/P//8k3LlyuHp6UmlSpVYuXJlmhsshBBCiMdLqoKRzZs3M2jQIHbu3MnatWuJjY2lRYsWRERE2N1n+/btvPrqq/Tu3Zv9+/fTtm1b2rZty+HDhx+58UIIIYTI/jRd1/W07nzjxg3y58/P5s2bady4sc1tOnXqREREBMuXL4+/rW7dulStWpWJEyc69ThhYWH4+fkRGhqKr69vWpsrhBBCiEzk7Pn7kXJGQkNDAfD397e7zY4dO2jevHmS21q2bMmOHTvs7hMdHU1YWFiSHyGEEEI8ntIcjFitVt566y0aNGhAxYoV7W4XHBxMQEBAktsCAgIIDg62u8/IkSPx8/OL/wkKCkprM4UQQgiRxaU5GBk0aBCHDx9m7ty56dkeAEaMGEFoaGj8z6VLl9L9MYQQQgiRNZjSstObb77J8uXL2bJlC4ULF3a4bYECBQgJCUlyW0hICAUKFLC7j4eHBx4eHmlpmhBCCCGymVT1jOi6zptvvsnixYvZsGEDxYsXT3GfevXqsX79+iS3rV27lnr16qWupUIIIYR4LKWqZ2TQoEHMmTOHpUuX4uPjE5/34efnh5eXFwDdunWjUKFCjBw5EoChQ4fSpEkTRo8ezQsvvMDcuXPZs2cPv/76azo/FSGEEEJkR6nqGZkwYQKhoaE8/fTTBAYGxv/MmzcvfpuLFy9y7dq1+N/r16/PnDlz+PXXX6lSpQoLFixgyZIlDpNehRBCCPHkeKQ6I5lF6owIIYQQ2U+m1BkRQgghhHhUEowIIYQQwqUkGBFCCCGES0kwIoQQQgiXkmBECCGEEC4lwYgQQgghXEqCESGEEEK4lAQjQgghhHApCUaEEEII4VISjAghhBDCpSQYEUIIIYRLSTAihBBCCJeSYEQIIYQQLiXBiBBCCCFcyuTqBojs6dydcxy/eZwc7jmoV7gebkY3VzdJCCFENiXBiEiV07dPM2DFANadXRd/W17vvHzc+GMG1x6MpmkubJ0QQojsSIIR4bQLdy9Qd0pd7kbdTXL7zfs3Gbp6KDfv3+TzZz53TeOEEEJkW5IzIpz22ebPuBt1F4tusXn/V/98xeWwy5ncKiGEENmdBCPCKZGxkcw5NMduIAKgoTHz4MxMbJUQQojHgQQjwim3I28TbYl2uI1BM3Ap9FImtUgIIcTjQoIR4ZRcnrkwakaH21h1K/lz5M+kFgkhhHhcSDAinJLDPQftnmrnMCCx6Ba6VO6Sia0SQgjxOJBgRDjt0yaf4m50txmQaGj0rd6X0nlKu6BlQgghsjMJRoTTKuSvwMbuGynpXzLJ7e5Gd4bVHcb4F8a7qGVCCCGyM6kzIlKlTuE6HB90nK0Xt3L0xlFyuuekValW5PHO4+qmCSGEyKYkGBGppmkajYo2olHRRq5uihBCiMeABCNCOOHw9cNM3DORvdf24m3ypk25NnSv0h0/Tz9XN00IIbI9Tdd13dWNSElYWBh+fn6Ehobi6+vr6uaIJ8z3277nvXXvYTKYMFvNaKj1d/J652V9t/VUCqjk4hYKIUTW5Oz5WxJYhXBgxckVvLfuPQDMVjMA+oP/bkfepuWslkSZo1zZRCGEyPYkGBHCge+2f2e3topFt3At/Bp/Hvkzk1slhBCPFwlGhLAj1hLLlgtbHK7HY9SMrD27NhNbJYQQjx8JRoSwQ8e5dKq44RshhBBpI8GIEHa4G92plL8SBgcfE6tupX5Q/UxslRBCPH4kGBHCgWF1h2HFavM+Awa83bzpWrlrJrdKCCEeLxKMCOFAj6o96FWtF0CSRFaTwYSb0Y1FnRZJrREhhHhEEowI4YCmaUxpPYWFryykUdFG5PLMRUCOAPpV78fB/gdpUbKFq5sohBDZnhQ9E0IIIUSGkKJnQgghhMgWJBgRQgghhEtJMCKEEEIIl5JgRAghhBAuJcGIEEIIIVxKghEhhBBCuJQEI0IIIYRwKQlGhBBCCOFSEowIIYQQwqUkGBFCCCGES0kwIoQQQgiXkmBECCGEEC4lwYgQQgghXEqCESGEEEK4lAQjQgghhHApCUaEEEII4VISjAghhBDCpSQYEUIIIYRLSTAinngh4SH8b/3/CBwViPsX7hT7qRhf//M1oVGhrm6aEEI8EVIdjGzZsoXWrVtTsGBBNE1jyZIlDrfftGkTmqYl+wkODk5rm4VIN2dun6HqpKp8t+07giOCibXGciH0Ah9v/JjaU2pzI+KGq5sohBCPvVQHIxEREVSpUoVx48alar8TJ05w7dq1+J/8+fOn9qGFSHevLXqNGxE3sOiWJLdbdStnbp/hzZVvuqhlQgjx5DCldofnnnuO5557LtUPlD9/fnLlypXq/YTIKAeCD/DvlX/t3m/RLSw8tpBr964R6BOYiS0TQognS6bljFStWpXAwECeffZZtm3b5nDb6OhowsLCkvwIkd52X9md4jYW3cKB4AMZ3xghhHiCZXgwEhgYyMSJE1m4cCELFy4kKCiIp59+mn379tndZ+TIkfj5+cX/BAUFZXQzxRPI3eiertsJIYRIG03XdT3NO2saixcvpm3btqnar0mTJhQpUoTff//d5v3R0dFER0fH/x4WFkZQUBChoaH4+vqmtblCJHE57DJFfyqKVbfa3Sane06C3w4mh3uOTGyZEEI8HsLCwvDz80vx/O2Sqb21a9fm9OnTdu/38PDA19c3yY8Q6a2wb2FerfgqRs1o834NjSG1h0ggIoQQGcwlwciBAwcIDJSEQOF6k16cRJNiTQDigxKTQeV1d67Ymc+e+cxlbRNCiCdFqmfThIeHJ+nVOHfuHAcOHMDf358iRYowYsQIrly5wsyZMwH46aefKF68OBUqVCAqKoopU6awYcMG1qxZk37PQog0yuGeg7Vd17L2zFp+/+93gsODKepXlF7VelE/qD6aprm6iUII8dhLdTCyZ88ennnmmfjfhw8fDkD37t2ZPn06165d4+LFi/H3x8TE8Pbbb3PlyhW8vb2pXLky69atS3IMIVzJoBloWaolLUu1dHVThBDiifRICayZxdkEGCGEEEJkHVk6gVUIIYQQIo4EI0IIIYRwKQlGhBBCCOFSEowIIYQQwqUkGBFCCCGES0kwIoQQQgiXkmBECCGEEC4lwYgQQgghXEqCESGEEEK4lAQjQgghhHApCUaEEEII4VISjAghhBDCpSQYEUIIIYRLSTAihBBCCJeSYEQIEc9sNXM94joRMRGuboqIo+tw8ybcuePqlgiRYSQYEUJwN+ou7619j7zf5SVgVAA+I314fvbzbL+03dVNyx7u3oWxY2HAAHjnHdi+XQURj8JigZ9/hhIlIF8+8PeHqlVh7tz0aLEQWYqm64/6icl4YWFh+Pn5ERoaiq+vr6ubI8Rj5U7kHer/Vp9Tt05h0S3xtxs1IwCLOi3ipbIvuap5Wd8ff0CvXhAdDSaTCkLMZmjcGJYsgdy5U39MqxU6d4YFC9TvcV/TBoO675NP4LPP0u0pCJFRnD1/S8+IEE+4Tzd9miwQAbDoFqy6la6Lu3I/9r6LWpfFbdwIr78OUVEqYIiNVYEIwLZt0LZt2npI5s2DP/9U+ybe32pV///8c9i//5GbL0RWIcGIEE+wyNhIpu6fmiwQiaOjExYdxp9H/szklmUTX36peitssVhgyxY1ZJNa48bZPy6oHpgJE1J/XCGyKAlGhHiCXQq7lGKvh5vBjSM3jmRSi7KRe/dgwwYVdNhjMsGiRak/9uHDCb0gtpjNcOhQ6o8rRBYlwYgQT7AcbjlS3EbXdbzdvDOhNdnMfSeGrjQNwsNTf2zvFF5vTYOcOVN/XCGyKJOrG5AVRZmjWHtmLbcjb1M8d3EaFWmEpmmublaWFXz3MsfmjcPjxm2KlKtD4bbd1BWhyHS6rrPt0jbO3D5Dbq/cPFviWbzcvOxuX8i3ENUDq3Mg+ABW3faVuFk30+6pdhnV5OwrTx6VnOpoyq3ZDOXLp/7Yr7yiZuc46nXp0CH1xxUii5LZNInous7Yf8fy8caPCY0Ojb+9ZO6S/Nr6V5oWb5phj50dRcREMP3DF2g3cTOBiS7+bvu6w48/4t9roOsa9wTadH4TfZf15fTt0/G3+Xn48WmTT3mr7lt2A+q/TvxFm7ltbN5n1Iy0LNWSFa+tyJA2Z3v/+x989539oMHDA65dS/2MmrNnoVIllRj78HCN0QgFCsDx49I7IrI8mU2TBj/s+IEhq4ckCUQAzt09R8tZLdl6cauLWpb1WKwWvh9Wm0GjNlPgoV7o3GEx+PceRPjMKa5p3BNox6UdtPi9BWdvn01ye2h0KMPXDOfbbd/a3felsi8x8YWJuBncMGgGTAYTJoPq2WpavCl/tP8jQ9uerY0YARUrqgAhMaNRDaVMnpy2qb0lSsDff0OuXOp3kymht7FoUTWLRwIR8RiRnpEHQqNCKTC6AFHmKJv3GzQDdQrVYXtvKQIFsPzYUqrUbUuhMNsRrQ6E5/XBJ/hO8i9qke4aT2vM9kvb7c6K8TB6EPxOMLk8c9k9xo2IG8w4OIOTt07i6+FLx/IdqV2odoYPUR4IPsDEPRPZc3UP3m7etC3Xlh5Ve+Dv5Z+hj5tu7t2DkSNh4sSEIZunn4aPPoJmzR7t2JGRMH8+7NihgpHmzeHFF2UYVGQbzp6/JRh5YPqB6fRa2gsdxy/HmSFnKJG7RIa0ITv59NMmfPb5lpQ3XL8emsrwVka6GHqRoj8VdbiNhsavrX+lT/U+mdQq53yz9RtGrB+BSTNh1lV9Dg0Nfy9/1ndbT5UCVVzcwlQwm+HGDZV86ufn6tYIkSXIME0qBYcHYzSkfAUfHB6cCa3J+qzBV53b8Nq1jG1IdnL1qsovGDJE1ac4dy5dDhsSHpLiNkaDkWv3stbfYtmJZYxYPwIgPhABVdvkbtRdWs5qSWRspKual3omEwQGSiAiRBpIMPJAQZ+CmK1mp7YTYCgc5NyGhQplbEOyA12H//s/CApSOQYTJ6rfS5ZUgYmjGRNOCPQJTHEbi9VCId+s9bf4fvv38SXnH2bRLYREhDD/yPxMbpUQwhUkGHng5XIvO6ylYNSMNC7amGK5imVeo7Kwep3e4bwf2CvLZAXC8udS63NktNhYVTq7Vy/o0gV++ilrrXA6ZoxaR8RqVT+xsSoA0XU1ffPTT50+VIwlhnmH59FzaU+6Lu7KmF1jyOmek2eKPWP3xA7gYfKgQ/msMxU01hLLPxf/sZvjAuozt+7cukxslRDCVSQYecDHw4fvmn9n8z6DZsBoMPL9s9+nz4PpOmzdCjNmwF9/qSS1bKZF6VZM710dSB6QxP1uGptCSev0cOoUlCmj6jL8/rta0XT4cNUj89dfGfvYzoiJUeuI2KPrMHo0hIba3+aBEzdPUPqX0nRe2JlZB2fxx6E/eGv1WxT6oRBtyrbBzahmw9jyTbNv8PXIOotMppSbFcdifbReIyFE9iDBSCKDag9i6ktTCcgRkOT2CvkqsKn7JmoXqv3oD7Jpkzp5NmoEPXpAmzZqnPnHHx99yfFMZNAMfPDtNn799AXOPzRz8UY+b+7Nm4l3x9cythGRkWq2wuXL6nezOaHHISoK2reHAwcytg0p2LD8F15sdRvvD8HrQ6jbG36uDeHuiTaKioLVqx0eJyImgqYzm3Il7AqgciwsugUdncjYSN5d+y5TW0+lUv5KSfbLnyM/v774K0PrDk3vp/ZI3I3uVAmoYjd4ArDqVuoH1c/EVonHisWiSubv3atmPIksTWbT2GC2mvnnwj/cjrxNidwlqFqgavpMb9yxA5o0UR8SW+tOjBwJH3zw6I+Tye7cv82RZb/hHnKDYk/VI3+zlzK+RwRUz1KPHvbvN5nUMuy//57xbbHhxx0/MnzNcIwWsDw0gmKywIA98NV68IkBpkyB3r3tHmvy3sn0W97P7v0mg4luVbox9aWpHAg+wNk7Z8ntmZuGRRriZnRLp2eUvmYenEn3Jd1t3mfQDHi7eXN52GX8PCUhVKSCrquFBr/5Bq6o4B0vLzWM+/XXkAnnEJFApvZmRY0bqxU8HVVrDA5OKHQkHGvfHpYscbygWI4caVsb5BEdCD5AtUnVHG5jsEL1a7B5Onhv2gb17fcCvDjnRVaeWulweCOXZy7uvJ+FcmVSoOs6/Vf059e9v2LUjPH5IybNhMloYtmry2heormLWymyBF1Xs8+ioqB4cRVc2PP22/DDD8lvNxqhcmX45x/1vSAyhUztzWouXlQfAkczJ2JiYMGCzGtTdnf/vuNABNRr6gLjdo+Lr2Jqj9UAewNh0nP5oV49h9vej72fYp5FtDk61e10JU3TmPD8BJZ2XsozxZ8hj1ceCvkUYmCtgfzX/z8JRIQycyaULatmn1WoAPnzw7BhEBaWfNuDB20HIqC+ew8eVL0mIsuRYCSzhKRcCwKjUepypEbVqo6ruxoMqlS3C+y4tMOpqeJoMKGhhyod7kC1AtUcBjcGzUClgEp2789KdF1nzqE51J5cG/cv3en4Z0e83bxZ0nkJl4df5ufnfqZ0ntKubqbICr74Arp3h9MJ6y0RHg6//KKGvB/u9Zw61XF1WqtVTa0XWY4EI5klMOVaEFgsUpcjNfr2dZz0a7XC4MGZ155EPEweTm2na3A+KuVCem/UfMPhzBKrbmVwbdc819TQdZ1+y/vx+qLX2XttLxbdQowlhpWnVtJ4WmN+2/+bS9r0z4V/eGPZG7Sb146hq4ZyIPhAprdDPOTMmYRp7w9/zi0W+O8/NW0+sdOnVSK7IxcupF8bRbqRYCSzFC4Mzzzj+Erew0OWBU+NEiXUFRJgNRqYUQVq9gOPj8D3A+g+tAgHW7qmnPiLpV90WPcjMWem3JbJU4YfWqru58TH1VA9Kp0rdua1Shk8eykd/Hn0T6bsUwsoWvWEITaz1YyOTt9lfTl/93ymtScyNpKX/niJxtMb89uB31hyfAnj94yn2qRqvLHccQAoMtiUKY4T4a1WmDAh6W3+/imvheXj8+htE+lOgpHM9P334OZm/wP2zTeS6Z1aAwdiWb2SV/vnpcfLsL8AxJjgnifMyXOVmlPrsOzEskxv1hs138DD5BEfLNhj0kx0rdzVqWO+VfctVr62ksZFEwrJlc1blokvTGR2u9kOp8lmFWN2jXEYpGloTNozKdPa8+bKN1l5eiWQEBDFDa9N3juZr//5OtPaIh5y6lTKOWGXL6signE6d3acl2cyQVfnPm8ic8lsmsy2axe88YZKpIqTP79aq6RvX9e1KxubuGciA1cMtJngqaHhafLkyvAr5PaysZS7rqsZTsuWqUz9KlWgUye12Jkdh0IOMf/IfEKjQymTpwyvV3rd5rE3n9/Mi3+8SHiM7dk8Rs1ITvecHOx/kKK5HC9097AYSwwWqwUvNwezCrIgr6+87K6MHadZ8Was65bxlVev3btG0I9BDqvA+nn4EfxOMJ4mzwxvj3hI794qedXRsIuHh6o3FJdzZbFAgwawZ0/yoMRoVLNo9u9XvaoiU8hsmqyqTh1ViGv/fli4EDZsUNG9BCJp9tPOn+zep6MTZY5ixsEZye+8cQMaNlQ/o0fD+PGqFkFgIKxalWzz+7H3aT+/PZUnVuabbd8wcc9EhqwaQuDoQJu5Dk2KNeHCWxf47OnPyOOVB1DBkRHVM1A0V1E29diU6kAEVNGw7BaIALgZHNc80dCczrd5VGvOrHEYiACERoey8/LOTGmPeMgrrzgOREwmePXVpMnfRqP67D77rPrdYEhIaA0Kgo0bJRDJohzPPRQZp2pV9ZNNXAy9yOS9kzkYchBPkyety7SmY4WOmXvFeOWKGkfeuxfc3eH554ls34YTt0443M2gGdh9dXfSG61WeP75hAqtib/07t2Dl15SvVjVq8ff3GNJD5YcX6I2TzRTJtoSTe+/epPPOx+ty7ZO8jD+Xv580uQTPmnyCYdCDrH69GpiLDHUKlSL5iWaZ4uhlfTUumxr5h+Z73Cm0YulX8yUtkRbnJsKnVJPjsggzz4LdevC7t3Jeznigox3302+X+7cKiA5cgRWrlTT+2vUgBYtMqcYo0gTGaYRKZq8dzL9V/RHQ8OiWzBoBqy6lSJ+RVjfbT2l/EtlfCNmzYKePRMWmzMYwGoltlAB3Ps6no1i0kx0qdKFaW2mJdy4ejU895yDnUzw8sswX60ae+zGMcqPL293c4NmoEpAFfa9sS9VT+tJs/fqXupMqWOzR8KoGfH38ufMkDP4eGR8kuHuK7upPcXxEg8GzcClYZdktW5XuX1b9ZCsX696PQwGlSOSP79aHDMzFuIUj0SGaUS62HBuA/2W98OqW+NPIHGzIK7eu8qzvz9LjCWDC4vt3Anduqnei7iEtgf/dwu+wTNX3B0mRZp1M8+VeijwWLjQcT0CsxkWL46/Ilt8fLHDx7DqVvYH7+di6EXnntMTqkbBGsxpPwc3Q8KifnFJvnm887Cu27pMCUQAahasSdUCVe3+XU2aiTZl20gg4kr+/rBunRrW/vRT1ROyYIEa2pZA5LEiwzTCoW+3fpukVHdiZquZ83fPs+T4El6p8ErGNWLUKHVVZGv82GLhgw0WNtpJkDdqRgr7FqZtubZJ7wgPTzlT32xWXbxeXoTHhGPQDCnmGNhLVhUJXqnwCo2KNGLq/qnsvrIbN6MbrUq14tWKr5LDPfPKdGuaxpx2c2j4W0PCYsKSDB0ZNSOF/Qoz7nmp1pklZLNhbZF6EowIu8xWM2vPrnVYhtyoGVlxakWqgxFd17lx/wYWq4WAnAGOcydWrHCYyNbinIFfrlZiaKFD8UNJGho6OoE+gazpugZ3o3vSncqVS7HqKYUKgafKiSmXtxyx1liHm3saPQnyDXJ8TAFAoE8gHzX+yNXN4Kl8T7G//35Gbx/N9IPTCYsOI693Xt6o8QbD6g4jj3ceVzdRiCeCBCP2HDyofry8oHlzlRT1hLFYLSmuh6Kjp2qYRtd1ph+Yznfbv+P4zeMAFPErwrC6wxhcezBGg40u81jHQQBWK29eDeK5kQv5de+vHAg+gJebF23KtqFTxU54u9mYptu7N3z+uf1jGgwwaFB8wNKhfAcGrxrMveh7Nl8To2akS5UumTbEINJPEb8i/Pzcz/z83M+YreYU1xQSQqQ/+dQ97NgxtRbC7kSzLzw81Inpm29U0TIXCgkP4cb9GwTmDMzwqzYPkwdl85Tl5K2TDoOSGoE1nD7mu2vfZfSO0UmKgV0Mvcjwv4ez8/JO5rSfk7yXpGpVNWZsb1jFYICaNSnpX5Jvn/3WuYYULgw//ghDh8Ynw8YzGqFmTXXfA95u3kxvM50Of3bAQNLhGqNmpIhfEb5q+pVzj50d3bql1k3Klw8CAlzdmgwjgYgQriEJrIlduKBqTux7aEZEdLQ6cfXp45p2Absu7+LZmc9SYHQBKk2oRP5R+Xl53svxvQupdSfyDtsubmP3ld3EWuz3PAytM9TufRoabgY3elbt6dRjbr+0ndE7RgMkC250dOYdmcfCowttNGKo4/wOgyFtf5shQ2DRIqhWLeG23LnhvfdU9v5Dhc9efuplNnbfSJNiTeJv83bz5o0ab7Crzy7y58if+jZkdceOQdu2avZCpUpQoICacvnvv65umRDiMSJTexMbMEDVsXBUaOfAAVWlMxNtOr+JFr+3SDKjBdQVubebN9t7b6difudWp70deZu317zN7P9mx+dA5M+Rn/cbvM+wusPQHsqjsFgtdFrQiYXHFmLAgBUVFJgMJnRdZ16HebQv396px+62uBt/HP7Dbo0Jo2akUdFGbOy+MekdViv06AG//560F8NkUrNdZs6ELl2caoNd16+rCqyBgU71ft2OvM296HsE5Ax4fKtzHj4M9evD/ftJ6zzETbFcswaeftplzRNCZH0ytTe1LBaYMSPlin8zZ2Zem1BTRnsu7YlFtySbyWHRLdyPvc/AFQOdOlZYdBgNf2vI7wd/T5KMeT3iOm+veZuhq5P3ghgNRuZ1mMeU1lOoGFARg2bAy+RFh6c6sLPPTqcDEYBD1w85LHZl0S0cvn44+R0GA0yfrv4+Vauq3z08oE0b2Lbt0QMRUFf+RYo4PQzn7+VP0VxFH99ABFRw/nAgAup3i0VVq01pRpIQQjhBBkjj3L+v1jhwRNchOOXl3tPTxnMbHa5iatEt/HPxH07dOkXpPKUdHmvMrjGcuHUiyWqpif3y7y/0qd6HygGVk9xuNBjpXb03vav3Rtf1ZL0nzvJx94mf5WJPTvectu8wGFStkW7d1N8hjW0QTjp5ErZutX+/1QrnzsGWLdI7IoR4ZNIzEidHDvXjiKap6Z6Z6NTtU05td/r26RS3mbhnot1ABNTQy9R9Ux0eI62BCEDH8h0d3m/UjHSq0CnlA0kgkvFOOfe+4+TJjG2HEOKJIMFIHINBlRs32q+yidmsZtpkIj8PP6e28/VwnEuj6zpX7l1xuI3Zaubc3XNOty21ulftToGcBWxWvDRqRnK452BQrUEZ9vgiFfyce985vZ0QQjggwUhiH3wAefLYLhOuadCvH1SokKlNer708ynmJRT0KUjdwnUdbqNpWooBi8lgytDpwr4evmzqsYliuYoBagXXuFVc83jnYV3XdQT5SdGwLKFuXTVzxhEvL8fr+wghhJMkGEmsUCG1DsrDax7kzAmffAITJmR6k/w8/Xiv/nsOt/n86c9tFwt7SNfKXR3WUTBbzbxW8bVUtzE1yuQpw4k3T/BX578YWGsg/Wv254/2f3Bp2CVqFaqVoY8tUsFkgi++cLzNe++BLFwphEgHMrXXnlOn1NRGT08VnKSUT5KBrLqVEetGMHrHaHR0jJoRs9WMm9GNkc1GMrzecKeOc+7OOapNqkZ4THiymTlGzUjDIg3Z0H1Dmpa1339tPxP2TOC/kP/w8fChXbl2tC7TmsXHF7Pk+BIiYiOoEViD/jX7UymgUqqP70oxlhgWHl3I7EOzuXH/BiVzl6SPXpVnFuxFO3dezcRp2DDhPePjA+3bq1k+ORMScqPN0Sw8po5z8/5NSucqybsRVam8ci/a+fOqmFi3bmqWkL1ZPTt2wK+/wtGjKonUaFQzW/Lnh9dfhw4dwN3d9r5pMXo0/O9/qgpu3FRqTYN33oGvv07bkuzBwTB5Mqxdq55Do0bwxhtQrFj6tTsThMeEM+u/WSw8tpB70feoHFCZ/jX7Uz2wuqubJkSW4ez5O9XByJYtW/j+++/Zu3cv165dY/HixbRt29bhPps2bWL48OEcOXKEoKAgPvroI3r06OH0Y7okGMmCrt27xtzDc7kecZ0ifkXoVLET/l7+qTrGweCDdPyzI6dun8KoGbHqVnR02pVrx/S209NUzvzTjZ/y+ZbPMRlMmK3m+BkzBs1A3NtLR4+//5tm3/B+w/dT/TiucPP+TZrPbM7BkIMYNANW3YpJ1zBrOq8e1pi5SMeka2qGT5y4BNuCBWHjRihdmhsRN2g2sxmHrh/CoBkwxlr5cwG0OQ4Wg4bRqicEFnXrwurVSfMxdF0Vf/vll4TtEourv1KpkirYli9f+r0It2/D3Llw6ZIKmDp1UvVY0mLdOnjpJVVIMG5asNGoXrNZs9Sxs4FTt07xzIxnuHrvKpD0/f1x44/5/BkHSw0I8QTJsGBk1apVbNu2jRo1atCuXbsUg5Fz585RsWJF+vfvT58+fVi/fj1vvfUWK1asoGXLlun6ZIRzdF1n0/lN7Lu2Dw+TB8+Veo6S/iXTdKy5h+fy6sJXU73fX53/onXZ1ml6zMzUclZL1p9db3O1Xk2H+fOhwzE7OxuNULQonDhBs9kt2Xxhc/xxvlsDw3eA0danz2hUVU8XLEi4bcIEGOhEPRmjUU21Xbcu5W0z25UrULq0Ki5n62vHaFRFBSs6V8DPVcxWM2XHluXC3Qt2V3H+o/0fdK7YOZNbJkTWk2HBSJKdNS3FYOT9999nxYoVHD6cUMyqc+fO3L17l9WrVzv1OBKMZF3VJlXjv5D/HE4ZfphRM1IvqB7/9PwnA1v26I7eOEqF8Y4Tlv8bDxWvg6PJxuen/UjxC8Pif88ZDcGjIIej9f80Dc6eVUMXViuULAnnzzvf+EOHst5J/dNP4auvkvfqxDGZ1Iy2X3/N3HY95G7UXWYcmMHCYwu5H3uf6oHVGVBzANUC1bIBS44v4eV5L9vd36AZqJS/Egf6H8ikFguRdTl7/s7womc7duygefPmSW5r2bIlb731lt19oqOjiY6Ojv89LCwso5onHsHdqLscCD6Q6v0suoWtF7cSY4nB3Zg++Q1R5ihWnFzB5bDL5M+Rn5f8apNj+mxYulQNCdSurRY7rOH8on5rz6yNH5qxJVckVLqewkFMJu4uX4ChcsJxal9JIRAB1XOwYYOqcnr+fOoCEYNB5WNktWBk1Sr7gQioqfMrV2Zee2w4FHKIpjObcuv+rfjifAdDDjJ532S+eOYLPmr8EWvPrI0fkrHFqls5GHKQu1F3yeWZKxNbL0T2leHBSHBwMAEPrfIZEBBAWFgYkZGReHl5Jdtn5MiRfPbZZxndNPGILFYHJxZn9095ElCKZv03i8GrBnM36i4GzUCdC1ZenAVWs4bB+qDj78QJmDYNRo5UU7idaZ+dLvg4Rmc7g8zmJKsUp2Y/1ZBUvs6aZnNZg/3X9jN6x2j+OvEXMZYYKgdUZmidobxa6dU0JS2nmqOlFlKzTQaJNkfTclZL7kTeSVIlOC7o+Hjjx1TIVyHF98XD+wkhUpYlp/aOGDGC0NDQ+J9Lly65uknCBn8vf4rnKo6mwzNnYeIymPsnvHgCHFR8R0OjQr4KeLklD0RTa/6R+XRd3JW7UXcByBlpZeVs8I4lIRCBhJPciBEqOdQJ9QrXczj8dMsbzvs5fKpgNuPVqGmSE9j+QIh15pNXr576f7Fiqv6NsywWtcBdIguPLqT2lNrMOzKPezH3iLZEs/faXros7kL3Jd1TNcyWZo0a2a7hE8dkSj6tPhMtOLqAa+HX7AYbRs3I99u/p27hug4DDQ2NYrmKkccr42r2CPG4yfBgpECBAoSEhCS5LSQkBF9fX5u9IgAeHh74+vom+RFZj6ZpvFfxDTZOhw0zodd+6HAUZiyCnDHYPUvr6AyrO8z2nalg1a28tzZpDZauB8E32k5iKKgkydGjnTp+3cJ1qRJQxW5tFqMOuws5yBcxGMDfnzIDPqJi/orxlWdv5oA5FcFsb0eTSU0VrvRgCrSbGwwe7Nw0WpNJ7ZcoGLkecZ3XFr2GxWpJchKNC0Bm/TeLGQdmpHzsRzVggOOF9cxm9TzTSNd1bt2/xe3I26QlFW7duXUO6/BYdAs7Lu+gbdm2+Hv5O+xNsrUCthDCvgwPRurVq8f69euT3LZ27VrqxV31iWztjR820/CS+tJ1s6oTtH80LJ4HHhYwJh6eeHAy7lGlBz2r9Xzkx/73yr9cCL2Q5LZnzqfQU2GxwKZNtmdzPETTNP7s+Cd5vPIkKWGv6eqn5lV4zt4SLiaTqlGzdCmatzcLOi4gj3fCcYY+B0fygxX1E89gUNNmZ89OerwRI6BFi7iG2X7MB8EPCxYk2Wba/mmYrWa7CxRqaPy06ye7r0O6KVdOJadqWtIekrh/f/216j1JJatuZfzu8ZQZW4a83+clz3d5qDShEjMOzEhVUGKxWpza3t3kztLOS/E0eWLSEp5H3N+2Q/kOsqyBEKmU6mAkPDycAwcOcODAAUBN3T1w4AAXL14E1BBLt27d4rfv378/Z8+e5b333uP48eOMHz+e+fPnM2zYo18ZCxc7cgRt5SpVI+Mhzc/CwQnQ/7gPATkCyOWZi4ZFGrKg4wJ+a/NbuuQo3Lx/M9ltmu54ZstlXziS20xonpwqWChRAiZOtJuXUTpPaf4b8B8fN/6YYlpufKOgcgiMWwGbpkPOuERUoxEqV4ZcuVQw8eabakZLw4YAlM1blkMDDvFhow8p6lcUPZcv/UdUYvs7naD8U6qSacmSqurpgQNQpEjShri7w7JlMH061Kypts+VSxU7y5lTTSH++GP1mGXKJNl199XdDk+yOjr/hfzH3qt7Hbxy6aR3b9i1C155RQ095c4NL7ygknVHjEj14XRdp/fS3gxaOYgzt8/E3370xlF6LO3Bu2vfdfpY9YPqOxyuihte9HbzpmGRhhwacIg3a79JYM5Acnnmol7hevzR/g/mdpjrVEXkFN2+DX/8AVOmqGJ3aZz4eO3eNQ5fP8ydyDuP3iYhMkiqp/Zu2rSJZ555Jtnt3bt3Z/r06fTo0YPz58+zadOmJPsMGzaMo0ePUrhwYT7++GMpevY4+PZb+PDDlBMsjx+HsmXT9aGtupWDwQep/mvSapfDtsOoNcmj7DUl4ZNnYFdh9bubBTofgq83QOEwoGpVtRSAh4ftB7x1SwUZsXamwRiN0Lo1LF78KE8rXdyPvc+yE8sIiQihkE8h5h+dz8KjC1NMvMzhloM9/fZQLm+5TGrpo/vrxF+0mdvG4TZbe26lQZEGKR7rXvQ9Cv9YmPCYcLtByZTWU+hdvXea2uo0s1klWf/yC8TEJNxevjzMnOn0jLB/LvzDRxs/YsuFLYDquWn/VHu+bvZ1musKCZFamVJnJLNIMJJFffYZfPllyjMgDhyAKlXS5SE3nNvA99u+Z83ZNVh1K54mT6LN0fFDELnvw8UfwSs2YaLOvArwagfVa2JNFKWYLJD3Puye/CAg6d5d9TzYoI8dy933BqPp4Bdlp/fFYIDr11OXbJrOxv07jhHrR3Av5l78tGQvkxeR5sgU9zVqRjpV7MTsdrNT3DaraD6zORvObbA7BGUymOhUoROz2s1y6ngbz23khTkvEGuNjc+vMWpGLLqFXlV7MeWlKemfC3L/PsybBwcPqt66o0dh+fLkPSFGo7p/zx415OXAqlOraP1Ha3T0JIGVUTPi6+HLrj67KJ2ndPo+DyFskGAkqzl8GBYuhHv3VC9B585qDZPsbMkSeNl+8SdArex6/XqSNVrSasLuCQxcOTD+5ADEl56P+z9A8zPw1x+q9yPGBAXegXB30G2cQ0wW6HQYZi1G5S7cvp3k76LrOpP3TWb0XyM4abgNQMUQeHe7SpZNdsjDhzN9Zec4k/ZMov+K/nbvT/wa2WMymAj9IBRvN+/0bl6623x+M8/MeCbF51Qxf0UODTjk9HHP3D7D2H/H8ufRP4k0R1KtQDUG1RpE23Jt0z8QWbVKfReEhalEZavVcU+j0ahK5j+cU5SI2Wqm8A+FuR5x3eZrY9SMtCjZgpWvu7ami3gySDCSVdy/D127wqJF6ovEYFA9CV5eaiz41dSXUs8yzGYIClLBhq1ZEkajWgBt3LhHfqgzt89QZmwZp6egtjoFE5bDlmLQvS0OE0lMFrjxPeSKQuUuPBiG1HWdvsv6MnX/VDQSEmM1K+gGeOGEGuapnHiyWEiIyuPISLquhpSuXFFrxTRoQLQ1lsDRgdyJsp8X4EwwAnBp2CUK+xZOzxanuxM3T1B1UlWizFEpblu3UF129NmRCa1KpX37oE4dFXyk5mvYZFLBi53ZiM4MXWloXBx2Mcv/nUX25+z5O0vWGXmsdOmiqoCC+tKJjVVfPPfvq1VW165N+7EvXoTPP1cltN9+W3XfpkV4uAoYatZUwUWDBmq4IlEVXJtMJrU4i7t78voRRqPqSv7qq7S16SGT9k5KUjjsYQbNQFW3INbNUCXaV86GYqFwyl/N8nHEbISLcWvSjR4NkWpIY+WplUzdPxVIOkNHf/CpWVEWqgyAGv1gXyGDmu2S0YHIypVqfZf69aFjR1WXo3hxDk/4zGEgAsT3IDniZnDLFvUxftjxg1NFxTQ0XqnwSia0KA2++Ub9P7XXg2Yz3L1r9+5Tt04lmf1li47O2TtnU/e4QmQgCUYcOXtWrYC6b1/aMtkPHVIJjfa6XTVNBROppevqJF+smNp/1iwYMwZq1VILrEWmnB8QLyREJcQNHqye5+XL6qq7Z0+14Fp4uOP9GzVSQdBrryUsXZ8/v5rZsX27mvGRDvZd2+cwAdOqWzkedZlmFwxUSrRWjF80WJzoWfeLu8BeuVIlolosjN89PsUvdYCDBaBRdyuH3uuR8gM9ilWr4MUX1fsysYsXqTFkJB2OpHwIRz0jJoOJVyu9arMYnVW3svT4Ul6Y/QKlxpSizpQ6/LLrF8KiXbNUw7wj85wKRvJ656VH1R5pf6DYWDWjpVkzKFVKvd+nTk3dZ8wWi0V9N6Sl4qyHh5rCbYefp59TVWJ9PbJZL7N4rEkwYsuhQ+pEXLIkNG+uTtalS8Off6buOAsXOq44abXC1q1qmCM1fvsNPvpIBSUWi/pCi/tSW7YM+vRx/ljduqmTm64nBFxxQy67d4ODNYTiVagAM2aoL+jISAgOVouipeOQmqfJM8Wres2q0+MlKz3bwMwqEGWC9kdt54rEMVihYjBMrgFd2sGQVjo7T6xHX7GCgyEHnfpStxgg0h3+d31Oap+W83QdhgxJ+PfDdwM/rwJjCs3tVrmbzds1NAyagfDocKbum8r92Pvx98VaYukwvwNt57Xl7zN/c+bOGXZf2c3Q1UOpPKEyF0MvpvVZpVni9tnjYfRgY/eN5PbKnbYHiYhQn//XXlO1ac6cgW3b1OerTh01wyqtYmPTFoiYTKq31d6sL+Clsi85LN6moVEyd0mqBKRPUrkQ6UGCkYcdOaK6wLduTXr72bOqNoKd2RY23btnv0DVw9s5y2p13JtitaorOWcWVjt5Etassf+laLGoqYTOfukaDCrbX9PUENKwYZAvn+oxKVsWfvxRDU+lQesyrVPMd4g0wYwqML0qdH8Zir4Fdz2hxwEVdCSjg1WDwwHwTQOYWxEm1IR6faDNpn6pKlevAytOrrBZ+yRd7NoFp0/b7aHTgILh0PS87d0NmoHy+cozrc00vmn2DX4efknu19GxWC38deIv+izrQ9APQWy/tB2Ar/75iiXHlwAJ6/XoD/67cu8KL897OU0VTx9F6TylUxy261+zPxXyP0Iy8fDhKviAhAA97nkePQqpKE+QjIcHFCqUun2MRvDzU72ODty6f4vqBarbvV9H58umX0qFWKHs3q0uHj/4AObOTXl4PoNIMPKwt99WV/cPD63EfQkNHqyumJxRtmzKVz9eXqp+hbMOH1Ynekc0TfWQpOThgMuW2Fj1Zk2NuKm8Y8fCzZvqGKdOqde2SZPUBV8PNC7qxJolWqIf4EYOaNYNvlwP3Q+qqb1GXcPNov7tbknY3mJUPRzmB6MyK3xD8DR6OjVME0dH50rYlVQ+MyddverUZoXvaclO0gbNgEEzMP758RgMBt5v+D7B7wQzr8M8crjliC9AZ9EtmHX1fr0bfZeWs1py+vZpxuwaYzcQNFvN7Lu2j52Xdz7Ck0u9N3M2dTh0atWtvFHjDfXL6dMqsChbVg219OyphiQduX2bqN+nsTvAwq5CEOH20P0WC6xYoXpL0kLT1CrSzpT4j/P002oItWhRm3ebrWb6LutL+fHl2Re8L8n7wPDgq97T5MmEFybQuWLntLVbPD5u3VLJ+rVrq+rHP/ygJlQUKgQbN2Z6cyQYSezKFdVT4GhqXXi484WtOne2m/EOqCudnj3BOxXTKJ3pWTAYnNvO2Suj1FxBWa3Qvr0KOBIHYnHDQPv3w//+5/zxHph9aHaqq7bqGtz1gt+rwG/LjZxeUJCvmnzGOyfyMHkp+Edit3a8VYMjN47g5eZFoXAD72yDn1fCR5uh+G37j+lMPY80KVDAqc1qVHvB5u3D6w6nSbEm8b97mjw5ffs0keZImzOUrLqVyNhIvtn6TYqJsUbNyKbzm+zef/bOWb7c8iVDVg3hu23fce3eNaeei11Tp9K711iankve42V48Pf8/OnPeSrfU/DXX6pY2JgxqifwzBmVY1WjhioqZkOsJZZPFg2mwJBYaveDun0h4F0Y3lL1vsXTddiyJe3PY+hQledlfCjgjQtQRo9Ws7uWL1cB1bp1Kpiy48P1HzJ1n0q4frj8vxUrbcu1JfjtYPrXtD/9WzwhrFZV+fiff9TvZnNCQcc7d+D559WFbyaSYCSxy5dTTlQ1meDCBcfbxPH1hcmT1cn84Ssgo1Fd4fzf/6WujaVLO85DAfXGqlgx5WM5s0Kqh4eKnJ21fr0a0rIX0FksKgEwpcTYh+y6sitNK8vqwMLygL8/Jbq/xftP9eXr2iOoekMj2AfHteN1nQXHq3B+tJVv1kH/PfDpJjg9Bn5ZYXvoJ7dnGvMTUlK3rkpYdhAY3s/tw1vm5cl6May6le+2f8fvB39PcvvCYwsdvqYW3cK6s+ucap6tnhOL1cKbK9+k1JhS/N+m/2PinomMWD+CoB+D+Hzz52kb2gkOhv79cbfAitnw6WbIl6ijsvx1tWr0mH/H8POf76B37Kg+D4nfj3FB8pAhCcMwD1h1K50WdOLLK38Qmug6IsIdfq4Dz73+0IrLjzI85e2tPi/vvafK4sepVk1d8Awfrq5cX3hB5a85cDfqrsMeLFAF3dyN7mlvr3h8rFmjhn5tfU9breoz8t13mdokCUYSy5s35W0sFue2i/Paa/D33+pkEsfLC/r1U12u+fKlro158qiiR/YCEoNBdbO1apXysUqWVLMzHr4yS3ysnj2TflGmZPfulIOlyEiVEJgKbga3FBNYbdLgvhtw44b60i9cGP77j8iglIfG3tyt0XLmNky6WgDQ3QomXX1oBu6Gr+LWf9QTfmav/xHd0cq0aWUwwE8/PXhOtl+Ht1pY4oeZbPlg/QdYrAlfPs4kgVqsFnJ55nK8jW6xOYz20YaPGL97vMpH0S3EWmOx6lYsuoVPN33KuN1pqD/z22/x+RseFvhkM1wdDRd+hGuj4MAEGL8Cbkbc5N7Y0VhjY+wGDOfzGFk35X9sOb+Fq/euEmuJZfXp1Sw+vtjmSd1qgM3FYU6lRDemYWG/JHLkUF3kISHqIickRM1Oa9s2VYdZe2YtURbHNVdCo0PZetGJoVnx+Js/3/H3tNmsqgJnYi6YBCOJlSypam04Gsc1mdQwRGo8+6y6AgsOVrkTN2/C+PGpD0TijB6tTqoPBxEmk0oW/eMP+wHGw6ZPV93YkPC84/Zt3Fg9VpxDh1QQFRQEBQuqoOihK0vc3R0vEx+na1fV9eyk50o95/S2SehQPXG6hcUCs2ZRLk9ZTA6m2Zgs8NEm+x9EA/DWTsgVSZJclS+OT2JC+yJOjblGxESw+NhiZh6cyc7LO1PuKWjTRs3QKlgw6e0BAez//m0mP+U4uLh672qSk1GNwBoOZ13EJb2+WetNu4GgSTNRJaAKDYKSrv1yJ/IOP+780eGV+uebPyfWYmetn+holZMxY4YKXOPeU0eOJAvGTFYoEgoFwtUSAEFhajmAp8+pIPJhx/JC825QfLCFZ4ttocmMJhT6oRA+I30YvGpwfH6FLQYrTKqB+qy1aqV6KtODm5taHDGNdWoiYp3LY3MmABVPgLCwlNcUi4lJ24yvNJJg5GFxhYjsdYe//37qekYSCwhQY76pyRGxd5zdu9WYc9z02bgg6d9/U3e1lieP2ue339QKs2XKQNOmKipeuzahrXPnqu7jadPUcNa1a6qqbMOGSbvzWrZ0LhgJC4MBA5xuZrcq3cjtmTtVCaUAaDDg4VpwVit5V2ykY2Bzu3kogffg46bwbQO4ZqeSvacFnjv10I06fFnyCuYWze0WtNN1na+2fEXAqADazW9H9yXdqTe1HhUnVGTX5V2On8/LLxN+6ggTfh9Kg5GlKPdNYVqPrsnMiilPQYakKx0PrDXQYa0Oq25l7dm1nLx1khYlWgDEv/7ag/8K+BRgcafFyWZmrD69mmiL46z8G/dvxM/YSWLSJJXU/eKLasbKM8+o1ZVXr1bvxxRymCwaxNh5m5zyh/q9YZONHNBoSzRn75zFiv33r9UAZ/1RQciMGQ7bkZkq5ndiWBYon698BrdEZAtly6acPF24sAqSM4kEIw9r1kytuRJ3hRL3B/P0VPkdaSlSlhHy5lW9FrduqZ6W8HAVMFSqlPK+D/P0VMMxmzfDiRNqPPGVVxK68c6dUz0ZcTVN4sT9+/33ExL5KlVSPUEp9cxYrSoh7+ECXnb4efrxd9e/8fPwiz8ROvTgirjHfqh32fYmHffYTt4EuOwHv1WD/zWDoOHwfX3bD5Ez5qEbNbjmA/sK6DBwoM1uzg83fMhHGz9KdjV74uYJnpnxDAeDD9p9WpfDLlNlcnUGnRnDjugznIi6zKozq/lp10+gw9NnocMRqHEFm8m5xXIVi/93/aD6fNDgAwC7QZmOzsJjC7l+/zrD6w6nQr4KFPIpRJUCVRjVYhSHBhyieO7iyfYLj3EuJyjZduPHQ//+KokusYsXVe5E8eIOr9ZiNVhWRs2O2lgczA+9TUY0h3vu6v400SGPX6C6GMjoarupUCOwBlUCqtgN1o2akaeLPS2L4wmlTx/HF40Gg/r+ykQSjNjSurW6+v/rLzXdaeZM1RPw6aepm1mSGUwm1bvhoAjSI5s40fHYocmkZivEmTtXRdXOOHrU6WbULFiTs0PP8nOrn2lVqhXNijejd7Xe5PawndMy8F+YttT+8b7wtN8LoWtqmq/VoKb8vtdCFVJLTAOO2Rlpu2/S1TDU9qRX/lfvXeW7bbYTwyy6hRhLDB9vtF1HQtd12s9vz8XQi/F1PuL2i2tPk4uqNt+eyXB4PDR4kGtt0AxUyFeB6oFJ60983exr5rafSyEf+zUvLLqF/cH7+WHnD/x3/T9CIkKoGlCVfjX62c0nKZfX8aqyccrmLZvwS0SECmxtP3n1/7lz1bRxG+PdVtRr8E1D9fuvNdTfLu4r97YXLC73CIEIYDAY6P7MWyrXIwvRNI2ZL88kh3sOTFrS18ZkMJHLMxe/vviri1onspzixVWuEiQ/pxmNUL16QpHFTCLBiD0mkwpKhg5VvQLpVNY8W9q82fH4otmcNCHV3x++/NK5Y6fyS93P04/BdQaz8vWVrOu2jikvTeHCsAtMeGECL5Z5kWbFm/FevXe5MMGDcQ4WJT3lD/vz2slXsEWH/3taTfkFdcV90h+2FrG9bdm40ZCHZl79cegPh3kUFt3C8pPLuXU/eaG53Vd38++Vf+0OregajKkD0Q9OtuVuwoYZUO+yhlEzMuGFCcmGUzRNo1PFTqmaBWS2mvn9v99pOaul3ZyPhkUaUiZPGbs9LkbNyDPFnqGUf6KpqsuXO55lZbWqvKWff4bKlQGIMagfK6ribqeOsCtIbX7ZDzq8ooJK3Wjkqo8KLtPKpJko6FOQPtVTUeE4E1UOqMyevnvoUrlL/KwZT5Mnvar2Yt8b++J7RaLN0fxx6A/eW/seH2/42Ll8JfH4+eADtfpzuUQXDr6+qur2xo2ZHnCnMO1BZDWRsZHMODiDyfsmcznsMgVyFqBX1V70qtYLHw+fjHlQZ5JhHx5/fP55lcwa8/A4RiL+/qra7SPy8fChf83+SesnBK6B6/aHO4Lt5IHYpcG53HA0H5S7oXISur2MzanB3rEQGHdODQ2FXr3U0Jeu80xZP+qW0tjuoPimjs6N+zfI4510wbqNa3/FqDtea+eOl2pjtWCVvKkDEzblIHz9amoWrMnUfVP5dd+vnL97nnze+ehepTt9a/TlWnjqan9YdAvbL21n0bFFdKrYKdn9mqYxo+0Mms5oSowlJklZfZPBhI+7DxNemJB0p+Bg9T5KKefIbIY9ewhduYQ5X72CMdrMfwGqnkyYZ9JNl5eF2XM/pOeOSPJs/AtwPmkaEoavrLqVygUqs6DjAvy97K8L42ql85RmWttpTHxxImHRYfh5+iWZzrvp/CY6zO/ArchbuBncVDXWf76kUZFGLHxlIflypDGpXmRPr72mCp1dugRRUSqJ2tMz5f0ygAQj2cjdqLtJcgp0dG5E3GDY38MYv2c8W3psISBnQPo/cIsWahqyvZOEyaQSVxPz91fVan/4wf4Qz4gRGTe89OyzcNB+MFIw9UVgAQh1h2Vl4dOn4ZCtOmQ6VA558G9fXzXuajLF5zlUDQlm20Yrg5+DsXVsP4ZBMxCQI9HfUdfhgw/Qt0+FpjiujULStXhO5IUppcP5969BHA8/R1h0GBoaOjrXI67zwfoPGLd7HDndc3Lj/g0nXwXFqBmZsn+KzWAEoG7huuzss5NPN33KXyf+wqpbcTO40aliJz57+jNK5C6RdIeCBZ1Lfi5UCDQNvxdepmz5v3lxzot2i80NqzuMHi2+gA4agYymyfSn2XJhS4pLCwDMbTeXq+FXsepWGhZpSO1CtdNcQv1u1F3G7x7Pr3t/5Vr4NfJ556NXtV4Mrj04QwIAD5MH+UxJj3vk+hGem/0cMRZ1gRBrTejV2nFpB61mt+LfPv9iNDzCOJaIt//afibtncSB4APkdM9J+6fa06Vyl3S5aLxw9wLjd49n0fFFRMZGUqNgDQbVGsSzJZ5N/XtU01QQ4mKang3658LCwvDz8yM0NBTfdFx8LbvpsqgLcw/Ptbl4m8lgonmJ5qx6fVX6P/DVq2rac3S07cBC09SMnJo1k95uNqsZM1OmqN4VTVP7W60qN+DrrzMuB+fMGTXjwd7b22Qi7wgjt4zOr8Ng0oz80nAkA/55z+F2vy+CLv+R8HztqN0Hdj+UWmPUjLxU9iUWdVqEruv8deIvflr+ITvvHkEHolNIbveLguBR4GmG0fXgnZZqmrKj+iOPolzechwbdCzF7cKiw7gdeZt83vnI4W6n+zcqSlWaDQ21fb/BoIZnXn5ZvaeCgyFfPi71as+E2gb+OLuU25G38fPwo35QfT5q/FGyWSbbL22n0bRGThXQOz7oeNKcljQKCQ+h4bSGaqZOosc1akYCcgawvdd2iuayXeI9PfVY0oPZh2Y7nEG1/NXlvFDGdhVf4bzPNn3G/23+P0wGE2arOT7hvkDOAmzqsYkyecqk+dj/XPiHVrNbEW2Ojj8XxD3OkDpD+KnlT1lq3SFnz98SjGQTIeEhFPqhUIqryJ4afCrpOHx6+ftvVYgpNjYhf8RkUoHF5MlqKMKe48dVCe7r11Via7duqppoerh6FcaNU7VV7t2Dp56CAQPY26gkxvf/R5U564lwh6nVYGp1uOqjekV6H/fG+vZwhu9xLrfFZIWOIXmZ0WAUje6PZU/I/mR/C6MVal2BzYt8ca9aQ5VaftAjcjQf/FJb9arEGKHOZXjqBnzfMNH+mhFPkyf/9v2Xp/I+xXtr32PUjlFJh2biPq02vmsMVnhvG4xcD6tKwfNdUvla2hF0F1qcUWv57CkIuwupxzdoBpoWa8rabranMNuk66os+61b6j3wcM2U336D3r2T72cwqOAuIEAFIYl7UIxGFcRs22Z33ZbEpu6fSp+/HOd9lMxdklODT6XLl3q7ee1YdnKZzSDAZDBRv3B9Nvfc/MiP44iu63h/7U2U2X5hNJNm4vXKrzO97fQMbcvjbv6R+XRaYLu30KgZKeJXhJODTzqs8WPPveh7BP0YxL2Ye3YD6tntZvNapddSfeyMIsHIY2b5yeW0/qN1itvNaDuDblVsLxP/yC5dUjUgVq9WJ9kmTWDAAKJLFWfhsYXMPTyX25G3KZOnDP1q9KNu4bopH/NRHDigaqKEhXE5h4XJ1eHvUnA0L9zzBM0Kg3fB6tJw6kH6ha4BusppKJe3HKX8S7HspONFBY0WtSLuzqkaBcN0Yl98nn7dcjPr+Lz4E4wJI6+71+CX4oPwadNRLTF/6BAAS8uqREpI6KGw1VtRq2AtJreeTJUCVVh1ahXPz3nefqMSBSUGq0rMbHUKlsxVlUmbdoMtxdRskrTKEQ2Tl0Gnwyr20VEZ7/sKwKsd4GTeVH7xrVihhuYevC5omiocNnq0CiLjzJ6tquUmXhywfHm1Yu3u3ban9ppM0KCB05V92/zRhuUnl9utKTK9zXS6V+3u3PNy4ErYFYJ+DEpxWOjIwCMZWgPEYrVg+sLxyU9Do225tizqtCjD2vEkqD6pOgdDDjrsfVv4ykLaPdUu1ceeuGciA1cMtPt+MmgGqhaoyt5+e1N97Izi7PlbckayCWcXiUvtYnKpEhSkZskkmikTEh5C01+rc/TGUQyaAatuZdeVXUw7MI0BNQcw9vmxGdMms1nNdgoLY0lpC506gNnwYLbEg8+pboAx9R78nvgCV1P5NidvnaRsnrJMaT2FL//5kvN3zwOQw+TN/dj76BrkiIGe++GjLRAQoQ7stmIV0+p+wTfDLrPripoeXLdwXfLnSFR34kHSb3BOeKWjCgoS53IkDkQ+aPgBr1d6PcmQwphdYzBqRrs9YQZdLfTnYYbSt6HfXuh4VPXgWDTYVDzp4zmj2B2odg1Wl1IzU5b+AU0uJEy5iztcpRDY+hv0+KwqHcp3AOD83fMsOLqAu1F3Ke1fmg7lOyQdjpk7VyXLJabrKrG3bl21TkZcVv/rr6tFJrduVTV0ihZV1YqLF7c/7GU2q1lfx44lDWzsmNVuFi/Pe5n159Yne50NmoFVp1fRoEiDR+5l3Hdtn1P5Kbuv7M7QYMRoMFLUrygXQu2vq2XQDI80fCAgNCqU/cH7HW5jMphYd3ZdmoKRrRe3YtAMdr8XrLqVfdf2EWOJyXbrEEkwkk3ULVwXd6N7fPKZLRoaTYo2sXt/RugwvwMnb50EiL8SiOstmLBnAmXzlGVo3aHp/8DLl8PlyxzPCx0fPtk/fBK2c1K26BaWnljKz8/9TK9qvbgVeQtd18m7bjv3O7YlzAPyRKrhiSR0HcaMIeD993mp7Eu2D96iBRw6xJTqFswG+4GBUTOy6/IuRjb9Gs6fV7U2ihVj15VdDofkrAYoeRt2TkX1MHToAFfWwZ07WDUnApFEAVrBMJj8F7Q6rQKPbxqqCqXNztve1U0H/yhYdFWtR9P3r75M3T8VTVNTiGOtsby56k0+aPABh68fZvXhJZz9Ngo/3UYtAYtFPefhw2FlornYRqPqeYuzZIlz62Ts3u1UMOLj4cParmsZv3s8Q1YPiU/qBfU+XnB0AX+f+Zvtvbar1X/TyM3oXAVLZ7d7FANrDWTE+hF2r9itujXLTlvOLlIaRo/jKG9H13XO3jlLtCWaErlL4GlKmN2SlXJB0pvUGckm/L386Vm1p8O6DR3KdyDILyjT2rT7ym62Xtrq8IP1/fbvkyzOlm62bwc3N8Y+WFA4tb0AcXR0dl3ehaZp5PXOS74c+dC2bycHbgSG2whE4ly/7nj15gEDwGBgW1BCbRJbLLqFgFX/qMTM4sXVasv58jF6aRS5HS0joqvhGAwGNWtnyhRVmG/FCtymz6RqztIOe6Q04LWDUCEYtk+FZ88mfBkM3K1K6Mc6aLfRCh6/z2HQikFM3T8VHR2rbo2foREeE85HGz9i/tH5tDwcRe4oB182Fosa+ks8LPMwZ8tSuzt/NaijM3rH6Ph/J2mSbuFe9D0GrRzk9PFsqR9UHy+Tl8NtjJqRpsWbPtLjOGNw7cHUKlgrWZXWuOTKdk+1Y/Gxxcw7PI/IWNuzk4RjuT1zUyJ3CYcVos1WM/UK10t2u67r/Lb/N8qMLUOpX0pRYXwF8n+fn3fWvBNfqfiZYs84DHiMmjH+wjW7kWAkG/mh5Q/xPR9xXyhxJ5wagTX4tXXmVlhce3ZtimvFXLl3hRO3TqT/gxuNoOusKP3oM0WMBiOxllgWHF1A5wWdmXdsgXMBlKP6K8WKwYIFGFOYh/vmLvhjnlktABcnMpJuu6LYMfXBQnw2GHR48ZQGOXPCqlUqIPHwUPVdunZlWPOP7F4Ba1a1kNzPq2DHVCgcBm6JNvWNVmvuuKXQEaHfvh0fiNhj1a0UvwuxKX3T6DrW8+fs39+wYcr1D0wmlUPkpM3nN3Pu7jm7r5NFt7Dx/EbO3D7j9DEf5uvhy8BaA+2enIyaka6Vu1Igp6154unLy82L9d3W8079d/Dz8Iu/PV+OfLgZ3Fh4bCEj1o+g88LOBI4OZMaBrLP2TnahaRrD6g6ze79BM5DbM7fN6fCfbvqU3n/1TvJ+uxdzj592/kTTGU25H3ufzhU7k9crr93vXYtu4d367z76E3EBCUayEW83b9Z0XcPCVxbSqlQrKuavSPPizZnTbg7/9PonxaXe05vZanaq29BRz0maNWsGZjPmR3wHmwwmSvmXouqkqnT8syMLji7g19xnMVocTP3UNBVspDQ3/6WXaP7aR3bDkYB78MPfD355aAjCaNUpeRv+90/y/QxW8LEY6dnqAzUzpV7yq6yulbvS927JB8dKuN1kUYHHwvmQNwpyxtpe2dbdiXIf9/L5OvX3v+CXtA32/HjCwcnPz0/VbLG3uJfBoBbVS8V6MXHDi+m1nT1fN/ual596GSB+BkXcyeSZYs8w7oVxj3T81MjhnoNvmn9DyDshnBp8iv81/B/XI67H92jFXXWHRofSY2kP5h+Zn2lte1wMqDmAThVUsJG4d9KoGfEwerCk8xK83ZIulnr85nG+2PIFYLuXbu+1vYzfPR5vN29WdVmFj4dPkmPHva8+afxJmnJRsgKZTSPS7O/Tf9NqdiuH2/h6+BL8djBebl6cvHWS8bvHs+n8JjRNo2XJlvSv2T/J4m1Os1qhUiU6VzjGwnJ6mnpH4q5K/7v+H/+F/JcQNOlwaDyUvZW0xyCJsWNhUMpd+Hci71Ds52KEx4QnuwJ//x/4aoPtYCDOXU/I/55GrEGPv7r28/Rj1eurHM9WunMHPX8+lpayMKY27A9UwzrtjsGQXapU/CMxGFjbozEvFNuWpHiWLbnuw/VR9l9LC3A4AGoONHL17Wv2i4DFxKhqkYsWJRSSi/t/q1bqdi/HQyKJzTk0h9cXvZ7idlt7bqVBkQZOH9cWXdf55+I/TDswjQt3L1DQpyDdqnSjeQn7K0dntPCYcAJGBXA/1v54YPFcxTk95LTL2phdWXUrfx75k3G7x3Ho+iG8TF68UuEVBtceTEn/ksm2f/vvtxnz7xiHF27FcxXn7FC1sOj1iOtM2TeFRceSFj2rU9hOJUUXkqm9j7vISLVE/Z07ann1hg0zfRE/q26l9C+luXD3gs1xTINm4O16b/Pds9/x+8Hf6bm0J5qmxX/gjJoRo8HInx3/tJ8Imsj1iOtM2jOJuUfmci/6Hs0oQYs/9/FaS+fKqcYlKcbNnmhctDEjGo7gudnPJdu26B3YNB2KhKKmz+oknPgGDFC1Tey93rquKtaePAl+fuwol5OWi9sRERsRH5AYNSOTlljodtBBwPPAqCXvs+7eAUwGE8+WeJbuVbun3At24ABUq5bCK5KyhycigVrnRStVij+mvMVr6wc4dZyRa+H9bcmPFffUW78GK8vAc6WeY9KLk+znPum6qt8ybZqaal6wIHTvroZnUvn+vxt1lwKjChBtsV/4LjBnIBeHXUxTTYiszlE9jMR29dlF7UK1M6FFT66X/ngpxRIDANZPrNkuiVWm9j6udF0tFPZ//5e0UmXJkqr42DPPZFpTDJqBxZ0W8/T0pwmLDku0eqz6sDQIasBnT3/GfyH/0WNpD3UiThT6WnQLVotVzcgZfDK+h+Re9D2mHZjGjIMzuBFxg2K5itGqVCtGbR9FaHRo/Al9OpeY3iJRg2ydOQEfdx9alGxBpDlS1X3wC6JX1V60LtuaD9d/GF+9MLELuaHiQHj9kKqz0ci3Im4VK6vl7R0Ffjt2qKJdxxKqktbLmZOr7wxhzDPeLD+1gmhzNEaDkVCP3U68yAbeafEp76Tiih9QwxpOiNXUWK293hkNCHdTwzmgcj8WVdApMv172lRshs8/7xEeE57i9NX/NVP/f3uHGrKxGFQQFuoJA15QgQjA6tOrKfVLKRa+spAXy7xoo0EaNG6sfh5RLs9cDK83nG+2fmO3/Z82+fSxDEQAbt2/lWQWkaPtngS6rnMv5h5uBje83FL5eXtEfp5+DqfyA+Rwy5HtApHUkJ6RLMZitbD27FqO3jhKDrcctC7bmoI+iapUfved7WXWDQb1s2mTKv6UiS6HXWbsv2P5/b/fCYsKo4R/CQbWHEiPqj3wMHnQ568+zDg4w24XpFEz8k79d/im+TdcvXeVxtMac/aO6o7U0ePrlzjLoBloWbIlrUq2okqBKtQqVCvZGC2o1/qFOS+w5syaFL+QR7cYzfB6wx0/8IEDKn8jJsb2GisffghffklkbCQFRhfgqdNhamquHbrRiPbCC7B0qePHtadaNbU+j52PuA50fRm+XQf5w5MnrFo0WF4GOreHWlfVzKL/AuCWjwF/L38uD7vM4uOLeW3ha2ia5tTfKG8EvHxMTZk+m1sVhHu4xL2GhpvRjeODjlM8d/G0PXcnWawWhq8Zzi+7fsGgGeJrOBg0A++U70urbdcpvW4vuaMNeFWtCW+8oQL+x+CkkGJhvQeODTpGubzlUtwuu4q1xDJu9zjG7BrDubsqibpJ0SZ80PADWpVyPAydXpadWMZLc+33DpsMJnpW7ZnpkxTSgwzTZENbL27ltYWvcSnsEkbNiFVXXXK9q/Xml+d+wSM8EgID1RoethgM6mS4dWv8Tbqus+vKLvZf24+HyYNWpVolDW4sFrVse44cahgiHdy6f4sVp1YQHhPOU3mfovuS7lwKu+Rwn2oFqrHvjX08Pf1ptl3a9khJrxoaY54bw5u137S7jcVqodOCTiw8ttCpY+bxysO1t68lqQfx8Gv72gez8Vy/OaFc/sOMRrh8mY2Rx2g6synosGoWND8LpocDAUAzGjHs2AG1ajnVxmQWL4Z29pPZTuWGMkPVkNT0JfB0opnKMQZVPv+tVhBj523xTLFn+LLpl4RGhfLppk/ZfVX19JgMJlqVasW+a/u4eu9qqoNJUAHqgJoDqFmwJhGxEVTIV4HGRRs7vDKMtcRy5s4ZDJqBkrlLpmrBt4uhF/nj0B9cj7hObs/cHN6+hFEj98YvqGhAFdUzWYG+fWHiRPvJtNmE2Wom6McgQsJDbAbjBs1ArYK12NlnpwtalznMVjMvz32ZFadWAAnJo3G9FOOeH8fAWgMzvB0Wq4U6U+pwIPhAst4Rg2bA0+TJ/jf2Z8uidBKMZDMHgg9Qb2o9Yiwxyb64DZqBThU6MSe0OfTpk3Lxp3PnoFgxDl8/zGsLX+PQ9UPx3bEGzUC3Kt0YX+V/eH3/E0yfDvfvq8S/rl1VuW4768bcj73P5vObuR97n4r5KyZbRMxsNfPe2vcY++9YYq2xyXI0HKkcUJnZ7WZTaUKlFF6plGloVAmowv7+9ishjtk1hrdWv+VUdcw4K15bwfOl1ZXkketHeHXhq/GvrX+EzvXvU5ieZjDAqFH83bp8fOJvzmiYtRDanASzpmqSuFvhlifs+uZNnh/6S/LjREfDggWqbPqtW2pBwL591dBF4pN1p07w55923y8tummsLwHWB69BuRtQ46paO2dDcbhlZz27OHF/304VOvH7y79zLfwaoVGhFPYtTG6v3ESZo1hwdAFLTywlKjaKgj4FmX1oNlHmKKeLQyV+nNL+pfn95d+TJenFWmIZuXUkv/z7Czfvq8zcgj4FGV53OMPqDUtV8mVkbCQ1J1Zn4efHKXnLwfTmX36BN+0Hu9nFshPLaDuvLegkKY1v1Iy4Gd3Y0mMLtQqlMRjOBibtmcSAFQMcllc/M+RM2pLsU+nm/Zt0nN+RTRc2YTKY0NCItcZSIGcBFnRc8MhJ1K4iwUg2035ee5aeWOrwS/qQaQgV/2+87bU5EtuxgwvlAqk2qVqSXI44Bgw8f87EX7MtaOZE95lM4OOjFhxLVMXSqlv5astXfL/9e+7FJCSLNi7amMmtJ8dH6/2W9WPKvimpOsGDWqDrzdpvUiZPGQatHJR8fx3y3Fd5BndTGMo1WFVPw1Ohbnzc9gfydOimanAkPpyuU3JMSc7fPZ+qtk59aSq9qvXiwt0LyV7bcjfgWEozNN3cYNgwrn30FoV/LJwk6Cx/HdoeB+9YOJwfFj0FW/v/m/xEcP26StY8ckQFN1ZrQmJt9+4wdarqgTl4EKpWdfBCGSj3njcnPMOdfv72aGi8Xe9tvm/xfYrbHr1xlGErBrPm/Aa7lXHtMWpG3I3u7O67mwr5KwDqivLleerK1lbvS/cq3ZnWZprTY+3T9k9j7g+9+HuW/W10QCtaFM6ezfa9IwBrzqzhvbXvcTDkYPxtTYo2YXSL0dQoWMOFLct4FcdX5OiNo3a/B4yakQ8afsCXTZ1bUDM97L26lxUPcstqFKxB6zKtM6VCb0Zx9vyd/T9Jj4GImAiWnFjiMBAxGUzM8T5jfwggsYIFVeAQfc/mMa1YWV48hu2BD91nNkNYmDqpJfLW6rf4ZNMnSQIRgG0Xt1Fvaj0u3L3AqVunmLxvcqoDkbj2DKg1INkJw2CFwTvhzM9w83u48y3snwCv/mf7OC1PwYUf4e9Z8MOyWPL0How1ID988UWS3oHQ6FDO3T2X6rYW8ikEwKjto5K9tiE51NCKQxYLFCpEoE8gbcu1TZIYeTQ/fN0YPmoGC6qYqFC4mu0r0ldegRMPisjF5aXEBaczZ8L3DwKCOXMcD7tZrQRdDU+XKZs6OmN3jyUsOizFbcvnK8/fx2ry8nG1AGFqWHQLMZaY+HoMAAuOLmDZyWV2h4FmHJzB+nPrnX6Mmf/NpOl5x0XaNFDVdy9edPq4WVmLki040P8AxwYdY3OPzZwdcpZNPTY99oGIruscu3nM4feARbdwKORQJrYKahSswSdNPuGrZl/R7ql22ToQSQ0JRrKAsOgwp8bUbxXN57gKpdEITz+NHhSkEkZ1+z0oJgv8XsXGHRaLWt/joLpKOnnrJL/8a2OoAPVBDYsO4+t/vmbOoTkpVmMFkpyATQYTBs3A9DbTKZOnDE2KNon/YtCsavjip9VQ7G7C/pWuw5xF8PmGpMdtfB6WzyHJGD+AISoaPvkEPv00ftuU2lkxBH5bAndHQtQXsGcSDDnqS7OiT6Prus3X9o43LC+rhlrsMhhUnQxg/PPjKeJXJFlbjJoRPw8/Xq34KnWm1MHzS098R/ry+qLX2bfpD7UYnL2eMV2HH36A2Fg1fJOC3vtIdS6HPVHmKLZc2JLyhjExMGkSH2wFSxpqw1h0CwuOLoivjTFhzwSHf0+TwcSve5Mm/R2/eZy+y/qS65tceHzpQZWJVfh176+YrWZuRNwAHefC1Kzeqbx6tVojycsLvL3hhRdgvf3ArFzecjQu2jjDk4azCk3TUiybbtSMmT6z5kklwUgW4O/ln+L6FbquUyxfGfj2W9sbGAzqSvi77zBbzfFrGdhj0eBG8gkmCR4s8z7z4ExMmv0rbLPVzMz/ZhISEeLUVfaLZV6kkE8hCvsWpluVbux/Yz9dq3QF4Kl8T9G8eHNMBhMdj8KrR9QbNPFR46agfrwFqidayuSbdeqK1W4LvvlGrQCLWiStdsHaNtv7/EnYOwm6/Ad+0apQWNVg+Gl+GKbOr2GOjU7WQxTnf83Uard2A5L/+z+1+iwQkDOA3X1382GjD+NLgec2+TD4XnmevurGe+veY8+VPURb1OPNPzKfOpu7sLBCCq/xjRtw9KjK+0nhZNn+gjcNCte3eTI3asb4djnbe+JoEcd4165BaCi1r8BPq9RNpkQ9JJqVFCMBi24hNEpNaz9x64TDHkWz1czRG0fjf99wbgPVJlVj+oHphEaHEmOJ4VDIIfov789Lf7xE8dzF2VHE4LACrQ4qkTylCryu9MUX8NxzsGGDSniPjIS//4bmzWH0aFe3Lst4udzLDqduW3QLbcq2ycQWPbkkGMkCPEwe9Kjaw+FJX0ene9XuMHiwqifycNnrihXVtN5atXAzupHHK4/DxzTqDwp62fOgrsXVe1dTHNuPMkeRzztfikmJ7kZ3ZrebzeXhl7k07BJTX5pK5YDKSbaZ3X42pf1LM+hfx70MsQbo/6BMR9E7UO+y40qmmM0q6fOB9xu+n6xXwDcK5v2pZkwkLkRm1B+8BIsX4/brFPJ657X5EEfzQ8NeqtppEv7+MGYM/O9/SW/28uezZz7j2uALWA+14/ZH96i88QgLcwcDSRMKzVYzFqy89rKV6ykklmI2q9LojoIRoxG37r1Y3fVvulftnuQL2agZ6VyxM8cHHefwgMO8WvHVFB5Q5Y1UK+BEkbVE9VKG7oJtU6H9UTW1OCAcKoc8KDDngKfJE38vf4Aka6zYa1duz9yASsBuP789MZaYJLO19Af//X3mb/J45WFZaSvn/Ry8/zTgrbccr03kSlu3qt5ASDqsG/fvd96Bffsyv11Z0Dv13wESaiMlZtJMlMhdItuWV89uJBjJIj5u/DH5c+a3G6V/8cwXCVNy+/SBy5fVVc+CBeqL5cABqJtQHrxfjX4Ou6/NRuhlb7KJp6da+wWcWsDL3ehOz2o9Ha5UadJMvFbpNZv1PhLLnyM/e/rtoc4d72TTXRNzs0Ll6+rf+RytbhvHaFS9Bg+0e6odXzf9WrXtwWve7aBKIHX4ofjpJ/pV62v3tT0YCLX7wcm542DhQlUl99o1FUTaS6J85x20xUsA+LmWFYOdq3IdNb30N0fnfKMRAgKgcGHVE2OLyQQFCsCHH5LTPSdTX5rK1eFXWdp5KUs6LeHy8MvMajcLP08/KuSvwKx2s2hctLHd96ZRM9KqVCvnuvfz51dTlR8kfta/BHMXQsgoCB4Fy/5w3DFiMpjoVrkbHiYPAF6v9HqKPTevVXoNUBVH70bdtTs0ZdWtrDmzhhfLvcRLr6mCbIkDkrh/W9u1g+Ep1JxxpbFjHecLmUxqG0H1wOosfGUhXm5eaGiYDKb493nx3MVZ3219/HtNZCwJRrKIQJ9AdvbeSZuybZJ8uRb2Lczk1pP5X6OkV9W4uaniS+3bq+JWD53o3q73NkF+QbZPIDoM2K3yL5LRNHXizJULUAuuOar5YTKYeL3S6xTLVYxPm3xqdzujwcgr5V+xe39i3m7eePjmdriNFYhwV0MIV3wgxcwHiyVZt/qIRiM4POAwA2sOpEnRJrQNL+R4doSuw5kzDK/UT722tgISHfrv0Sgz4CMoV051izta1v72bZg0CaxWLBocLABWR03QYN/DPS+JWC0WghvX4FrIGfjoI3XsQoUSNjAaoW1b2LmTu7k8mbpvKl9s/oLFxxfTqEgj2pRrYzMAndF2Bvm889nMcSnkW4jJrSfbb9TDPv7YdlE4ICjCyEcXbQ9/GDUjuT1z81Hjj+Jve6PmG+TxymMzODQZTAT5BdGlchcAdl/ZjZvBcTLgtfBrjHluDK3b/486w3LyeRM4ngeu+cCZyoWJnjsb4/w/060mT4bYvt3xjDuzWVUKFgC8VPYlrgy/ws+tfub1Sq/Tq2ovlnRawtFBRzNlSq9QZGpvFhQcHszJWyfJ4ZaDqgWqpqp4U2LX7l3jzVVvsuT4kvirwVyeuXi33jt8MPcyhgkT1ZeqrqsgxGyGnj3h11+TfNnam7Jr1Iz4uPuwp98eSvqXRNd1JuyZwAfrPkiWV2HUjOjozGw7k9crp7w4GcOHq6ENO7OHrMCIdr7c792NcbvHsfJ33WbxsHje3hASAjlz2n/M3r3ht99SbltkJMHmuwx+twKL8t+ODx5yRcK72+GDrWAwGFUPQEpf+gsWQMeOgOoRcPtETWG2x4CBH9ZqDN1mf0jMCrzT1ptuE7ZRtUBV9RoeOKDqyZQpAwEB/LDjB/63/n/J1mWpWqAq016aRtXAqsmOGxIewk87f2Lq/qncvH+TgBwB9Kneh6F1h9odurLlYPBBDs75Aa/ps2h+Rid3tCHh/Ve/PvpffzH29By+/OdLrkeoiFlDo1WpVox9fiwlcpdIcryjN47y0h8vxRc8A9XLUSl/Jf569a/4E8qw1cMYu3tsigX1br57kzzeebgfe5+DwQex6lYqB1TGx8PH6efoUqVLw+nTjrepUkW9J4TIYFJn5ElmscD8+TB+PBw5wrW8nhxu1wCPlztSp0abhG7HY8dgxgy4ckV123frBpWSFx2zWC18tOEjftr1E1HmhOqvNQJrML3tdCrmrxh/29aLW2k0rZHdphk1IyfePEFJ/5IcvXGUMbvGsPTEUmLMMdQqVIvBtQfzfOnn0c6fV22JjEx2FW02wP3cPsQcPkju/EXou6wvu/+exo4p4GlOGpDEL1czaRL06+f4dRs2DH76yfE2Pj5q+vORI1CxItdyqrogHhaoc1n9P7HQf7eiVa6Er4ed9+2cOfB6QnD2wmuwpiQOVyE+v6I0RfacRrPz0bUABwKh7buFOTf0XLLesYl7JjJghf0F7gyagWWvLosv8PawsOgwzBYzub1yp2qtjGM3jtF9Sff4Sq0AHhgZdLcM30Q3wq1jZ3j66fhevlhLLP9e+VdV8s33FEX8bPeYLDm+hMGrBnM57HL8bb4evrQo0YKr964SbYmmdqHaVA6onOLzrhJQhX1vuD6fIjwmnBhLDLk9U/caAykG8hiNqrjhF1/Yvl+IdCTByJPKbFaVNxctSiiKBeoLyMsL1q2DOmlbZjo0KpT159ZzP/Y+FfJVoFpg8uSFV/58hcXHFztch2ZY3WE0LtqY9vPbo6MnWcXXolsYWmcoP7b8EW37dmjTRk1TjeupMZuheHE1bbFMQmnkvVf3smbR97QZu5byJ24nPGDRovDVV0lO+Hb17Kkq0qbk/n346y/o3DnFTTu3h3mVVI/D+w3ep3PFh/Y5dgzKl4//dVMxaNpdDcc8TEPDoBk4MNZCxRvJ708sOAcEvguLOy2mbbm28bfHWGIo9EOh+Eql9nibvAl+JzhJb8C8w/P4dtu37A9WyUal/EsxvO5w3qj5Rop5G+fvnqf6pOo2i/BpaHSr0o3pbac7flJx9u1Tf3+zmeWldV46+RmAw3oRcYshFshRgJuRN+2+P+d3mE/HCh2da0cGWHlqJSO3jmTrRbWkQ2HfwgypPYShdYemOA013pkzUKGCmkb98Ne7wQAeHmpF6cKF07n1QiQnwciTavRoePdd2zMpjEbIk0ctve4oj+ERFBhVgJCIEIfbVMlfhRO3TxBtjrZ7Avmz4590KN9B9YzMn6+GO4xGePZZePFFx2P2p06p6pi5ciVJlkxRjx7w++928xni3bsHGzfCS/YXtorzUmdYVo749Vk+avQRXzR96Ir06afVDIgHV7KTq0P/F1WPjsUAmp40OFk9E5qdsz8kZQUOFIC6A90YWmcoHzT8gJ92/sS0A9MIDg92uhT7182+ZkTDEQB8vOFjvvznyyTrzMSVae9auSvT2053GJD0X96fqfunOhwiOdj/YLLZVUlcv47esQO7z/zD36U1Yg06U6pCsI/t4M2egjkLcjU8Yc2cuEDlq6ZfJc/NykRj/x3L4FWDky2fYNAMNC/RnOWvLne+ANbq1WpdoujohPezwaAuSJYty9TVvcWTTYKRJ5HVqupLXHK8KB1//OHUVX1aFBxdkGvh1xxuU9i3MFfvXbU7q8GoGalbuC5be221eX+GmTgRBg60PyVW06BsWdWbER6uhrYiIuweLsINAt6BiIeS8Xf33U3NgjUTbjh3DurXV7N9HgQk53PBpFoa+4q4c61ycQ7dOR6/eedD8IeD9f2swODnYVIdIw2CGrDj8g5irbEpPPnkTJqJDd034O3mTc3JNR1uu6DjAtqXb2/zPovVgs9IHyLNkfYfy2BiaJ2hjGoxyvYGsbGE1K9MuyrH2R6kapPopL5wmlEz0qx4M7pV6caiY4u4F3OPCvkq8EbNNyibpywW3eKw7kRGuXD3AiXGlLD7mdDQ+OW5XxhUe5DzB71+XS0PsGWLeu82bap6//I4nvYvRHqScvBPouDglAMRNzeVbZ9BWpZs6fDL3KgZ8TZ5O6z8adEt7Ly8k0yJk/fsgV69oEYN1Svi7m5/Cq6uq7wSUImwb79td1sdWFMCYh86WZoMJibsmZD0xuLFYf9+dbwHJ4pipryMrPE+f399EYvJkGTa9ILysKOw7ToYViDUAyJNYIy1sOXiljQFIgBm3cyLf7zIjzt/TPFvOm63/YV5ImIjHAYioIr6BYcH270/ZtGfNKt1nH8fzG43G9NewXXj+Y28Xvl1FnZayJquaxhWbxjjd4/H7xs/3L5wI9/3+fhw/Yfcup9yFdv0MnnfZIdT40H1nKRK/vwqN2TVKli5UtUXkUBEZFESjDxOnC3ClIHFmobUGYLFansYQEPDzehGCf8SKX7xGjRD6hP3Uuvjj9Uwzu+/qzyEHTsSxtkTv0Zx/+7WTdV4ifPppzAgaUKknuj/L5+AXZMhT6LOE7PVzIHgA8nbUqCAqq5786bqHblxA0aORM+Xj+M3jycZzjIboWUXmFchaUASt0XOGPjtLzj/E1Rx3EmVonvR99h8YbPD4RWLbuG/EDsLBgE53HKQw81xpTZN0+LX/rFl8d8/cSTAcWKvs3T0+ED32I1jVJ1YlQm7J8TPALt5/ybfbvuWmpNrcu3eI76ATjp8/bDD4TMdnRO3TqRb+X6RfZ27c473175Pg6kNaDytMV9t+YqQcMdD49mBBCOPk/z51Wq7jk7isbGq9kUGqRZYLT5/IHFFWaNmxMPkweJOi2ldprXDYxg1I81LZFwbAZg3D758sBJnXE0GXU8IRLy8VPGwXLmgQQP480+V3Pog/+Ry2GWO3DxG2A8joX//+MPGvfJxH6wK12HWIhLdr5HTPdH04kuX1MycsESLzCXKcdE0zWavxD1P6NIB6vZRvSBWEsrhxy17ny8C1s8Ef2eKwjkQGRuZYvDoqJid0WCkZ9WeKS4r0L1qd7v3z/U6a7cYXGoYNSN1C9VF0zR0XefVha+q2UEPrTVk0S1cDr3MoJWpGBZ5BN5u3imumeRh8kiXhQ1F9jXn0BzKjC3D6B2j2X55O/9c/IdPNn1CiTEl2Hhuo6ub90jknf040TR47z37OQ9Go6pB0KpVhjajW5VuHBt0jMF1BlMjsAa1CtZiRMMRnBp8ilalWtG1cldye+a2++Vr0S3xZZozzLff2k9stVhUTsjYsXDnjlqcrkMH0DRWn15N7cm1CfoxiIoTKpL3u7x0vzWFK3ZKULjp0OoMlE00+6X9U+1Vt3mtWqoQW8WKqvu8a1dVrTWR83fPY7bY75XocBTcLLY/yCYdckU5qLTrBB2dwJwOqqyhTvAdyzuegfJBww/w9/a3+TfX0HijxhuUz1fexp7KbT83h8XgnGXRLbxV9y0A9lzdw8GQg3Z7JMy6maUnlqolETLYy+VeTnHV7pfLvZzh7RBZ14HgA3RdrIpQJn6vWHUrUeYoXvzjRYdDnVmdBCOPm+7d1WwaSJhxomnqJzAQVq7EokG0Odr+MdJBmTxl+KHlD+zpt4d/+/7LF02/oLCvmkro4+HD6i6r8fHwSXKlZzKY0ND4udXPNC3eNOMad++eytFwNGvGZFKl3BOZc2gOz89+nr3X9sbfFmuNZXY5M7X7YjcgsaJmvxg1I/lz5KfPEQ+1guqePQkbmc0wa5aq2no14eQ3YfeE5AdMpMNRB4XeUOu8dDhq//6UGDQDnSp0In+O/DYDCYNmwMPkwZu133R4nEK+hdjReweNizZOcntO95x80uQTxr8w3uH+T5Wql2RBvdSK69kZXnd4/FojcVOUHbHqVodDUOmlbbm2lMlTxmbvUVzb363/boa3Q2RdP+/62W7PWFxAMnlvKiohZzESjDxuNA2++w527VJX2jVrqml8Eyawec1knt81BPcv3fH8ypPSv5Tml12/pFiRMiPUKlSL04NP823zb2lUpBG1CtZiQM0BHB54mCF1hmTsg9srBuVgu/CYcPot64eOnmzc3mKE6zngw2a2D6NrYLRCQZ+CbG6/HO9Bb9l/zLAwtdrqAytPr0yyYN7DvFPITdVS2MbR0IABA54mTwbUGsDG7hsp5KtyOhKv35HLIxd/d/nbqXVpSuQuwYbuGzj55kkWvbKIVa+vIvjtYP7v6f9Lcfihb6sPHeeLpJDrXD2wOqteX8WoFqPic5E8jM6tOeJp8nRqu0fhZnRjXdd1lMmraufEvcYaGt5u3ix6ZZHNuj7iybHq1CqH39VW3crq06szsUXpKwsvsCAeSe3a6ueBGQdm0HP+80nqRJy5fYahq4ey5swaFndenOlTGvN45+Gd+u9k/JDMw/z8Ekpm2xvSMpuhYcP4X+cfmc/9WPvJF2Yj/FERxqwC34c6nYw6tO75DaPbD8ftt+lqSXdH/vtPrcD89NN2k4HjHCgA+c4k5Ik8LNYA+xysdehoaMBgMLCk0xLyeOchj3ceTg8+zdITS1l3dh0Wq4X6QfXpXLEzXm5eSfY7ffs0U/ZN4eStk/h5+vFK+VdoWaplfMBROk9pSucp7fB5PaxGwRoMqT2EMf+OSVRW90E7dbDaSWkxGUwUz1WcnX12Jnt/tyjZIllNj4f5efhRt3Bdu/enpyC/IP7r/x9/n/mbFSdXEG2JpnpgdbpU7mK/gq94YjhTHyitM+eyAglGngDX7l2jz7I+6OhJ3tBxMzRWnFrBpD2TUlfDIDvTNDVFd+BA2/cbDCpxtVMnjt88zu4ru1l6Yikmg8nhhz3GBJd9oXyi/BCzAc6X8MdSvYpaY+jwYaeaqDdtijZ2LI2KNOLU7VN2r4jG1YbnHSxD4maFibWceshkzFYzF0MvJhzL6EaH8h1UMTpQw1wREWCwxM84+nLLl3yy8ZP4oNdoMDL9wHRqF6zNytdXksc77VNLf2r1E2XzluXbrd9wMUxNYfdz9+WNmv0pmqsoQ1apHjWrbsWgGbDoFor6FWVN1zU2A+1An0C6V+nO9IPTbc5S0dB4u97bmdIzEsdoMPJ86eftluIXT64GQQ1YcXJFsmTrOEbNmGwYNDuRomdPgK+2fMUnmz5xWFCpTJ4yHH/zuM37H0tWa0LFVU1L1kNysVlNenT2ZOOV1BVeu/gDBIWpi3erBtdywtO9DZzJZeXZEs+yfN9TuP80xunjnZs9jpKn3rRf6lyHicvhjb1qTZq4kQyLpnpkvm4IHz7CxKSCPgW5+NbFpIs1Xr+uEoCnTFHDSh4e8Prr/N7pKbrtsJ3XEPdFuaH7hrQ35gGrbuX07dPEWmIp6V8yPli4EnaFKfumcDDkIF5uXrQp24a25do6LKMeGRvJK3++wvJTyzEZTFisFowGI2armX41+jHhhQkyg0VkCRvPbaTpTPu5dAbNwIk3T1DKv1QmtiplUoFVxOv4Z0cWHl3ocO0OgNiPY11SfTLd3b+v6oZYLGp10ly5bG8XFaVmspw5k+Tmm95Q7Q21bLyjFXQTM2gGapmKMn9aBDmuXOeGN8yoCr/WgNveCdt8kvNFPn37L6eOadbA0KAB40Z1YsjqIUmG2OKGFyrnr0yl/BUp8Ocqemy4E79mzZ5AGFUf5lWEFGblpmhbr23UD6qvfrlyBerWVbN+EuXU6CYj5QZaOeXveI2YPX33UKNgjUdrUDrTdZ1tl7Yx679ZXI+4TpBvED2r9VQrHguRhXyx+Qs+2fRJ/BIGQHwQPa3NNIfT413F2fP3Y3DmESnxNHnGd1vbYzKYUqxzkOXFxsInn8C4cWrGDKir9h49YNQoVTU1sQULkgUiAL/UTl0goqFqVrzb9nvKWF8n2s7LbNWtfBmxkmFBAeS4HIIxhcsAkw5s3cYP604AJKlIG5gzkN/a/MazJZ8FYEmFJVR66mVyRKuE2fuJOgPi1pBJq9Co0IRfBg1SlX4fSgI+n9PCSX/HxzFqRpafXJ4hwcit+7c4efsk/5z/h6UnlnLmzhn8vfzpUrkLb9R4w+HwkKZpNCzSkIZFGtrdRois4OMmH9OgSAN+2vkTWy9uxaAZaFWqFW/VfSvpEhPZkAQjT4CXyrzErP9m2b3fZDDxYpkXM77iaUayWtVqxUuWJB1yiY5WwwkHDqikUM9E4//TpiVd2fiB36qlHIhoaPE5JDncc/Dri7/iYfIg2uJ4yrTZaubpl0PZMkHNcnEm3gm/dwu8kvY4XA2/yth/x8YHI23LteW3l35j0MpBRJmjcDOYsOpWrLqVvjX6svfqXvYH709TBc/4bt8rV9RqxTY6U6Od+CYxaIYUX5/UuhR6iXfXvsuCowuSBdshESF8vPFjxv47ln96/kNJ/5Lp+thCuELT4k0ztvSBizy5wci+fbBwoSpu9dRT8Npr8JgOAbUt15aSuUtyIfSCzURIq27lvfrvuaBl6SM0KpTZ8z7kRORifJ5RdTWqJq79Y7Goqc5Tp6or+zhXrtisNXLdTuVyzQotzkDzs5DH3RePxs8Q2/oFOlR5lRzuOVhyfIlT7d3vH0WjXrBsDhS+Z387HbjqA7c8kp/8rbqVv07+RY8lPfDz8KNKgSp0qtCJDuU7MP/IfM7cOUNuz9x0rNCRYlZfzv7yBStX7eeOJ8ytAEfzp9xOo2akflD9hJkvR4/anX1U9C74RMM9B7NlY62xVCuQftNTr4Rdoc6UOtyIuGG318+qW7kRcYN289tx4I0D2TvgFuIxlqackXHjxvH9998THBxMlSpV+OWXX6idaBppYtOnT6dnz55JbvPw8CAqpemNiaRrzkhYGLzyCvz9typspWlqGqeXlzpZZdBqtq52/u55nv39WU7fPo3pwVUzqBPOjLYzeLXSqy5uYdrM+m8W/Zb1Iyo2EpNVncDNRnjxhFrZNmdMoo2NRvV3b/agIMizz8KGDckCkiJvwSU/kuRalLgNK2ZDuVsQYwCDpmGy6GpNmWXLoGZNLoZepNhPxZweEvGJguBR4Gm23UNi0eDDpvBtI/vHSNxD4+vhy+x2s3mxzIsJG0yaBEOGQGwsVqMRq9WMyaoCkh5twdcvH7cjb6vHS3RCN2pGvN282d57OxXzV1Q3bt0Kjew3ZnhLGFPHdq+SQTOQxysPl4dfdphQmhq9lvbi9/9+d7pOzj89/5GhGCEyWYat2jtv3jyGDx/Op59+yr59+6hSpQotW7bk+vXrdvfx9fXl2rVr8T8XLlxI7cOmn44dYd069W+zWeUZ6DpERqrekQ2Pnu2fFRXLVYyjA4+y8JWFdKnchVcqvMLIZiO5MvxKtg1E1pxZQ7fF3Yg0R6JraoXcuMJYq0rDqw+vaG+xqMqnR46o33v3ttkz0nefql0RJ0c0bJgBJe+o392tqEAE1IJ2zZrBpUsU8StC67Ktnc69uecJnTuok3dsok+i9cHPhmLwQz3Hx9DR46cb34u+x8vzXmbP1QeVXRcuVOvmPFj8z2BWgQhAp2MaF488y7W3r7Gt1zaeLvZ0/DENmoHWZVuzq8+uhEAEVN0af/uJIZ9vhGrBqlhaYiaDCXejOwteWZBugUhETASzD812OhAxaka2XkzdzChQaxB9vvlzXl/0Ov2X92ftmbVPzGJ1ETERbL24lX8u/ENYdFjKOwjxCFLdM1KnTh1q1arF2LFqOWur1UpQUBCDBw/mgw8+SLb99OnTeeutt7h7926aG5luPSO7dycpBJaM0aiu/DZm7wWHnhQNpjZg55WdDk8OByZAlcQLWppM0KWLyheJjYWmTdVqvYkSMu94Qs1+cDGXqhPyxm4Yv8JB5G40wttvw7ffEhIeQoPfGnDu7jmnT1rVr8K726DdMRXonPKH8bU1fqvrQRjO9yCCOvG3KduGBR3/VDOFjh2zX9hN0+DUKSipcimCw4O5ef8mgTkD7Sd8fv+9Wv/IFoOB+326M6ZrGcbvHs+lsEt4mjzpXLEz79Z/1+HaM6l1+vZpSv/ifOE0o2bk62Zf814D54cjx+waw7C/h8WXY9c0DbPVTN1CdVn+2vJHqpmSlcVYYvh4w8eM3zOe8JhwQCXB96nWh2+f/dbhoohCPCxDekZiYmLYu3cvzROt+mowGGjevDk7duywu194eDhFixYlKCiINm3acCTuytSO6OhowsLCkvyki0WLEtZrscViUUmOd+6kz+OJDHMj4gbbL293eMI3WWDBw+c/s1mt2Avg5garVqn1fBK9L3LHGtl2tx3PlWyFhkbHlNZ2sVjgjz8ACMgZwJ5+e/jymS8J8g1y6rnsKwivdgSPj8H0MXw+pQu9ph+kd90BqZ7hZLaaWXJ8CbGnTjjM8QBUMLJ4cfyvBXIWoGL+io5Psu+8A8OHq3+bTCoQi3vtnnsO7+9+5IOGH3Bx2EViP47l/v/uM63NtHQNRAByeeZK1fYW3ZKqpL9FxxYxdPVQrLoVi27Bolvie2F2X91Nu3ntyAZVEVLNqlvpML8Do3aMig9EAKLMUUzYM4GWs1oSY4lxcAQh0iZVwcjNmzexWCwEBAQkuT0gIIDgYNurBZYtW5bffvuNpUuXMmvWLKxWK/Xr1+fy5ct2H2fkyJH4+fnF/wQFOfelnqJ799QXcErCw1PeRrhU4i9KezQdwm2NCkRFJZykc+ZUuUJXr8LSpWo2zuXLFJixkL+6reL8W+ep7l0y5Q9KRET8P3N55mJEoxFs7J7KHjYNPm32Ob+//DuVAirxv0b/o4hfkVQHJBbdQmxYQkBt1WBDcZhUA+ZXgHtxr4nRmDAF2uk2ajB6NJw4oQKT559XpfXd3GDFCsifH3r2hDNn1NoqGZQwmtc7L02LN3XqtTEZTNQrXC9VUx+/3PKl3WJnFt3Clotb+PfKv8nui4yNZNGxRUzaMynFtUSyohUnV7Ds5DKbQb5Ft7D14lbmHJrjgpaJx12GlxasV68e3bp1o2rVqjRp0oRFixaRL18+Jk2aZHefESNGEBoaGv9z6dKl9GnMU0+pK2NHfH3hoWBLZD2BPoHkcLMz7eUBsxGeuvnQjZoGpUolD0rz5YOXXoI2bVRS6gNF/IqQu2ZDxz1qRiOUT37lX9CnoFNd2nEnvYG1BvJh4w/jb8/rnZedfXbStXLXVOVaBOYMxKtkOXBzY31xKDEUmnWH/i9Cp45Q4B34sjHosbHqM5EWZcqohRj/+UcN9cQ+KJMfE6NWH65ZU/XMZKDPnv4MSFjV1p7iuYqz4JUFTh83ODw4xWnQJoOJpSeWJrlt7L9jKTC6AO3nt6f/iv48P+d5gn4MYvGxxXaOkvVM3jfZ8eKJmoFf9/6aiS0ST4pUBSN58+bFaDQSEhKS5PaQkBAKFHCwGlcibm5uVKtWjdOn7S+o4eHhga+vb5KfdPH666oIlj1GI/TpA+7pk2QnMo6nyZNe1XrZ/eLUdPCKhVcP2bhz4ECVeHr9uuNhjDj9+zsOYi0Wm+vceLl50bNqT4df7iaDiaF1hnJ04FHGPT8u2dV4/hz5mdZ2GiHvhLC3314299icLEE0MYNmYGCtgWi5c7O9RzNadYFLcR+fB+fs++7wcVP45DlPePll+88rJb17q56Vh18bs1nd3qtX2o/thIZFGrK081L8vVRSbdwqt6B6pxoVacTk1pM50P8ABX0KOn3cyNjIFLfR0IgyJ+TzjNk1hsGrBidL9AwJD6H9/PasOLnC6cd3pbN3zjosjmjVrZy9czYTW2TH1auqwGGFClCihJohuWmTq1slHkGqghF3d3dq1KjB+vXr42+zWq2sX7+eevVSSPt/wGKxcOjQIQIDA1PX0vSQKxdMnqyuig0PPXWjUXU3f/RR5rdLpMn/Pf1/lPQvmexkb3xwQpq6TMMn8fC2waB6RcaOVcMJAQHqCn/iRJuzauLVrZuQJ/Fwj4qmqRP6K6/Y3PWzpz+jeO7iyduoGdHQmN1uNj+0/IGn8jnuocjlmYvqgdVpXLQxY55Ta9s8HLgYNSM1AmswrO4wAEbUvIuugdXOp/ybOrFcN4favjMlhw7Bzp3JKrHGi6vtcshWNJh+XijzAlffvsqfHf/k0yaf8lOrn7j41kXuvH+HLT230Kd6n1QnXBbyLYSfh5/DbWKtsVQJqAKoWScfbvjQ5nZx07zfWftOtsgxyZcjX4pr8eTzzpdJrbFjxw4oWxa+/lr1vp07p3KfnnkG3n3XuQsMkeWkephm+PDhTJ48mRkzZnDs2DEGDBhAREREfC2Rbt26MWLEiPjtP//8c9asWcPZs2fZt28fXbp04cKFC/Tp0yf9nkVqdOmiak3Ur59wm48PDB4M27dD7tyuaZdINX8vf3b03sGgWoOSDNk0KNqItUU/orNWKWHjPHmgalU1pHA20ZXdmTMwYAC88YbjL7FRo1Ql19KJZnAULAjffAPz58evWvuwPN552Nl7JwNrDUzSxoZFGrKu2zpeqWA7iHFkUO1BLOm0hBqBCWXVc3nm4t3677Kx+0ZyuOfgStgVtlzb6bCSrFXTmX9kfqofH0iYHp2SDB6qAXA3utOhfAc+avwRQ+oMIcjv0XLM3I3uvFHjDfu9bmj4efjF/+1WnFrhMIdJR+f4zeMcDDn4SO3KDN0qd3M4PGXQDK5d/yQiAl58Ua0/lTgQjuudGzVKfR5FtpPqCqydOnXixo0bfPLJJwQHB1O1alVWr14dn9R68eJFDIl6He7cuUPfvn0JDg4md+7c1KhRg+3bt1Pexhh7pnn2WfVz86Z6cxco4Hj4RmRZ/l7+/Pzcz3z37HcEhweT0z1nwmyQHp+roZjoaHVSfO45dXvioCPu31OmQPv20KqV7QfSNDUs0atX/CJxx9xDGb3rJxaMykukOZKn8j7FoFqD6FmtZ5IFB/N452HMc2P47tnvCAkPSdrGNGpTrg1tyrVh5+WdjNs9jhUnV/DDzh9YdnIZA2sNpFbBWikew6gZuR5hvz6QQzkc5+vE886e00A/bvIx68+tT5Y7YtJMoMEf7f/Ay80LgOsR151a/yfNr3Um6lyxM6N2jOLEzRPJhmtMBhMFfQrSp7qLLiRBzVq7fdv+/QaDSrDu1Cnz2iTShazaK54M7dqpSqn2cj9MJhWs/KVW1NV1ncXHF/Pzrp/598q/uBnceKH0CwyvN5xahWqx/ux6XpjzQpIpn3H5Cs+Veo4lnZfgZnTL0Ke07eI2WsxqQYwlJlkb6gfVZ/ul7Q5PkBoak16cRN8afVP/4OfPQ7lyKtCzJ0cOCAlxPnDJYiJiIvhx54+M3z2ea+HXMGpG2j3VjvcbvJ9ksb8lx5fw8ryUc2+ODjya4nBcVnA94jqvLXyN9efWo6GhaRpW3Uq9wvWY22EuRfyKuK5xXbuqgMTe8GCcqCi5wMwinD1/SzAingylStlcoTeJokXh/Hl0XWfwqsGM2z0Oo2aMv0KMK6M/ufVkhv89nHsx92x2aRs0AyObjUxVga3UirHEUPiHwtyKvGW3DSVyleDc3XN2ExI9TZ4Evx2Mn6fj/IgkoqNh2DDVkxQ3g8aeTz+F//s/54+dRem6zv3Y+3iYPJL0eMWJscQQODowvqz+wwyageoFqrO73+6Mbmq6OnL9CBvPb0TXdRoUaUD1wOqubpLzwUh0tExEyCIyrBy8ENmSj4/T2yw6tohxu8cBSddrMVvNahXcZX0JjQ61O7Zu1a388u8v8feHhIdw/u75dC0WtfjYYm7cv+GwDTfu38DT5Gk39+Hb5t+mLhDRdbV206RJ9gORuNyZN99Usx0eA5qmkcM9h81ABFSOyS/P/WLzPoNmwKgZ+anVTxnYwoxRIX8F3qz9JoPrDM4agQhAkyaOAxGDAWrVkkAkG5JgRDwZXnkl+QyqxAyG+HHmn3f97HA6rq7rDqfXglrTZMaBGdT4tQYFRheg+M/FCfg+gA/WfeBUwbaU7L66GzeD42Gg0OhQ5naYS51CdZLcXtCnIL+99BtD6gxJ3YNu366KwtmbeaRparmFU6fgl18cv952WHUrG89tZNy/45h+YDo3Im6k+hiu8Fql11jQcQHFcxVPcnuVgCps7L6RBkUauKhlj5lXX1XrI9l7b1mtamkGke3IMI14Mty8qXIc7t5NfmVlNKpid8ePQ/78eH3llaSGhC3OJCyCujJO3Hth1IxUD6weP+slrf63/n98v/37FCt8Xhp2icK+hTlx8wRn7pwhl2cu6hSqg9GQuqquAPTrp9b0cVRzJU8e9VqnwY5LO+iyuAtn75yNf31NBhMDaw1k1LOjMjwHJz1YdSt7ru7hRsQNivgVoVJApZR3Eqmzcye0aJF0Ro3JpN6X772nZrhlUOVfkXoyTCNEYnnzqgUQ4+rbuLmpH1CzqTZuVLVHwG53fGKOApHEdRoeHkax6Bb2XtvLTzt/Sl37H9KqVCuHgYiGRrm85SjkUwiAsnnL8nzp56kfVD9tgQhAcHDKFYxv3XJcs8WO/0L+o9nMZpy/ex5IeH3NVjO/7PqFN5a/kepjuoJBM1C7UG1eKPOCBCIZpW5dtRzBRx+pxSBLllQz4TZvhm+/lUAkm5JgRDw5KlVSNUYWLFB1Rfr1gz//VEWTqlSJ3+z5Us87DEg0NAJyBKhpnjZYdavDYRyrbmXc7nGPVASrUZFG1AisYbcNOjojGo5I37VhChVyXBYfVFn9NAzPfL75c2IsMTZzYHR0ph2YxombJ1J9XPGYCgxUydGHDsHp0zB3LjRu7OpWiUcgwYh4sri5qauoX35RlVg7dEjoIXlgeL3hWKy2k+SMmhF/L3/WdV1HkVxqimNcT0hcnkmVgCopBgHXwq8RaU657Lg9mqbx16t/UTpP6SRtiAuiPm78MV0rd03z8W3q0cNxz4jRCH1TP004PCacxccXOyxDbtJMzD40O9XHFkJkD6kueibE465O4TrMaDuDnktVVWGLbomv3+Hn6cffXf6mYkBFjg48yoKjC1h4bCERMRFUyF+BfjX68cOOHzhy4wiOUkqMmhEP46PVQSjoU5AD/Q+w+Nhi/jz6J6HRofx/e/ce3FSZ/gH8e5L0gvZCkd6gUaByWSgVV7GkgAoUWXC13dWtVARX67pgcYSOsxStGxdwAQVlHdkqF4VBERaWVS7lZkEuUoUChcJgEUu3LhAY9idtpdtLkvf3x7GFQJI2kJyTk34/Tqb0nNP0yTOtefqe933eX3T+BZ6/53kkxSTd1HM7dd998gTCVauu71ZrMMi3u6ZM8fhpq+tdr0xqJkmSZiazBqwjR+RHhw5AWhq7VZNXcQIrkQtV1VVYdHARvjnzDYL1wRh952iMTx7f6nLYbd9vw6iPR7k8b5AM+M0vfoN//E6DbautVuDVV+WRpf/9PLIjSXLn2kWLgIQEj5+y3lqPjnM6osHmuoGaXtJj5rCZmD50ustryEe+/RaYMAE4cFWflJAQeXPIuXOvG1kkuhqbnhGpxC7sMC0x4dC5Q7AKx9saEiTodXp8nf21QxdPzamtBfbskZtLDRgAdO/e6pe489z657D8yHKXk3J1kg5VU6rQNaLrTX0f8lBVFXD33UB19fWr0CRJ3gl9xQp1YiNN4GoaIpXoJB02jdsEk1HeydqgM7T0BIkIicD6seu1XYgAcoO4MWPkHYtvshABAPMDZnTq0MnlhFzzA2YWImqYOxeoqXHeaEwI4OOPgdJSxcOiwMORESIfEULgmzPf4PNvP0e9tR53xd2FzH6ZHm9p316c/vE0JhdOxuZTm1uW9saFxeG1+1/DpHsneXdlELXObpeLzro619cYDPKO52+/rVxcpCltff/mBFYiH5EkCYMSBmFQwiCffy+r3Yr15euxt2ovJEgY3n04fnXnr268p4gKukd1x6Zxm1BVXYXyi+UICw7DwK4D29T3hXygrs59IQLIoyPnzikTDwU0/pYTaVyppRSPfPoI/lPzn5bbQW9//TYSoxJROK4QvW7rpXKEnrk98nZ1d4Yl2S23AGFhwE9uti+QJLn/DNFN4pwRIg2z/GTB8OXDca5W/uu0yd6EJru8iV3lpUo8uOxBVNdXqxkiaZVOBzz7rPtGd1ar3H+G6CaxGCHSsIIDBahpqHHaMMwmbLD8ZMGy0mXKB0aBYdo0eb8hvZPbfZIkN7lL8kFPG2p3WIwQadinxz5127lUQGD18dUKRkQBpUsXoLgYeOABx+NhYcBrrwEFBerERQGHc0aIVGIXdmz/fjs+PPwhKqsrEXtrLCbcNQHpvdPbvEPtT41u7uf/rKah5mZDvTGlpcAHHwCHD8tvXr/9LTB+vLxC41o2G7BxI7B8OXDmDGA0ysP/o0c7/6uclNO9O1BUJO8BU1YGhIbK+8DceuO7ThNdi8UIkQoabY3IXJOJz8s/h17SwyZs0Et6bDi5AYMSBmHLuC2tdnoFgL7RfXHh8gWXoyMGnQH9Y1TYPXbGDMBsvrK1uyQBO3YAs2bJH/v0uXLt5cvAr38NfPmlXHjYbMDBg8A//ylvFf/ZZ3ILclLXnXfKDyIf4G0aIhW8WvQqNpzcAAAthUTzxwNnDiB7fXabnidnYI7b2zRWuxUT7514k9F6aO1auRABrmysJ4T8uHBBbh3f1HTl+smTgd275X83N9dq/vjFF8DUqcrETUSqYTFCpLDahlr8veTvLjeHswkb1p1Yh8pLla0+V3qfdIxNGtuykV+z5s8n3TsJ99+h8Nbqc+fKKzGcsdmAf/8b+Pxz+fPz5+UunnYXG+XZ7cBHHwH//a9vYiUiv8BihEhh+8/sR12T+2ZSAgI7Tu9o9bl0kg4f/+ZjzHtoHowRxpbjPaJ6oODhAiwcs1DZzqW1tUBJieviApBv3XzxhfzvXbuujJ640tgI7N3rvRiJyO9wzgiRwtzdVrmaq03jrqXX6ZFrysWUQVNwtvYsJEjoEt5FnfbpzvYwcaa5APH0eiIKSBwZIVLY3XF3t6nFuSnB5NHz6iQdEiIS0DWiq3r7uERGAomJ8oRVV6xWwPTza7vvvtafU5Ladh0RaRaLESKFRd8ajaykLOgl50tWDToDhhiHoH+sCqtgbpYkAbm58mRVZ3Q6oGNHYOxY+fPERHlCq6sun3o9kJ4uL/UlooDFYoRIBe+Ofhf9YvpB+vm/ZjpJh/iweHzy2CcqRneTJk4EsrLkf1/dI8RgAEJC5KW6V/eo+Ogj4I47rp/0KknyUtJFi3weMhGpi8UIkQo6hnbEvmf34W+/+hv6RvdFREgEEqMSMXPYTJROLNX2RnE6nbxCZvVqIDVVHgmJjwdeeAE4evT6bp5xcXJfkTlzgF69gIgIoHdvYN484MABIDpalZdBRMqRhHA1nuo/ampqEBkZierqakRERKgdDhEREbVBW9+/uZqG/Ft9vdxO3GoF+veX/8omIqKAwts05J+sVuAvf5GH8FNT5b0w4uLkXUJrVNprhYiIfIIjI+R/hJA3SVu50nFVRkODPNnx0CFgzx7glltUC5GIiLyHIyPkf3bvBj75xPnyUJtNvm2zZInycRERkU+wGCH/s3Sp674TzT74QJlYiIjI51iMkP+pqHDf/lsIebM1IiIKCCxGyP9ERzs2y3KmUydlYiEiIp9jMUL+56mn3G+gptfLE1yJiCggsBgh//Poo8DAgc5HRwwGoHNnICdH+biIiMgnWIyQ/wkKArZuBUaPlj+XpCv7lvTrJy/rjY1VLz4iIvIq9hnROpsN+P57wG6Xd0ANClI7Iu+IigI2bABOngS2b5cntKakyA9329MHKCEETl86jXprPbp37I4OQR3UDomIyGtYjGiV3Q4sWADMnw+cPSsf69wZePFFYPr0wClKevWSH+3YiiMrMGvPLJz870kAwK1Bt+K5Xz6HGcNmICKEezURkfZxozwtEgJ49llg2bLrz0kS8PDD8jbtra1IIb/3xu43kL8zHxIkCFz5VdVLeiTFJGHvs3sRFhymYoRERK619f2bc0a0aMcO54UIIBcqGzcC//iHoiGR91X8WIHXdr4GAA6FCADYhA1lF8qw4OsFKkRGRORdLEa06IMP3Hco1euB999XLh7yiaWHlkInuf4VtQs7CkoKFIyIiMg3WIxo0YkT7juU2mxAebly8ZBPfPd/3103InKts7Vn0WBtUCgiIiLfYDGiRVFRra8o4dwazYsMiXQ7MgIAwfpgBOkDZLIyEbVbLEa0KCvL/XmdTu5iSpqW2S8TVrvrETCDzoAn+j3RasFCROTv+H8xLRo/Hrj9dufzRvR6ed+WiROVj4u8akSPETAlmKCXrl8VpZN0MOgM+NPgP6kQGRGRd7EY0aKwMGDXLqBvX/lzg+FKYdK9u3wuJka9+MgrdJIOm57chGHdhgGQl/MG6eRbMrd1uA2bx21GUkySmiESEXkF+4xomRBya/SiIrkJ2pAhwMiRV1qnU8AotZRiQ/kG1FvrcXf83Ujvnc65IkTk99r6/s1ihIiIiHyCTc+IiIhIE1iMEBERkapYjBAREZGqWIwQERGRqliMEBERkarc7LZGdJXTp4F9++Q29EOHAkaj2hH5v//9D9i+HfjxRyAxERg8uPU2/kRE7dANjYwsXLgQ3bp1Q2hoKFJSUrB//363169ZswZ9+vRBaGgo+vfvj8LCwhsKllRw8SKQni6/mT71FDBuHHDHHUBmJnDpktrR+SchgHfeAeLj5dz9/vdyAderl9yQjoiIHHhcjKxevRq5ubkwm804dOgQ7rrrLowaNQoXLlxwev2+ffuQlZWF7OxsHD58GBkZGcjIyMCxY8duOnjysbo64IEHgE2b5DfYZkIA69bJDdYauGPsdebOBXJzgepqx+MVFXLOiovViYuIyE953PQsJSUFAwcOxHvvvQcAsNvtMBqNePHFF5GXl3fd9U888QQuX76MjRs3thwbNGgQBgwYgPfff79N35NNz1RSUADk5DgWItdasYKb8l3txx+BuDigsdH5eZ1O7pTLERIiagd80vSssbERBw8eRFpa2pUn0OmQlpaGYhd/7RUXFztcDwCjRo1yeT0ANDQ0oKamxuFBKvjwQ/fndbrWr2lv1q4Fmppcn7fbgd27gaoq5WIiIvJzHhUjFy9ehM1mQ2xsrMPx2NhYWCwWp19jsVg8uh4AZs+ejcjIyJaHkZMl1XH2rPtREbtdvoausFjknZNbc/6872MhItIIv1zaO336dFRXV7c8fvjhB7VDap8SEtxvuqfTcVXNtbp0AWy21q+Lj/d9LEREGuFRMdK5c2fo9Xqcv+avuvPnzyMuLs7p18TFxXl0PQCEhIQgIiLC4UEq+MMf5NEPV+x2IDtbuXi04PHHgZAQ1+f1emDECLnQIyIiAB4WI8HBwbjnnntQVFTUcsxut6OoqAgmk8np15hMJofrAWD79u0uryc/8tRTwC9/6fy2g14v98147DHl4/JnkZHA7NnOz+l0QFCQvNqGiIhaeHybJjc3F4sXL8by5ctx4sQJTJo0CZcvX8YzzzwDAJgwYQKmT5/ecv1LL72ELVu2YP78+fj222/x+uuvo6SkBJMnT/beqyDfCA0FduwAxo51LEgMBuDpp4GtW+U3V3I0ZQqwaBEQE+N4vH9/eRXNPfeoEhYRkb/yeGkvALz33nt46623YLFYMGDAALz77rtISUkBADz44IPo1q0bli1b1nL9mjVrkJ+fj8rKSvTs2RNvvvkmxowZ0+bvx6W9fsBiAb75Ru4gajIB0dFqR+T/mpqAPXvk5nA9egADBqgdERGRotr6/n1DxYjSWIwQERFpj0/6jBARERF5G4sRIiIiUhWLESIiIlIVixEiIiJSFYsRIiIiUhWLESIiIlIVixEiIiJSFYsRIiIiUhWLESIiIlKVQe0A2qK5SWxNTY3KkRAREVFbNb9vt9bsXRPFSG1tLQDAaDSqHAkRERF5qra2FpGRkS7Pa2JvGrvdjrNnzyI8PBySJKkdjqbU1NTAaDTihx9+4L4+N4m59C7m07uYT+9hLr1HCIHa2lp06dIFOp3rmSGaGBnR6XRISEhQOwxNi4iI4C+VlzCX3sV8ehfz6T3MpXe4GxFpxgmsREREpCoWI0RERKQqFiMBLiQkBGazGSEhIWqHonnMpXcxn97FfHoPc6k8TUxgJSIiosDFkREiIiJSFYsRIiIiUhWLESIiIlIVixEiIiJSFYsRDSsoKEBycnJLYx6TyYTNmze7/Zo1a9agT58+CA0NRf/+/VFYWKhQtP7P03wuXrwYQ4cORVRUFKKiopCWlob9+/crGLH/upGfzWarVq2CJEnIyMjwbZAaciP5vHTpEnJychAfH4+QkBD06tWLv++4sVwuWLAAvXv3RocOHWA0GjF16lTU19crFHH7wGJEwxISEjBnzhwcPHgQJSUlGD58ONLT03H8+HGn1+/btw9ZWVnIzs7G4cOHkZGRgYyMDBw7dkzhyP2Tp/n88ssvkZWVhZ07d6K4uBhGoxEPPfQQzpw5o3Dk/sfTXDarrKzEyy+/jKFDhyoUqTZ4ms/GxkaMHDkSlZWVWLt2LcrLy7F48WJ07dpV4cj9j6e5XLlyJfLy8mA2m3HixAksXboUq1evxiuvvKJw5AFOUECJiooSS5YscXouMzNTPPzwww7HUlJSxB//+EclQtMkd/m8ltVqFeHh4WL58uU+jkqbWsul1WoVqampYsmSJeLpp58W6enpygWnQe7yWVBQIHr06CEaGxsVjkqb3OUyJydHDB8+3OFYbm6uGDx4sBKhtRscGQkQNpsNq1atwuXLl2EymZxeU1xcjLS0NIdjo0aNQnFxsRIhakpb8nmturo6NDU1oVOnTj6OTlvamssZM2YgJiYG2dnZCkanPW3J5/r162EymZCTk4PY2FgkJSXhr3/9K2w2m8LR+re25DI1NRUHDx5suQVbUVGBwsJCjBkzRslQA54mNsoj18rKymAymVBfX4+wsDD861//Qt++fZ1ea7FYEBsb63AsNjYWFotFiVA1wZN8XmvatGno0qXLdQVfe+VJLvfu3YulS5eitLRU2SA1xJN8VlRUYMeOHRg3bhwKCwtx6tQpvPDCC2hqaoLZbFY4cv/jSS6ffPJJXLx4EUOGDIEQAlarFRMnTuRtGm9Te2iGbk5DQ4P47rvvRElJicjLyxOdO3cWx48fd3ptUFCQWLlypcOxhQsXipiYGCVC1QRP8nm12bNni6ioKHHkyBEFotSGtuaypqZGdOvWTRQWFrYc422a63nys9mzZ09hNBqF1WptOTZ//nwRFxenVLh+zZNc7ty5U8TGxorFixeLo0ePinXr1gmj0ShmzJihcNSBjcVIgBkxYoR4/vnnnZ4zGo3inXfecTj25z//WSQnJysQmTa5y2ezt956S0RGRooDBw4oFJU2ucrl4cOHBQCh1+tbHpIkCUmShF6vF6dOnVIhWv/n7mfz/vvvFyNGjHA4VlhYKACIhoYGJcLTFHe5HDJkiHj55Zcdjq1YsUJ06NBB2Gw2JcJrFzhnJMDY7XY0NDQ4PWcymVBUVORwbPv27W2eE9EeucsnALz55puYOXMmtmzZgnvvvVfByLTHVS779OmDsrIylJaWtjweffRRDBs2DKWlpTAajSpE6//c/WwOHjwYp06dgt1ubzl28uRJxMfHIzg4WKkQNcNdLuvq6qDTOb5V6vV6AIDg1m7eo3Y1RDcuLy9P7Nq1S5w+fVocPXpU5OXlCUmSxLZt24QQQowfP17k5eW1XP/VV18Jg8Eg5s2bJ06cOCHMZrMICgoSZWVlar0Ev+JpPufMmSOCg4PF2rVrxblz51oetbW1ar0Ev+FpLq/F2zSOPM1nVVWVCA8PF5MnTxbl5eVi48aNIiYmRsyaNUutl+A3PM2l2WwW4eHh4tNPPxUVFRVi27ZtIjExUWRmZqr1EgISJ7Bq2IULFzBhwgScO3cOkZGRSE5OxtatWzFy5EgAQFVVlUNFn5qaipUrVyI/Px+vvPIKevbsic8++wxJSUlqvQS/4mk+CwoK0NjYiMcff9zhecxmM15//XUlQ/c7nuaS3PM0n0ajEVu3bsXUqVORnJyMrl274qWXXsK0adPUegl+w9Nc5ufnQ5Ik5Ofn48yZM4iOjsYjjzyCN954Q62XEJAkITjOREREROrhnyZERESkKhYjREREpCoWI0RERKQqFiNERESkKhYjREREpCoWI0RERKQqFiNERESkKhYjREREpCoWI0RERKQqFiNERESkKhYjREREpCoWI0RERKSq/we3wT0HjjPy0QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pl_train[\"OP1_AVG\"], pl_train[\"HOME_POWER\"], c=color_col)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "1AmtNLmlLANq",
        "outputId": "4042b2ab-dc2f-411e-b6cf-9116686a17cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pl_train[\"OPX_RATE\"], pl_train[\"HOME_POWER\"], c=color_col)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Ihm4qKugLCX8",
        "outputId": "95f93c80-ff3b-477d-bf36-1f2ab37c035c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict decrease"
      ],
      "metadata": {
        "id": "NPlAWt9xdrUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_rows\", 100)"
      ],
      "metadata": {
        "id": "0r7_uusSkEAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset_with_season()"
      ],
      "metadata": {
        "id": "lEGUsl6Sfk9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minh_dataset = get_dir_database(dataset.copy())\n",
        "minh_dataset = get_weighted_OHE_dataset(minh_dataset)\n",
        "minh_dataset = get_odds_percent_database(minh_dataset)\n",
        "minh_dataset = get_odds_rankings(minh_dataset, True)\n",
        "minh_dataset = get_stat_percent_database(minh_dataset)\n",
        "minh_dataset = minh_dataset.drop(minh_dataset[minh_dataset.games < 4].index)\n",
        "minh_dataset = get_power_database(minh_dataset)\n",
        "# minh_dataset = minh_dataset.drop(columns=[\"home_team\", \"away_team\"])\n",
        "minh_dataset = minh_dataset.drop(columns=[\"home_wins_rate\", \"home_tie_rate\", \"home_loss_rate\", \"away_wins_rate\", \"away_tie_rate\", \"away_loss_rate\",])\n",
        "max_symbol = \"H\"\n",
        "mid_symbol = \"D\"\n",
        "min_symbol = \"A\"\n",
        "minh_dataset = minh_dataset[(minh_dataset[\"OP_MAX_ODD\"] == max_symbol) & (minh_dataset[\"OP_MID_ODD\"] == mid_symbol) & (minh_dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "# minh_dataset = minh_dataset[minh_dataset[\"OP_MIN_ODD\"] == \"H\"]\n",
        "minh_dataset\n",
        "\n",
        "minh_dataset[\"OP_MID_ODD\"] = minh_dataset[\"OP_MID_ODD\"].apply(lambda x: 0 if x == \"D\" else 1)\n",
        "minh_dataset[\"OP_MAX_ODD\"] = minh_dataset[\"OP_MAX_ODD\"].apply(lambda x: 0 if x == \"D\" else 1)\n",
        "minh_dataset_dr = minh_dataset.drop(columns = [\"result\", \"season\", \"OP1_AVG\", \"OPX_AVG\", \"OP2_AVG\", \"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"DIRX\", \"DIR2\", \"date\", \"OP_MIN_ODD\"])\n",
        "minh_dataset_dr\n",
        "curr_label = \"DIR1\"\n",
        "\n",
        "get_dir_dataset_stats(minh_dataset_dr, curr_label)\n",
        "\n",
        "minh_test = minh_dataset_dr.loc[2700:]\n",
        "minh_train = minh_dataset_dr.drop(index=minh_test.index)\n",
        "\n",
        "\n",
        "\n",
        "# minh_train = minh_train.sample(frac=1)\n",
        "# get_dir_dataset_stats(minh_train, curr_label)\n",
        "# minh_train = minh_train.groupby(curr_label).sample(n=792)\n",
        "# get_dir_dataset_stats(minh_train, curr_label)\n",
        "# minh_val = minh_train.groupby(curr_label).sample(frac=.2)\n",
        "# get_dir_dataset_stats(minh_val, curr_label)\n",
        "# minh_train = minh_train.drop(index=minh_val.index)\n",
        "# get_dir_dataset_stats(minh_train, curr_label)\n",
        "# minh_train = minh_train.sample(frac=1)\n",
        "# minh_val = minh_val.sample(frac=1)\n",
        "\n",
        "# minh_val_target, minh_val_features = get_features_and_labels(minh_val, curr_label)\n",
        "minh_train_target, minh_train_features = get_features_and_labels(minh_train, curr_label)\n",
        "minh_test_target, minh_test_features = get_features_and_labels(minh_test, curr_label)\n",
        "\n",
        "# stats_dataset.groupby([\"DIR1\"]).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YUTvhl0dt2G",
        "outputId": "7790b2e2-69b4-4b08-b1b1-1a309e44bd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U% : 63.787%, 347/544; D% : 36.213%, 197/544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minh_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "BE-kIFHHCJf1",
        "outputId": "44a81073-adb4-4661-b87d-3d9cf2d95bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  DIR1  Alaves  Almeria  Ath Bilbao  Atl. Madrid  Barcelona  Betis  \\\n",
              "2702      4     0       0        0           0            0          0      0   \n",
              "2703      4     1       0        0           0            0          1      0   \n",
              "2706      4     1       0        0           1            0          0      0   \n",
              "2707      4     1       0        0           0            0          0      0   \n",
              "2721      6     1       0        0           0            0          1      0   \n",
              "...     ...   ...     ...      ...         ...          ...        ...    ...   \n",
              "3380     34     0       2        0           0            0          0      0   \n",
              "3382     34     0       0        0           0            0          0      0   \n",
              "3394     35     1       0        0           0            1          0      0   \n",
              "3397     35     0       0        0           0            0          0      1   \n",
              "3398     35     1       0        2           0            0          1      0   \n",
              "\n",
              "      Cadiz CF  Celta Vigo  Dep. La Coruna  Eibar  Elche  Espanyol  Getafe  \\\n",
              "2702         0           0               0      0      0         2       0   \n",
              "2703         2           0               0      0      0         0       0   \n",
              "2706         0           0               0      0      2         0       0   \n",
              "2707         0           0               0      0      0         0       2   \n",
              "2721         0           0               0      0      0         0       0   \n",
              "...        ...         ...             ...    ...    ...       ...     ...   \n",
              "3380         0           0               0      0      0         0       0   \n",
              "3382         0           0               0      0      0         0       0   \n",
              "3394         0           0               0      0      0         0       2   \n",
              "3397         0           0               0      0      0         0       0   \n",
              "3398         0           0               0      0      0         0       0   \n",
              "\n",
              "      Gijon  Girona  Granada CF  Huesca  Las Palmas  Leganes  Levante  Malaga  \\\n",
              "2702      0       0           0       0           0        0        0       0   \n",
              "2703      0       0           0       0           0        0        0       0   \n",
              "2706      0       0           0       0           0        0        0       0   \n",
              "2707      0       0           0       0           0        0        0       0   \n",
              "2721      0       0           0       0           0        0        0       0   \n",
              "...     ...     ...         ...     ...         ...      ...      ...     ...   \n",
              "3380      0       1           0       0           0        0        0       0   \n",
              "3382      0       0           2       0           0        0        0       0   \n",
              "3394      0       0           0       0           0        0        0       0   \n",
              "3397      0       0           0       0           2        0        0       0   \n",
              "3398      0       0           0       0           0        0        0       0   \n",
              "\n",
              "      Mallorca  Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  Sevilla  \\\n",
              "2702         0        0               0            0              0        1   \n",
              "2703         0        0               0            0              0        0   \n",
              "2706         0        0               0            0              0        0   \n",
              "2707         0        0               0            0              1        0   \n",
              "2721         2        0               0            0              0        0   \n",
              "...        ...      ...             ...          ...            ...      ...   \n",
              "3380         0        0               0            0              0        0   \n",
              "3382         0        0               0            1              0        0   \n",
              "3394         0        0               0            0              0        0   \n",
              "3397         0        0               0            0              0        0   \n",
              "3398         0        0               0            0              0        0   \n",
              "\n",
              "      Valencia  Valladolid  Villarreal  OP1_RATE  OPX_RATE  OP2_RATE  \\\n",
              "2702         0           0           0  0.380323  0.373433  0.246244   \n",
              "2703         0           0           0  0.555260  0.346135  0.098605   \n",
              "2706         0           0           0  0.424161  0.364781  0.211059   \n",
              "2707         0           0           0  0.415749  0.348460  0.235791   \n",
              "2721         0           0           0  0.552027  0.347479  0.100494   \n",
              "...        ...         ...         ...       ...       ...       ...   \n",
              "3380         0           0           0  0.392551  0.388486  0.218963   \n",
              "3382         0           0           0  0.505016  0.380226  0.114758   \n",
              "3394         0           0           0  0.446213  0.364544  0.189243   \n",
              "3397         0           0           0  0.391489  0.377828  0.230683   \n",
              "3398         0           0           0  0.462094  0.410349  0.127557   \n",
              "\n",
              "      OP_MAX_ODD  OP_MID_ODD  HOME_POWER  \n",
              "2702           1           0    3.000000  \n",
              "2703           1           0    0.000000  \n",
              "2706           1           0    0.200000  \n",
              "2707           1           0    0.200000  \n",
              "2721           1           0    0.545455  \n",
              "...          ...         ...         ...  \n",
              "3380           1           0    0.588235  \n",
              "3382           1           0    0.283333  \n",
              "3394           1           0    0.687500  \n",
              "3397           1           0    0.658537  \n",
              "3398           1           0    0.283019  \n",
              "\n",
              "[104 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce570fd2-4e77-45ac-973a-c6419829e945\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.380323</td>\n",
              "      <td>0.373433</td>\n",
              "      <td>0.246244</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.555260</td>\n",
              "      <td>0.346135</td>\n",
              "      <td>0.098605</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2706</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.424161</td>\n",
              "      <td>0.364781</td>\n",
              "      <td>0.211059</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2707</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.415749</td>\n",
              "      <td>0.348460</td>\n",
              "      <td>0.235791</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2721</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.552027</td>\n",
              "      <td>0.347479</td>\n",
              "      <td>0.100494</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.392551</td>\n",
              "      <td>0.388486</td>\n",
              "      <td>0.218963</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.588235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3382</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.505016</td>\n",
              "      <td>0.380226</td>\n",
              "      <td>0.114758</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3394</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.446213</td>\n",
              "      <td>0.364544</td>\n",
              "      <td>0.189243</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.391489</td>\n",
              "      <td>0.377828</td>\n",
              "      <td>0.230683</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.658537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.410349</td>\n",
              "      <td>0.127557</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce570fd2-4e77-45ac-973a-c6419829e945')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce570fd2-4e77-45ac-973a-c6419829e945 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce570fd2-4e77-45ac-973a-c6419829e945');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4abb2cdc-d87e-4e06-bb2f-6f16926fb73b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4abb2cdc-d87e-4e06-bb2f-6f16926fb73b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4abb2cdc-d87e-4e06-bb2f-6f16926fb73b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91630772-ac78-4c11-839a-4685368e0cfc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('minh_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91630772-ac78-4c11-839a-4685368e0cfc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('minh_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "minh_test"
            }
          },
          "metadata": {},
          "execution_count": 469
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFZymapUevun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(minh_train_features)\n",
        "steps_per_epoch = len(minh_train_features)/32\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=True)\n",
        "\n",
        "model_9 = tf.keras.Sequential([\n",
        "      normalizer,\n",
        "      layers.Dense(8),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(8),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(8),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      # layers.Dense(8, activation=\"sigmoid\"),\n",
        "      layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "weights = class_weight.compute_class_weight('balanced',\n",
        "                                            classes=np.unique(minh_train_target),\n",
        "                                            y=minh_train_target)\n",
        "\n",
        "model_9.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ohf8C3RtnKd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpiCAvbN1bxh",
        "outputId": "5d9c7f1b-80c5-4cec-b206-1a19718cfe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.294, 0.815])"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model_9.fit(\n",
        "    minh_train_features,\n",
        "    minh_train_target,\n",
        "    epochs=500,\n",
        "    callbacks=[early_stopping],\n",
        "    # validation_freq=5,\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "\n",
        "    # validation_data = (minh_val_features, minh_val_target),\n",
        "    class_weight={0: weights[0] - 0.1, 1: weights[1] + 0.1},\n",
        "    validation_split=0.1\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCaqycjUnR5r",
        "outputId": "752901cf-4b4b-4897-b7aa-55b0c93c4c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.4849 - loss: 0.7338 - val_accuracy: 0.7045 - val_loss: 0.6518\n",
            "Epoch 2/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4487 - loss: 0.7559 - val_accuracy: 0.7045 - val_loss: 0.6494\n",
            "Epoch 3/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5507 - loss: 0.7053 - val_accuracy: 0.7045 - val_loss: 0.6506\n",
            "Epoch 4/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 0.7104 - val_accuracy: 0.6818 - val_loss: 0.6510\n",
            "Epoch 5/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5790 - loss: 0.6862 - val_accuracy: 0.7045 - val_loss: 0.6515\n",
            "Epoch 6/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5912 - loss: 0.7047 - val_accuracy: 0.6136 - val_loss: 0.6518\n",
            "Epoch 7/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5138 - loss: 0.7076 - val_accuracy: 0.6818 - val_loss: 0.6522\n",
            "Epoch 8/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5450 - loss: 0.6961 - val_accuracy: 0.6591 - val_loss: 0.6538\n",
            "Epoch 9/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5768 - loss: 0.6962 - val_accuracy: 0.6136 - val_loss: 0.6561\n",
            "Epoch 10/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5337 - loss: 0.7237 - val_accuracy: 0.6136 - val_loss: 0.6584\n",
            "Epoch 11/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5081 - loss: 0.6987 - val_accuracy: 0.5909 - val_loss: 0.6601\n",
            "Epoch 12/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5559 - loss: 0.7046 - val_accuracy: 0.5909 - val_loss: 0.6617\n",
            "Epoch 13/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5899 - loss: 0.6852 - val_accuracy: 0.6136 - val_loss: 0.6633\n",
            "Epoch 14/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6328 - loss: 0.6839 - val_accuracy: 0.5909 - val_loss: 0.6645\n",
            "Epoch 15/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6035 - loss: 0.6808 - val_accuracy: 0.5909 - val_loss: 0.6654\n",
            "Epoch 16/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5934 - loss: 0.6977 - val_accuracy: 0.5909 - val_loss: 0.6664\n",
            "Epoch 17/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.7083 - val_accuracy: 0.5682 - val_loss: 0.6679\n",
            "Epoch 18/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6137 - loss: 0.6811 - val_accuracy: 0.5682 - val_loss: 0.6689\n",
            "Epoch 19/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5792 - loss: 0.6882 - val_accuracy: 0.5682 - val_loss: 0.6698\n",
            "Epoch 20/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5875 - loss: 0.7001 - val_accuracy: 0.5682 - val_loss: 0.6701\n",
            "Epoch 21/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6551 - loss: 0.6563 - val_accuracy: 0.5682 - val_loss: 0.6710\n",
            "Epoch 22/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6240 - loss: 0.6775 - val_accuracy: 0.5682 - val_loss: 0.6720\n",
            "Epoch 23/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6251 - loss: 0.6757 - val_accuracy: 0.5682 - val_loss: 0.6732\n",
            "Epoch 24/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5823 - loss: 0.6900 - val_accuracy: 0.5682 - val_loss: 0.6742\n",
            "Epoch 25/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6718 - loss: 0.6436 - val_accuracy: 0.5682 - val_loss: 0.6756\n",
            "Epoch 26/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6537 - loss: 0.6833 - val_accuracy: 0.5682 - val_loss: 0.6764\n",
            "Epoch 27/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6312 - loss: 0.6695 - val_accuracy: 0.5682 - val_loss: 0.6777\n",
            "Epoch 28/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6347 - loss: 0.6751 - val_accuracy: 0.5682 - val_loss: 0.6786\n",
            "Epoch 29/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6344 - loss: 0.6788 - val_accuracy: 0.5682 - val_loss: 0.6794\n",
            "Epoch 30/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5986 - loss: 0.6849 - val_accuracy: 0.5682 - val_loss: 0.6807\n",
            "Epoch 31/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5977 - loss: 0.6775 - val_accuracy: 0.5682 - val_loss: 0.6824\n",
            "Epoch 32/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6558 - loss: 0.6656 - val_accuracy: 0.5682 - val_loss: 0.6842\n",
            "Epoch 33/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5986 - loss: 0.6717 - val_accuracy: 0.5682 - val_loss: 0.6859\n",
            "Epoch 34/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6482 - loss: 0.6668 - val_accuracy: 0.5682 - val_loss: 0.6868\n",
            "Epoch 35/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6270 - loss: 0.6506 - val_accuracy: 0.5682 - val_loss: 0.6876\n",
            "Epoch 36/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.6379 - val_accuracy: 0.5682 - val_loss: 0.6886\n",
            "Epoch 37/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6717 - loss: 0.6416 - val_accuracy: 0.5682 - val_loss: 0.6895\n",
            "Epoch 38/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - loss: 0.6757 - val_accuracy: 0.5682 - val_loss: 0.6902\n",
            "Epoch 39/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - loss: 0.6780 - val_accuracy: 0.5682 - val_loss: 0.6907\n",
            "Epoch 40/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6456 - loss: 0.6591 - val_accuracy: 0.5682 - val_loss: 0.6929\n",
            "Epoch 41/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6625 - loss: 0.6524 - val_accuracy: 0.5455 - val_loss: 0.6951\n",
            "Epoch 42/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6918 - loss: 0.6358 - val_accuracy: 0.5455 - val_loss: 0.6985\n",
            "Epoch 43/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6232 - loss: 0.6750 - val_accuracy: 0.5455 - val_loss: 0.6991\n",
            "Epoch 44/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6409 - loss: 0.6613 - val_accuracy: 0.5682 - val_loss: 0.7005\n",
            "Epoch 45/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6647 - loss: 0.6497 - val_accuracy: 0.5455 - val_loss: 0.7021\n",
            "Epoch 46/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6612 - loss: 0.6471 - val_accuracy: 0.5455 - val_loss: 0.7028\n",
            "Epoch 47/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6179 - loss: 0.6628 - val_accuracy: 0.5455 - val_loss: 0.7039\n",
            "Epoch 48/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6614 - loss: 0.6482 - val_accuracy: 0.5455 - val_loss: 0.7053\n",
            "Epoch 49/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6755 - loss: 0.6472 - val_accuracy: 0.5455 - val_loss: 0.7059\n",
            "Epoch 50/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7064 - loss: 0.6212 - val_accuracy: 0.5455 - val_loss: 0.7051\n",
            "Epoch 51/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6920 - loss: 0.6246 - val_accuracy: 0.5455 - val_loss: 0.7062\n",
            "Epoch 52/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6403 - loss: 0.6603 - val_accuracy: 0.5455 - val_loss: 0.7076\n",
            "Epoch 52: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "CPU times: user 8.8 s, sys: 354 ms, total: 9.15 s\n",
            "Wall time: 10.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_label = \"OP1_AVG\"\n",
        "# features = minh_val_features\n",
        "# target = minh_val_target\n",
        "# features = minh_train_features\n",
        "# target = minh_train_target\n",
        "\n",
        "features = minh_test_features\n",
        "target = minh_test_target\n",
        "num = len(features)\n",
        "features = features[:num]\n",
        "target = target[:num]\n",
        "dataset_temp = minh_dataset.loc[2700:]\n",
        "\n",
        "\n",
        "print(len(features))\n",
        "# loaded_model = tf.keras.models.load_model(f\"{model_save_pwd}/HDA_H_70A_40D.keras\")\n",
        "# predictions = loaded_model.predict(features)\n",
        "predictions = model_9.predict(features)\n",
        "\n",
        "# target_data = np.array(target).astype('float32')\n",
        "# target_data = [x[0] for x in target_data]\n",
        "correct = 0\n",
        "pred_up = 0\n",
        "pred_up_correct = 0\n",
        "pred_down = 0\n",
        "pred_down_correct = 0\n",
        "winnings = 0\n",
        "num_invested = 0\n",
        "winnings_correct = 0\n",
        "num_correct_dec = 0\n",
        "winnings_ideal = 0\n",
        "num_ideal = 0\n",
        "predicted_classes = [1 if x >= 0.5 else 0 for x in predictions]\n",
        "for prediction_class, target_val, raw_pred, (ind, row) in zip(predicted_classes, target, predictions, dataset_temp.iterrows()):\n",
        "  # prediction_class = np.argmax(prediction)\n",
        "  # prediction_class = random.randint(0, 1)\n",
        "  result = row[\"result\"]\n",
        "  ret = row[odd_label] - 1 if result == \"H\" else -1\n",
        "  if target_val == 0:\n",
        "    winnings_ideal += ret\n",
        "    num_ideal += 1\n",
        "    # print(f\"tv: {target_val}, ret: {ret}, winnings: {ev}\")\n",
        "    if target_val == prediction_class:\n",
        "      winnings_correct += ret\n",
        "      num_correct_dec += 1\n",
        "\n",
        "  if prediction_class == 0:\n",
        "    winnings += ret\n",
        "    num_invested += 1\n",
        "\n",
        "  print(f\"probability: {raw_pred}, pred: {prediction_class}, real: {target_val}, return: {ret}\")\n",
        "  if prediction_class == target_val:\n",
        "    correct += 1\n",
        "\n",
        "  if prediction_class == 1:\n",
        "    pred_up += 1\n",
        "    pred_up_correct += 1 if prediction_class == target_val else 0\n",
        "  else:\n",
        "    pred_down += 1\n",
        "    pred_down_correct += 1 if prediction_class == target_val else 0\n",
        "\n",
        "calculated_ideal_winnings = calculate_winnings(test_dataset_temp[test_dataset_temp[\"DIR1\"] == 0], odd_label, \"H\")\n",
        "\n",
        "get_dir_dataset_stats(minh_test, curr_label)\n",
        "print(f\"calculated ideal winnings: {format(calculated_ideal_winnings, '.3f')}\")\n",
        "print_percent_str(\"pred up accuracy\", pred_up_correct, pred_up)\n",
        "print_percent_str(\"pred down accuracy\", pred_down_correct, pred_down)\n",
        "print_percent_str(\"correct\", correct, num)\n",
        "print(\"\")\n",
        "print_percent_str(\"ideal ev\", winnings_ideal, num_ideal)\n",
        "print_percent_str(\"ideal ev calc\", calculated_ideal_winnings, len(test_dataset_temp[test_dataset_temp[\"DIR1\"] == 0]))\n",
        "print_percent_str(\"ev of only correct down preds\", winnings_correct, num_correct_dec)\n",
        "print_percent_str(\"ev of only downs\", winnings, num_invested)\n",
        "# print(f\"ev: {format(ev, '.3f')}, ev of only correct down preds: {format(ev_correct, '.3f')}\")\n",
        "# print(f\"up: {is_up/num}, {is_up}/{num}\")\n",
        "# confusion_matrix = tf.math.confusion_matrix(\n",
        "#     target,\n",
        "#     predicted_classes,\n",
        "#     num_classes=3,\n",
        "#     weights=None,\n",
        "#     dtype=tf.dtypes.int32,\n",
        "#     name=None\n",
        "# )\n",
        "# confusion_matrix\n",
        "plot_confusion_matrix(target, predicted_classes, [\"D\", \"U\"], \"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dIkqFqZQnmqk",
        "outputId": "a96aa65c-b562-4e15-a0f8-eb9e9eaedcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "probability: [0.655], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.517], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.544], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.606], pred: 1, real: 1.0, return: 2.738\n",
            "probability: [0.53], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.521], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.549], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.51], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.528], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.526], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.551], pred: 1, real: 1.0, return: 2.448\n",
            "probability: [0.], pred: 0, real: 0.0, return: 2.324\n",
            "probability: [0.522], pred: 1, real: 1.0, return: 3.877\n",
            "probability: [0.542], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.584], pred: 1, real: 1.0, return: 2.659\n",
            "probability: [0.487], pred: 0, real: 0.0, return: 3.933\n",
            "probability: [0.65], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.523], pred: 1, real: 0.0, return: 3.0540000000000003\n",
            "probability: [0.581], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.534], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.568], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.624], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.559], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.566], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.674], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.577], pred: 1, real: 1.0, return: 2.03\n",
            "probability: [0.56], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.557], pred: 1, real: 1.0, return: 3.58\n",
            "probability: [0.497], pred: 0, real: 0.0, return: 4.105\n",
            "probability: [0.58], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.612], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.636], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.], pred: 0, real: 0.0, return: 6.33\n",
            "probability: [0.552], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.57], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.547], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.544], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.569], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.552], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.568], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.565], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.545], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.487], pred: 0, real: 0.0, return: -1\n",
            "probability: [0.531], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.584], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.536], pred: 1, real: 0.0, return: 4.214\n",
            "probability: [0.558], pred: 1, real: 1.0, return: 3.652\n",
            "probability: [0.669], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.606], pred: 1, real: 1.0, return: 2.644\n",
            "probability: [0.529], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.588], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.549], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.574], pred: 1, real: 1.0, return: 5.882\n",
            "probability: [0.515], pred: 1, real: 0.0, return: 2.714\n",
            "probability: [0.551], pred: 1, real: 0.0, return: 3.7699999999999996\n",
            "probability: [0.532], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.582], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.554], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.535], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.652], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.55], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.519], pred: 1, real: 1.0, return: 3.362\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.567], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.487], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.662], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.547], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.541], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.546], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.543], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.565], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.515], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.542], pred: 1, real: 0.0, return: 2.705\n",
            "probability: [0.565], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.459], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.521], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.519], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.549], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.585], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.476], pred: 0, real: 1.0, return: 2.45\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.473], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.576], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "probability: [0.503], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.54], pred: 1, real: 1.0, return: 3.6050000000000004\n",
            "probability: [0.619], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.558], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.618], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.501], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.532], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.609], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.581], pred: 1, real: 1.0, return: 2.675\n",
            "probability: [0.548], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.558], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.522], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.582], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.528], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.529], pred: 1, real: 1.0, return: -1\n",
            "probability: [0.568], pred: 1, real: 0.0, return: -1\n",
            "probability: [0.], pred: 0, real: 1.0, return: -1\n",
            "U% : 74.038%, 77/104; D% : 25.962%, 27/104\n",
            "calculated ideal winnings: 15.149\n",
            "pred up accuracy: 75.000%      66.000/88\n",
            "pred down accuracy: 31.250%      5.000/16\n",
            "correct: 68.269%      71.000/104\n",
            "\n",
            "ideal ev: 56.107%      15.149/27\n",
            "ideal ev calc: 56.107%      15.149/27\n",
            "ev of only correct down preds: 313.840%      15.692/5\n",
            "ev of only downs: 50.887%      8.142/16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"HDA_H_59A_27D_56EV.keras\"\n",
        "model_path = f\"{model_save_pwd}/{model_name}\"\n",
        "model_9.save(f\"{model_path}\")\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxw1zKL_CNqp",
        "outputId": "d3c03ec8-c7bf-4f3c-dfb4-91da218f5898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/JSIP Final Project/models/HDA_H_59A_27D_56EV.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 3\n",
        "ev = calculate_winnings(test_dataset_temp[:num], odd_label, \"H\")\n",
        "print(ev)\n",
        "test_dataset_temp[:num]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "fo3ws_6S_RHY",
        "outputId": "cf1f4e1d-14c5-427f-9af3-dcc5c69b9866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games         date     season result  OP1_AVG  OPX_AVG  OP2_AVG  \\\n",
              "2702      4  10 Sep 2022  2022/2023      A    3.367    3.306    2.180   \n",
              "2703      4  10 Sep 2022  2022/2023      A    7.923    4.939    1.407   \n",
              "2706      4  11 Sep 2022  2022/2023      A    3.943    3.391    1.962   \n",
              "\n",
              "      CP1_AVG  CPX_AVG  CP2_AVG  DIR1  DIRX  DIR2  Alaves  Almeria  \\\n",
              "2702    2.559    3.184    2.947     0     0     1       0        0   \n",
              "2703    9.390    5.291    1.337     1     1     0       0        0   \n",
              "2706    4.674    3.603    1.805     1     1     0       0        0   \n",
              "\n",
              "      Ath Bilbao  Atl. Madrid  Barcelona  Betis  Cadiz CF  Celta Vigo  \\\n",
              "2702           0            0          0      0         0           0   \n",
              "2703           0            0          1      0         2           0   \n",
              "2706           1            0          0      0         0           0   \n",
              "\n",
              "      Dep. La Coruna  Eibar  Elche  Espanyol  Getafe  Gijon  Girona  \\\n",
              "2702               0      0      0         2       0      0       0   \n",
              "2703               0      0      0         0       0      0       0   \n",
              "2706               0      0      2         0       0      0       0   \n",
              "\n",
              "      Granada CF  Huesca  Las Palmas  Leganes  Levante  Malaga  Mallorca  \\\n",
              "2702           0       0           0        0        0       0         0   \n",
              "2703           0       0           0        0        0       0         0   \n",
              "2706           0       0           0        0        0       0         0   \n",
              "\n",
              "      Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  Sevilla  Valencia  \\\n",
              "2702        0               0            0              0        1         0   \n",
              "2703        0               0            0              0        0         0   \n",
              "2706        0               0            0              0        0         0   \n",
              "\n",
              "      Valladolid  Villarreal  OP1_RATE  OPX_RATE  OP2_RATE  OP_MAX_ODD  \\\n",
              "2702           0           0  0.380323  0.373433  0.246244           1   \n",
              "2703           0           0  0.555260  0.346135  0.098605           1   \n",
              "2706           0           0  0.424161  0.364781  0.211059           1   \n",
              "\n",
              "      OP_MID_ODD OP_MIN_ODD  HOME_POWER  \n",
              "2702           0          A         3.0  \n",
              "2703           0          A         0.0  \n",
              "2706           0          A         0.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-713d73fd-338e-48ac-a55c-6eeb0bc0b97d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>date</th>\n",
              "      <th>season</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>DIR1</th>\n",
              "      <th>DIRX</th>\n",
              "      <th>DIR2</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>4</td>\n",
              "      <td>10 Sep 2022</td>\n",
              "      <td>2022/2023</td>\n",
              "      <td>A</td>\n",
              "      <td>3.367</td>\n",
              "      <td>3.306</td>\n",
              "      <td>2.180</td>\n",
              "      <td>2.559</td>\n",
              "      <td>3.184</td>\n",
              "      <td>2.947</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.380323</td>\n",
              "      <td>0.373433</td>\n",
              "      <td>0.246244</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703</th>\n",
              "      <td>4</td>\n",
              "      <td>10 Sep 2022</td>\n",
              "      <td>2022/2023</td>\n",
              "      <td>A</td>\n",
              "      <td>7.923</td>\n",
              "      <td>4.939</td>\n",
              "      <td>1.407</td>\n",
              "      <td>9.390</td>\n",
              "      <td>5.291</td>\n",
              "      <td>1.337</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.555260</td>\n",
              "      <td>0.346135</td>\n",
              "      <td>0.098605</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2706</th>\n",
              "      <td>4</td>\n",
              "      <td>11 Sep 2022</td>\n",
              "      <td>2022/2023</td>\n",
              "      <td>A</td>\n",
              "      <td>3.943</td>\n",
              "      <td>3.391</td>\n",
              "      <td>1.962</td>\n",
              "      <td>4.674</td>\n",
              "      <td>3.603</td>\n",
              "      <td>1.805</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.424161</td>\n",
              "      <td>0.364781</td>\n",
              "      <td>0.211059</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-713d73fd-338e-48ac-a55c-6eeb0bc0b97d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-713d73fd-338e-48ac-a55c-6eeb0bc0b97d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-713d73fd-338e-48ac-a55c-6eeb0bc0b97d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8730a8a9-713f-4c28-98ba-8493a350da91\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8730a8a9-713f-4c28-98ba-8493a350da91')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8730a8a9-713f-4c28-98ba-8493a350da91 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 507
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# random forest increase/decrease"
      ],
      "metadata": {
        "id": "cm0Wy8sJzthn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_decision_forests as tfdf"
      ],
      "metadata": {
        "id": "A5Se-MRl5qr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_with_result = get_dataset_with_season()"
      ],
      "metadata": {
        "id": "Vu-06ozJ0IGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfdc_dataset = get_stat_percent_database(dataset_with_result.copy())\n",
        "# rfdc_dataset = get_diff_database(rfdc_dataset)\n",
        "rfdc_dataset = get_odds_percent_database(rfdc_dataset)\n",
        "rfdc_dataset = get_odds_percent_database_closing(rfdc_dataset)\n",
        "# rfdc_dataset = get_dir_database(rfdc_dataset)\n",
        "# rfdc_dataset[\"MAX_DIFF\"] = get_max_diff(rfdc_dataset)\n",
        "rfdc_dataset = get_odds_rankings(rfdc_dataset, True)\n",
        "# rfdc_dataset = get_odds_rankings(rfdc_dataset, False)\n",
        "rfdc_dataset = rfdc_dataset.drop(index=rfdc_dataset[rfdc_dataset.games < 4].index)\n",
        "rfdc_dataset[\"OP_SUM\"] = rfdc_dataset[\"OP1_AVG\"] + rfdc_dataset[\"OPX_AVG\"] + rfdc_dataset[\"OP2_AVG\"]\n",
        "# rfdc_dataset[\"CP_SUM\"] = rfdc_dataset[\"CP1_AVG\"] + rfdc_dataset[\"CPX_AVG\"] + rfdc_dataset[\"CP2_AVG\"]\n",
        "rfdc_dataset[\"HOME_POWER\"] = (rfdc_dataset[\"home_wins_rate\"] * 2 + rfdc_dataset[\"home_tie_rate\"]) / (rfdc_dataset[\"away_wins_rate\"] * 2 + rfdc_dataset[\"away_tie_rate\"])\n",
        "rfdc_dataset[\"HOME_POWER\"] = [10 if x > 10 else x for x in rfdc_dataset[\"HOME_POWER\"]]\n",
        "rfdc_dataset = rfdc_dataset.drop(columns=[\"CP1_RATE\", \"CPX_RATE\", \"CP2_RATE\", \"home_team\", \"away_team\"])\n",
        "rfdc_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "s4L48lemz5yp",
        "outputId": "59bc3043-a5b6-46f8-8f45-19dddc8b2860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games         date     season result  OP1_AVG  OPX_AVG  OP2_AVG  \\\n",
              "40        4  22 Sep 2015  2015/2016      A    2.528    3.115    2.900   \n",
              "41        4  22 Sep 2015  2015/2016      H    3.329    3.263    2.187   \n",
              "42        4  22 Sep 2015  2015/2016      H    1.244    5.543   13.128   \n",
              "43        4  23 Sep 2015  2015/2016      H    2.113    3.384    3.412   \n",
              "44        4  23 Sep 2015  2015/2016      D    2.382    3.094    3.138   \n",
              "...     ...          ...        ...    ...      ...      ...      ...   \n",
              "3415     37  25 May 2024  2023/2024      D    1.314    5.714    7.809   \n",
              "3416     37  26 May 2024  2023/2024      A    3.341    3.939    1.954   \n",
              "3417     37  26 May 2024  2023/2024      A    2.250    3.304    3.124   \n",
              "3418     37  26 May 2024  2023/2024      D    2.313    3.401    2.947   \n",
              "3419     37  26 May 2024  2023/2024      D    1.861    3.684    3.929   \n",
              "\n",
              "      CP1_AVG  CPX_AVG  CP2_AVG  ...  away_tie_rate  away_loss_rate  OP1_RATE  \\\n",
              "40      2.539    3.125    2.978  ...       0.500000        0.500000  0.295915   \n",
              "41      3.115    3.299    2.343  ...       0.750000        0.000000  0.379200   \n",
              "42      1.331    4.873   11.233  ...       0.000000        0.750000  0.062465   \n",
              "43      2.142    3.415    3.433  ...       0.500000        0.250000  0.237176   \n",
              "44      2.367    3.020    3.368  ...       0.250000        0.250000  0.276527   \n",
              "...       ...      ...      ...  ...            ...             ...       ...   \n",
              "3415    1.219    7.152   11.637  ...       0.378378        0.243243  0.088562   \n",
              "3416    4.479    4.244    1.692  ...       0.189189        0.135135  0.361815   \n",
              "3417    2.330    3.162    3.284  ...       0.432432        0.378378  0.259276   \n",
              "3418    2.342    3.450    3.020  ...       0.243243        0.432432  0.267059   \n",
              "3419    1.932    3.670    3.847  ...       0.243243        0.405405  0.196432   \n",
              "\n",
              "      OPX_RATE  OP2_RATE  OP_MAX_ODD  OP_MID_ODD  OP_MIN_ODD  OP_SUM  \\\n",
              "40    0.364626  0.339459           D           A           H   8.543   \n",
              "41    0.371682  0.249117           H           D           A   8.779   \n",
              "42    0.278333  0.659202           A           D           H  19.915   \n",
              "43    0.379841  0.382983           A           D           H   8.909   \n",
              "44    0.359183  0.364291           A           D           H   8.614   \n",
              "...        ...       ...         ...         ...         ...     ...   \n",
              "3415  0.385118  0.526319           A           D           H  14.837   \n",
              "3416  0.426576  0.211609           D           H           A   9.234   \n",
              "3417  0.380733  0.359991           D           A           H   8.678   \n",
              "3418  0.392680  0.340261           D           A           H   8.661   \n",
              "3419  0.388854  0.414714           A           D           H   9.474   \n",
              "\n",
              "     HOME_POWER  \n",
              "40     1.000000  \n",
              "41     0.800000  \n",
              "42     3.000000  \n",
              "43     0.750000  \n",
              "44     0.400000  \n",
              "...         ...  \n",
              "3415   1.547619  \n",
              "3416   0.543860  \n",
              "3417   1.100000  \n",
              "3418   0.878788  \n",
              "3419   0.857143  \n",
              "\n",
              "[3060 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5921b812-ecf3-4467-ac56-de171c217bf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>date</th>\n",
              "      <th>season</th>\n",
              "      <th>result</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CP1_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>CP2_AVG</th>\n",
              "      <th>...</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>4</td>\n",
              "      <td>22 Sep 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>A</td>\n",
              "      <td>2.528</td>\n",
              "      <td>3.115</td>\n",
              "      <td>2.900</td>\n",
              "      <td>2.539</td>\n",
              "      <td>3.125</td>\n",
              "      <td>2.978</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.295915</td>\n",
              "      <td>0.364626</td>\n",
              "      <td>0.339459</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.543</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4</td>\n",
              "      <td>22 Sep 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>3.329</td>\n",
              "      <td>3.263</td>\n",
              "      <td>2.187</td>\n",
              "      <td>3.115</td>\n",
              "      <td>3.299</td>\n",
              "      <td>2.343</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379200</td>\n",
              "      <td>0.371682</td>\n",
              "      <td>0.249117</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>8.779</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4</td>\n",
              "      <td>22 Sep 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>1.244</td>\n",
              "      <td>5.543</td>\n",
              "      <td>13.128</td>\n",
              "      <td>1.331</td>\n",
              "      <td>4.873</td>\n",
              "      <td>11.233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.062465</td>\n",
              "      <td>0.278333</td>\n",
              "      <td>0.659202</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>19.915</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4</td>\n",
              "      <td>23 Sep 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>H</td>\n",
              "      <td>2.113</td>\n",
              "      <td>3.384</td>\n",
              "      <td>3.412</td>\n",
              "      <td>2.142</td>\n",
              "      <td>3.415</td>\n",
              "      <td>3.433</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.237176</td>\n",
              "      <td>0.379841</td>\n",
              "      <td>0.382983</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>8.909</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4</td>\n",
              "      <td>23 Sep 2015</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>D</td>\n",
              "      <td>2.382</td>\n",
              "      <td>3.094</td>\n",
              "      <td>3.138</td>\n",
              "      <td>2.367</td>\n",
              "      <td>3.020</td>\n",
              "      <td>3.368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.276527</td>\n",
              "      <td>0.359183</td>\n",
              "      <td>0.364291</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>8.614</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>37</td>\n",
              "      <td>25 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>D</td>\n",
              "      <td>1.314</td>\n",
              "      <td>5.714</td>\n",
              "      <td>7.809</td>\n",
              "      <td>1.219</td>\n",
              "      <td>7.152</td>\n",
              "      <td>11.637</td>\n",
              "      <td>...</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.385118</td>\n",
              "      <td>0.526319</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>14.837</td>\n",
              "      <td>1.547619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>A</td>\n",
              "      <td>3.341</td>\n",
              "      <td>3.939</td>\n",
              "      <td>1.954</td>\n",
              "      <td>4.479</td>\n",
              "      <td>4.244</td>\n",
              "      <td>1.692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.361815</td>\n",
              "      <td>0.426576</td>\n",
              "      <td>0.211609</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.234</td>\n",
              "      <td>0.543860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>A</td>\n",
              "      <td>2.250</td>\n",
              "      <td>3.304</td>\n",
              "      <td>3.124</td>\n",
              "      <td>2.330</td>\n",
              "      <td>3.162</td>\n",
              "      <td>3.284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.259276</td>\n",
              "      <td>0.380733</td>\n",
              "      <td>0.359991</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.678</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>D</td>\n",
              "      <td>2.313</td>\n",
              "      <td>3.401</td>\n",
              "      <td>2.947</td>\n",
              "      <td>2.342</td>\n",
              "      <td>3.450</td>\n",
              "      <td>3.020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.392680</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>8.661</td>\n",
              "      <td>0.878788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3419</th>\n",
              "      <td>37</td>\n",
              "      <td>26 May 2024</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>D</td>\n",
              "      <td>1.861</td>\n",
              "      <td>3.684</td>\n",
              "      <td>3.929</td>\n",
              "      <td>1.932</td>\n",
              "      <td>3.670</td>\n",
              "      <td>3.847</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.196432</td>\n",
              "      <td>0.388854</td>\n",
              "      <td>0.414714</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>9.474</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3060 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5921b812-ecf3-4467-ac56-de171c217bf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5921b812-ecf3-4467-ac56-de171c217bf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5921b812-ecf3-4467-ac56-de171c217bf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9bf19754-d5c9-4dac-b262-f95376fcb815\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bf19754-d5c9-4dac-b262-f95376fcb815')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9bf19754-d5c9-4dac-b262-f95376fcb815 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3219651e-e394-4c14-8339-7bb0099cde78\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rfdc_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3219651e-e394-4c14-8339-7bb0099cde78 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rfdc_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rfdc_dataset"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 'combo': ('D', 'H', 'A'), 'symbol': 'D',\n",
        "max_symbol = \"D\"\n",
        "mid_symbol = \"H\"\n",
        "min_symbol = \"A\"\n",
        "symbol = \"D\"\n",
        "label = \"CPX_AVG\"\n",
        "combo_ds = rfdc_dataset[(rfdc_dataset[\"OP_MAX_ODD\"] == max_symbol) & (rfdc_dataset[\"OP_MID_ODD\"] == mid_symbol) & (rfdc_dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "combo_ds = combo_ds.drop(columns=[\"CP1_AVG\", \"CP2_AVG\", \"date\"])\n",
        "combo_test = combo_ds[(combo_ds[\"season\"] == \"2023/2024\") | (combo_ds[\"season\"] == \"2022/2023\")]\n",
        "combo_test = combo_test.drop(columns=[\"result\", \"season\"])\n",
        "# combo_test = combo_test.drop(index=combo_test[(combo_test[\"home_team\"] == \"Almeria\") | (combo_test[\"away_team\"] == \"Almeria\")].index)\n",
        "combo_train = combo_ds.drop(index=combo_test.index)\n",
        "combo_train = combo_train.drop(columns=[\"result\", \"season\"])\n",
        "combo_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "HAc_B0I82ctu",
        "outputId": "3b00fc96-8b31-41e6-c7e5-e234431cc4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  OP1_AVG  OPX_AVG  OP2_AVG  CPX_AVG  home_wins_rate  \\\n",
              "53        5    3.109    3.178    2.357    3.081        0.800000   \n",
              "66        6    2.787    3.280    2.515    3.257        0.666667   \n",
              "78        7    2.763    3.055    2.670    3.107        0.428571   \n",
              "92        9    2.816    3.229    2.513    3.285        0.222222   \n",
              "99        9    2.828    3.207    2.519    3.303        0.333333   \n",
              "...     ...      ...      ...      ...      ...             ...   \n",
              "2619     33    2.816    3.120    2.584    3.095        0.242424   \n",
              "2620     34    3.177    3.447    2.183    3.482        0.147059   \n",
              "2622     34    3.511    3.609    1.991    3.683        0.500000   \n",
              "2630     35    2.921    3.286    2.453    3.361        0.285714   \n",
              "2656     37    3.499    3.526    2.177    3.238        0.324324   \n",
              "\n",
              "      home_tie_rate  home_loss_rate  away_wins_rate  away_tie_rate  \\\n",
              "53         0.200000        0.000000        0.800000       0.000000   \n",
              "66         0.000000        0.333333        0.666667       0.333333   \n",
              "78         0.428571        0.142857        0.285714       0.142857   \n",
              "92         0.333333        0.444444        0.555556       0.333333   \n",
              "99         0.333333        0.333333        0.333333       0.222222   \n",
              "...             ...             ...             ...            ...   \n",
              "2619       0.333333        0.424242        0.515152       0.181818   \n",
              "2620       0.323529        0.529412        0.441176       0.323529   \n",
              "2622       0.205882        0.294118        0.558824       0.264706   \n",
              "2630       0.400000        0.314286        0.485714       0.200000   \n",
              "2656       0.297297        0.378378        0.243243       0.243243   \n",
              "\n",
              "      away_loss_rate  OP1_RATE  OPX_RATE  OP2_RATE OP_MAX_ODD OP_MID_ODD  \\\n",
              "53          0.200000  0.359671  0.367654  0.272675          D          H   \n",
              "66          0.000000  0.324749  0.382195  0.293055          D          H   \n",
              "78          0.571429  0.325518  0.359920  0.314562          D          H   \n",
              "92          0.111111  0.329049  0.377308  0.293643          D          H   \n",
              "99          0.444444  0.330606  0.374912  0.294482          D          H   \n",
              "...              ...       ...       ...       ...        ...        ...   \n",
              "2619        0.303030  0.330516  0.366197  0.303286          D          H   \n",
              "2620        0.235294  0.360736  0.391393  0.247871          D          H   \n",
              "2622        0.176471  0.385358  0.396115  0.218527          D          H   \n",
              "2630        0.314286  0.337298  0.379446  0.283256          D          H   \n",
              "2656        0.513514  0.380243  0.383178  0.236579          D          H   \n",
              "\n",
              "     OP_MIN_ODD  OP_SUM  HOME_POWER  \n",
              "53            A   8.644    1.125000  \n",
              "66            A   8.582    0.800000  \n",
              "78            A   8.488    1.800000  \n",
              "92            A   8.558    0.538462  \n",
              "99            A   8.554    1.125000  \n",
              "...         ...     ...         ...  \n",
              "2619          A   8.520    0.675000  \n",
              "2620          A   8.807    0.512195  \n",
              "2622          A   9.111    0.872340  \n",
              "2630          A   8.660    0.829268  \n",
              "2656          A   9.202    1.296296  \n",
              "\n",
              "[254 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d65262a5-7e1e-4b26-9336-e92eeb950dd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>CPX_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>OP_MAX_ODD</th>\n",
              "      <th>OP_MID_ODD</th>\n",
              "      <th>OP_MIN_ODD</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>HOME_POWER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>5</td>\n",
              "      <td>3.109</td>\n",
              "      <td>3.178</td>\n",
              "      <td>2.357</td>\n",
              "      <td>3.081</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.359671</td>\n",
              "      <td>0.367654</td>\n",
              "      <td>0.272675</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.644</td>\n",
              "      <td>1.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>6</td>\n",
              "      <td>2.787</td>\n",
              "      <td>3.280</td>\n",
              "      <td>2.515</td>\n",
              "      <td>3.257</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.324749</td>\n",
              "      <td>0.382195</td>\n",
              "      <td>0.293055</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.582</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>7</td>\n",
              "      <td>2.763</td>\n",
              "      <td>3.055</td>\n",
              "      <td>2.670</td>\n",
              "      <td>3.107</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.325518</td>\n",
              "      <td>0.359920</td>\n",
              "      <td>0.314562</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.488</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>9</td>\n",
              "      <td>2.816</td>\n",
              "      <td>3.229</td>\n",
              "      <td>2.513</td>\n",
              "      <td>3.285</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.329049</td>\n",
              "      <td>0.377308</td>\n",
              "      <td>0.293643</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.558</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>9</td>\n",
              "      <td>2.828</td>\n",
              "      <td>3.207</td>\n",
              "      <td>2.519</td>\n",
              "      <td>3.303</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.330606</td>\n",
              "      <td>0.374912</td>\n",
              "      <td>0.294482</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.554</td>\n",
              "      <td>1.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>33</td>\n",
              "      <td>2.816</td>\n",
              "      <td>3.120</td>\n",
              "      <td>2.584</td>\n",
              "      <td>3.095</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.330516</td>\n",
              "      <td>0.366197</td>\n",
              "      <td>0.303286</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.520</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2620</th>\n",
              "      <td>34</td>\n",
              "      <td>3.177</td>\n",
              "      <td>3.447</td>\n",
              "      <td>2.183</td>\n",
              "      <td>3.482</td>\n",
              "      <td>0.147059</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.360736</td>\n",
              "      <td>0.391393</td>\n",
              "      <td>0.247871</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.807</td>\n",
              "      <td>0.512195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2622</th>\n",
              "      <td>34</td>\n",
              "      <td>3.511</td>\n",
              "      <td>3.609</td>\n",
              "      <td>1.991</td>\n",
              "      <td>3.683</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.385358</td>\n",
              "      <td>0.396115</td>\n",
              "      <td>0.218527</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.111</td>\n",
              "      <td>0.872340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2630</th>\n",
              "      <td>35</td>\n",
              "      <td>2.921</td>\n",
              "      <td>3.286</td>\n",
              "      <td>2.453</td>\n",
              "      <td>3.361</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.337298</td>\n",
              "      <td>0.379446</td>\n",
              "      <td>0.283256</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>8.660</td>\n",
              "      <td>0.829268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>37</td>\n",
              "      <td>3.499</td>\n",
              "      <td>3.526</td>\n",
              "      <td>2.177</td>\n",
              "      <td>3.238</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>0.380243</td>\n",
              "      <td>0.383178</td>\n",
              "      <td>0.236579</td>\n",
              "      <td>D</td>\n",
              "      <td>H</td>\n",
              "      <td>A</td>\n",
              "      <td>9.202</td>\n",
              "      <td>1.296296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d65262a5-7e1e-4b26-9336-e92eeb950dd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d65262a5-7e1e-4b26-9336-e92eeb950dd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d65262a5-7e1e-4b26-9336-e92eeb950dd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43b83184-3876-48cd-8f19-fdaa57e65ed0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43b83184-3876-48cd-8f19-fdaa57e65ed0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43b83184-3876-48cd-8f19-fdaa57e65ed0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c47c0cd6-1122-4ead-8088-21512807ee3d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combo_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c47c0cd6-1122-4ead-8088-21512807ee3d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combo_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combo_train",
              "summary": "{\n  \"name\": \"combo_train\",\n  \"rows\": 254,\n  \"fields\": [\n    {\n      \"column\": \"games\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 4,\n        \"max\": 37,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          28,\n          33,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP1_AVG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22850789054746273,\n        \"min\": 2.616,\n        \"max\": 3.826,\n        \"num_unique_values\": 212,\n        \"samples\": [\n          2.766,\n          3.002,\n          3.127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OPX_AVG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19019739099093633,\n        \"min\": 2.865,\n        \"max\": 3.943,\n        \"num_unique_values\": 212,\n        \"samples\": [\n          3.301,\n          3.211,\n          3.441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP2_AVG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18729626882517458,\n        \"min\": 1.841,\n        \"max\": 2.8,\n        \"num_unique_values\": 210,\n        \"samples\": [\n          2.615,\n          2.504,\n          2.174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPX_AVG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28351377526825866,\n        \"min\": 2.78,\n        \"max\": 4.963,\n        \"num_unique_values\": 219,\n        \"samples\": [\n          3.785,\n          3.475,\n          3.683\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"home_wins_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1422235870549199,\n        \"min\": 0.0,\n        \"max\": 0.8,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          0.38235294117647056,\n          0.3333333333333333,\n          0.15384615384615385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"home_tie_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1192675889612895,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          0.42105263157894735,\n          0.5517241379310345,\n          0.4782608695652174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"home_loss_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16641545833132046,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          1.0,\n          0.9,\n          0.18181818181818182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"away_wins_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14793420595383183,\n        \"min\": 0.07692307692307693,\n        \"max\": 1.0,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          0.20588235294117646,\n          0.75,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"away_tie_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12809367736147878,\n        \"min\": 0.0,\n        \"max\": 0.7272727272727273,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          0.43243243243243246,\n          0.3157894736842105,\n          0.2727272727272727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"away_loss_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14075688701283517,\n        \"min\": 0.0,\n        \"max\": 0.8,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          0.29411764705882354,\n          0.4444444444444444,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP1_RATE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020588797610707022,\n        \"min\": 0.30309350017379216,\n        \"max\": 0.39812695109261187,\n        \"num_unique_values\": 254,\n        \"samples\": [\n          0.3269789608276183,\n          0.3121717820049014,\n          0.33233325640433875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OPX_RATE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015595692894159211,\n        \"min\": 0.3395354349371889,\n        \"max\": 0.4360465116279069,\n        \"num_unique_values\": 254,\n        \"samples\": [\n          0.3804486806927816,\n          0.38440891585949355,\n          0.3835679667666743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP2_RATE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026272266355752825,\n        \"min\": 0.19157127991675338,\n        \"max\": 0.3298774740810556,\n        \"num_unique_values\": 254,\n        \"samples\": [\n          0.2925723584796001,\n          0.30341930213560514,\n          0.2840987768289869\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP_MAX_ODD\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP_MID_ODD\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"H\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP_MIN_ODD\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OP_SUM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1834795464198572,\n        \"min\": 8.438,\n        \"max\": 9.61,\n        \"num_unique_values\": 209,\n        \"samples\": [\n          8.690000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HOME_POWER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2739612461283742,\n        \"min\": 0.0,\n        \"max\": 2.5,\n        \"num_unique_values\": 192,\n        \"samples\": [\n          0.8888888888888888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_1 = combo_train.sample(frac=.8)\n",
        "train_2 = combo_train.drop(index=train_1.index)"
      ],
      "metadata": {
        "id": "54aUiBGg-Y-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_data = tfdf.keras.pd_dataframe_to_tf_dataset(train_1, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "tf_train_data\n",
        "tf_test_data = tfdf.keras.pd_dataframe_to_tf_dataset(train_2, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "tf_test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqWNa5s8z4MN",
        "outputId": "1fcf530e-2a6f-4580-f7cb-db4fc47d2e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'games': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'OP1_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OPX_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP2_AVG': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'home_wins_rate': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'home_tie_rate': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'home_loss_rate': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'away_wins_rate': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'away_tie_rate': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'away_loss_rate': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP1_RATE': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OPX_RATE': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP2_RATE': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'OP_MAX_ODD': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'OP_MID_ODD': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'OP_MIN_ODD': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'OP_SUM': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'HOME_POWER': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}, TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tuner = tfdf.tuner.RandomSearch(num_trials=2)\n",
        "\n",
        "model_10 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    max_depth=8,\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    categorical_algorithm=\"RANDOM\",\n",
        "    task=tfdf.keras.Task.REGRESSION,\n",
        "    )\n",
        "model_10.compile(metrics=[\"mse\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyMgbLoGz6QA",
        "outputId": "f04b230b-059d-486f-9c49-f9881f3afb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpk6s4xoyc as temporary training directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.fit(tf_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFMfSdu0z98N",
        "outputId": "8e8c1e67-3247-4542-88b4-b9ebc2217bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading training dataset...\n",
            "Training dataset read in 0:00:01.346309. Found 203 examples.\n",
            "Training model...\n",
            "Model trained in 0:00:01.677945\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7e532e67cac0>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sokUXfi0Bgi",
        "outputId": "2bfa822f-a852-4e5f-821f-ebe989e49650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"gradient_boosted_trees_model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"GRADIENT_BOOSTED_TREES\"\n",
            "Task: REGRESSION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (18):\n",
            "\tHOME_POWER\n",
            "\tOP1_AVG\n",
            "\tOP1_RATE\n",
            "\tOP2_AVG\n",
            "\tOP2_RATE\n",
            "\tOPX_AVG\n",
            "\tOPX_RATE\n",
            "\tOP_MAX_ODD\n",
            "\tOP_MID_ODD\n",
            "\tOP_MIN_ODD\n",
            "\tOP_SUM\n",
            "\taway_loss_rate\n",
            "\taway_tie_rate\n",
            "\taway_wins_rate\n",
            "\tgames\n",
            "\thome_loss_rate\n",
            "\thome_tie_rate\n",
            "\thome_wins_rate\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1.        \"OPX_AVG\"  0.412890 ################\n",
            "    2.       \"OP1_RATE\"  0.248664 ######\n",
            "    3.       \"OP2_RATE\"  0.219206 ####\n",
            "    4. \"away_loss_rate\"  0.204078 ###\n",
            "    5.        \"OP1_AVG\"  0.191518 ##\n",
            "    6.     \"HOME_POWER\"  0.179194 #\n",
            "    7.        \"OP2_AVG\"  0.166327 #\n",
            "    8.         \"OP_SUM\"  0.157566 \n",
            "    9.       \"OPX_RATE\"  0.155666 \n",
            "   10.  \"away_tie_rate\"  0.150178 \n",
            "   11. \"away_wins_rate\"  0.149954 \n",
            "   12.  \"home_tie_rate\"  0.146621 \n",
            "   13.          \"games\"  0.146417 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1.       \"OP1_RATE\"  3.000000 ################\n",
            "    2. \"away_loss_rate\"  3.000000 ################\n",
            "    3.       \"OP2_RATE\"  2.000000 ########\n",
            "    4.        \"OPX_AVG\"  2.000000 ########\n",
            "    5.        \"OP1_AVG\"  1.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1.        \"OPX_AVG\" 58.000000 ################\n",
            "    2.       \"OP1_RATE\" 37.000000 ##########\n",
            "    3.        \"OP1_AVG\" 36.000000 #########\n",
            "    4.     \"HOME_POWER\" 35.000000 #########\n",
            "    5.        \"OP2_AVG\" 28.000000 #######\n",
            "    6.       \"OP2_RATE\" 25.000000 ######\n",
            "    7.         \"OP_SUM\" 15.000000 ###\n",
            "    8.       \"OPX_RATE\" 14.000000 ###\n",
            "    9. \"away_loss_rate\" 12.000000 ###\n",
            "   10. \"away_wins_rate\"  8.000000 #\n",
            "   11.  \"away_tie_rate\"  7.000000 #\n",
            "   12.          \"games\"  1.000000 \n",
            "   13.  \"home_tie_rate\"  1.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1.        \"OPX_AVG\" 22.335563 ################\n",
            "    2.       \"OP1_RATE\" 13.693348 #########\n",
            "    3.       \"OP2_RATE\" 12.677036 #########\n",
            "    4.        \"OP1_AVG\"  8.134587 #####\n",
            "    5. \"away_loss_rate\"  6.301670 ####\n",
            "    6.     \"HOME_POWER\"  2.107962 #\n",
            "    7.        \"OP2_AVG\"  1.172922 \n",
            "    8.       \"OPX_RATE\"  1.081010 \n",
            "    9.         \"OP_SUM\"  0.931988 \n",
            "   10. \"away_wins_rate\"  0.355476 \n",
            "   11.  \"away_tie_rate\"  0.277001 \n",
            "   12.  \"home_tie_rate\"  0.070272 \n",
            "   13.          \"games\"  0.030173 \n",
            "\n",
            "\n",
            "\n",
            "Loss: SQUARED_ERROR\n",
            "Validation loss value: 0.143988\n",
            "Number of trees per iteration: 1\n",
            "Node format: NOT_SET\n",
            "Number of trees: 11\n",
            "Total number of nodes: 565\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 11 Average: 51.3636 StdDev: 5.10388\n",
            "Min: 41 Max: 57 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 41, 42) 1   9.09%   9.09% ###\n",
            "[ 42, 43) 0   0.00%   9.09%\n",
            "[ 43, 44) 1   9.09%  18.18% ###\n",
            "[ 44, 45) 0   0.00%  18.18%\n",
            "[ 45, 46) 0   0.00%  18.18%\n",
            "[ 46, 47) 0   0.00%  18.18%\n",
            "[ 47, 48) 1   9.09%  27.27% ###\n",
            "[ 48, 49) 0   0.00%  27.27%\n",
            "[ 49, 50) 0   0.00%  27.27%\n",
            "[ 50, 51) 0   0.00%  27.27%\n",
            "[ 51, 52) 1   9.09%  36.36% ###\n",
            "[ 52, 53) 0   0.00%  36.36%\n",
            "[ 53, 54) 2  18.18%  54.55% #####\n",
            "[ 54, 55) 0   0.00%  54.55%\n",
            "[ 55, 56) 4  36.36%  90.91% ##########\n",
            "[ 56, 57) 0   0.00%  90.91%\n",
            "[ 57, 57] 1   9.09% 100.00% ###\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 288 Average: 5.82986 StdDev: 1.64218\n",
            "Min: 1 Max: 8 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2)  5   1.74%   1.74% #\n",
            "[ 2, 3)  6   2.08%   3.82% #\n",
            "[ 3, 4)  8   2.78%   6.60% #\n",
            "[ 4, 5) 46  15.97%  22.57% ######\n",
            "[ 5, 6) 44  15.28%  37.85% ######\n",
            "[ 6, 7) 71  24.65%  62.50% ##########\n",
            "[ 7, 8) 56  19.44%  81.94% ########\n",
            "[ 8, 8] 52  18.06% 100.00% #######\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 288 Average: 0 StdDev: 0\n",
            "Min: 0 Max: 0 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 0, 0] 288 100.00% 100.00% ##########\n",
            "\n",
            "Attribute in nodes:\n",
            "\t58 : OPX_AVG [NUMERICAL]\n",
            "\t37 : OP1_RATE [NUMERICAL]\n",
            "\t36 : OP1_AVG [NUMERICAL]\n",
            "\t35 : HOME_POWER [NUMERICAL]\n",
            "\t28 : OP2_AVG [NUMERICAL]\n",
            "\t25 : OP2_RATE [NUMERICAL]\n",
            "\t15 : OP_SUM [NUMERICAL]\n",
            "\t14 : OPX_RATE [NUMERICAL]\n",
            "\t12 : away_loss_rate [NUMERICAL]\n",
            "\t8 : away_wins_rate [NUMERICAL]\n",
            "\t7 : away_tie_rate [NUMERICAL]\n",
            "\t1 : home_tie_rate [NUMERICAL]\n",
            "\t1 : games [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t3 : away_loss_rate [NUMERICAL]\n",
            "\t3 : OP1_RATE [NUMERICAL]\n",
            "\t2 : OPX_AVG [NUMERICAL]\n",
            "\t2 : OP2_RATE [NUMERICAL]\n",
            "\t1 : OP1_AVG [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t12 : OPX_AVG [NUMERICAL]\n",
            "\t6 : OP2_RATE [NUMERICAL]\n",
            "\t5 : OP1_RATE [NUMERICAL]\n",
            "\t4 : away_loss_rate [NUMERICAL]\n",
            "\t1 : OP1_AVG [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t25 : OPX_AVG [NUMERICAL]\n",
            "\t9 : OP2_RATE [NUMERICAL]\n",
            "\t9 : OP1_RATE [NUMERICAL]\n",
            "\t4 : away_loss_rate [NUMERICAL]\n",
            "\t3 : OP1_AVG [NUMERICAL]\n",
            "\t2 : OPX_RATE [NUMERICAL]\n",
            "\t2 : HOME_POWER [NUMERICAL]\n",
            "\t1 : games [NUMERICAL]\n",
            "\t1 : OP_SUM [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t33 : OPX_AVG [NUMERICAL]\n",
            "\t17 : OP1_RATE [NUMERICAL]\n",
            "\t13 : OP1_AVG [NUMERICAL]\n",
            "\t12 : OP2_RATE [NUMERICAL]\n",
            "\t9 : HOME_POWER [NUMERICAL]\n",
            "\t5 : OPX_RATE [NUMERICAL]\n",
            "\t5 : OP2_AVG [NUMERICAL]\n",
            "\t4 : away_loss_rate [NUMERICAL]\n",
            "\t4 : OP_SUM [NUMERICAL]\n",
            "\t1 : games [NUMERICAL]\n",
            "\t1 : away_wins_rate [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t49 : OPX_AVG [NUMERICAL]\n",
            "\t32 : OP1_RATE [NUMERICAL]\n",
            "\t25 : OP1_AVG [NUMERICAL]\n",
            "\t25 : HOME_POWER [NUMERICAL]\n",
            "\t20 : OP2_AVG [NUMERICAL]\n",
            "\t19 : OP2_RATE [NUMERICAL]\n",
            "\t12 : OP_SUM [NUMERICAL]\n",
            "\t9 : OPX_RATE [NUMERICAL]\n",
            "\t7 : away_loss_rate [NUMERICAL]\n",
            "\t6 : away_wins_rate [NUMERICAL]\n",
            "\t4 : away_tie_rate [NUMERICAL]\n",
            "\t1 : home_tie_rate [NUMERICAL]\n",
            "\t1 : games [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t277 : ObliqueCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t11 : ObliqueCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t28 : ObliqueCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t56 : ObliqueCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t104 : ObliqueCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t210 : ObliqueCondition\n",
            "\n",
            "Training logs:\n",
            "Number of iteration to final model: 11\n",
            "\tIter:1 train-loss:0.273060 valid-loss:0.163745  train-rmse:0.273060 valid-rmse:0.163745\n",
            "\tIter:2 train-loss:0.249826 valid-loss:0.150848  train-rmse:0.249826 valid-rmse:0.150848\n",
            "\tIter:3 train-loss:0.229803 valid-loss:0.139141  train-rmse:0.229803 valid-rmse:0.139141\n",
            "\tIter:4 train-loss:0.210342 valid-loss:0.134044  train-rmse:0.210342 valid-rmse:0.134044\n",
            "\tIter:5 train-loss:0.193477 valid-loss:0.131910  train-rmse:0.193477 valid-rmse:0.131910\n",
            "\tIter:6 train-loss:0.178668 valid-loss:0.130765  train-rmse:0.178668 valid-rmse:0.130765\n",
            "\tIter:16 train-loss:0.089540 valid-loss:0.163183  train-rmse:0.089540 valid-rmse:0.163183\n",
            "\tIter:26 train-loss:0.055286 valid-loss:0.190846  train-rmse:0.055286 valid-rmse:0.190846\n",
            "\tIter:36 train-loss:0.039044 valid-loss:0.197014  train-rmse:0.039044 valid-rmse:0.197014\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model_10.evaluate(tf_test_data, verbose=1, return_dict=True)\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR4jHtPP6Yv5",
        "outputId": "e888ac1f-e57a-42fe-e253-92d510f5579c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 336ms/step - loss: 0.0000e+00 - mse: 0.0300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.0, 'mse': 0.02998298779129982}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_10.predict(tf_test_data).flatten()\n",
        "num_correct = 0\n",
        "test_data = train_2\n",
        "total = len(predictions)\n",
        "for pred, true, op in zip(predictions, test_data[label], test_data[\"OPX_AVG\"]):\n",
        "  # pred = 1 if pred > .5 else 0\n",
        "  if pred > op and true > op:\n",
        "    num_correct += 1\n",
        "  elif pred < op and true < op:\n",
        "    num_correct += 1\n",
        "  print(f\"pred: {pred > op}, true: {true > op}\")\n",
        "  print(f\"pred: {pred}, true: {true}, op {op}\")\n",
        "\n",
        "\n",
        "print_percent_str(\"num correct\", num_correct, total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHoENQHu85kv",
        "outputId": "c3eb5014-d3bb-4620-d9c0-6c5a6523a435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "pred: False, true: True\n",
            "pred: 3.471444606781006, true: 3.558, op 3.487\n",
            "pred: True, true: False\n",
            "pred: 3.3004074096679688, true: 3.085, op 3.151\n",
            "pred: True, true: True\n",
            "pred: 3.2258026599884033, true: 3.208, op 3.124\n",
            "pred: True, true: True\n",
            "pred: 3.406662940979004, true: 3.385, op 3.303\n",
            "pred: True, true: True\n",
            "pred: 3.208134651184082, true: 3.282, op 3.143\n",
            "pred: True, true: True\n",
            "pred: 3.240617275238037, true: 3.313, op 3.177\n",
            "pred: True, true: True\n",
            "pred: 3.246584177017212, true: 3.175, op 3.128\n",
            "pred: False, true: True\n",
            "pred: 3.403801918029785, true: 3.549, op 3.487\n",
            "pred: True, true: True\n",
            "pred: 3.271205186843872, true: 3.26, op 3.221\n",
            "pred: True, true: False\n",
            "pred: 3.438768148422241, true: 3.297, op 3.317\n",
            "pred: True, true: False\n",
            "pred: 3.2802846431732178, true: 3.179, op 3.26\n",
            "pred: True, true: True\n",
            "pred: 3.410590410232544, true: 3.443, op 3.397\n",
            "pred: True, true: True\n",
            "pred: 3.713073492050171, true: 3.549, op 3.407\n",
            "pred: True, true: True\n",
            "pred: 3.460174083709717, true: 3.443, op 3.276\n",
            "pred: True, true: True\n",
            "pred: 3.2202653884887695, true: 3.203, op 3.137\n",
            "pred: True, true: True\n",
            "pred: 3.528358221054077, true: 3.825, op 3.487\n",
            "pred: False, true: True\n",
            "pred: 3.4119694232940674, true: 3.846, op 3.451\n",
            "pred: True, true: True\n",
            "pred: 3.3045358657836914, true: 3.253, op 3.194\n",
            "pred: False, true: True\n",
            "pred: 3.3996591567993164, true: 3.801, op 3.52\n",
            "pred: True, true: False\n",
            "pred: 3.4906673431396484, true: 3.328, op 3.362\n",
            "pred: True, true: True\n",
            "pred: 3.409125804901123, true: 3.348, op 3.313\n",
            "pred: True, true: False\n",
            "pred: 3.3940563201904297, true: 3.223, op 3.313\n",
            "pred: True, true: False\n",
            "pred: 3.3136351108551025, true: 3.171, op 3.19\n",
            "pred: True, true: True\n",
            "pred: 3.35891056060791, true: 3.433, op 3.33\n",
            "pred: True, true: False\n",
            "pred: 3.267364025115967, true: 3.197, op 3.217\n",
            "pred: False, true: True\n",
            "pred: 3.3867015838623047, true: 3.501, op 3.402\n",
            "pred: True, true: False\n",
            "pred: 3.087984085083008, true: 2.967, op 3.028\n",
            "pred: False, true: True\n",
            "pred: 3.4245779514312744, true: 3.875, op 3.452\n",
            "pred: True, true: False\n",
            "pred: 3.1184701919555664, true: 2.828, op 2.984\n",
            "pred: True, true: True\n",
            "pred: 3.1856086254119873, true: 3.017, op 3.013\n",
            "pred: True, true: False\n",
            "pred: 3.3137478828430176, true: 3.168, op 3.175\n",
            "pred: False, true: False\n",
            "pred: 3.279932737350464, true: 3.211, op 3.282\n",
            "pred: True, true: False\n",
            "pred: 3.1067581176757812, true: 2.969, op 3.021\n",
            "pred: False, true: True\n",
            "pred: 3.8005123138427734, true: 4.128, op 3.876\n",
            "pred: True, true: True\n",
            "pred: 3.229727029800415, true: 3.204, op 3.141\n",
            "pred: True, true: True\n",
            "pred: 3.235628843307495, true: 3.427, op 3.181\n",
            "pred: True, true: True\n",
            "pred: 3.2877445220947266, true: 3.216, op 3.2\n",
            "pred: True, true: False\n",
            "pred: 3.1022984981536865, true: 2.877, op 2.883\n",
            "pred: True, true: True\n",
            "pred: 3.30680513381958, true: 3.541, op 3.253\n",
            "pred: True, true: True\n",
            "pred: 3.124232292175293, true: 3.208, op 3.017\n",
            "pred: True, true: True\n",
            "pred: 3.1971259117126465, true: 3.165, op 3.073\n",
            "pred: True, true: True\n",
            "pred: 3.258098602294922, true: 3.229, op 3.211\n",
            "pred: True, true: False\n",
            "pred: 3.1552486419677734, true: 2.961, op 3.066\n",
            "pred: False, true: False\n",
            "pred: 3.252138614654541, true: 3.225, op 3.257\n",
            "pred: True, true: True\n",
            "pred: 3.1694796085357666, true: 3.099, op 3.08\n",
            "pred: False, true: False\n",
            "pred: 3.403127908706665, true: 3.362, op 3.467\n",
            "pred: True, true: False\n",
            "pred: 3.1947193145751953, true: 2.933, op 3.064\n",
            "pred: True, true: False\n",
            "pred: 3.274362564086914, true: 3.089, op 3.148\n",
            "pred: True, true: True\n",
            "pred: 3.252211570739746, true: 3.251, op 3.179\n",
            "pred: True, true: False\n",
            "pred: 3.5172879695892334, true: 3.349, op 3.501\n",
            "pred: False, true: True\n",
            "pred: 3.2220373153686523, true: 3.361, op 3.286\n",
            "num correct: 52.941%      27/51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bet or no bet"
      ],
      "metadata": {
        "id": "6S_0DB8IQNC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_with_result = get_dataset_with_season()"
      ],
      "metadata": {
        "id": "1Aj2quG3URGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_dataset = get_stat_percent_database(dataset_with_result.copy())\n",
        "# bnb_dataset = get_diff_database(bnb_dataset)\n",
        "bnb_dataset = get_odds_percent_database(bnb_dataset)\n",
        "# bnb_dataset = get_odds_percent_database_closing(bnb_dataset)\n",
        "# bnb_dataset = get_dir_database(bnb_dataset)\n",
        "bnb_dataset = get_weighted_OHE_dataset(bnb_dataset)\n",
        "bnb_dataset = get_power_database(bnb_dataset)\n",
        "# bnb_dataset[\"MAX_DIFF\"] = get_max_diff(bnb_dataset)\n",
        "bnb_dataset = get_odds_rankings(bnb_dataset, True)\n",
        "# bnb_dataset = get_odds_rankings(bnb_dataset, False)\n",
        "bnb_dataset = bnb_dataset.drop(index=bnb_dataset[bnb_dataset.games < 4].index)\n",
        "bnb_dataset[\"OP_SUM\"] = bnb_dataset[\"OP1_AVG\"] + bnb_dataset[\"OPX_AVG\"] + bnb_dataset[\"OP2_AVG\"]\n",
        "# bnb_dataset[\"CP_SUM\"] = bnb_dataset[\"CP1_AVG\"] + bnb_dataset[\"CPX_AVG\"] + bnb_dataset[\"CP2_AVG\"]\n",
        "max_symbol = \"D\"\n",
        "mid_symbol = \"A\"\n",
        "min_symbol = \"H\"\n",
        "bnb_dataset = bnb_dataset[(bnb_dataset[\"OP_MAX_ODD\"] == max_symbol) & (bnb_dataset[\"OP_MID_ODD\"] == mid_symbol) & (bnb_dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "# bnb_dataset[\"OP_MIN_ODD_NUM\"] = bnb_dataset[\"OP_MIN_ODD\"].apply(lambda x: -10 if x == \"H\" else 0 if x == \"D\" else 10)\n",
        "# bnb_dataset[\"OP_MID_ODD_NUM\"] = bnb_dataset[\"OP_MID_ODD\"].apply(lambda x: -10 if x == \"H\" else 0 if x == \"D\" else 10)\n",
        "# bnb_dataset[\"OP_MAX_ODD_NUM\"] = bnb_dataset[\"OP_MAX_ODD\"].apply(lambda x: -10 if x == \"H\" else 0 if x == \"D\" else 10)\n",
        "symbol = \"D\"\n",
        "bnb_dataset[f\"result_{symbol}\"] = bnb_dataset[\"result\"].apply(lambda x: 1 if x == symbol else 0)\n",
        "bnb_dataset = bnb_dataset.drop(columns=[\"OP_MAX_ODD\", \"OP_MID_ODD\", \"OP_MIN_ODD\", \"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"result\", \"date\"])\n",
        "bnb_dataset\n",
        "\n",
        "curr_label = f\"result_{symbol}\"\n",
        "bnb_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "baK-kTpgQPNv",
        "outputId": "5cc28502-2023-4dee-9af0-f2bff0491dd4"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games     season  OP1_AVG  OPX_AVG  OP2_AVG  home_wins_rate  \\\n",
              "40        4  2015/2016    2.528    3.115    2.900        0.250000   \n",
              "47        4  2015/2016    2.568    3.177    2.784        0.000000   \n",
              "56        5  2015/2016    2.433    3.224    2.926        0.200000   \n",
              "58        5  2015/2016    2.296    3.224    3.178        0.200000   \n",
              "67        6  2015/2016    2.431    3.252    2.944        0.166667   \n",
              "...     ...        ...      ...      ...      ...             ...   \n",
              "3404     36  2023/2024    2.633    3.064    2.818        0.388889   \n",
              "3412     37  2023/2024    2.286    3.489    2.950        0.432432   \n",
              "3414     37  2023/2024    2.243    3.555    3.029        0.054054   \n",
              "3417     37  2023/2024    2.250    3.304    3.124        0.270270   \n",
              "3418     37  2023/2024    2.313    3.401    2.947        0.270270   \n",
              "\n",
              "      home_tie_rate  home_loss_rate  away_wins_rate  away_tie_rate  \\\n",
              "40         0.000000        0.750000        0.000000       0.500000   \n",
              "47         0.500000        0.500000        0.750000       0.250000   \n",
              "56         0.400000        0.400000        0.200000       0.000000   \n",
              "58         0.400000        0.400000        0.200000       0.400000   \n",
              "67         0.166667        0.666667        0.333333       0.500000   \n",
              "...             ...             ...             ...            ...   \n",
              "3404       0.388889        0.222222        0.416667       0.333333   \n",
              "3412       0.324324        0.243243        0.621622       0.108108   \n",
              "3414       0.324324        0.621622        0.162162       0.405405   \n",
              "3417       0.351351        0.378378        0.189189       0.432432   \n",
              "3418       0.243243        0.486486        0.324324       0.243243   \n",
              "\n",
              "      away_loss_rate  OP1_RATE  OPX_RATE  OP2_RATE  Alaves  Almeria  \\\n",
              "40          0.500000  0.295915  0.364626  0.339459       0        0   \n",
              "47          0.000000  0.301090  0.372494  0.326416       0        0   \n",
              "56          0.800000  0.283467  0.375626  0.340906       0        0   \n",
              "58          0.400000  0.263969  0.370660  0.365371       0        0   \n",
              "67          0.166667  0.281790  0.376956  0.341254       0        0   \n",
              "...              ...       ...       ...       ...     ...      ...   \n",
              "3404        0.250000  0.309219  0.359836  0.330945       0        0   \n",
              "3412        0.270270  0.262006  0.399885  0.338109       0        0   \n",
              "3414        0.432432  0.254107  0.402742  0.343152       0        2   \n",
              "3417        0.378378  0.259276  0.380733  0.359991       0        0   \n",
              "3418        0.432432  0.267059  0.392680  0.340261       1        0   \n",
              "\n",
              "      Ath Bilbao  Atl. Madrid  Barcelona  Betis  Cadiz CF  Celta Vigo  \\\n",
              "40             0            0          0      0         0           0   \n",
              "47             0            0          0      0         0           0   \n",
              "56             1            0          0      0         0           0   \n",
              "58             0            0          0      1         0           0   \n",
              "67             2            0          0      0         0           0   \n",
              "...          ...          ...        ...    ...       ...         ...   \n",
              "3404           0            0          0      2         0           0   \n",
              "3412           0            1          0      0         0           0   \n",
              "3414           0            0          0      0         1           0   \n",
              "3417           0            0          0      0         0           0   \n",
              "3418           0            0          0      0         0           0   \n",
              "\n",
              "      Dep. La Coruna  Eibar  Elche  Espanyol  Getafe  Gijon  Girona  \\\n",
              "40                 0      0      0         0       0      0       0   \n",
              "47                 0      0      0         0       0      0       0   \n",
              "56                 0      0      0         0       0      0       0   \n",
              "58                 0      0      0         0       0      2       0   \n",
              "67                 0      0      0         0       0      0       0   \n",
              "...              ...    ...    ...       ...     ...    ...     ...   \n",
              "3404               0      0      0         0       0      0       0   \n",
              "3412               0      0      0         0       0      0       0   \n",
              "3414               0      0      0         0       0      0       0   \n",
              "3417               0      0      0         0       2      0       0   \n",
              "3418               0      0      0         0       0      0       0   \n",
              "\n",
              "      Granada CF  Huesca  Las Palmas  Leganes  Levante  Malaga  Mallorca  \\\n",
              "40             2       0           0        0        0       0         0   \n",
              "47             0       0           0        0        0       2         0   \n",
              "56             0       0           0        0        0       0         0   \n",
              "58             0       0           0        0        0       0         0   \n",
              "67             0       0           0        0        0       0         0   \n",
              "...          ...     ...         ...      ...      ...     ...       ...   \n",
              "3404           0       0           0        0        0       0         0   \n",
              "3412           0       0           0        0        0       0         0   \n",
              "3414           0       0           0        0        0       0         0   \n",
              "3417           0       0           0        0        0       0         1   \n",
              "3418           0       0           2        0        0       0         0   \n",
              "\n",
              "      Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  Sevilla  Valencia  \\\n",
              "40          0               0            0              1        0         0   \n",
              "47          0               0            0              0        0         0   \n",
              "56          0               0            0              2        0         0   \n",
              "58          0               0            0              0        0         0   \n",
              "67          0               0            0              0        0         1   \n",
              "...       ...             ...          ...            ...      ...       ...   \n",
              "3404        0               0            0              1        0         0   \n",
              "3412        0               0            0              2        0         0   \n",
              "3414        0               0            0              0        0         0   \n",
              "3417        0               0            0              0        0         0   \n",
              "3418        0               0            0              0        0         0   \n",
              "\n",
              "      Valladolid  Villarreal  HOME_POWER  OP_SUM  result_D  \n",
              "40             0           0    1.000000   8.543         0  \n",
              "47             0           1    0.285714   8.529         0  \n",
              "56             0           0    2.000000   8.583         1  \n",
              "58             0           0    1.000000   8.698         0  \n",
              "67             0           0    0.428571   8.627         0  \n",
              "...          ...         ...         ...     ...       ...  \n",
              "3404           0           0    1.000000   8.515         0  \n",
              "3412           0           0    0.880000   8.725         0  \n",
              "3414           0           0    0.592593   8.827         0  \n",
              "3417           0           0    1.100000   8.678         0  \n",
              "3418           0           0    0.878788   8.661         1  \n",
              "\n",
              "[478 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-183657b8-58a1-483f-ade5-fc63d8472f32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>season</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>HOME_POWER</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>result_D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>4</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.528</td>\n",
              "      <td>3.115</td>\n",
              "      <td>2.900</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.295915</td>\n",
              "      <td>0.364626</td>\n",
              "      <td>0.339459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.543</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.568</td>\n",
              "      <td>3.177</td>\n",
              "      <td>2.784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301090</td>\n",
              "      <td>0.372494</td>\n",
              "      <td>0.326416</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>8.529</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>5</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.433</td>\n",
              "      <td>3.224</td>\n",
              "      <td>2.926</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.283467</td>\n",
              "      <td>0.375626</td>\n",
              "      <td>0.340906</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.583</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>5</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.296</td>\n",
              "      <td>3.224</td>\n",
              "      <td>3.178</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.263969</td>\n",
              "      <td>0.370660</td>\n",
              "      <td>0.365371</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.698</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>6</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.431</td>\n",
              "      <td>3.252</td>\n",
              "      <td>2.944</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.281790</td>\n",
              "      <td>0.376956</td>\n",
              "      <td>0.341254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>8.627</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>36</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>2.633</td>\n",
              "      <td>3.064</td>\n",
              "      <td>2.818</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.309219</td>\n",
              "      <td>0.359836</td>\n",
              "      <td>0.330945</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3412</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>2.286</td>\n",
              "      <td>3.489</td>\n",
              "      <td>2.950</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.262006</td>\n",
              "      <td>0.399885</td>\n",
              "      <td>0.338109</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>8.725</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3414</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>2.243</td>\n",
              "      <td>3.555</td>\n",
              "      <td>3.029</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.254107</td>\n",
              "      <td>0.402742</td>\n",
              "      <td>0.343152</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>8.827</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>2.250</td>\n",
              "      <td>3.304</td>\n",
              "      <td>3.124</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.259276</td>\n",
              "      <td>0.380733</td>\n",
              "      <td>0.359991</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>8.678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>2.313</td>\n",
              "      <td>3.401</td>\n",
              "      <td>2.947</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.392680</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>8.661</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>478 rows × 47 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-183657b8-58a1-483f-ade5-fc63d8472f32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-183657b8-58a1-483f-ade5-fc63d8472f32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-183657b8-58a1-483f-ade5-fc63d8472f32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-004accd8-d8c5-4e4b-98c3-d2657e3cc10e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-004accd8-d8c5-4e4b-98c3-d2657e3cc10e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-004accd8-d8c5-4e4b-98c3-d2657e3cc10e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6cbc2dfe-32fb-46f9-8b55-56ef7a8aafbc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bnb_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6cbc2dfe-32fb-46f9-8b55-56ef7a8aafbc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bnb_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bnb_dataset"
            }
          },
          "metadata": {},
          "execution_count": 401
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 'combo': ('D', 'H', 'A'), 'symbol': 'D',\n",
        "\n",
        "# if symbol == \"H\":\n",
        "#   odds_label = \"OP1_AVG\"\n",
        "# elif symbol == \"D\":\n",
        "#   odds_label = \"OPX_AVG\"\n",
        "# else:\n",
        "#   odds_label = \"OP2_AVG\"\n",
        "bnb_test = bnb_dataset[(bnb_dataset[\"season\"] == \"2023/2024\") | (bnb_dataset[\"season\"] == \"2022/2023\")]\n",
        "bnb_test = bnb_test.drop(columns=[\"season\"])\n",
        "bnb_train = bnb_dataset.drop(index=bnb_test.index)\n",
        "bnb_train = bnb_train.drop(columns=[\"season\"])\n",
        "bnb_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "KdcC7pq-QfqI",
        "outputId": "bf64e85f-c20f-4552-fd94-d6dcd93ce922"
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  OP1_AVG  OPX_AVG  OP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "2708      4    2.596    3.456    2.603        0.750000       0.000000   \n",
              "2709      4    2.562    3.199    2.805        0.250000       0.250000   \n",
              "2712      5    2.393    3.165    3.043        0.400000       0.000000   \n",
              "2725      6    2.499    3.273    2.802        0.166667       0.166667   \n",
              "2726      6    2.330    3.387    2.971        0.333333       0.166667   \n",
              "...     ...      ...      ...      ...             ...            ...   \n",
              "3404     36    2.633    3.064    2.818        0.388889       0.388889   \n",
              "3412     37    2.286    3.489    2.950        0.432432       0.324324   \n",
              "3414     37    2.243    3.555    3.029        0.054054       0.324324   \n",
              "3417     37    2.250    3.304    3.124        0.270270       0.351351   \n",
              "3418     37    2.313    3.401    2.947        0.270270       0.243243   \n",
              "\n",
              "      home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  OP1_RATE  \\\n",
              "2708        0.250000        0.750000       0.250000        0.000000  0.299942   \n",
              "2709        0.500000        0.750000       0.000000        0.250000  0.299089   \n",
              "2712        0.600000        0.400000       0.200000        0.400000  0.278223   \n",
              "2725        0.666667        0.500000       0.000000        0.500000  0.291463   \n",
              "2726        0.500000        0.833333       0.000000        0.166667  0.268186   \n",
              "...              ...             ...            ...             ...       ...   \n",
              "3404        0.222222        0.416667       0.333333        0.250000  0.309219   \n",
              "3412        0.243243        0.621622       0.108108        0.270270  0.262006   \n",
              "3414        0.621622        0.162162       0.405405        0.432432  0.254107   \n",
              "3417        0.378378        0.189189       0.432432        0.378378  0.259276   \n",
              "3418        0.486486        0.324324       0.243243        0.432432  0.267059   \n",
              "\n",
              "      OPX_RATE  OP2_RATE  Alaves  Almeria  Ath Bilbao  Atl. Madrid  Barcelona  \\\n",
              "2708  0.399307  0.300751       0        0           0            0          0   \n",
              "2709  0.373453  0.327457       0        2           0            0          0   \n",
              "2712  0.367980  0.353796       0        0           0            0          0   \n",
              "2725  0.381735  0.326802       0        0           0            0          0   \n",
              "2726  0.389848  0.341966       0        0           0            0          0   \n",
              "...        ...       ...     ...      ...         ...          ...        ...   \n",
              "3404  0.359836  0.330945       0        0           0            0          0   \n",
              "3412  0.399885  0.338109       0        0           0            1          0   \n",
              "3414  0.402742  0.343152       0        2           0            0          0   \n",
              "3417  0.380733  0.359991       0        0           0            0          0   \n",
              "3418  0.392680  0.340261       1        0           0            0          0   \n",
              "\n",
              "      Betis  Cadiz CF  Celta Vigo  Dep. La Coruna  Eibar  Elche  Espanyol  \\\n",
              "2708      2         0           0               0      0      0         0   \n",
              "2709      0         0           0               0      0      0         0   \n",
              "2712      0         0           1               0      0      0         0   \n",
              "2725      0         0           0               0      0      0         2   \n",
              "2726      1         0           2               0      0      0         0   \n",
              "...     ...       ...         ...             ...    ...    ...       ...   \n",
              "3404      2         0           0               0      0      0         0   \n",
              "3412      0         0           0               0      0      0         0   \n",
              "3414      0         1           0               0      0      0         0   \n",
              "3417      0         0           0               0      0      0         0   \n",
              "3418      0         0           0               0      0      0         0   \n",
              "\n",
              "      Getafe  Gijon  Girona  Granada CF  Huesca  Las Palmas  Leganes  Levante  \\\n",
              "2708       0      0       0           0       0           0        0        0   \n",
              "2709       0      0       0           0       0           0        0        0   \n",
              "2712       0      0       0           0       0           0        0        0   \n",
              "2725       0      0       0           0       0           0        0        0   \n",
              "2726       0      0       0           0       0           0        0        0   \n",
              "...      ...    ...     ...         ...     ...         ...      ...      ...   \n",
              "3404       0      0       0           0       0           0        0        0   \n",
              "3412       0      0       0           0       0           0        0        0   \n",
              "3414       0      0       0           0       0           0        0        0   \n",
              "3417       2      0       0           0       0           0        0        0   \n",
              "3418       0      0       0           0       0           2        0        0   \n",
              "\n",
              "      Malaga  Mallorca  Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  \\\n",
              "2708       0         0        0               0            0              0   \n",
              "2709       0         0        1               0            0              0   \n",
              "2712       0         0        0               0            0              0   \n",
              "2725       0         0        0               0            0              0   \n",
              "2726       0         0        0               0            0              0   \n",
              "...      ...       ...      ...             ...          ...            ...   \n",
              "3404       0         0        0               0            0              1   \n",
              "3412       0         0        0               0            0              2   \n",
              "3414       0         0        0               0            0              0   \n",
              "3417       0         1        0               0            0              0   \n",
              "3418       0         0        0               0            0              0   \n",
              "\n",
              "      Sevilla  Valencia  Valladolid  Villarreal  HOME_POWER  OP_SUM  result_D  \n",
              "2708        0         0           0           1    0.857143   8.655         0  \n",
              "2709        0         0           0           0    0.500000   8.566         0  \n",
              "2712        0         2           0           0    0.800000   8.601         0  \n",
              "2725        0         1           0           0    0.500000   8.574         1  \n",
              "2726        0         0           0           0    0.500000   8.688         0  \n",
              "...       ...       ...         ...         ...         ...     ...       ...  \n",
              "3404        0         0           0           0    1.000000   8.515         0  \n",
              "3412        0         0           0           0    0.880000   8.725         0  \n",
              "3414        0         0           0           0    0.592593   8.827         0  \n",
              "3417        0         0           0           0    1.100000   8.678         0  \n",
              "3418        0         0           0           0    0.878788   8.661         1  \n",
              "\n",
              "[112 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c052faf-71ae-4947-9c5d-11e3b0ba933b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>HOME_POWER</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>result_D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2708</th>\n",
              "      <td>4</td>\n",
              "      <td>2.596</td>\n",
              "      <td>3.456</td>\n",
              "      <td>2.603</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.299942</td>\n",
              "      <td>0.399307</td>\n",
              "      <td>0.300751</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>8.655</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>4</td>\n",
              "      <td>2.562</td>\n",
              "      <td>3.199</td>\n",
              "      <td>2.805</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.299089</td>\n",
              "      <td>0.373453</td>\n",
              "      <td>0.327457</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.566</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>5</td>\n",
              "      <td>2.393</td>\n",
              "      <td>3.165</td>\n",
              "      <td>3.043</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.278223</td>\n",
              "      <td>0.367980</td>\n",
              "      <td>0.353796</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>8.601</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2725</th>\n",
              "      <td>6</td>\n",
              "      <td>2.499</td>\n",
              "      <td>3.273</td>\n",
              "      <td>2.802</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.291463</td>\n",
              "      <td>0.381735</td>\n",
              "      <td>0.326802</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.574</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2726</th>\n",
              "      <td>6</td>\n",
              "      <td>2.330</td>\n",
              "      <td>3.387</td>\n",
              "      <td>2.971</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.268186</td>\n",
              "      <td>0.389848</td>\n",
              "      <td>0.341966</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.688</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>36</td>\n",
              "      <td>2.633</td>\n",
              "      <td>3.064</td>\n",
              "      <td>2.818</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.309219</td>\n",
              "      <td>0.359836</td>\n",
              "      <td>0.330945</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3412</th>\n",
              "      <td>37</td>\n",
              "      <td>2.286</td>\n",
              "      <td>3.489</td>\n",
              "      <td>2.950</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.262006</td>\n",
              "      <td>0.399885</td>\n",
              "      <td>0.338109</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>8.725</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3414</th>\n",
              "      <td>37</td>\n",
              "      <td>2.243</td>\n",
              "      <td>3.555</td>\n",
              "      <td>3.029</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.254107</td>\n",
              "      <td>0.402742</td>\n",
              "      <td>0.343152</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>8.827</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>37</td>\n",
              "      <td>2.250</td>\n",
              "      <td>3.304</td>\n",
              "      <td>3.124</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.259276</td>\n",
              "      <td>0.380733</td>\n",
              "      <td>0.359991</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>8.678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3418</th>\n",
              "      <td>37</td>\n",
              "      <td>2.313</td>\n",
              "      <td>3.401</td>\n",
              "      <td>2.947</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.392680</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>8.661</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c052faf-71ae-4947-9c5d-11e3b0ba933b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c052faf-71ae-4947-9c5d-11e3b0ba933b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c052faf-71ae-4947-9c5d-11e3b0ba933b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2dbafd74-39bf-46b3-8680-a3c766e12860\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dbafd74-39bf-46b3-8680-a3c766e12860')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2dbafd74-39bf-46b3-8680-a3c766e12860 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9af0fbae-b23a-4471-b555-335ccb133b3a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bnb_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9af0fbae-b23a-4471-b555-335ccb133b3a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bnb_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bnb_test"
            }
          },
          "metadata": {},
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_train_features = bnb_train.drop(columns=curr_label)\n",
        "# bnb_train_features = np.array(bnb_train_features).astype('float32')\n",
        "bnb_train_target = [[1-x, x, y] for x, y in zip(bnb_train[curr_label], bnb_train[odds_label])]\n",
        "# bnb_train_target = [[1, x] if x > 0 else [0, x] for x in bnb_train_target]\n",
        "# bnb_train_target = np.array(bnb_train_target).astype('float32')\n",
        "\n",
        "\n",
        "bnb_test_features = bnb_test.drop(columns=curr_label)\n",
        "# bnb_test_features = np.array(bnb_test_features).astype('float32')\n",
        "# bnb_test_target = bnb_test[label]\n",
        "bnb_test_target = [[1-x, x, y] for x, y in zip(bnb_test[curr_label], bnb_test[odds_label])]\n",
        "# bnb_test_target = [[1, x] if x > 0 else [0, x] for x in bnb_test_target]\n",
        "# bnb_test_target = np.array(bnb_test_target).astype('float32')"
      ],
      "metadata": {
        "id": "h23anX6fTtmJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "80cd4943-6361-41c0-d54c-5147a76448f5"
      },
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'odds_label' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-409-598b1f269915>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbnb_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# bnb_train_features = np.array(bnb_train_features).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbnb_train_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0modds_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# bnb_train_target = [[1, x] if x > 0 else [0, x] for x in bnb_train_target]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# bnb_train_target = np.array(bnb_train_target).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'odds_label' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cp7LXAqZQeh",
        "outputId": "955dc15c-26ad-42f6-b918-632b63792784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2380, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(tensor):\n",
        "  return tf.math.divide(tensor,  tf.math.abs(tensor))\n",
        "\n",
        "def penalized_loss(y_true, y_pred):\n",
        "    # y_true_positive = tf.math.greater_equal(y_true, 0)\n",
        "    true_class = y_true[:, 0]\n",
        "    odds = y_true[:, 1]\n",
        "\n",
        "    # # weights = tf.math.multiply(losses, values)\n",
        "\n",
        "    # predicted_class = tf.math.divide(normalize(y_pred - 0.5) + 1.0, 2.0)\n",
        "    # diff = tf.math.abs(tf.math.subtract(predicted_class, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "    # weights = tf.math.divide(tf.math.abs(odds), diff) * signs\n",
        "    # return tf.math.reduce_sum(weights)\n",
        "\n",
        "    losses = tf.keras.ops.binary_crossentropy(true_class, y_pred[:, 0])\n",
        "    weighted_loss = tf.math.abs(odds) * losses\n",
        "    # return tf.math.reduce_sum(weighted_loss)\n",
        "    # bet (1), dont bet (0)\n",
        "    predicted_class_tanh = normalize(y_pred - 0.5) * -1 # b: -1, nb: 1\n",
        "    # predicted_class_sig = (predicted_class_tanh + 1.0) / 2 # b: 0, nb: 1\n",
        "    # predicted_class_scaled = ((predicted_class_sig / 2.0) - 1.0) * predicted_class_tanh  # 1, -0.5\n",
        "    # weight = odds * (predicted_class_scaled * -1)\n",
        "    # loss = tf.reduce_sum(weight)\n",
        "\n",
        "    pred_sum = tf.math.abs(tf.math.reduce_sum(predicted_class_tanh))\n",
        "    length = tf.cast(tf.size(predicted_class_tanh), dtype=tf.float32)\n",
        "    penalty = predicted_class_tanh * weighted_loss + (pred_sum / length)\n",
        "\n",
        "    return penalty\n",
        "\n",
        "    # signs = normalize(tf.math.subtract(true_class, y_pred)) * normalize(tf.math.subtract(0.5, y_pred))\n",
        "\n",
        "\n",
        "    # true positive, confidence increases -> loss decreases\n",
        "    # pred_rounded = .6 - .5 / |.6 - .5| = (1 + 1) / 2 = 1\n",
        "\n",
        "    # sign = (true - odd) * (0.5 - odd) = -1 if same, 1 if true\n",
        "\n",
        "    # true: 1, pred: 0.6, odd: 6, return 6 / .4 = 15 * -1 = -15\n",
        "    # true: 1, pred: 0.8, odd: 6, return 6 / .2 = 30 * -1 = -30\n",
        "    # diff: | pred_rounded - .6 | = .4\n",
        "    # diff: | pred_rounded - .8 | = .2\n",
        "    # correct = pred_rounded\n",
        "\n",
        "    # correct = true - pred = 1 - 0.6 = +\n",
        "    # off = .4 * 6 = 2.4\n",
        "    # off = .2 * 6 = 1.2\n",
        "\n",
        "    # 6 / .4 = 15 / 6 = 2.5\n",
        "    # 6 / .2 = 30 / 6 = 5\n",
        "\n",
        "    # true * odd = 1 * 6 = 6\n",
        "\n",
        "\n",
        "    # true negative, confidence increases -> loss decreases\n",
        "    # pred_rounded = .4 - .5 / |.4 - .5| = (-1 + 1) / 2 = 0\n",
        "    # true: 0, pred: 0.4 odd: -1 return |-1| / .4 = 2.5 * -1 = -2.5\n",
        "    # true: 0, pred: 0.2 odd: -1 return |-1| / .2 = 5 * -1 = -5\n",
        "    # diff: | pred_rounded - .4 | = .4\n",
        "    # diff: | pred_rounded - .2 | = .2\n",
        "\n",
        "    # true = (0 - 0.4) * -1 = +\n",
        "    # off = .4 * 1 = .4\n",
        "    # off = .2 * 1 - .2\n",
        "    # .4 * -1 = -0.4 / -1 = .4\n",
        "    # .2 * -1 = -0.2 / -1 = .2\n",
        "\n",
        "    # false positive, confidence increases -> loss increases\n",
        "    # pred_rounded = .8 - .5 / |.8 - .5| = (1 + 1) / 2 = 1\n",
        "    # true: 0, pred: .8, odd: -1, return |-1| / .2 = 5\n",
        "    # true: 0, pred: .6, odd: -1, return |-1| / .4 = 2.5\n",
        "    # diff: | pred_rounded - .8 | = .2\n",
        "    # diff: | pred_rounded - .6 | = .4\n",
        "\n",
        "    # off = .8 * 1 = .8\n",
        "    # off = .6 * 1 =\n",
        "    # true * odd = 0 * -1 = 0\n",
        "\n",
        "\n",
        "    # false negative, confidence increases -> loss increases\n",
        "    # pred_rounded = .2 - .5 / |.2 - .5| = (-1 + 1) / 2 = 0\n",
        "    # true: 1, pred: .2, odd: 6, return 6 / .2 = 30\n",
        "    # true: 1, pred: .4, odd: 6, return 6 / .4 = 15\n",
        "    # diff: | pred_rounded - .2 | = .2\n",
        "    # diff: | pred_rounded - .2 | = .4\n",
        "\n",
        "    # off = .8\n",
        "    # off = .6\n",
        "\n",
        "    # true -> positive\n",
        "    # false -> negative\n",
        "    # correctness increases -> loss decreases\n",
        "    #\n",
        "\n",
        "\n",
        "    # y_pred_normalized = tf.math.divide(y_pred, tf.math.abs(y_pred))\n",
        "    # y_pred_normalized = tf.math.add(y_pred_normalized, 1)\n",
        "    # # y_pred_normalized = tf.math.divide(y_pred_normalized, 2)\n",
        "    # y_pred_normalized = tf.math.multiply(y_pred_normalized, y_true)\n",
        "    # y_pred_normalized = tf.math.multiply(y_pred_normalized, -1)\n",
        "    # # y_pred_normalized = tf.math.add(y_pred_normalized, 5)\n",
        "    # # y_values = tf.where(y_pred_positive, y_true, 0)\n",
        "    # # y_pred_addition = tf.math.add(mask, y_pred)\n",
        "    # value = tf.math.reduce_sum(y_pred_normalized)\n",
        "    # # return tf.where(tf.math.equal(value, 0), -10.0, value)\n",
        "    # return value\n",
        "    # return tf.convert_to_tensor(-10) if tf.math.equal(value, 0) else value"
      ],
      "metadata": {
        "id": "Ia61xsp5QZ43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def odds_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The function implements the custom loss function mentioned in info.pdf\n",
        "\n",
        "    Inputs\n",
        "    true : a vector of dimension batch_size, 7. A label encoded version of the output and the backp1_a and backp1_b\n",
        "    pred : a vector of probabilities of dimension batch_size , 5.\n",
        "\n",
        "    Returns\n",
        "    the loss value\n",
        "    \"\"\"\n",
        "    no_bet = y_true[:, 0:1]\n",
        "    win_home_team = y_true[:, 1:2]\n",
        "    odds_a = y_true[:, 2:3]\n",
        "    gain_loss_vector = tf.concat([tf.zeros_like(odds_a),\n",
        "                                  win_home_team * (odds_a - 1) + (1 - win_home_team) * -1], axis=1)\n",
        "    return -1 * tf.reduce_mean(tf.reduce_sum(gain_loss_vector * y_pred, axis=1))\n",
        "    # return gain_loss_vector\n",
        "\n",
        "\n",
        "\n",
        "# true = np.array([[1, 0, 2.0], [0, 1, 3]]).astype('float32')\n",
        "# pred = np.array([[0.6, 0.1], [0.2, 0.6]]).astype('float32')\n",
        "\n",
        "odds_loss(true, pred).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9eHWnPL-Z4v",
        "outputId": "ac18e232-30c8-42ee-99f8-fb808e2ac9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {},
          "execution_count": 544
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_loss(y_true, y_pred):\n",
        "    no_bet = y_true[:, 0:1]\n",
        "    should_bet = y_true[:, 1:2]\n",
        "    odds = y_true[:, 2:3]\n",
        "\n",
        "    odds_ev = should_bet * (odds - 1) + (1 - should_bet) * -1\n",
        "    scale_vector = tf.concat([tf.zeros_like(odds_ev), odds_ev], axis=1)\n",
        "    # tf.zeros_like(odds_ev)\n",
        "    # -(should_bet * (odds - 1))/10.0\n",
        "    # return scale_vector\n",
        "    return -1 * tf.reduce_mean(tf.reduce_sum(scale_vector * y_pred, axis=1))\n",
        "    # return -1 * tf.reduce_mean(scale_vector * y_pred)\n",
        "    # return tf.reduce_sum(scale_vector)\n",
        "    # win_home_team * (odds_a - 1) + (1 - win_home_team) * -1,"
      ],
      "metadata": {
        "id": "ldN9uYcd1SxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7z--LkEQIma1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = np.array(bnb_train_target)[0:4, :]\n",
        "bnb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W7QaOGu4Evn",
        "outputId": "1d032241-b6a8-49b8-efed-e962783ce040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 2.528],\n",
              "       [1.   , 3.329],\n",
              "       [1.   , 1.244],\n",
              "       [1.   , 2.113]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = np.array(bnb_train_target)[0:4, :]\n",
        "evs = [true * (odd - 1) + (1 - true) * -1 for true, odd in zip(bnb[:, 0], bnb[:, 1])]\n",
        "print(evs)\n",
        "# sum(evs)\n",
        "# np.sum(evs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11nYNjYO6m3T",
        "outputId": "9f78f33e-da05-4541-a56a-b4b41aa64cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.0, 2.329, 0.244, 1.113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = np.array(bnb_train_target)[0:4, :]\n",
        "print(bnb)\n",
        "pred = np.array([[1, 0], [1, 0], [1, 0], [1, 0]]).astype(\"float32\")\n",
        "print(pred)\n",
        "true = np.array(bnb).astype('float32')\n",
        "weighted_loss(true, pred)\n",
        "# correct = penalized_loss(bnb_train_target, bnb_train_target[:, 0])\n",
        "# print(f\"loss: {loss}\")\n",
        "# -1,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs-enVrYXl2D",
        "outputId": "f6c1f23f-7693-4d47-fac4-2aee5cabe8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.    1.    3.329]\n",
            " [0.    1.    6.366]\n",
            " [1.    0.    5.768]\n",
            " [0.    1.    3.476]]\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-0.0>"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_train_target"
      ],
      "metadata": {
        "id": "-uo4j_1NU6B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "correct = penalized_loss(bnb_train_target, bnb_train_target[:, 0])\n",
        "\n",
        "fake_predictions = np.full(bnb_train_target[:, 0].shape, 0.3).astype(\"float32\")\n",
        "print(fake_predictions.dtype)\n",
        "nothing = penalized_loss(bnb_train_target, fake_predictions)\n",
        "\n",
        "fake_predictions = np.full(bnb_train_target[:, 0].shape, 0.7).astype(\"float32\")\n",
        "all = penalized_loss(bnb_train_target, fake_predictions)\n",
        "print(f\"correct_only: {correct}, none: {nothing}, all: {all}\")"
      ],
      "metadata": {
        "id": "KaK9ygJsYdSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy9hmZGwYBZu",
        "outputId": "75cd1414-3aed-4b68-eb32-d98b256ef04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.   , 2.829]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(bnb_train_features))\n",
        "steps_per_epoch = len(bnb_train_features)/32\n",
        "\n",
        "bnb_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                classes=np.unique(np.array(bnb_train_target)[:, 1]),\n",
        "                                                y=np.array(bnb_train_target)[:, 1])\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.5,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "\n",
        "# tf.keras.layers.LeakyReLU()\n",
        "model_11 = tf.keras.Sequential([\n",
        "      normalizer,\n",
        "      layers.Dense(15),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      layers.Dense(15),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2),\n",
        "      # layers.Dense(15),\n",
        "      # layers.LeakyReLU(),\n",
        "      # layers.Dropout(rate=0.2),\n",
        "      # layers.Dense(15),\n",
        "      # layers.LeakyReLU(),\n",
        "      # layers.Dropout(rate=0.3),\n",
        "      layers.Dense(2, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_11.compile(\n",
        "    optimizer=tf.keras.optimizers.Adagrad(learning_rate = 0.09),\n",
        "    loss=weighted_loss)\n",
        "\n",
        "bnb_weights"
      ],
      "metadata": {
        "id": "z2drqsGfXyYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e6bcf1-9a97-454f-a512-55d6ee2777d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.734, 1.568])"
            ]
          },
          "metadata": {},
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pGNXK-BGs1T",
        "outputId": "b99170eb-1def-47ad-ccb1-6d5ca714918c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.282, 0.82 ])"
            ]
          },
          "metadata": {},
          "execution_count": 498
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_11.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XYK9HvWCeVOA",
        "outputId": "20650b06-3cc5-495c-e4f4-85b3bc8d1741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m690\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_38 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_39 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">690</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,888\u001b[0m (11.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,888</span> (11.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m962\u001b[0m (3.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">962</span> (3.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,926\u001b[0m (7.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> (7.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_11.predict(bnb_train_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKqZQ4NceMfx",
        "outputId": "103273f2-0b5f-4a36-b278-8a5cf6b71605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(predictions[:, 0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U47oYOuChSnP",
        "outputId": "fbfb688f-1f29-41af-e471-0dc793a6dccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2380,)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logdir=f\"{pwd_parent}/logs/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "history = model_11.fit(\n",
        "    np.array(bnb_train_features),\n",
        "    np.array(bnb_train_target),\n",
        "    epochs=400,\n",
        "    callbacks=[early_stopping],\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    # class_weight={0: bnb_weights[0] + 10, 1: bnb_weights[1]},\n",
        "    # sample_weight=bnb_weights,\n",
        "    validation_split=0.2\n",
        "\n",
        "    # validation_data=(om_train_features[40:50], om_train_target[40:50])\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUfbzVBNYHrJ",
        "outputId": "d18ecf52-0c65-463f-9a69-078386f045d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.3311 - val_loss: -0.0643\n",
            "Epoch 2/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3073 - val_loss: -0.0647\n",
            "Epoch 3/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3785 - val_loss: -0.0623\n",
            "Epoch 4/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.2709 - val_loss: -0.0660\n",
            "Epoch 5/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3609 - val_loss: -0.0585\n",
            "Epoch 6/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2333 - val_loss: -0.0586\n",
            "Epoch 7/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3247 - val_loss: -0.0590\n",
            "Epoch 8/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2542 - val_loss: -0.0588\n",
            "Epoch 9/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2572 - val_loss: -0.0631\n",
            "Epoch 10/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.3119 - val_loss: -0.0615\n",
            "Epoch 11/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2392 - val_loss: -0.0615\n",
            "Epoch 12/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3800 - val_loss: -0.0630\n",
            "Epoch 13/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2699 - val_loss: -0.0625\n",
            "Epoch 14/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3738 - val_loss: -0.0546\n",
            "Epoch 15/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3615 - val_loss: -0.0601\n",
            "Epoch 16/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3527 - val_loss: -0.0610\n",
            "Epoch 17/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3209 - val_loss: -0.0548\n",
            "Epoch 18/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3309 - val_loss: -0.0660\n",
            "Epoch 19/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4724 - val_loss: -0.0623\n",
            "Epoch 20/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4664 - val_loss: -0.0644\n",
            "Epoch 21/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4177 - val_loss: -0.0683\n",
            "Epoch 22/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.3219 - val_loss: -0.0639\n",
            "Epoch 23/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4499 - val_loss: -0.0607\n",
            "Epoch 24/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4626 - val_loss: -0.0523\n",
            "Epoch 25/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5074 - val_loss: -0.0496\n",
            "Epoch 26/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4095 - val_loss: -0.0526\n",
            "Epoch 27/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.3248 - val_loss: -0.0494\n",
            "Epoch 28/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.3228 - val_loss: -0.0516\n",
            "Epoch 29/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4573 - val_loss: -0.0422\n",
            "Epoch 30/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4453 - val_loss: -0.0484\n",
            "Epoch 31/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4218 - val_loss: -0.0314\n",
            "Epoch 32/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4573 - val_loss: -0.0253\n",
            "Epoch 33/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3379 - val_loss: -0.0305\n",
            "Epoch 34/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4661 - val_loss: -0.0423\n",
            "Epoch 35/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4286 - val_loss: -0.0325\n",
            "Epoch 36/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.3352 - val_loss: -0.0224\n",
            "Epoch 37/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.3910 - val_loss: -0.0185\n",
            "Epoch 38/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4478 - val_loss: -0.0116\n",
            "Epoch 39/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4183 - val_loss: 0.0015\n",
            "Epoch 40/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4101 - val_loss: 0.0051\n",
            "Epoch 41/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4657 - val_loss: 0.0067\n",
            "Epoch 42/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5523 - val_loss: 0.0120\n",
            "Epoch 43/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3849 - val_loss: 0.0196\n",
            "Epoch 44/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4819 - val_loss: 0.0167\n",
            "Epoch 45/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4086 - val_loss: 0.0210\n",
            "Epoch 46/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4413 - val_loss: 0.0282\n",
            "Epoch 47/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.4071 - val_loss: 0.0401\n",
            "Epoch 48/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4525 - val_loss: 0.0390\n",
            "Epoch 49/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.4261 - val_loss: 0.0295\n",
            "Epoch 50/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4474 - val_loss: 0.0328\n",
            "Epoch 51/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4773 - val_loss: 0.0327\n",
            "Epoch 52/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4610 - val_loss: 0.0274\n",
            "Epoch 53/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4872 - val_loss: 0.0186\n",
            "Epoch 54/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4807 - val_loss: 0.0377\n",
            "Epoch 55/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4899 - val_loss: 0.0431\n",
            "Epoch 56/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4086 - val_loss: 0.0359\n",
            "Epoch 57/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4641 - val_loss: 0.0404\n",
            "Epoch 58/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4845 - val_loss: 0.0449\n",
            "Epoch 59/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4395 - val_loss: 0.0373\n",
            "Epoch 60/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.4481 - val_loss: 0.0475\n",
            "Epoch 61/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4928 - val_loss: 0.0533\n",
            "Epoch 62/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3834 - val_loss: 0.0508\n",
            "Epoch 63/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4498 - val_loss: 0.0506\n",
            "Epoch 64/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3762 - val_loss: 0.0545\n",
            "Epoch 65/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5321 - val_loss: 0.0556\n",
            "Epoch 66/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4225 - val_loss: 0.0525\n",
            "Epoch 67/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4953 - val_loss: 0.0480\n",
            "Epoch 68/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5347 - val_loss: 0.0464\n",
            "Epoch 69/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5181 - val_loss: 0.0445\n",
            "Epoch 70/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4086 - val_loss: 0.0389\n",
            "Epoch 71/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.3688 - val_loss: 0.0357\n",
            "Epoch 71: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logs = f\"{pwd_parent}/logs\""
      ],
      "metadata": {
        "id": "RRubq9orQv9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir \"/content/drive/MyDrive/JSIP Final Project/logs\""
      ],
      "metadata": {
        "id": "0Ao1xLyfExoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_test_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "SM_P2fIKE3Uk",
        "outputId": "850be137-c055-4b58-cfbc-746520979051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  OP1_AVG  OPX_AVG  OP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "2702      4    3.367    3.306    2.180        0.250000       0.250000   \n",
              "2703      4    7.923    4.939    1.407        0.000000       0.000000   \n",
              "2706      4    3.943    3.391    1.962        0.000000       0.250000   \n",
              "2707      4    3.738    3.133    2.120        0.000000       0.250000   \n",
              "2721      6    7.597    4.782    1.383        0.333333       0.333333   \n",
              "...     ...      ...      ...      ...             ...            ...   \n",
              "3380     34    3.573    3.536    1.993        0.323529       0.235294   \n",
              "3382     34    6.293    4.738    1.430        0.117647       0.264706   \n",
              "3394     35    4.289    3.504    1.819        0.285714       0.371429   \n",
              "3397     35    3.496    3.374    2.060        0.285714       0.200000   \n",
              "3398     35    5.376    4.774    1.484        0.057143       0.314286   \n",
              "\n",
              "      home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  OP1_RATE  \\\n",
              "2702        0.500000        0.000000       0.250000        0.750000  0.380323   \n",
              "2703        1.000000        0.750000       0.250000        0.000000  0.555260   \n",
              "2706        0.750000        0.500000       0.250000        0.250000  0.424161   \n",
              "2707        0.750000        0.500000       0.250000        0.250000  0.415749   \n",
              "2721        0.333333        0.833333       0.166667        0.000000  0.552027   \n",
              "...              ...             ...            ...             ...       ...   \n",
              "3380        0.441176        0.676471       0.147059        0.176471  0.392551   \n",
              "3382        0.617647        0.794118       0.176471        0.029412  0.505016   \n",
              "3394        0.342857        0.628571       0.114286        0.257143  0.446213   \n",
              "3397        0.514286        0.400000       0.371429        0.228571  0.391489   \n",
              "3398        0.628571        0.657143       0.200000        0.142857  0.462094   \n",
              "\n",
              "      OPX_RATE  OP2_RATE  Alaves  Almeria  Ath Bilbao  Atl. Madrid  Barcelona  \\\n",
              "2702  0.373433  0.246244       0        0           0            0          0   \n",
              "2703  0.346135  0.098605       0        0           0            0          1   \n",
              "2706  0.364781  0.211059       0        0           1            0          0   \n",
              "2707  0.348460  0.235791       0        0           0            0          0   \n",
              "2721  0.347479  0.100494       0        0           0            0          1   \n",
              "...        ...       ...     ...      ...         ...          ...        ...   \n",
              "3380  0.388486  0.218963       2        0           0            0          0   \n",
              "3382  0.380226  0.114758       0        0           0            0          0   \n",
              "3394  0.364544  0.189243       0        0           0            1          0   \n",
              "3397  0.377828  0.230683       0        0           0            0          0   \n",
              "3398  0.410349  0.127557       0        2           0            0          1   \n",
              "\n",
              "      Betis  Cadiz CF  Celta Vigo  Dep. La Coruna  Eibar  Elche  Espanyol  \\\n",
              "2702      0         0           0               0      0      0         2   \n",
              "2703      0         2           0               0      0      0         0   \n",
              "2706      0         0           0               0      0      2         0   \n",
              "2707      0         0           0               0      0      0         0   \n",
              "2721      0         0           0               0      0      0         0   \n",
              "...     ...       ...         ...             ...    ...    ...       ...   \n",
              "3380      0         0           0               0      0      0         0   \n",
              "3382      0         0           0               0      0      0         0   \n",
              "3394      0         0           0               0      0      0         0   \n",
              "3397      1         0           0               0      0      0         0   \n",
              "3398      0         0           0               0      0      0         0   \n",
              "\n",
              "      Getafe  Gijon  Girona  Granada CF  Huesca  Las Palmas  Leganes  Levante  \\\n",
              "2702       0      0       0           0       0           0        0        0   \n",
              "2703       0      0       0           0       0           0        0        0   \n",
              "2706       0      0       0           0       0           0        0        0   \n",
              "2707       2      0       0           0       0           0        0        0   \n",
              "2721       0      0       0           0       0           0        0        0   \n",
              "...      ...    ...     ...         ...     ...         ...      ...      ...   \n",
              "3380       0      0       1           0       0           0        0        0   \n",
              "3382       0      0       0           2       0           0        0        0   \n",
              "3394       2      0       0           0       0           0        0        0   \n",
              "3397       0      0       0           0       0           2        0        0   \n",
              "3398       0      0       0           0       0           0        0        0   \n",
              "\n",
              "      Malaga  Mallorca  Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  \\\n",
              "2702       0         0        0               0            0              0   \n",
              "2703       0         0        0               0            0              0   \n",
              "2706       0         0        0               0            0              0   \n",
              "2707       0         0        0               0            0              1   \n",
              "2721       0         2        0               0            0              0   \n",
              "...      ...       ...      ...             ...          ...            ...   \n",
              "3380       0         0        0               0            0              0   \n",
              "3382       0         0        0               0            1              0   \n",
              "3394       0         0        0               0            0              0   \n",
              "3397       0         0        0               0            0              0   \n",
              "3398       0         0        0               0            0              0   \n",
              "\n",
              "      Sevilla  Valencia  Valladolid  Villarreal  HOME_POWER  OP_SUM  \n",
              "2702        1         0           0           0    3.000000   8.853  \n",
              "2703        0         0           0           0    0.000000  14.269  \n",
              "2706        0         0           0           0    0.200000   9.296  \n",
              "2707        0         0           0           0    0.200000   8.991  \n",
              "2721        0         0           0           0    0.545455  13.762  \n",
              "...       ...       ...         ...         ...         ...     ...  \n",
              "3380        0         0           0           0    0.588235   9.102  \n",
              "3382        0         0           0           0    0.283333  12.461  \n",
              "3394        0         0           0           0    0.687500   9.612  \n",
              "3397        0         0           0           0    0.658537   8.930  \n",
              "3398        0         0           0           0    0.283019  11.634  \n",
              "\n",
              "[104 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7911c6c8-ec65-40e6-bb8e-253ba9f4508d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>HOME_POWER</th>\n",
              "      <th>OP_SUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>4</td>\n",
              "      <td>3.367</td>\n",
              "      <td>3.306</td>\n",
              "      <td>2.180</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.380323</td>\n",
              "      <td>0.373433</td>\n",
              "      <td>0.246244</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703</th>\n",
              "      <td>4</td>\n",
              "      <td>7.923</td>\n",
              "      <td>4.939</td>\n",
              "      <td>1.407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555260</td>\n",
              "      <td>0.346135</td>\n",
              "      <td>0.098605</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2706</th>\n",
              "      <td>4</td>\n",
              "      <td>3.943</td>\n",
              "      <td>3.391</td>\n",
              "      <td>1.962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.424161</td>\n",
              "      <td>0.364781</td>\n",
              "      <td>0.211059</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>9.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2707</th>\n",
              "      <td>4</td>\n",
              "      <td>3.738</td>\n",
              "      <td>3.133</td>\n",
              "      <td>2.120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.415749</td>\n",
              "      <td>0.348460</td>\n",
              "      <td>0.235791</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>8.991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2721</th>\n",
              "      <td>6</td>\n",
              "      <td>7.597</td>\n",
              "      <td>4.782</td>\n",
              "      <td>1.383</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552027</td>\n",
              "      <td>0.347479</td>\n",
              "      <td>0.100494</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>13.762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>34</td>\n",
              "      <td>3.573</td>\n",
              "      <td>3.536</td>\n",
              "      <td>1.993</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>0.147059</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.392551</td>\n",
              "      <td>0.388486</td>\n",
              "      <td>0.218963</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>9.102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3382</th>\n",
              "      <td>34</td>\n",
              "      <td>6.293</td>\n",
              "      <td>4.738</td>\n",
              "      <td>1.430</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.505016</td>\n",
              "      <td>0.380226</td>\n",
              "      <td>0.114758</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>12.461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3394</th>\n",
              "      <td>35</td>\n",
              "      <td>4.289</td>\n",
              "      <td>3.504</td>\n",
              "      <td>1.819</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.114286</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.446213</td>\n",
              "      <td>0.364544</td>\n",
              "      <td>0.189243</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>9.612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>35</td>\n",
              "      <td>3.496</td>\n",
              "      <td>3.374</td>\n",
              "      <td>2.060</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.391489</td>\n",
              "      <td>0.377828</td>\n",
              "      <td>0.230683</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>8.930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>35</td>\n",
              "      <td>5.376</td>\n",
              "      <td>4.774</td>\n",
              "      <td>1.484</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.410349</td>\n",
              "      <td>0.127557</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283019</td>\n",
              "      <td>11.634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7911c6c8-ec65-40e6-bb8e-253ba9f4508d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7911c6c8-ec65-40e6-bb8e-253ba9f4508d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7911c6c8-ec65-40e6-bb8e-253ba9f4508d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3f46a1f-6fbd-419f-8005-ce8f4262b042\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3f46a1f-6fbd-419f-8005-ce8f4262b042')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3f46a1f-6fbd-419f-8005-ce8f4262b042 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ae847ba8-4996-423d-b14e-07eda8e011da\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bnb_test_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae847ba8-4996-423d-b14e-07eda8e011da button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bnb_test_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bnb_test_features"
            }
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# max_symbol = 1\n",
        "# mid_symbol = 3\n",
        "# min_symbol = 0\n",
        "# bnb_test_hda = bnb_test[(bnb_test[\"OP_MAX_ODD\"] == max_symbol) & (bnb_test[\"OP_MID_ODD\"] == mid_symbol) & (bnb_test[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "# target = bnb_test_hda[comp_label]\n",
        "target = bnb_test_target\n",
        "features = bnb_test_features\n",
        "# target = bnb_train_target\n",
        "# features = bnb_train_features\n",
        "num = len(target)\n",
        "target = target[:num]\n",
        "# features = bnb_test_hda.drop(columns=[comp_label])\n",
        "features = features[:num]\n",
        "# comp_data = bnb_train[comp_label][:num]\n",
        "\n",
        "predictions = model_11.predict(features)\n",
        "\n",
        "# predictions = predictions.flatten()\n",
        "print(predictions)\n",
        "prob_no_bet = predictions[:, 0]\n",
        "prob_bet = predictions[:, 1]\n",
        "sum = 0\n",
        "correct_choice = 0\n",
        "is_positive = 0\n",
        "\n",
        "pred_bet_correct = 0\n",
        "pred_bet_num = 0\n",
        "pred_nb_correct = 0\n",
        "pred_nb_num = 0\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "# predicted_classes = [1 if nb < .4 else 0 for nb, b in predictions]\n",
        "# nb < .4 is generally good?\n",
        "# print(predicted_classes)\n",
        "true_classes = np.array(target)[:, 1]\n",
        "# print(true_classes.dtype)\n",
        "# print(target.dtype)\n",
        "for nb, b, predicted_class, true_class, odds in zip(prob_no_bet, prob_bet, predicted_classes, true_classes, features[odds_label]):\n",
        "  added = 0\n",
        "  if true_class == 1:\n",
        "    is_positive += 1\n",
        "\n",
        "  if predicted_class == 1:\n",
        "    pred_bet_num += 1\n",
        "    added = -1\n",
        "    if predicted_class == true_class:\n",
        "      pred_bet_correct += 1\n",
        "      added = odds -1\n",
        "      correct_choice += 1\n",
        "  else:\n",
        "    pred_nb_num += 1\n",
        "    if predicted_class == true_class:\n",
        "      pred_nb_correct += 1\n",
        "      correct_choice += 1\n",
        "\n",
        "  sum += added\n",
        "  print(f\"nb: {format(nb, '.3f')}, b: {format(b, '.3f')} pred_class: {predicted_class}, true: {true_class}, added {format(added, '.3f')}\")\n",
        "\n",
        "get_dir_dataset_stats(bnb_test, curr_label)\n",
        "loss = weighted_loss(np.array(target), predictions)\n",
        "print(f\"loss: {format(loss, '.4f')}\")\n",
        "print_percent_str(f\"{symbol} correct of total\", is_positive, num)\n",
        "print_percent_str(\"bet\", pred_bet_num, num)\n",
        "print_percent_str(\"correct choice of total\", correct_choice, num)\n",
        "\n",
        "print_percent_str(\"pred no bet accuracy\", pred_nb_correct, pred_nb_num)\n",
        "print_percent_str(\"pred bet accuracy\", pred_bet_correct, pred_bet_num)\n",
        "\n",
        "print_percent_str(\"ev\", sum, pred_bet_num)\n",
        "# compare_predictions_single(predictions, comp_data, target)\n",
        "# get_mse(predictions, comp_data, target, om_test.iloc[:num])\n",
        "\n",
        "\n",
        "plot_confusion_matrix(true_classes, predicted_classes, [\"NB\", \"B\"], \"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fMve01neFIO6",
        "outputId": "e6a07d34-0f02-4454-a048-5e396a6f847e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "[[0.362 1.   ]\n",
            " [0.345 0.738]\n",
            " [0.214 1.   ]\n",
            " [0.91  0.   ]\n",
            " [0.938 0.   ]\n",
            " [0.49  0.998]\n",
            " [0.976 0.   ]\n",
            " [0.964 0.   ]\n",
            " [0.481 0.995]\n",
            " [0.651 0.999]\n",
            " [0.95  0.   ]\n",
            " [0.441 0.736]\n",
            " [0.662 0.349]\n",
            " [0.429 0.994]\n",
            " [0.093 1.   ]\n",
            " [0.357 0.931]\n",
            " [1.    0.   ]\n",
            " [0.732 0.   ]\n",
            " [0.673 0.999]\n",
            " [0.722 0.   ]\n",
            " [0.703 0.   ]\n",
            " [0.797 0.   ]\n",
            " [0.584 0.012]\n",
            " [0.837 0.   ]\n",
            " [0.324 0.938]\n",
            " [1.    0.   ]\n",
            " [0.351 0.969]\n",
            " [0.566 0.   ]\n",
            " [0.659 0.001]\n",
            " [0.623 0.51 ]\n",
            " [0.765 0.   ]\n",
            " [1.    0.   ]\n",
            " [0.64  0.   ]\n",
            " [0.512 0.898]\n",
            " [0.894 0.   ]\n",
            " [0.383 0.98 ]\n",
            " [0.812 0.   ]\n",
            " [0.548 0.   ]\n",
            " [0.43  0.996]\n",
            " [0.547 0.016]\n",
            " [0.374 0.995]\n",
            " [0.962 0.   ]\n",
            " [0.389 0.998]\n",
            " [0.571 0.   ]\n",
            " [1.    0.   ]\n",
            " [0.853 0.   ]\n",
            " [0.334 0.96 ]\n",
            " [0.135 1.   ]\n",
            " [0.745 0.016]\n",
            " [1.    0.   ]\n",
            " [0.385 1.   ]\n",
            " [0.391 0.919]\n",
            " [0.658 0.876]\n",
            " [0.946 0.   ]\n",
            " [0.689 0.729]\n",
            " [0.968 0.   ]\n",
            " [0.844 0.052]\n",
            " [0.495 0.891]\n",
            " [0.804 0.006]\n",
            " [0.96  0.   ]\n",
            " [0.51  0.612]\n",
            " [0.939 0.   ]\n",
            " [0.795 0.021]\n",
            " [0.634 0.415]\n",
            " [1.    0.   ]\n",
            " [0.637 0.517]\n",
            " [0.986 0.   ]\n",
            " [1.    0.   ]\n",
            " [0.965 0.   ]\n",
            " [0.587 0.034]\n",
            " [1.    0.   ]\n",
            " [0.953 0.   ]\n",
            " [0.817 0.931]\n",
            " [0.974 0.   ]\n",
            " [0.607 0.   ]\n",
            " [0.905 0.   ]\n",
            " [0.986 0.   ]\n",
            " [0.583 0.583]\n",
            " [0.979 0.   ]\n",
            " [1.    0.   ]\n",
            " [0.949 0.   ]\n",
            " [0.838 0.001]\n",
            " [0.598 0.989]\n",
            " [0.982 0.   ]\n",
            " [1.    0.   ]\n",
            " [0.872 0.   ]\n",
            " [0.937 0.   ]\n",
            " [0.782 0.001]\n",
            " [0.48  0.953]\n",
            " [0.596 0.004]\n",
            " [0.544 0.997]\n",
            " [0.957 0.   ]\n",
            " [0.658 0.215]\n",
            " [0.672 0.337]\n",
            " [0.334 0.965]\n",
            " [0.77  0.341]]\n",
            "nb: 0.362, b: 1.000 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.345, b: 0.738 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.214, b: 1.000 pred_class: 1, true: 1.0, added 2.290\n",
            "nb: 0.910, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.938, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.490, b: 0.998 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.976, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.964, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.481, b: 0.995 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.651, b: 0.999 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.950, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.441, b: 0.736 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.662, b: 0.349 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.429, b: 0.994 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.093, b: 1.000 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.357, b: 0.931 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.732, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.673, b: 0.999 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.722, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.703, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.797, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.584, b: 0.012 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.837, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.324, b: 0.938 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.351, b: 0.969 pred_class: 1, true: 1.0, added 2.152\n",
            "nb: 0.566, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.659, b: 0.001 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.623, b: 0.510 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.765, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.640, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.512, b: 0.898 pred_class: 1, true: 1.0, added 2.232\n",
            "nb: 0.894, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.383, b: 0.980 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.812, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.548, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.430, b: 0.996 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.547, b: 0.016 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.374, b: 0.995 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.962, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.389, b: 0.998 pred_class: 1, true: 1.0, added 2.527\n",
            "nb: 0.571, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.853, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.334, b: 0.960 pred_class: 1, true: 1.0, added 2.413\n",
            "nb: 0.135, b: 1.000 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.745, b: 0.016 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.385, b: 1.000 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.391, b: 0.919 pred_class: 1, true: 1.0, added 2.516\n",
            "nb: 0.658, b: 0.876 pred_class: 1, true: 1.0, added 2.337\n",
            "nb: 0.946, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.689, b: 0.729 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.968, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.844, b: 0.052 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.495, b: 0.891 pred_class: 1, true: 1.0, added 2.605\n",
            "nb: 0.804, b: 0.006 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.960, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.510, b: 0.612 pred_class: 1, true: 1.0, added 2.226\n",
            "nb: 0.939, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.795, b: 0.021 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.634, b: 0.415 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.637, b: 0.517 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.986, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.965, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.587, b: 0.034 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.953, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.817, b: 0.931 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.974, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.607, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.905, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.986, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.583, b: 0.583 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.979, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.949, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.838, b: 0.001 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.598, b: 0.989 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.982, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 1.000, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.872, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.937, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.782, b: 0.001 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.480, b: 0.953 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.596, b: 0.004 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.544, b: 0.997 pred_class: 1, true: 1.0, added 2.986\n",
            "nb: 0.957, b: 0.000 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.658, b: 0.215 pred_class: 0, true: 0.0, added 0.000\n",
            "nb: 0.672, b: 0.337 pred_class: 0, true: 1.0, added 0.000\n",
            "nb: 0.334, b: 0.965 pred_class: 1, true: 0.0, added -1.000\n",
            "nb: 0.770, b: 0.341 pred_class: 0, true: 0.0, added 0.000\n",
            "U% : 28.125%, 27/96; D% : 71.875%, 69/96\n",
            "loss: -0.0035\n",
            "D correct of total: 28.125%      27.000/96\n",
            "bet: 32.292%      31.000/96\n",
            "correct choice of total: 60.417%      58.000/96\n",
            "pred no bet accuracy: 73.846%      48.000/65\n",
            "pred bet accuracy: 32.258%      10.000/31\n",
            "ev: 10.594%      3.284/31\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"BNB_DHAD_60C_32B_10EV.keras\"\n",
        "model_path = f\"{model_save_pwd}/{model_name}\"\n",
        "model_11.save(f\"{model_path}\")\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNd3d8XJH9pE",
        "outputId": "6d5f3376-b467-41e9-8280-f04ee7991c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/JSIP Final Project/models/BNB_DHAD_60C_32B_10EV.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bet or no bet decision\n"
      ],
      "metadata": {
        "id": "iHv0r34RX7T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_with_result = get_dataset_with_season()"
      ],
      "metadata": {
        "id": "Fx8kqUMvZB-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnbd_dataset = get_stat_percent_database(dataset_with_result.copy())\n",
        "# bnbd_dataset = get_diff_database(bnbd_dataset)\n",
        "bnbd_dataset = get_odds_percent_database(bnbd_dataset)\n",
        "# bnbd_dataset = get_odds_percent_database_closing(bnbd_dataset)\n",
        "# bnbd_dataset = get_dir_database(bnbd_dataset)\n",
        "bnbd_dataset = get_weighted_OHE_dataset(bnbd_dataset)\n",
        "bnbd_dataset = get_power_database(bnbd_dataset)\n",
        "# bnbd_dataset[\"MAX_DIFF\"] = get_max_diff(bnbd_dataset)\n",
        "bnbd_dataset = get_odds_rankings(bnbd_dataset, True)\n",
        "# bnbd_dataset = get_odds_rankings(bnbd_dataset, False)\n",
        "bnbd_dataset = bnbd_dataset.drop(index=bnbd_dataset[bnbd_dataset.games < 4].index)\n",
        "bnbd_dataset[\"OP_SUM\"] = bnbd_dataset[\"OP1_AVG\"] + bnbd_dataset[\"OPX_AVG\"] + bnbd_dataset[\"OP2_AVG\"]\n",
        "# bnbd_dataset[\"CP_SUM\"] = bnbd_dataset[\"CP1_AVG\"] + bnbd_dataset[\"CPX_AVG\"] + bnbd_dataset[\"CP2_AVG\"]\n",
        "max_symbol = \"A\"\n",
        "mid_symbol = \"D\"\n",
        "min_symbol = \"H\"\n",
        "bnbd_dataset = bnbd_dataset[(bnbd_dataset[\"OP_MAX_ODD\"] == max_symbol) & (bnbd_dataset[\"OP_MID_ODD\"] == mid_symbol) & (bnbd_dataset[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "# bnbd_dataset[\"OP_MIN_ODD_NUM\"] = bnbd_dataset[\"OP_MIN_ODD\"].apply(lambda x: -10 if x == \"H\" else 0 if x == \"D\" else 10)\n",
        "# bnbd_dataset[\"OP_MID_ODD_NUM\"] = bnbd_dataset[\"OP_MID_ODD\"].apply(lambda x: -10 if x == \"H\" else 0 if x == \"D\" else 10)\n",
        "# bnbd_dataset[\"OP_MAX_ODD_NUM\"] = bnbd_dataset[\"OP_MAX_ODD\"].apply(lambda x: -10 if x == \"H\" else 0 if x == \"D\" else 10)\n",
        "bnbd_dataset\n",
        "for symbol in [\"H\", \"D\", \"A\"]:\n",
        "  bnbd_dataset[f\"result_{symbol}\"] = bnbd_dataset[\"result\"].apply(lambda x: 1 if x == symbol else 0)\n",
        "  # bnbd_dataset\n",
        "bnbd_dataset = bnbd_dataset.drop(columns=[\"OP_MAX_ODD\", \"OP_MID_ODD\", \"OP_MIN_ODD\", \"CP1_AVG\", \"CPX_AVG\", \"CP2_AVG\", \"result\", \"date\"])\n",
        "labels = [\"result_H\", \"result_D\", \"result_A\"]\n",
        "# curr_label = f\"result_{symbol}\"\n",
        "bnbd_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "WZ3dww36YA8m",
        "outputId": "2fd81e12-a39a-4cff-eaf5-0a2cef6d70d5"
      },
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games     season  OP1_AVG  OPX_AVG  OP2_AVG  home_wins_rate  \\\n",
              "42        4  2015/2016    1.244    5.543   13.128        0.750000   \n",
              "43        4  2015/2016    2.113    3.384    3.412        0.250000   \n",
              "44        4  2015/2016    2.382    3.094    3.138        0.000000   \n",
              "49        4  2015/2016    2.133    3.250    3.476        0.250000   \n",
              "50        5  2015/2016    1.454    4.365    7.080        0.200000   \n",
              "...     ...        ...      ...      ...      ...             ...   \n",
              "3407     36  2023/2024    1.641    3.705    5.390        0.194444   \n",
              "3409     36  2023/2024    1.910    3.316    4.213        0.166667   \n",
              "3410     37  2023/2024    1.241    6.417    9.689        0.648649   \n",
              "3415     37  2023/2024    1.314    5.714    7.809        0.783784   \n",
              "3419     37  2023/2024    1.861    3.684    3.929        0.270270   \n",
              "\n",
              "      home_tie_rate  home_loss_rate  away_wins_rate  away_tie_rate  \\\n",
              "42         0.000000        0.250000        0.250000       0.000000   \n",
              "43         0.250000        0.500000        0.250000       0.500000   \n",
              "44         0.500000        0.500000        0.500000       0.250000   \n",
              "49         0.500000        0.250000        0.250000       0.500000   \n",
              "50         0.600000        0.200000        0.200000       0.000000   \n",
              "...             ...             ...             ...            ...   \n",
              "3407       0.416667        0.388889        0.055556       0.305556   \n",
              "3409       0.388889        0.444444        0.277778       0.222222   \n",
              "3410       0.162162        0.189189        0.108108       0.243243   \n",
              "3415       0.189189        0.027027        0.378378       0.378378   \n",
              "3419       0.270270        0.459459        0.351351       0.243243   \n",
              "\n",
              "      away_loss_rate  OP1_RATE  OPX_RATE  OP2_RATE  Alaves  Almeria  \\\n",
              "42          0.750000  0.062465  0.278333  0.659202       0        0   \n",
              "43          0.250000  0.237176  0.379841  0.382983       0        0   \n",
              "44          0.250000  0.276527  0.359183  0.364291       0        0   \n",
              "49          0.250000  0.240772  0.366859  0.392369       0        0   \n",
              "50          0.800000  0.112722  0.338398  0.548880       0        0   \n",
              "...              ...       ...       ...       ...     ...      ...   \n",
              "3407        0.638889  0.152850  0.345101  0.502049       0        1   \n",
              "3409        0.500000  0.202352  0.351308  0.446340       0        0   \n",
              "3410        0.648649  0.071540  0.369920  0.558540       0        0   \n",
              "3415        0.243243  0.088562  0.385118  0.526319       0        0   \n",
              "3419        0.405405  0.196432  0.388854  0.414714       0        0   \n",
              "\n",
              "      Ath Bilbao  Atl. Madrid  Barcelona  Betis  Cadiz CF  Celta Vigo  \\\n",
              "42             0            2          0      0         0           0   \n",
              "43             0            0          0      0         0           0   \n",
              "44             0            0          0      0         0           0   \n",
              "49             0            0          0      2         0           0   \n",
              "50             0            0          0      0         0           0   \n",
              "...          ...          ...        ...    ...       ...         ...   \n",
              "3407           0            0          0      0         0           0   \n",
              "3409           0            0          0      0         2           0   \n",
              "3410           0            0          0      0         0           0   \n",
              "3415           0            0          0      1         0           0   \n",
              "3419           0            0          0      0         0           2   \n",
              "\n",
              "      Dep. La Coruna  Eibar  Elche  Espanyol  Getafe  Gijon  Girona  \\\n",
              "42                 0      0      0         0       1      0       0   \n",
              "43                 0      0      0         0       0      1       0   \n",
              "44                 0      1      0         0       0      0       0   \n",
              "49                 1      0      0         0       0      0       0   \n",
              "50                 0      0      0         0       0      0       0   \n",
              "...              ...    ...    ...       ...     ...    ...     ...   \n",
              "3407               0      0      0         0       0      0       0   \n",
              "3409               0      0      0         0       0      0       0   \n",
              "3410               0      0      0         0       0      0       2   \n",
              "3415               0      0      0         0       0      0       0   \n",
              "3419               0      0      0         0       0      0       0   \n",
              "\n",
              "      Granada CF  Huesca  Las Palmas  Leganes  Levante  Malaga  Mallorca  \\\n",
              "42             0       0           0        0        0       0         0   \n",
              "43             0       0           0        0        0       0         0   \n",
              "44             0       0           0        0        2       0         0   \n",
              "49             0       0           0        0        0       0         0   \n",
              "50             1       0           0        0        0       0         0   \n",
              "...          ...     ...         ...      ...      ...     ...       ...   \n",
              "3407           0       0           0        0        0       0         2   \n",
              "3409           0       0           1        0        0       0         0   \n",
              "3410           1       0           0        0        0       0         0   \n",
              "3415           0       0           0        0        0       0         0   \n",
              "3419           0       0           0        0        0       0         0   \n",
              "\n",
              "      Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  Sevilla  Valencia  \\\n",
              "42          0               0            0              0        0         0   \n",
              "43          0               2            0              0        0         0   \n",
              "44          0               0            0              0        0         0   \n",
              "49          0               0            0              0        0         0   \n",
              "50          0               0            0              0        0         2   \n",
              "...       ...             ...          ...            ...      ...       ...   \n",
              "3407        0               0            0              0        0         0   \n",
              "3409        0               0            0              0        0         0   \n",
              "3410        0               0            0              0        0         0   \n",
              "3415        0               0            2              0        0         0   \n",
              "3419        0               0            0              0        0         1   \n",
              "\n",
              "      Valladolid  Villarreal  HOME_POWER  OP_SUM  result_H  result_D  result_A  \n",
              "42             0           0    3.000000  19.915         1         0         0  \n",
              "43             0           0    0.750000   8.909         1         0         0  \n",
              "44             0           0    0.400000   8.614         0         1         0  \n",
              "49             0           0    1.000000   8.859         0         0         1  \n",
              "50             0           0    2.500000  12.899         1         0         0  \n",
              "...          ...         ...         ...     ...       ...       ...       ...  \n",
              "3407           0           0    1.933333  10.736         0         1         0  \n",
              "3409           0           0    0.928571   9.439         0         1         0  \n",
              "3410           0           0    3.176471  17.347         1         0         0  \n",
              "3415           0           0    1.547619  14.837         0         1         0  \n",
              "3419           0           0    0.857143   9.474         0         1         0  \n",
              "\n",
              "[1688 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d794e36d-2d0b-4289-9153-77502e370cc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>season</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>HOME_POWER</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>result_H</th>\n",
              "      <th>result_D</th>\n",
              "      <th>result_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>1.244</td>\n",
              "      <td>5.543</td>\n",
              "      <td>13.128</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.062465</td>\n",
              "      <td>0.278333</td>\n",
              "      <td>0.659202</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>19.915</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.113</td>\n",
              "      <td>3.384</td>\n",
              "      <td>3.412</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.237176</td>\n",
              "      <td>0.379841</td>\n",
              "      <td>0.382983</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>8.909</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.382</td>\n",
              "      <td>3.094</td>\n",
              "      <td>3.138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.276527</td>\n",
              "      <td>0.359183</td>\n",
              "      <td>0.364291</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>8.614</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>4</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>2.133</td>\n",
              "      <td>3.250</td>\n",
              "      <td>3.476</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.240772</td>\n",
              "      <td>0.366859</td>\n",
              "      <td>0.392369</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.859</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>5</td>\n",
              "      <td>2015/2016</td>\n",
              "      <td>1.454</td>\n",
              "      <td>4.365</td>\n",
              "      <td>7.080</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.112722</td>\n",
              "      <td>0.338398</td>\n",
              "      <td>0.548880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>12.899</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3407</th>\n",
              "      <td>36</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>1.641</td>\n",
              "      <td>3.705</td>\n",
              "      <td>5.390</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.152850</td>\n",
              "      <td>0.345101</td>\n",
              "      <td>0.502049</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.933333</td>\n",
              "      <td>10.736</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3409</th>\n",
              "      <td>36</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>1.910</td>\n",
              "      <td>3.316</td>\n",
              "      <td>4.213</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.202352</td>\n",
              "      <td>0.351308</td>\n",
              "      <td>0.446340</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>9.439</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3410</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>1.241</td>\n",
              "      <td>6.417</td>\n",
              "      <td>9.689</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.071540</td>\n",
              "      <td>0.369920</td>\n",
              "      <td>0.558540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.176471</td>\n",
              "      <td>17.347</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>1.314</td>\n",
              "      <td>5.714</td>\n",
              "      <td>7.809</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.385118</td>\n",
              "      <td>0.526319</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.547619</td>\n",
              "      <td>14.837</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3419</th>\n",
              "      <td>37</td>\n",
              "      <td>2023/2024</td>\n",
              "      <td>1.861</td>\n",
              "      <td>3.684</td>\n",
              "      <td>3.929</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.243243</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.196432</td>\n",
              "      <td>0.388854</td>\n",
              "      <td>0.414714</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>9.474</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1688 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d794e36d-2d0b-4289-9153-77502e370cc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d794e36d-2d0b-4289-9153-77502e370cc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d794e36d-2d0b-4289-9153-77502e370cc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c4b4405-65da-4183-9793-3f3a11f87c87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c4b4405-65da-4183-9793-3f3a11f87c87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c4b4405-65da-4183-9793-3f3a11f87c87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1243773b-89d7-4ce7-a42b-cfd32c768db7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bnbd_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1243773b-89d7-4ce7-a42b-cfd32c768db7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bnbd_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bnbd_dataset"
            }
          },
          "metadata": {},
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 'combo': ('D', 'H', 'A'), 'symbol': 'D',\n",
        "\n",
        "\n",
        "bnbd_test = bnbd_dataset[(bnbd_dataset[\"season\"] == \"2023/2024\") | (bnbd_dataset[\"season\"] == \"2022/2023\")]\n",
        "bnbd_test = bnbd_test.drop(columns=[\"season\"])\n",
        "bnbd_train = bnbd_dataset.drop(index=bnbd_test.index)\n",
        "bnbd_train = bnbd_train.drop(columns=[\"season\"])\n",
        "print(f\"train len: {len(bnbd_train)}, test len {len(bnbd_test)}\")\n",
        "bnbd_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "vXvLWopZaI0r",
        "outputId": "72f0261f-ba75-46d8-d743-04dffbbe1bbb"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train len: 1320, test len 368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      games  OP1_AVG  OPX_AVG  OP2_AVG  home_wins_rate  home_tie_rate  \\\n",
              "42        4    1.244    5.543   13.128        0.750000       0.000000   \n",
              "43        4    2.113    3.384    3.412        0.250000       0.250000   \n",
              "44        4    2.382    3.094    3.138        0.000000       0.500000   \n",
              "49        4    2.133    3.250    3.476        0.250000       0.500000   \n",
              "50        5    1.454    4.365    7.080        0.200000       0.600000   \n",
              "...     ...      ...      ...      ...             ...            ...   \n",
              "2647     36    2.048    3.554    3.605        0.166667       0.305556   \n",
              "2648     36    1.973    3.273    4.363        0.222222       0.250000   \n",
              "2650     37    1.674    4.271    4.515        0.702703       0.189189   \n",
              "2653     37    2.114    3.446    3.538        0.459459       0.432432   \n",
              "2658     37    1.754    3.863    4.736        0.216216       0.351351   \n",
              "\n",
              "      home_loss_rate  away_wins_rate  away_tie_rate  away_loss_rate  OP1_RATE  \\\n",
              "42          0.250000        0.250000       0.000000        0.750000  0.062465   \n",
              "43          0.500000        0.250000       0.500000        0.250000  0.237176   \n",
              "44          0.500000        0.500000       0.250000        0.250000  0.276527   \n",
              "49          0.250000        0.250000       0.500000        0.250000  0.240772   \n",
              "50          0.200000        0.200000       0.000000        0.800000  0.112722   \n",
              "...              ...             ...            ...             ...       ...   \n",
              "2647        0.527778        0.222222       0.194444        0.583333  0.222439   \n",
              "2648        0.527778        0.305556       0.250000        0.444444  0.205328   \n",
              "2650        0.108108        0.513514       0.189189        0.297297  0.160038   \n",
              "2653        0.108108        0.378378       0.351351        0.270270  0.232359   \n",
              "2658        0.432432        0.270270       0.297297        0.432432  0.169419   \n",
              "\n",
              "      OPX_RATE  OP2_RATE  Alaves  Almeria  Ath Bilbao  Atl. Madrid  Barcelona  \\\n",
              "42    0.278333  0.659202       0        0           0            2          0   \n",
              "43    0.379841  0.382983       0        0           0            0          0   \n",
              "44    0.359183  0.364291       0        0           0            0          0   \n",
              "49    0.366859  0.392369       0        0           0            0          0   \n",
              "50    0.338398  0.548880       0        0           0            0          0   \n",
              "...        ...       ...     ...      ...         ...          ...        ...   \n",
              "2647  0.386011  0.391550       1        0           0            0          0   \n",
              "2648  0.340618  0.454053       0        0           0            0          0   \n",
              "2650  0.408317  0.431644       0        0           0            0          0   \n",
              "2653  0.378765  0.388877       0        0           1            0          0   \n",
              "2658  0.373129  0.457452       0        0           0            0          0   \n",
              "\n",
              "      Betis  Cadiz CF  Celta Vigo  Dep. La Coruna  Eibar  Elche  Espanyol  \\\n",
              "42        0         0           0               0      0      0         0   \n",
              "43        0         0           0               0      0      0         0   \n",
              "44        0         0           0               0      1      0         0   \n",
              "49        2         0           0               1      0      0         0   \n",
              "50        0         0           0               0      0      0         0   \n",
              "...     ...       ...         ...             ...    ...    ...       ...   \n",
              "2647      0         0           0               0      0      0         0   \n",
              "2648      0         0           0               0      0      0         0   \n",
              "2650      1         0           0               0      0      0         0   \n",
              "2653      0         0           0               0      0      0         0   \n",
              "2658      0         0           0               0      0      0         1   \n",
              "\n",
              "      Getafe  Gijon  Girona  Granada CF  Huesca  Las Palmas  Leganes  Levante  \\\n",
              "42         1      0       0           0       0           0        0        0   \n",
              "43         0      1       0           0       0           0        0        0   \n",
              "44         0      0       0           0       0           0        0        2   \n",
              "49         0      0       0           0       0           0        0        0   \n",
              "50         0      0       0           1       0           0        0        0   \n",
              "...      ...    ...     ...         ...     ...         ...      ...      ...   \n",
              "2647       0      0       0           0       0           0        0        2   \n",
              "2648       0      0       0           0       0           0        0        0   \n",
              "2650       0      0       0           0       0           0        0        0   \n",
              "2653       0      0       0           0       0           0        0        0   \n",
              "2658       0      0       0           2       0           0        0        0   \n",
              "\n",
              "      Malaga  Mallorca  Osasuna  Rayo Vallecano  Real Madrid  Real Sociedad  \\\n",
              "42         0         0        0               0            0              0   \n",
              "43         0         0        0               2            0              0   \n",
              "44         0         0        0               0            0              0   \n",
              "49         0         0        0               0            0              0   \n",
              "50         0         0        0               0            0              0   \n",
              "...      ...       ...      ...             ...          ...            ...   \n",
              "2647       0         0        0               0            0              0   \n",
              "2648       0         2        0               1            0              0   \n",
              "2650       0         0        0               0            2              0   \n",
              "2653       0         0        0               0            0              0   \n",
              "2658       0         0        0               0            0              0   \n",
              "\n",
              "      Sevilla  Valencia  Valladolid  Villarreal  HOME_POWER  OP_SUM  result_H  \\\n",
              "42          0         0           0           0    3.000000  19.915         1   \n",
              "43          0         0           0           0    0.750000   8.909         1   \n",
              "44          0         0           0           0    0.400000   8.614         0   \n",
              "49          0         0           0           0    1.000000   8.859         0   \n",
              "50          0         2           0           0    2.500000  12.899         1   \n",
              "...       ...       ...         ...         ...         ...     ...       ...   \n",
              "2647        0         0           0           0    1.000000   9.207         1   \n",
              "2648        0         0           0           0    0.806452   9.609         1   \n",
              "2650        0         0           0           0    1.311111  10.460         0   \n",
              "2653        2         0           0           0    1.219512   9.098         1   \n",
              "2658        0         0           0           0    0.935484  10.353         0   \n",
              "\n",
              "      result_D  result_A  \n",
              "42           0         0  \n",
              "43           0         0  \n",
              "44           1         0  \n",
              "49           0         1  \n",
              "50           0         0  \n",
              "...        ...       ...  \n",
              "2647         0         0  \n",
              "2648         0         0  \n",
              "2650         1         0  \n",
              "2653         0         0  \n",
              "2658         1         0  \n",
              "\n",
              "[1320 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e86f4489-2015-40af-8241-8ff9eb5d575c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>games</th>\n",
              "      <th>OP1_AVG</th>\n",
              "      <th>OPX_AVG</th>\n",
              "      <th>OP2_AVG</th>\n",
              "      <th>home_wins_rate</th>\n",
              "      <th>home_tie_rate</th>\n",
              "      <th>home_loss_rate</th>\n",
              "      <th>away_wins_rate</th>\n",
              "      <th>away_tie_rate</th>\n",
              "      <th>away_loss_rate</th>\n",
              "      <th>OP1_RATE</th>\n",
              "      <th>OPX_RATE</th>\n",
              "      <th>OP2_RATE</th>\n",
              "      <th>Alaves</th>\n",
              "      <th>Almeria</th>\n",
              "      <th>Ath Bilbao</th>\n",
              "      <th>Atl. Madrid</th>\n",
              "      <th>Barcelona</th>\n",
              "      <th>Betis</th>\n",
              "      <th>Cadiz CF</th>\n",
              "      <th>Celta Vigo</th>\n",
              "      <th>Dep. La Coruna</th>\n",
              "      <th>Eibar</th>\n",
              "      <th>Elche</th>\n",
              "      <th>Espanyol</th>\n",
              "      <th>Getafe</th>\n",
              "      <th>Gijon</th>\n",
              "      <th>Girona</th>\n",
              "      <th>Granada CF</th>\n",
              "      <th>Huesca</th>\n",
              "      <th>Las Palmas</th>\n",
              "      <th>Leganes</th>\n",
              "      <th>Levante</th>\n",
              "      <th>Malaga</th>\n",
              "      <th>Mallorca</th>\n",
              "      <th>Osasuna</th>\n",
              "      <th>Rayo Vallecano</th>\n",
              "      <th>Real Madrid</th>\n",
              "      <th>Real Sociedad</th>\n",
              "      <th>Sevilla</th>\n",
              "      <th>Valencia</th>\n",
              "      <th>Valladolid</th>\n",
              "      <th>Villarreal</th>\n",
              "      <th>HOME_POWER</th>\n",
              "      <th>OP_SUM</th>\n",
              "      <th>result_H</th>\n",
              "      <th>result_D</th>\n",
              "      <th>result_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4</td>\n",
              "      <td>1.244</td>\n",
              "      <td>5.543</td>\n",
              "      <td>13.128</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.062465</td>\n",
              "      <td>0.278333</td>\n",
              "      <td>0.659202</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>19.915</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4</td>\n",
              "      <td>2.113</td>\n",
              "      <td>3.384</td>\n",
              "      <td>3.412</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.237176</td>\n",
              "      <td>0.379841</td>\n",
              "      <td>0.382983</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>8.909</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4</td>\n",
              "      <td>2.382</td>\n",
              "      <td>3.094</td>\n",
              "      <td>3.138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.276527</td>\n",
              "      <td>0.359183</td>\n",
              "      <td>0.364291</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>8.614</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>4</td>\n",
              "      <td>2.133</td>\n",
              "      <td>3.250</td>\n",
              "      <td>3.476</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.240772</td>\n",
              "      <td>0.366859</td>\n",
              "      <td>0.392369</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.859</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>5</td>\n",
              "      <td>1.454</td>\n",
              "      <td>4.365</td>\n",
              "      <td>7.080</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.112722</td>\n",
              "      <td>0.338398</td>\n",
              "      <td>0.548880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>12.899</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2647</th>\n",
              "      <td>36</td>\n",
              "      <td>2.048</td>\n",
              "      <td>3.554</td>\n",
              "      <td>3.605</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.222439</td>\n",
              "      <td>0.386011</td>\n",
              "      <td>0.391550</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.207</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2648</th>\n",
              "      <td>36</td>\n",
              "      <td>1.973</td>\n",
              "      <td>3.273</td>\n",
              "      <td>4.363</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.205328</td>\n",
              "      <td>0.340618</td>\n",
              "      <td>0.454053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>9.609</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2650</th>\n",
              "      <td>37</td>\n",
              "      <td>1.674</td>\n",
              "      <td>4.271</td>\n",
              "      <td>4.515</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.160038</td>\n",
              "      <td>0.408317</td>\n",
              "      <td>0.431644</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.311111</td>\n",
              "      <td>10.460</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2653</th>\n",
              "      <td>37</td>\n",
              "      <td>2.114</td>\n",
              "      <td>3.446</td>\n",
              "      <td>3.538</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.232359</td>\n",
              "      <td>0.378765</td>\n",
              "      <td>0.388877</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.219512</td>\n",
              "      <td>9.098</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2658</th>\n",
              "      <td>37</td>\n",
              "      <td>1.754</td>\n",
              "      <td>3.863</td>\n",
              "      <td>4.736</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.169419</td>\n",
              "      <td>0.373129</td>\n",
              "      <td>0.457452</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>10.353</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1320 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e86f4489-2015-40af-8241-8ff9eb5d575c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e86f4489-2015-40af-8241-8ff9eb5d575c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e86f4489-2015-40af-8241-8ff9eb5d575c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b9c4f52b-b5fb-48db-9263-bb14118378e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9c4f52b-b5fb-48db-9263-bb14118378e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b9c4f52b-b5fb-48db-9263-bb14118378e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_12625e78-e098-464f-b068-3845c6533ef6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bnbd_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_12625e78-e098-464f-b068-3845c6533ef6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bnbd_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bnbd_train"
            }
          },
          "metadata": {},
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if symbol == \"H\":\n",
        "#   odds_label = \"OP1_AVG\"\n",
        "# elif symbol == \"D\":\n",
        "#   odds_label = \"OPX_AVG\"\n",
        "# else:\n",
        "#   odds_label = \"OP2_AVG\"\n",
        "\n",
        "bnbd_train_features = bnbd_train.drop(columns=labels)\n",
        "# bnbd_train_features = np.array(bnbd_train_features).astype('float32')\n",
        "bnbd_train_target = [[x, y, z, 0, a, b, c] for x, y, z, a, b, c in zip(bnbd_train[labels[0]], bnbd_train[labels[1]], bnbd_train[labels[2]], bnbd_train[\"OP1_AVG\"], bnbd_train[\"OPX_AVG\"], bnbd_train[\"OP2_AVG\"])]\n",
        "# bnbd_train_target = [[1, x] if x > 0 else [0, x] for x in bnbd_train_target]\n",
        "# bnbd_train_target = np.array(bnbd_train_target).astype('float32')\n",
        "bnbd_train_target\n",
        "\n",
        "bnbd_test_features = bnbd_test.drop(columns=labels)\n",
        "# bnbd_test_features = np.array(bnbd_test_features).astype('float32')\n",
        "# bnbd_test_target = bnbd_test[label]\n",
        "bnbd_test_target = [[x, y, z, 0, a, b, c] for x, y, z, a, b, c in zip(bnbd_test[labels[0]], bnbd_test[labels[1]], bnbd_test[labels[2]], bnbd_test[\"OP1_AVG\"], bnbd_test[\"OPX_AVG\"], bnbd_test[\"OP2_AVG\"])]\n",
        "# bnbd_test_target = [[1, x] if x > 0 else [0, x] for x in bnbd_test_target]\n",
        "# bnbd_test_target = np.array(bnbd_test_target).astype('float32')"
      ],
      "metadata": {
        "id": "ftev4-AraPd_"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function()\n",
        "def weighted_loss_bnbd(y_true, y_pred):\n",
        "    bet_home = y_true[:, 0:1]\n",
        "    bet_draw = y_true[:, 1:2]\n",
        "    bet_away = y_true[:, 2:3]\n",
        "    no_bet = y_true[:, 3:4]\n",
        "    odds_home = y_true[:, 4:5]\n",
        "    odds_draw = y_true[:, 5:6]\n",
        "    odds_away = y_true[:, 6:7]\n",
        "\n",
        "    # home_ev = bet_home * (odds_home - 1) + (1 - bet_home) * -1\n",
        "    scale_vector = tf.concat([bet_home * (odds_home - 1) + (1 - bet_home) * -1,\n",
        "                              bet_draw * (odds_draw - 1) + (1 - bet_draw) * -1, #1\n",
        "                              bet_away * (odds_away - 1) + (1 - bet_away) * -1,\n",
        "                              tf.zeros_like(odds_home)\n",
        "                              ], axis=1)\n",
        "    # tf.zeros_like(odds_ev)\n",
        "    # -(should_bet * (odds - 1))/10.0\n",
        "    # return scale_vector\n",
        "    return -1 * tf.reduce_mean(tf.reduce_sum(scale_vector * y_pred, axis=1))\n",
        "    # return scale_vector\n",
        "    # return -1 * tf.reduce_mean(scale_vector * y_pred)\n",
        "    # return tf.reduce_sum(scale_vector)\n",
        "    # win_home_team * (odds_a - 1) + (1 - win_home_team) * -1,"
      ],
      "metadata": {
        "id": "PzRCIDFzcaKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnbd = np.array(bnbd_train_target)[0:4, :]\n",
        "print(bnbd)\n",
        "pred = np.array([[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1]]).astype(\"float32\")\n",
        "print(pred)\n",
        "true = np.array(bnbd).astype('float32')\n",
        "weighted_loss_bnbd(true, pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZOZyu-cdlf4",
        "outputId": "4cd62708-5d09-4d25-a546-0bb8135f5a1c"
      },
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.     0.     0.     0.     1.244  5.543 13.128]\n",
            " [ 1.     0.     0.     0.     2.113  3.384  3.412]\n",
            " [ 0.     1.     0.     0.     2.382  3.094  3.138]\n",
            " [ 0.     0.     1.     0.     2.133  3.25   3.476]]\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-0.06099999>"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_12.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "MYFJfotUfEPT",
        "outputId": "d09ee561-375a-4399-fa38-bac188824bbf"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_45\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_45\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization_45 (\u001b[38;5;33mNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)                  │              \u001b[38;5;34m91\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_142 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m690\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_97 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_97 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_143 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_98 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_98 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_144 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ normalization_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">690</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,081\u001b[0m (8.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,081</span> (8.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m994\u001b[0m (3.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">994</span> (3.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m91\u001b[0m (368.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (368.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m996\u001b[0m (3.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">996</span> (3.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\",\n",
        "    min_delta=0,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(bnbd_train_features))\n",
        "steps_per_epoch = len(bnbd_train_features)/32\n",
        "\n",
        "bnbd_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                classes=np.unique(np.array(bnbd_train_target)[:, 1]),\n",
        "                                                y=np.array(bnbd_train_target)[:, 1])\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.5,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "\n",
        "# tf.keras.layers.LeakyReLU()\n",
        "model_12 = tf.keras.Sequential([\n",
        "      normalizer,\n",
        "      layers.Dense(15),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2), #0.02\n",
        "      layers.Dense(15),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(rate=0.2), #0.02\n",
        "      # layers.Dense(15),\n",
        "      # layers.LeakyReLU(),\n",
        "      # layers.Dropout(rate=0.4), #not real\n",
        "      # layers.Dense(15),\n",
        "      # layers.LeakyReLU(),\n",
        "      # layers.Dropout(rate=0.2),\n",
        "      # layers.Dense(15),\n",
        "      # layers.LeakyReLU(),\n",
        "      # layers.Dropout(rate=0.3),\n",
        "      layers.Dense(4, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_12.compile(\n",
        "    optimizer=tf.keras.optimizers.Adagrad(learning_rate = 0.15), # DHA 0.09\n",
        "    loss=weighted_loss_bnbd)\n",
        "\n",
        "bnbd_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM8DP6v2g7ii",
        "outputId": "11a94821-4f5c-455c-d839-00f67f21c055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.732, 1.578])"
            ]
          },
          "metadata": {},
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logdir=f\"{pwd_parent}/logs/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "history = model_12.fit(\n",
        "    np.array(bnbd_train_features),\n",
        "    np.array(bnbd_train_target),\n",
        "    epochs=900,\n",
        "    callbacks=[early_stopping],\n",
        "    # Suppress logging.\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    # class_weight={0: bnb_weights[0] + 10, 1: bnb_weights[1]},\n",
        "    # sample_weight=bnb_weights,\n",
        "    validation_split=0.2\n",
        "\n",
        "    # validation_data=(om_train_features[40:50], om_train_target[40:50])\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_g3zQ2zil0U",
        "outputId": "1b88e07d-6870-4ec5-d297-71253affadee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0700 - val_loss: -0.0217\n",
            "Epoch 2/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.0509 - val_loss: -0.0431\n",
            "Epoch 3/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.2020 - val_loss: -0.0684\n",
            "Epoch 4/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.2866 - val_loss: -0.0881\n",
            "Epoch 5/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.2390 - val_loss: -0.1114\n",
            "Epoch 6/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.2829 - val_loss: -0.1586\n",
            "Epoch 7/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.3857 - val_loss: -0.1517\n",
            "Epoch 8/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.3767 - val_loss: -0.1007\n",
            "Epoch 9/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.3840 - val_loss: -0.1264\n",
            "Epoch 10/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.4798 - val_loss: -0.1292\n",
            "Epoch 11/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.4771 - val_loss: -0.1381\n",
            "Epoch 12/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.4665 - val_loss: -0.1212\n",
            "Epoch 13/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.6305 - val_loss: -0.1244\n",
            "Epoch 14/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.5591 - val_loss: -0.0926\n",
            "Epoch 15/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.5456 - val_loss: -0.0809\n",
            "Epoch 16/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5478 - val_loss: -0.1044\n",
            "Epoch 17/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.6002 - val_loss: -0.0675\n",
            "Epoch 18/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.5679 - val_loss: -0.0859\n",
            "Epoch 19/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.6031 - val_loss: -0.0760\n",
            "Epoch 20/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5740 - val_loss: -0.0504\n",
            "Epoch 21/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6427 - val_loss: -0.0520\n",
            "Epoch 22/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6335 - val_loss: -0.0593\n",
            "Epoch 23/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6495 - val_loss: -0.0544\n",
            "Epoch 24/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5524 - val_loss: -0.0714\n",
            "Epoch 25/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6772 - val_loss: -0.1051\n",
            "Epoch 26/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.6599 - val_loss: -0.0932\n",
            "Epoch 27/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6984 - val_loss: -0.0699\n",
            "Epoch 28/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7380 - val_loss: -0.0614\n",
            "Epoch 29/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6548 - val_loss: -0.0399\n",
            "Epoch 30/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7950 - val_loss: -0.0297\n",
            "Epoch 31/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6316 - val_loss: -0.0159\n",
            "Epoch 32/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6099 - val_loss: -0.0580\n",
            "Epoch 33/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6290 - val_loss: -0.0527\n",
            "Epoch 34/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6777 - val_loss: -0.0745\n",
            "Epoch 35/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5751 - val_loss: -0.0429\n",
            "Epoch 36/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7462 - val_loss: -0.0426\n",
            "Epoch 37/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6069 - val_loss: -0.0189\n",
            "Epoch 38/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8729 - val_loss: -0.0077\n",
            "Epoch 39/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6278 - val_loss: 0.0129\n",
            "Epoch 40/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7530 - val_loss: 0.0716\n",
            "Epoch 41/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.6987 - val_loss: 0.0405\n",
            "Epoch 42/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7296 - val_loss: 0.0359\n",
            "Epoch 43/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7746 - val_loss: 0.0221\n",
            "Epoch 44/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7120 - val_loss: 0.0255\n",
            "Epoch 45/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.8585 - val_loss: 0.0153\n",
            "Epoch 46/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.6828 - val_loss: -0.0209\n",
            "Epoch 47/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.8507 - val_loss: -0.0309\n",
            "Epoch 48/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7042 - val_loss: -0.0120\n",
            "Epoch 49/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7395 - val_loss: 0.0208\n",
            "Epoch 50/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: -0.7301 - val_loss: 0.0350\n",
            "Epoch 51/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.8446 - val_loss: 0.0069\n",
            "Epoch 52/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7565 - val_loss: 0.0392\n",
            "Epoch 53/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7731 - val_loss: 0.0495\n",
            "Epoch 54/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7998 - val_loss: 0.0323\n",
            "Epoch 55/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7579 - val_loss: 0.0508\n",
            "Epoch 56/900\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7970 - val_loss: 0.0373\n",
            "Epoch 56: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# max_symbol = 1\n",
        "# mid_symbol = 3\n",
        "# min_symbol = 0\n",
        "# bnb_test_hda = bnb_test[(bnb_test[\"OP_MAX_ODD\"] == max_symbol) & (bnb_test[\"OP_MID_ODD\"] == mid_symbol) & (bnb_test[\"OP_MIN_ODD\"] == min_symbol)]\n",
        "# target = bnb_test_hda[comp_label]\n",
        "target = bnbd_test_target\n",
        "features = bnbd_test_features\n",
        "# target = bnb_train_target\n",
        "# features = bnb_train_features\n",
        "num = len(target)\n",
        "target = target[:num]\n",
        "# features = bnb_test_hda.drop(columns=[comp_label])\n",
        "features = features[:num]\n",
        "# comp_data = bnb_train[comp_label][:num]\n",
        "loaded_model = tf.keras.models.load_model(f\"{model_save_pwd}/BNBD_ADH_53A_2p7EV.keras\", compile=False)\n",
        "# loaded_model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adagrad(learning_rate = 0.15), # DHA 0.09\n",
        "#     loss=weighted_loss_bnbd)\n",
        "predictions = loaded_model.predict(features)\n",
        "# predictions = model_12.predict(features)\n",
        "# , custom_objects={'weighted_loss_bnbd':weighted_loss_bnbd}\n",
        "# predictions = predictions.flatten()\n",
        "print(predictions)\n",
        "prob_home = predictions[:, 0]\n",
        "prob_bet = predictions[:, 1]\n",
        "sum = 0\n",
        "correct_choice = 0\n",
        "is_positive = 0\n",
        "\n",
        "pred_bet_correct = 0\n",
        "pred_bet_num = 0\n",
        "pred_nb_correct = 0\n",
        "pred_nb_num = 0\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "class_predicted = [0, 0, 0, 0]\n",
        "class_predicted_correct = [0, 0, 0, 0]\n",
        "class_predicted_winnings = [0, 0, 0, 0]\n",
        "class_true = [0, 0, 0, 0]\n",
        "# predicted_classes = [1 if nb < .4 else 0 for nb, b in predictions]\n",
        "# nb < .4 is generally good?\n",
        "# print(target[:, 0:4])\n",
        "# true_classes = np.argmax(target[:, 0:4], axis=1)\n",
        "# print(true_classes.dtype)\n",
        "# print(target.dtype)\n",
        "for prediction, true_data in zip(predictions, target):\n",
        "  # prob_home = prediction[0]\n",
        "  # prob_draw = prediction[1]\n",
        "  # prob_away = prediction[2]\n",
        "  # prob_nb = prediction[3]\n",
        "\n",
        "  # true_home = true_data[0]\n",
        "  # true_draw = true_data[1]\n",
        "  # true_away = true_data[2]\n",
        "  # true_nb = true_data[3]\n",
        "\n",
        "  # home_odds = true_data[4]\n",
        "  # draw_odds = true_data[5]\n",
        "  # away_odds = true_data[6]\n",
        "\n",
        "  predicted_class = np.argmax(prediction)\n",
        "  print(f\"predicted_class: {predicted_class}\")\n",
        "  print(f\"predictions: {prediction}\")\n",
        "\n",
        "  true_class_options = true_data[0:4]\n",
        "  true_odd_options = true_data[4:7]\n",
        "\n",
        "\n",
        "  true_class = np.argmax(true_class_options)\n",
        "  true_odd = true_odd_options[true_class]\n",
        "\n",
        "  # true_odd = np.argmax(true_odd_options)\n",
        "  print(f\"true_class: {true_class}\")\n",
        "  # print(f\"true_class_options: {true_class_options}\")\n",
        "  # print(f\"true_odd_options: {true_odd_options}\")\n",
        "  print(f\"true_odd: {true_odd}\")\n",
        "  # print(f\"true_data: {true_data}\")\n",
        "  added = 0\n",
        "  class_predicted[predicted_class] += 1\n",
        "  class_true[true_class] += 1\n",
        "  if predicted_class != 3:\n",
        "    pred_bet_num += 1\n",
        "    added = -1\n",
        "    if predicted_class == true_class:\n",
        "      class_predicted_correct[predicted_class] += 1\n",
        "      pred_bet_correct += 1\n",
        "      added = true_odd - 1\n",
        "      correct_choice += 1\n",
        "  else:\n",
        "    pred_nb_num += 1\n",
        "\n",
        "  class_predicted_winnings[predicted_class] += added\n",
        "  print(true_data)\n",
        "\n",
        "  # added = 0\n",
        "  # if true_class == 1:\n",
        "  #   is_positive += 1\n",
        "\n",
        "  # if predicted_class == 1:\n",
        "  #   pred_bet_num += 1\n",
        "  #   added = -1\n",
        "  #   if predicted_class == true_class:\n",
        "  #     pred_bet_correct += 1\n",
        "  #     added = odds -1\n",
        "  #     correct_choice += 1\n",
        "  # else:\n",
        "  #   pred_nb_num += 1\n",
        "  #   if predicted_class == true_class:\n",
        "  #     pred_nb_correct += 1\n",
        "  #     correct_choice += 1\n",
        "\n",
        "  sum += added\n",
        "  print(f\"preds: {prediction}, pred_class: {predicted_class}, true: {true_class}, added {format(added, '.3f')}\")\n",
        "\n",
        "# get_dir_dataset_stats(bnb_test, curr_label)\n",
        "loss = weighted_loss_bnbd(np.array(target).astype(\"float32\"), predictions)\n",
        "print(f\"loss: {format(loss, '.4f')}\")\n",
        "# print_percent_str(f\"{symbol} correct of total\", is_positive, num)\n",
        "print_percent_str(\"bet\", pred_bet_num, num)\n",
        "# print_percent_str(\"correct choice of total\", correct_choice, num)\n",
        "\n",
        "# print_percent_str(\"pred no bet accuracy\", pred_nb_correct, pred_nb_num)\n",
        "\n",
        "print_percent_str(\"home true\", class_true[0], num)\n",
        "print_percent_str(\"draw true\", class_true[1], num)\n",
        "print_percent_str(\"away true\", class_true[2], num)\n",
        "\n",
        "print_percent_str(\"pred bet accuracy\", pred_bet_correct, pred_bet_num)\n",
        "print_percent_str(\"home correct\", class_predicted_correct[0], class_predicted[0])\n",
        "print_percent_str(\"draw correct\", class_predicted_correct[1], class_predicted[1])\n",
        "print_percent_str(\"away correct\", class_predicted_correct[2], class_predicted[2])\n",
        "print_percent_str(\"nb correct\", class_predicted_correct[3], class_predicted[3])\n",
        "\n",
        "print_percent_str(\"home ev\", class_predicted_winnings[0], class_predicted[0])\n",
        "print_percent_str(\"draw ev\", class_predicted_winnings[1], class_predicted[1])\n",
        "print_percent_str(\"away ev\", class_predicted_winnings[2], class_predicted[2])\n",
        "\n",
        "\n",
        "print_percent_str(\"ev\", sum, pred_bet_num)\n",
        "# compare_predictions_single(predictions, comp_data, target)\n",
        "# get_mse(predictions, comp_data, target, om_test.iloc[:num])\n",
        "\n",
        "\n",
        "# plot_confusion_matrix(true_classes, predicted_classes, [\"H\", \"D\", \"A\", \"NB\"], \"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMLA2jrkivl8",
        "outputId": "fce60e97-29a9-4f91-e35f-4b7b9e554126"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "[[0.122 0.703 0.09  0.503]\n",
            " [1.    0.    0.    0.057]\n",
            " [0.729 0.142 0.033 0.666]\n",
            " ...\n",
            " [0.938 0.014 0.    0.911]\n",
            " [0.712 0.344 0.005 0.961]\n",
            " [0.94  0.032 0.002 0.432]]\n",
            "predicted_class: 1\n",
            "predictions: [0.122 0.703 0.09  0.503]\n",
            "true_class: 0\n",
            "true_odd: 2.188\n",
            "[1, 0, 0, 0, 2.188, 3.21, 3.401]\n",
            "preds: [0.122 0.703 0.09  0.503], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.057]\n",
            "true_class: 0\n",
            "true_odd: 2.365\n",
            "[1, 0, 0, 0, 2.365, 3.143, 3.152]\n",
            "preds: [1.    0.    0.    0.057], pred_class: 0, true: 0, added 1.365\n",
            "predicted_class: 0\n",
            "predictions: [0.729 0.142 0.033 0.666]\n",
            "true_class: 0\n",
            "true_odd: 1.56\n",
            "[1, 0, 0, 0, 1.56, 3.98, 6.076]\n",
            "preds: [0.729 0.142 0.033 0.666], pred_class: 0, true: 0, added 0.560\n",
            "predicted_class: 1\n",
            "predictions: [0.019 0.997 0.071 0.502]\n",
            "true_class: 0\n",
            "true_odd: 1.265\n",
            "[1, 0, 0, 0, 1.265, 5.913, 10.096]\n",
            "preds: [0.019 0.997 0.071 0.502], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.08  0.165 0.046 0.137]\n",
            "true_class: 2\n",
            "true_odd: 3.476\n",
            "[0, 0, 1, 0, 2.117, 3.297, 3.476]\n",
            "preds: [0.08  0.165 0.046 0.137], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.249 0.151 0.    0.121]\n",
            "true_class: 0\n",
            "true_odd: 1.145\n",
            "[1, 0, 0, 0, 1.145, 8.152, 15.803]\n",
            "preds: [0.249 0.151 0.    0.121], pred_class: 0, true: 0, added 0.145\n",
            "predicted_class: 0\n",
            "predictions: [0.969 0.037 0.006 0.291]\n",
            "true_class: 0\n",
            "true_odd: 1.554\n",
            "[1, 0, 0, 0, 1.554, 3.959, 6.006]\n",
            "preds: [0.969 0.037 0.006 0.291], pred_class: 0, true: 0, added 0.554\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 2.188\n",
            "[1, 0, 0, 0, 2.188, 3.267, 3.324]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 1.188\n",
            "predicted_class: 1\n",
            "predictions: [0.495 0.641 0.02  0.215]\n",
            "true_class: 2\n",
            "true_odd: 4.447\n",
            "[0, 0, 1, 0, 1.914, 3.193, 4.447]\n",
            "preds: [0.495 0.641 0.02  0.215], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.96  0.013 0.01  0.168]\n",
            "true_class: 1\n",
            "true_odd: 3.515\n",
            "[0, 1, 0, 0, 1.882, 3.515, 4.081]\n",
            "preds: [0.96  0.013 0.01  0.168], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.709 0.196 0.014 0.807]\n",
            "true_class: 0\n",
            "true_odd: 1.579\n",
            "[1, 0, 0, 0, 1.579, 3.997, 5.691]\n",
            "preds: [0.709 0.196 0.014 0.807], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.326 0.911 0.031 0.861]\n",
            "true_class: 0\n",
            "true_odd: 1.581\n",
            "[1, 0, 0, 0, 1.581, 3.834, 5.879]\n",
            "preds: [0.326 0.911 0.031 0.861], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.491\n",
            "[1, 0, 0, 0, 1.491, 4.088, 6.772]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.491\n",
            "predicted_class: 1\n",
            "predictions: [0.164 0.636 0.157 0.269]\n",
            "true_class: 2\n",
            "true_odd: 3.399\n",
            "[0, 0, 1, 0, 2.23, 3.115, 3.399]\n",
            "preds: [0.164 0.636 0.157 0.269], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.305 0.876 0.02  0.769]\n",
            "true_class: 1\n",
            "true_odd: 5.237\n",
            "[0, 1, 0, 0, 1.336, 5.237, 8.02]\n",
            "preds: [0.305 0.876 0.02  0.769], pred_class: 1, true: 1, added 4.237\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.009]\n",
            "true_class: 0\n",
            "true_odd: 1.804\n",
            "[1, 0, 0, 0, 1.804, 3.518, 4.382]\n",
            "preds: [1.    0.    0.    0.009], pred_class: 0, true: 0, added 0.804\n",
            "predicted_class: 0\n",
            "predictions: [0.824 0.121 0.024 0.128]\n",
            "true_class: 2\n",
            "true_odd: 3.3\n",
            "[0, 0, 1, 0, 2.215, 3.223, 3.3]\n",
            "preds: [0.824 0.121 0.024 0.128], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.86  0.038 0.004 0.676]\n",
            "true_class: 0\n",
            "true_odd: 1.446\n",
            "[1, 0, 0, 0, 1.446, 4.262, 7.368]\n",
            "preds: [0.86  0.038 0.004 0.676], pred_class: 0, true: 0, added 0.446\n",
            "predicted_class: 3\n",
            "predictions: [0.234 0.837 0.005 0.845]\n",
            "true_class: 0\n",
            "true_odd: 1.271\n",
            "[1, 0, 0, 0, 1.271, 5.814, 9.895]\n",
            "preds: [0.234 0.837 0.005 0.845], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.065]\n",
            "true_class: 1\n",
            "true_odd: 3.187\n",
            "[0, 1, 0, 0, 2.024, 3.187, 3.938]\n",
            "preds: [1.    0.    0.    0.065], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.679 0.113 0.024 0.635]\n",
            "true_class: 1\n",
            "true_odd: 3.321\n",
            "[0, 1, 0, 0, 1.95, 3.321, 4.042]\n",
            "preds: [0.679 0.113 0.024 0.635], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.632 0.074 0.001 0.016]\n",
            "true_class: 1\n",
            "true_odd: 4.07\n",
            "[0, 1, 0, 0, 1.524, 4.07, 6.182]\n",
            "preds: [0.632 0.074 0.001 0.016], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.291 0.142 0.028 0.828]\n",
            "true_class: 0\n",
            "true_odd: 2.04\n",
            "[1, 0, 0, 0, 2.04, 3.353, 3.626]\n",
            "preds: [0.291 0.142 0.028 0.828], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.53\n",
            "[1, 0, 0, 0, 1.53, 4.133, 5.988]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.530\n",
            "predicted_class: 0\n",
            "predictions: [0.802 0.039 0.024 0.396]\n",
            "true_class: 0\n",
            "true_odd: 1.575\n",
            "[1, 0, 0, 0, 1.575, 4.037, 5.573]\n",
            "preds: [0.802 0.039 0.024 0.396], pred_class: 0, true: 0, added 0.575\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.282]\n",
            "true_class: 1\n",
            "true_odd: 4.13\n",
            "[0, 1, 0, 0, 1.5, 4.13, 6.784]\n",
            "preds: [0.998 0.    0.    0.282], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.201 0.897 0.046 0.611]\n",
            "true_class: 0\n",
            "true_odd: 1.543\n",
            "[1, 0, 0, 0, 1.543, 4.034, 6.146]\n",
            "preds: [0.201 0.897 0.046 0.611], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.73  0.153 0.046 0.236]\n",
            "true_class: 0\n",
            "true_odd: 2.012\n",
            "[1, 0, 0, 0, 2.012, 3.385, 3.754]\n",
            "preds: [0.73  0.153 0.046 0.236], pred_class: 0, true: 0, added 1.012\n",
            "predicted_class: 3\n",
            "predictions: [0.309 0.707 0.055 0.824]\n",
            "true_class: 0\n",
            "true_odd: 1.471\n",
            "[1, 0, 0, 0, 1.471, 4.56, 6.128]\n",
            "preds: [0.309 0.707 0.055 0.824], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.085]\n",
            "true_class: 0\n",
            "true_odd: 1.705\n",
            "[1, 0, 0, 0, 1.705, 3.638, 5.056]\n",
            "preds: [1.    0.    0.    0.085], pred_class: 0, true: 0, added 0.705\n",
            "predicted_class: 0\n",
            "predictions: [0.692 0.18  0.024 0.071]\n",
            "true_class: 2\n",
            "true_odd: 4.606\n",
            "[0, 0, 1, 0, 1.788, 3.493, 4.606]\n",
            "preds: [0.692 0.18  0.024 0.071], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.337 0.826 0.012 0.775]\n",
            "true_class: 0\n",
            "true_odd: 1.427\n",
            "[1, 0, 0, 0, 1.427, 4.492, 7.549]\n",
            "preds: [0.337 0.826 0.012 0.775], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.464 0.724 0.024 0.849]\n",
            "true_class: 0\n",
            "true_odd: 1.472\n",
            "[1, 0, 0, 0, 1.472, 4.505, 6.232]\n",
            "preds: [0.464 0.724 0.024 0.849], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.898 0.034 0.006 0.137]\n",
            "true_class: 1\n",
            "true_odd: 3.673\n",
            "[0, 1, 0, 0, 1.777, 3.673, 4.444]\n",
            "preds: [0.898 0.034 0.006 0.137], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.321\n",
            "[1, 0, 0, 0, 1.321, 5.157, 9.366]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.321\n",
            "predicted_class: 1\n",
            "predictions: [0.096 0.958 0.074 0.348]\n",
            "true_class: 1\n",
            "true_odd: 3.558\n",
            "[0, 1, 0, 0, 1.753, 3.558, 4.804]\n",
            "preds: [0.096 0.958 0.074 0.348], pred_class: 1, true: 1, added 2.558\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.151]\n",
            "true_class: 2\n",
            "true_odd: 4.284\n",
            "[0, 0, 1, 0, 1.854, 3.51, 4.284]\n",
            "preds: [1.    0.    0.    0.151], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.12  0.581 0.153 0.381]\n",
            "true_class: 0\n",
            "true_odd: 2.005\n",
            "[1, 0, 0, 0, 2.005, 3.391, 3.673]\n",
            "preds: [0.12  0.581 0.153 0.381], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.057 0.96  0.006 0.759]\n",
            "true_class: 1\n",
            "true_odd: 6.176\n",
            "[0, 1, 0, 0, 1.229, 6.176, 11.122]\n",
            "preds: [0.057 0.96  0.006 0.759], pred_class: 1, true: 1, added 5.176\n",
            "predicted_class: 0\n",
            "predictions: [0.816 0.177 0.036 0.226]\n",
            "true_class: 0\n",
            "true_odd: 2.023\n",
            "[1, 0, 0, 0, 2.023, 3.502, 3.559]\n",
            "preds: [0.816 0.177 0.036 0.226], pred_class: 0, true: 0, added 1.023\n",
            "predicted_class: 3\n",
            "predictions: [0.68  0.435 0.03  0.857]\n",
            "true_class: 2\n",
            "true_odd: 3.844\n",
            "[0, 0, 1, 0, 1.917, 3.556, 3.844]\n",
            "preds: [0.68  0.435 0.03  0.857], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.363 0.751 0.061 0.41 ]\n",
            "true_class: 2\n",
            "true_odd: 3.705\n",
            "[0, 0, 1, 0, 2.026, 3.315, 3.705]\n",
            "preds: [0.363 0.751 0.061 0.41 ], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.132\n",
            "[1, 0, 0, 0, 1.132, 8.672, 19.394]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.132\n",
            "predicted_class: 0\n",
            "predictions: [0.968 0.006 0.008 0.257]\n",
            "true_class: 1\n",
            "true_odd: 3.129\n",
            "[0, 1, 0, 0, 2.052, 3.129, 3.889]\n",
            "preds: [0.968 0.006 0.008 0.257], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.003 0.955 0.179 0.248]\n",
            "true_class: 0\n",
            "true_odd: 1.777\n",
            "[1, 0, 0, 0, 1.777, 3.558, 4.522]\n",
            "preds: [0.003 0.955 0.179 0.248], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.846 0.038 0.006 0.868]\n",
            "true_class: 1\n",
            "true_odd: 4.115\n",
            "[0, 1, 0, 0, 1.479, 4.115, 6.873]\n",
            "preds: [0.846 0.038 0.006 0.868], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.554 0.391 0.034 0.628]\n",
            "true_class: 1\n",
            "true_odd: 3.466\n",
            "[0, 1, 0, 0, 1.843, 3.466, 4.258]\n",
            "preds: [0.554 0.391 0.034 0.628], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.108 0.809 0.174 0.301]\n",
            "true_class: 2\n",
            "true_odd: 6.096\n",
            "[0, 0, 1, 0, 1.558, 3.904, 6.096]\n",
            "preds: [0.108 0.809 0.174 0.301], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.942 0.095 0.015 0.749]\n",
            "true_class: 1\n",
            "true_odd: 3.274\n",
            "[0, 1, 0, 0, 2.155, 3.274, 3.382]\n",
            "preds: [0.942 0.095 0.015 0.749], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.064 0.873 0.091 0.52 ]\n",
            "true_class: 0\n",
            "true_odd: 1.402\n",
            "[1, 0, 0, 0, 1.402, 4.57, 7.765]\n",
            "preds: [0.064 0.873 0.091 0.52 ], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 2.336\n",
            "[1, 0, 0, 0, 2.336, 3.104, 3.184]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 1.336\n",
            "predicted_class: 1\n",
            "predictions: [0.05  0.872 0.034 0.676]\n",
            "true_class: 0\n",
            "true_odd: 1.17\n",
            "[1, 0, 0, 0, 1.17, 7.359, 15.357]\n",
            "preds: [0.05  0.872 0.034 0.676], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.643 0.022 0.    0.174]\n",
            "true_class: 0\n",
            "true_odd: 1.238\n",
            "[1, 0, 0, 0, 1.238, 5.75, 12.657]\n",
            "preds: [0.643 0.022 0.    0.174], pred_class: 0, true: 0, added 0.238\n",
            "predicted_class: 0\n",
            "predictions: [0.617 0.333 0.109 0.184]\n",
            "true_class: 0\n",
            "true_odd: 2.514\n",
            "[1, 0, 0, 0, 2.514, 2.904, 3.078]\n",
            "preds: [0.617 0.333 0.109 0.184], pred_class: 0, true: 0, added 1.514\n",
            "predicted_class: 0\n",
            "predictions: [0.742 0.261 0.021 0.684]\n",
            "true_class: 0\n",
            "true_odd: 1.788\n",
            "[1, 0, 0, 0, 1.788, 3.433, 4.589]\n",
            "preds: [0.742 0.261 0.021 0.684], pred_class: 0, true: 0, added 0.788\n",
            "predicted_class: 3\n",
            "predictions: [0.114 0.874 0.006 0.878]\n",
            "true_class: 1\n",
            "true_odd: 6.317\n",
            "[0, 1, 0, 0, 1.229, 6.317, 10.97]\n",
            "preds: [0.114 0.874 0.006 0.878], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.489 0.235 0.071 0.246]\n",
            "true_class: 0\n",
            "true_odd: 1.841\n",
            "[1, 0, 0, 0, 1.841, 3.531, 4.228]\n",
            "preds: [0.489 0.235 0.071 0.246], pred_class: 0, true: 0, added 0.841\n",
            "predicted_class: 0\n",
            "predictions: [0.542 0.082 0.035 0.263]\n",
            "true_class: 2\n",
            "true_odd: 5.915\n",
            "[0, 0, 1, 0, 1.551, 3.947, 5.915]\n",
            "preds: [0.542 0.082 0.035 0.263], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.025 0.953 0.332 0.198]\n",
            "true_class: 0\n",
            "true_odd: 2.019\n",
            "[1, 0, 0, 0, 2.019, 3.177, 3.897]\n",
            "preds: [0.025 0.953 0.332 0.198], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.994 0.001 0.    0.874]\n",
            "true_class: 1\n",
            "true_odd: 3.317\n",
            "[0, 1, 0, 0, 2.082, 3.317, 3.513]\n",
            "preds: [0.994 0.001 0.    0.874], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.001 0.183]\n",
            "true_class: 0\n",
            "true_odd: 1.716\n",
            "[1, 0, 0, 0, 1.716, 3.436, 5.2]\n",
            "preds: [1.    0.    0.001 0.183], pred_class: 0, true: 0, added 0.716\n",
            "predicted_class: 0\n",
            "predictions: [0.84  0.212 0.014 0.297]\n",
            "true_class: 1\n",
            "true_odd: 3.51\n",
            "[0, 1, 0, 0, 1.729, 3.51, 4.947]\n",
            "preds: [0.84  0.212 0.014 0.297], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.222 0.773 0.128 0.263]\n",
            "true_class: 0\n",
            "true_odd: 2.036\n",
            "[1, 0, 0, 0, 2.036, 3.063, 3.999]\n",
            "preds: [0.222 0.773 0.128 0.263], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.955 0.016 0.022 0.221]\n",
            "true_class: 2\n",
            "true_odd: 2.967\n",
            "[0, 0, 1, 0, 2.526, 2.964, 2.967]\n",
            "preds: [0.955 0.016 0.022 0.221], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.935 0.002 0.007 0.117]\n",
            "true_class: 1\n",
            "true_odd: 3.388\n",
            "[0, 1, 0, 0, 1.892, 3.388, 4.106]\n",
            "preds: [0.935 0.002 0.007 0.117], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.001 0.195]\n",
            "true_class: 0\n",
            "true_odd: 1.657\n",
            "[1, 0, 0, 0, 1.657, 3.726, 5.247]\n",
            "preds: [1.    0.    0.001 0.195], pred_class: 0, true: 0, added 0.657\n",
            "predicted_class: 3\n",
            "predictions: [0.362 0.064 0.01  0.806]\n",
            "true_class: 0\n",
            "true_odd: 1.354\n",
            "[1, 0, 0, 0, 1.354, 4.772, 8.695]\n",
            "preds: [0.362 0.064 0.01  0.806], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.327 0.529 0.082 0.555]\n",
            "true_class: 0\n",
            "true_odd: 1.709\n",
            "[1, 0, 0, 0, 1.709, 3.779, 4.655]\n",
            "preds: [0.327 0.529 0.082 0.555], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.018 0.966 0.004 0.652]\n",
            "true_class: 0\n",
            "true_odd: 1.143\n",
            "[1, 0, 0, 0, 1.143, 7.742, 20.219]\n",
            "preds: [0.018 0.966 0.004 0.652], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 1\n",
            "true_odd: 4.133\n",
            "[0, 1, 0, 0, 1.556, 4.133, 5.473]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 2.518\n",
            "[1, 0, 0, 0, 2.518, 2.965, 3.043]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 1.518\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.035]\n",
            "true_class: 0\n",
            "true_odd: 1.431\n",
            "[1, 0, 0, 0, 1.431, 4.487, 7.214]\n",
            "preds: [0.999 0.    0.    0.035], pred_class: 0, true: 0, added 0.431\n",
            "predicted_class: 3\n",
            "predictions: [0.582 0.55  0.025 0.878]\n",
            "true_class: 1\n",
            "true_odd: 4.016\n",
            "[0, 1, 0, 0, 1.608, 4.016, 5.218]\n",
            "preds: [0.582 0.55  0.025 0.878], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.977 0.005 0.01  0.26 ]\n",
            "true_class: 2\n",
            "true_odd: 4.394\n",
            "[0, 0, 1, 0, 1.78, 3.63, 4.394]\n",
            "preds: [0.977 0.005 0.01  0.26 ], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.567 0.317 0.005 0.618]\n",
            "true_class: 0\n",
            "true_odd: 1.44\n",
            "[1, 0, 0, 0, 1.44, 4.712, 6.393]\n",
            "preds: [0.567 0.317 0.005 0.618], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.647 0.125 0.03  0.583]\n",
            "true_class: 0\n",
            "true_odd: 1.409\n",
            "[1, 0, 0, 0, 1.409, 4.443, 7.939]\n",
            "preds: [0.647 0.125 0.03  0.583], pred_class: 0, true: 0, added 0.409\n",
            "predicted_class: 0\n",
            "predictions: [0.807 0.027 0.004 0.588]\n",
            "true_class: 1\n",
            "true_odd: 4.112\n",
            "[0, 1, 0, 0, 1.416, 4.112, 9.027]\n",
            "preds: [0.807 0.027 0.004 0.588], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.765 0.39  0.032 0.853]\n",
            "true_class: 2\n",
            "true_odd: 3.425\n",
            "[0, 0, 1, 0, 2.178, 3.203, 3.425]\n",
            "preds: [0.765 0.39  0.032 0.853], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.104 0.664 0.013 0.83 ]\n",
            "true_class: 2\n",
            "true_odd: 7.741\n",
            "[0, 0, 1, 0, 1.416, 4.378, 7.741]\n",
            "preds: [0.104 0.664 0.013 0.83 ], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.568 0.39  0.002 0.915]\n",
            "true_class: 0\n",
            "true_odd: 1.287\n",
            "[1, 0, 0, 0, 1.287, 5.557, 9.759]\n",
            "preds: [0.568 0.39  0.002 0.915], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.741\n",
            "[1, 0, 0, 0, 1.741, 3.624, 4.685]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.741\n",
            "predicted_class: 0\n",
            "predictions: [0.982 0.016 0.009 0.259]\n",
            "true_class: 0\n",
            "true_odd: 1.902\n",
            "[1, 0, 0, 0, 1.902, 3.25, 4.405]\n",
            "preds: [0.982 0.016 0.009 0.259], pred_class: 0, true: 0, added 0.902\n",
            "predicted_class: 1\n",
            "predictions: [0.021 0.904 0.001 0.302]\n",
            "true_class: 0\n",
            "true_odd: 1.13\n",
            "[1, 0, 0, 0, 1.13, 8.587, 19.339]\n",
            "preds: [0.021 0.904 0.001 0.302], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.791\n",
            "[1, 0, 0, 0, 1.791, 3.595, 4.437]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.791\n",
            "predicted_class: 3\n",
            "predictions: [0.524 0.562 0.01  0.812]\n",
            "true_class: 1\n",
            "true_odd: 3.45\n",
            "[0, 1, 0, 0, 1.738, 3.45, 5.095]\n",
            "preds: [0.524 0.562 0.01  0.812], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.225 0.518 0.059 0.883]\n",
            "true_class: 0\n",
            "true_odd: 1.62\n",
            "[1, 0, 0, 0, 1.62, 3.785, 5.583]\n",
            "preds: [0.225 0.518 0.059 0.883], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.993 0.001 0.001 0.396]\n",
            "true_class: 0\n",
            "true_odd: 2.057\n",
            "[1, 0, 0, 0, 2.057, 3.226, 3.795]\n",
            "preds: [0.993 0.001 0.001 0.396], pred_class: 0, true: 0, added 1.057\n",
            "predicted_class: 3\n",
            "predictions: [0.056 0.781 0.018 0.807]\n",
            "true_class: 0\n",
            "true_odd: 1.164\n",
            "[1, 0, 0, 0, 1.164, 7.688, 16.576]\n",
            "preds: [0.056 0.781 0.018 0.807], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.901 0.017 0.013 0.741]\n",
            "true_class: 0\n",
            "true_odd: 2.298\n",
            "[1, 0, 0, 0, 2.298, 2.962, 3.48]\n",
            "preds: [0.901 0.017 0.013 0.741], pred_class: 0, true: 0, added 1.298\n",
            "predicted_class: 3\n",
            "predictions: [0.758 0.196 0.021 0.809]\n",
            "true_class: 1\n",
            "true_odd: 3.642\n",
            "[0, 1, 0, 0, 1.83, 3.642, 4.16]\n",
            "preds: [0.758 0.196 0.021 0.809], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.227]\n",
            "true_class: 2\n",
            "true_odd: 4.042\n",
            "[0, 0, 1, 0, 1.959, 3.282, 4.042]\n",
            "preds: [1.    0.    0.    0.227], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.81  0.314 0.007 0.533]\n",
            "true_class: 2\n",
            "true_odd: 5.27\n",
            "[0, 0, 1, 0, 1.662, 3.722, 5.27]\n",
            "preds: [0.81  0.314 0.007 0.533], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.045 0.856 0.159 0.35 ]\n",
            "true_class: 0\n",
            "true_odd: 1.797\n",
            "[1, 0, 0, 0, 1.797, 3.5, 4.584]\n",
            "preds: [0.045 0.856 0.159 0.35 ], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.205 0.579 0.108 0.412]\n",
            "true_class: 0\n",
            "true_odd: 1.602\n",
            "[1, 0, 0, 0, 1.602, 3.73, 5.935]\n",
            "preds: [0.205 0.579 0.108 0.412], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.733 0.052 0.009 0.791]\n",
            "true_class: 1\n",
            "true_odd: 4.043\n",
            "[0, 1, 0, 0, 1.481, 4.043, 7.19]\n",
            "preds: [0.733 0.052 0.009 0.791], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.068 0.923 0.074 0.144]\n",
            "true_class: 2\n",
            "true_odd: 4.937\n",
            "[0, 0, 1, 0, 1.836, 3.186, 4.937]\n",
            "preds: [0.068 0.923 0.074 0.144], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.409]\n",
            "true_class: 0\n",
            "true_odd: 1.681\n",
            "[1, 0, 0, 0, 1.681, 3.561, 5.353]\n",
            "preds: [1.    0.    0.    0.409], pred_class: 0, true: 0, added 0.681\n",
            "predicted_class: 3\n",
            "predictions: [0.399 0.275 0.002 0.819]\n",
            "true_class: 0\n",
            "true_odd: 1.324\n",
            "[1, 0, 0, 0, 1.324, 5.296, 8.779]\n",
            "preds: [0.399 0.275 0.002 0.819], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.988 0.    0.002 0.24 ]\n",
            "true_class: 1\n",
            "true_odd: 2.93\n",
            "[0, 1, 0, 0, 2.445, 2.93, 3.22]\n",
            "preds: [0.988 0.    0.002 0.24 ], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.109 0.824 0.012 0.819]\n",
            "true_class: 0\n",
            "true_odd: 1.243\n",
            "[1, 0, 0, 0, 1.243, 6.126, 11.259]\n",
            "preds: [0.109 0.824 0.012 0.819], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.995 0.005 0.003 0.548]\n",
            "true_class: 0\n",
            "true_odd: 2.131\n",
            "[1, 0, 0, 0, 2.131, 3.112, 3.696]\n",
            "preds: [0.995 0.005 0.003 0.548], pred_class: 0, true: 0, added 1.131\n",
            "predicted_class: 0\n",
            "predictions: [0.908 0.025 0.011 0.106]\n",
            "true_class: 0\n",
            "true_odd: 1.984\n",
            "[1, 0, 0, 0, 1.984, 3.285, 3.96]\n",
            "preds: [0.908 0.025 0.011 0.106], pred_class: 0, true: 0, added 0.984\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.607\n",
            "[1, 0, 0, 0, 1.607, 3.926, 5.439]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.607\n",
            "predicted_class: 3\n",
            "predictions: [0.567 0.228 0.098 0.698]\n",
            "true_class: 1\n",
            "true_odd: 3.539\n",
            "[0, 1, 0, 0, 2.003, 3.539, 3.58]\n",
            "preds: [0.567 0.228 0.098 0.698], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.279]\n",
            "true_class: 1\n",
            "true_odd: 3.308\n",
            "[0, 1, 0, 0, 2.062, 3.308, 3.625]\n",
            "preds: [1.    0.    0.    0.279], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.239]\n",
            "true_class: 0\n",
            "true_odd: 1.648\n",
            "[1, 0, 0, 0, 1.648, 3.652, 5.46]\n",
            "preds: [0.998 0.    0.    0.239], pred_class: 0, true: 0, added 0.648\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 1\n",
            "true_odd: 3.276\n",
            "[0, 1, 0, 0, 2.154, 3.276, 3.384]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.53  0.537 0.055 0.755]\n",
            "true_class: 0\n",
            "true_odd: 1.89\n",
            "[1, 0, 0, 0, 1.89, 3.213, 4.485]\n",
            "preds: [0.53  0.537 0.055 0.755], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.345 0.217 0.001 0.528]\n",
            "true_class: 0\n",
            "true_odd: 1.313\n",
            "[1, 0, 0, 0, 1.313, 4.97, 10.07]\n",
            "preds: [0.345 0.217 0.001 0.528], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.093 0.921 0.197 0.256]\n",
            "true_class: 1\n",
            "true_odd: 2.876\n",
            "[0, 1, 0, 0, 2.268, 2.876, 3.557]\n",
            "preds: [0.093 0.921 0.197 0.256], pred_class: 1, true: 1, added 1.876\n",
            "predicted_class: 1\n",
            "predictions: [0.453 0.668 0.025 0.504]\n",
            "true_class: 1\n",
            "true_odd: 3.677\n",
            "[0, 1, 0, 0, 1.543, 3.677, 6.934]\n",
            "preds: [0.453 0.668 0.025 0.504], pred_class: 1, true: 1, added 2.677\n",
            "predicted_class: 0\n",
            "predictions: [0.963 0.014 0.001 0.795]\n",
            "true_class: 0\n",
            "true_odd: 1.92\n",
            "[1, 0, 0, 0, 1.92, 3.355, 4.073]\n",
            "preds: [0.963 0.014 0.001 0.795], pred_class: 0, true: 0, added 0.920\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 1\n",
            "true_odd: 3.944\n",
            "[0, 1, 0, 0, 1.613, 3.944, 5.26]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.015 0.853 0.011 0.751]\n",
            "true_class: 0\n",
            "true_odd: 1.192\n",
            "[1, 0, 0, 0, 1.192, 6.83, 13.077]\n",
            "preds: [0.015 0.853 0.011 0.751], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.983 0.002 0.001 0.87 ]\n",
            "true_class: 0\n",
            "true_odd: 1.574\n",
            "[1, 0, 0, 0, 1.574, 3.961, 5.636]\n",
            "preds: [0.983 0.002 0.001 0.87 ], pred_class: 0, true: 0, added 0.574\n",
            "predicted_class: 0\n",
            "predictions: [0.997 0.001 0.001 0.141]\n",
            "true_class: 1\n",
            "true_odd: 3.138\n",
            "[0, 1, 0, 0, 2.11, 3.138, 3.693]\n",
            "preds: [0.997 0.001 0.001 0.141], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.001 0.001 0.414]\n",
            "true_class: 1\n",
            "true_odd: 3.278\n",
            "[0, 1, 0, 0, 2.072, 3.278, 3.544]\n",
            "preds: [0.999 0.001 0.001 0.414], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.956 0.005 0.001 0.101]\n",
            "true_class: 0\n",
            "true_odd: 1.703\n",
            "[1, 0, 0, 0, 1.703, 3.573, 5.052]\n",
            "preds: [0.956 0.005 0.001 0.101], pred_class: 0, true: 0, added 0.703\n",
            "predicted_class: 3\n",
            "predictions: [0.644 0.357 0.008 0.851]\n",
            "true_class: 0\n",
            "true_odd: 1.586\n",
            "[1, 0, 0, 0, 1.586, 3.603, 6.488]\n",
            "preds: [0.644 0.357 0.008 0.851], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.703 0.193 0.015 0.808]\n",
            "true_class: 2\n",
            "true_odd: 5.405\n",
            "[0, 0, 1, 0, 1.547, 4.26, 5.405]\n",
            "preds: [0.703 0.193 0.015 0.808], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.807 0.045 0.014 0.867]\n",
            "true_class: 2\n",
            "true_odd: 5.402\n",
            "[0, 0, 1, 0, 1.641, 3.74, 5.402]\n",
            "preds: [0.807 0.045 0.014 0.867], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.343 0.679 0.002 0.927]\n",
            "true_class: 1\n",
            "true_odd: 5.444\n",
            "[0, 1, 0, 0, 1.288, 5.444, 9.63]\n",
            "preds: [0.343 0.679 0.002 0.927], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.094]\n",
            "true_class: 0\n",
            "true_odd: 2.033\n",
            "[1, 0, 0, 0, 2.033, 3.195, 3.937]\n",
            "preds: [1.    0.    0.    0.094], pred_class: 0, true: 0, added 1.033\n",
            "predicted_class: 3\n",
            "predictions: [0.05  0.579 0.069 0.617]\n",
            "true_class: 2\n",
            "true_odd: 6.84\n",
            "[0, 0, 1, 0, 1.439, 4.537, 6.84]\n",
            "preds: [0.05  0.579 0.069 0.617], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.955 0.047 0.006 0.593]\n",
            "true_class: 0\n",
            "true_odd: 2.175\n",
            "[1, 0, 0, 0, 2.175, 3.103, 3.556]\n",
            "preds: [0.955 0.047 0.006 0.593], pred_class: 0, true: 0, added 1.175\n",
            "predicted_class: 3\n",
            "predictions: [0.895 0.082 0.007 0.944]\n",
            "true_class: 0\n",
            "true_odd: 1.737\n",
            "[1, 0, 0, 0, 1.737, 3.59, 4.8]\n",
            "preds: [0.895 0.082 0.007 0.944], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.909 0.042 0.001 0.459]\n",
            "true_class: 0\n",
            "true_odd: 1.583\n",
            "[1, 0, 0, 0, 1.583, 3.979, 5.62]\n",
            "preds: [0.909 0.042 0.001 0.459], pred_class: 0, true: 0, added 0.583\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.264\n",
            "[1, 0, 0, 0, 1.264, 5.72, 10.745]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.264\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.001 0.001 0.108]\n",
            "true_class: 2\n",
            "true_odd: 3.322\n",
            "[0, 0, 1, 0, 2.243, 3.159, 3.322]\n",
            "preds: [0.998 0.001 0.001 0.108], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.154 0.865 0.098 0.364]\n",
            "true_class: 2\n",
            "true_odd: 4.596\n",
            "[0, 0, 1, 0, 1.902, 3.131, 4.596]\n",
            "preds: [0.154 0.865 0.098 0.364], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.994 0.    0.001 0.816]\n",
            "true_class: 1\n",
            "true_odd: 3.24\n",
            "[0, 1, 0, 0, 1.992, 3.24, 3.99]\n",
            "preds: [0.994 0.    0.001 0.816], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.262 0.795 0.01  0.782]\n",
            "true_class: 0\n",
            "true_odd: 1.371\n",
            "[1, 0, 0, 0, 1.371, 4.932, 7.767]\n",
            "preds: [0.262 0.795 0.01  0.782], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.657]\n",
            "true_class: 0\n",
            "true_odd: 1.668\n",
            "[1, 0, 0, 0, 1.668, 3.553, 5.54]\n",
            "preds: [0.999 0.    0.    0.657], pred_class: 0, true: 0, added 0.668\n",
            "predicted_class: 0\n",
            "predictions: [0.954 0.02  0.002 0.903]\n",
            "true_class: 0\n",
            "true_odd: 1.896\n",
            "[1, 0, 0, 0, 1.896, 3.458, 4.108]\n",
            "preds: [0.954 0.02  0.002 0.903], pred_class: 0, true: 0, added 0.896\n",
            "predicted_class: 1\n",
            "predictions: [0.102 0.913 0.192 0.271]\n",
            "true_class: 0\n",
            "true_odd: 2.136\n",
            "[1, 0, 0, 0, 2.136, 2.86, 4.114]\n",
            "preds: [0.102 0.913 0.192 0.271], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.995 0.    0.001 0.266]\n",
            "true_class: 2\n",
            "true_odd: 3.439\n",
            "[0, 0, 1, 0, 2.233, 3.109, 3.439]\n",
            "preds: [0.995 0.    0.001 0.266], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 2\n",
            "true_odd: 4.043\n",
            "[0, 0, 1, 0, 1.981, 3.244, 4.043]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.693 0.088 0.009 0.692]\n",
            "true_class: 0\n",
            "true_odd: 1.374\n",
            "[1, 0, 0, 0, 1.374, 4.325, 9.745]\n",
            "preds: [0.693 0.088 0.009 0.692], pred_class: 0, true: 0, added 0.374\n",
            "predicted_class: 1\n",
            "predictions: [0.244 0.501 0.002 0.342]\n",
            "true_class: 0\n",
            "true_odd: 1.381\n",
            "[1, 0, 0, 0, 1.381, 4.66, 8.237]\n",
            "preds: [0.244 0.501 0.002 0.342], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.382 0.251 0.029 0.71 ]\n",
            "true_class: 0\n",
            "true_odd: 1.561\n",
            "[1, 0, 0, 0, 1.561, 4.062, 5.687]\n",
            "preds: [0.382 0.251 0.029 0.71 ], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.995 0.008 0.001 0.342]\n",
            "true_class: 2\n",
            "true_odd: 4.249\n",
            "[0, 0, 1, 0, 1.82, 3.611, 4.249]\n",
            "preds: [0.995 0.008 0.001 0.342], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.19  0.24  0.041 0.323]\n",
            "true_class: 0\n",
            "true_odd: 1.703\n",
            "[1, 0, 0, 0, 1.703, 3.768, 4.837]\n",
            "preds: [0.19  0.24  0.041 0.323], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.127\n",
            "[1, 0, 0, 0, 1.127, 9.256, 17.819]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.127\n",
            "predicted_class: 3\n",
            "predictions: [0.573 0.469 0.003 0.959]\n",
            "true_class: 0\n",
            "true_odd: 1.274\n",
            "[1, 0, 0, 0, 1.274, 5.563, 10.709]\n",
            "preds: [0.573 0.469 0.003 0.959], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.42  0.32  0.071 0.532]\n",
            "true_class: 0\n",
            "true_odd: 1.893\n",
            "[1, 0, 0, 0, 1.893, 3.664, 3.839]\n",
            "preds: [0.42  0.32  0.071 0.532], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.994 0.001 0.001 0.714]\n",
            "true_class: 0\n",
            "true_odd: 2.264\n",
            "[1, 0, 0, 0, 2.264, 3.029, 3.443]\n",
            "preds: [0.994 0.001 0.001 0.714], pred_class: 0, true: 0, added 1.264\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.585]\n",
            "true_class: 2\n",
            "true_odd: 4.207\n",
            "[0, 0, 1, 0, 1.838, 3.554, 4.207]\n",
            "preds: [1.    0.    0.    0.585], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.361 0.417 0.002 0.883]\n",
            "true_class: 0\n",
            "true_odd: 1.237\n",
            "[1, 0, 0, 0, 1.237, 5.977, 12.42]\n",
            "preds: [0.361 0.417 0.002 0.883], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.78\n",
            "[1, 0, 0, 0, 1.78, 3.76, 4.326]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.780\n",
            "predicted_class: 0\n",
            "predictions: [0.948 0.001 0.001 0.741]\n",
            "true_class: 0\n",
            "true_odd: 1.278\n",
            "[1, 0, 0, 0, 1.278, 5.487, 10.7]\n",
            "preds: [0.948 0.001 0.001 0.741], pred_class: 0, true: 0, added 0.278\n",
            "predicted_class: 0\n",
            "predictions: [1.   0.   0.   0.57]\n",
            "true_class: 0\n",
            "true_odd: 1.762\n",
            "[1, 0, 0, 0, 1.762, 3.61, 4.674]\n",
            "preds: [1.   0.   0.   0.57], pred_class: 0, true: 0, added 0.762\n",
            "predicted_class: 0\n",
            "predictions: [0.608 0.413 0.013 0.579]\n",
            "true_class: 0\n",
            "true_odd: 2.08\n",
            "[1, 0, 0, 0, 2.08, 3.184, 3.83]\n",
            "preds: [0.608 0.413 0.013 0.579], pred_class: 0, true: 0, added 1.080\n",
            "predicted_class: 0\n",
            "predictions: [1.   0.   0.   0.43]\n",
            "true_class: 0\n",
            "true_odd: 1.745\n",
            "[1, 0, 0, 0, 1.745, 3.637, 4.724]\n",
            "preds: [1.   0.   0.   0.43], pred_class: 0, true: 0, added 0.745\n",
            "predicted_class: 0\n",
            "predictions: [0.908 0.133 0.008 0.688]\n",
            "true_class: 2\n",
            "true_odd: 5.141\n",
            "[0, 0, 1, 0, 1.652, 3.812, 5.141]\n",
            "preds: [0.908 0.133 0.008 0.688], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.226 0.587 0.228 0.386]\n",
            "true_class: 0\n",
            "true_odd: 2.069\n",
            "[1, 0, 0, 0, 2.069, 3.013, 4.018]\n",
            "preds: [0.226 0.587 0.228 0.386], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.971 0.018 0.001 0.888]\n",
            "true_class: 1\n",
            "true_odd: 3.8\n",
            "[0, 1, 0, 0, 1.67, 3.8, 4.978]\n",
            "preds: [0.971 0.018 0.001 0.888], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.953\n",
            "[1, 0, 0, 0, 1.953, 3.54, 3.717]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.953\n",
            "predicted_class: 1\n",
            "predictions: [0.218 0.74  0.011 0.731]\n",
            "true_class: 0\n",
            "true_odd: 1.323\n",
            "[1, 0, 0, 0, 1.323, 5.149, 9.076]\n",
            "preds: [0.218 0.74  0.011 0.731], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.787]\n",
            "true_class: 0\n",
            "true_odd: 1.978\n",
            "[1, 0, 0, 0, 1.978, 3.383, 3.87]\n",
            "preds: [0.999 0.    0.    0.787], pred_class: 0, true: 0, added 0.978\n",
            "predicted_class: 3\n",
            "predictions: [0.497 0.014 0.013 0.718]\n",
            "true_class: 0\n",
            "true_odd: 2.164\n",
            "[1, 0, 0, 0, 2.164, 3.236, 3.424]\n",
            "preds: [0.497 0.014 0.013 0.718], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.801 0.316 0.008 0.534]\n",
            "true_class: 0\n",
            "true_odd: 1.661\n",
            "[1, 0, 0, 0, 1.661, 3.66, 5.38]\n",
            "preds: [0.801 0.316 0.008 0.534], pred_class: 0, true: 0, added 0.661\n",
            "predicted_class: 0\n",
            "predictions: [0.666 0.099 0.005 0.135]\n",
            "true_class: 1\n",
            "true_odd: 4.102\n",
            "[0, 1, 0, 0, 1.483, 4.102, 7.165]\n",
            "preds: [0.666 0.099 0.005 0.135], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.884 0.125 0.002 0.954]\n",
            "true_class: 2\n",
            "true_odd: 5.089\n",
            "[0, 0, 1, 0, 1.635, 3.957, 5.089]\n",
            "preds: [0.884 0.125 0.002 0.954], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.189]\n",
            "true_class: 2\n",
            "true_odd: 3.693\n",
            "[0, 0, 1, 0, 2.075, 3.295, 3.693]\n",
            "preds: [1.    0.    0.    0.189], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.986 0.001 0.    0.625]\n",
            "true_class: 0\n",
            "true_odd: 1.327\n",
            "[1, 0, 0, 0, 1.327, 4.789, 10.153]\n",
            "preds: [0.986 0.001 0.    0.625], pred_class: 0, true: 0, added 0.327\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.413\n",
            "[1, 0, 0, 0, 1.413, 4.688, 7.494]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.413\n",
            "predicted_class: 3\n",
            "predictions: [0.418 0.096 0.055 0.552]\n",
            "true_class: 0\n",
            "true_odd: 1.496\n",
            "[1, 0, 0, 0, 1.496, 4.428, 6.134]\n",
            "preds: [0.418 0.096 0.055 0.552], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.969 0.018 0.001 0.797]\n",
            "true_class: 0\n",
            "true_odd: 1.39\n",
            "[1, 0, 0, 0, 1.39, 5.077, 7.837]\n",
            "preds: [0.969 0.018 0.001 0.797], pred_class: 0, true: 0, added 0.390\n",
            "predicted_class: 0\n",
            "predictions: [0.847 0.125 0.012 0.816]\n",
            "true_class: 2\n",
            "true_odd: 4.281\n",
            "[0, 0, 1, 0, 1.917, 3.268, 4.281]\n",
            "preds: [0.847 0.125 0.012 0.816], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.329 0.417 0.002 0.31 ]\n",
            "true_class: 2\n",
            "true_odd: 11.576\n",
            "[0, 0, 1, 0, 1.259, 5.769, 11.576]\n",
            "preds: [0.329 0.417 0.002 0.31 ], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.805]\n",
            "true_class: 0\n",
            "true_odd: 1.916\n",
            "[1, 0, 0, 0, 1.916, 3.629, 3.817]\n",
            "preds: [0.999 0.    0.    0.805], pred_class: 0, true: 0, added 0.916\n",
            "predicted_class: 3\n",
            "predictions: [0.328 0.589 0.013 0.79 ]\n",
            "true_class: 0\n",
            "true_odd: 1.487\n",
            "[1, 0, 0, 0, 1.487, 4.499, 6.265]\n",
            "preds: [0.328 0.589 0.013 0.79 ], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.992 0.001 0.001 0.216]\n",
            "true_class: 1\n",
            "true_odd: 3.585\n",
            "[0, 1, 0, 0, 1.897, 3.585, 4.064]\n",
            "preds: [0.992 0.001 0.001 0.216], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.905 0.142 0.005 0.715]\n",
            "true_class: 1\n",
            "true_odd: 3.986\n",
            "[0, 1, 0, 0, 1.762, 3.986, 4.28]\n",
            "preds: [0.905 0.142 0.005 0.715], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.022 0.792 0.208 0.519]\n",
            "true_class: 1\n",
            "true_odd: 3.255\n",
            "[0, 1, 0, 0, 2.229, 3.255, 3.311]\n",
            "preds: [0.022 0.792 0.208 0.519], pred_class: 1, true: 1, added 2.255\n",
            "predicted_class: 0\n",
            "predictions: [0.58  0.322 0.118 0.539]\n",
            "true_class: 0\n",
            "true_odd: 1.571\n",
            "[1, 0, 0, 0, 1.571, 3.789, 6.119]\n",
            "preds: [0.58  0.322 0.118 0.539], pred_class: 0, true: 0, added 0.571\n",
            "predicted_class: 1\n",
            "predictions: [0.037 0.978 0.152 0.204]\n",
            "true_class: 2\n",
            "true_odd: 4.125\n",
            "[0, 0, 1, 0, 2.017, 3.085, 4.125]\n",
            "preds: [0.037 0.978 0.152 0.204], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.629 0.516 0.022 0.942]\n",
            "true_class: 0\n",
            "true_odd: 1.424\n",
            "[1, 0, 0, 0, 1.424, 4.665, 6.901]\n",
            "preds: [0.629 0.516 0.022 0.942], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.078 0.985 0.085 0.787]\n",
            "true_class: 0\n",
            "true_odd: 1.679\n",
            "[1, 0, 0, 0, 1.679, 3.833, 4.816]\n",
            "preds: [0.078 0.985 0.085 0.787], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.985 0.007 0.009 0.149]\n",
            "true_class: 0\n",
            "true_odd: 1.713\n",
            "[1, 0, 0, 0, 1.713, 3.698, 4.936]\n",
            "preds: [0.985 0.007 0.009 0.149], pred_class: 0, true: 0, added 0.713\n",
            "predicted_class: 0\n",
            "predictions: [0.922 0.048 0.023 0.14 ]\n",
            "true_class: 0\n",
            "true_odd: 2.53\n",
            "[1, 0, 0, 0, 2.53, 2.927, 3.066]\n",
            "preds: [0.922 0.048 0.023 0.14 ], pred_class: 0, true: 0, added 1.530\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.538\n",
            "[1, 0, 0, 0, 1.538, 4.249, 5.714]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.538\n",
            "predicted_class: 1\n",
            "predictions: [0.211 0.931 0.035 0.587]\n",
            "true_class: 0\n",
            "true_odd: 1.945\n",
            "[1, 0, 0, 0, 1.945, 3.22, 4.185]\n",
            "preds: [0.211 0.931 0.035 0.587], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.282 0.66  0.003 0.817]\n",
            "true_class: 0\n",
            "true_odd: 1.334\n",
            "[1, 0, 0, 0, 1.334, 5.089, 8.615]\n",
            "preds: [0.282 0.66  0.003 0.817], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.76  0.099 0.054 0.815]\n",
            "true_class: 1\n",
            "true_odd: 3.482\n",
            "[0, 1, 0, 0, 1.772, 3.482, 4.86]\n",
            "preds: [0.76  0.099 0.054 0.815], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.979 0.003 0.003 0.498]\n",
            "true_class: 0\n",
            "true_odd: 1.63\n",
            "[1, 0, 0, 0, 1.63, 3.438, 6.263]\n",
            "preds: [0.979 0.003 0.003 0.498], pred_class: 0, true: 0, added 0.630\n",
            "predicted_class: 0\n",
            "predictions: [1.   0.   0.   0.01]\n",
            "true_class: 0\n",
            "true_odd: 2.125\n",
            "[1, 0, 0, 0, 2.125, 3.244, 3.578]\n",
            "preds: [1.   0.   0.   0.01], pred_class: 0, true: 0, added 1.125\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.517\n",
            "[1, 0, 0, 0, 1.517, 4.361, 6.004]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.517\n",
            "predicted_class: 1\n",
            "predictions: [0.389 0.604 0.127 0.508]\n",
            "true_class: 2\n",
            "true_odd: 4.249\n",
            "[0, 0, 1, 0, 1.779, 4.012, 4.249]\n",
            "preds: [0.389 0.604 0.127 0.508], pred_class: 1, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.238 0.78  0.011 0.672]\n",
            "true_class: 0\n",
            "true_odd: 1.263\n",
            "[1, 0, 0, 0, 1.263, 6.153, 9.72]\n",
            "preds: [0.238 0.78  0.011 0.672], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.574 0.668 0.017 0.393]\n",
            "true_class: 1\n",
            "true_odd: 3.458\n",
            "[0, 1, 0, 0, 1.695, 3.458, 5.585]\n",
            "preds: [0.574 0.668 0.017 0.393], pred_class: 1, true: 1, added 2.458\n",
            "predicted_class: 1\n",
            "predictions: [0.459 0.516 0.055 0.406]\n",
            "true_class: 1\n",
            "true_odd: 3.305\n",
            "[0, 1, 0, 0, 1.93, 3.305, 4.21]\n",
            "preds: [0.459 0.516 0.055 0.406], pred_class: 1, true: 1, added 2.305\n",
            "predicted_class: 0\n",
            "predictions: [0.969 0.021 0.001 0.844]\n",
            "true_class: 0\n",
            "true_odd: 1.39\n",
            "[1, 0, 0, 0, 1.39, 4.89, 7.592]\n",
            "preds: [0.969 0.021 0.001 0.844], pred_class: 0, true: 0, added 0.390\n",
            "predicted_class: 0\n",
            "predictions: [0.929 0.054 0.011 0.802]\n",
            "true_class: 0\n",
            "true_odd: 2.02\n",
            "[1, 0, 0, 0, 2.02, 3.342, 3.926]\n",
            "preds: [0.929 0.054 0.011 0.802], pred_class: 0, true: 0, added 1.020\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.002 0.064]\n",
            "true_class: 1\n",
            "true_odd: 3.173\n",
            "[0, 1, 0, 0, 2.066, 3.173, 3.896]\n",
            "preds: [0.999 0.    0.002 0.064], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.949 0.026 0.01  0.628]\n",
            "true_class: 0\n",
            "true_odd: 2.242\n",
            "[1, 0, 0, 0, 2.242, 3.248, 3.322]\n",
            "preds: [0.949 0.026 0.01  0.628], pred_class: 0, true: 0, added 1.242\n",
            "predicted_class: 3\n",
            "predictions: [0.621 0.059 0.031 0.713]\n",
            "true_class: 0\n",
            "true_odd: 1.342\n",
            "[1, 0, 0, 0, 1.342, 5.08, 8.988]\n",
            "preds: [0.621 0.059 0.031 0.713], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.481\n",
            "[1, 0, 0, 0, 1.481, 4.431, 6.356]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.481\n",
            "predicted_class: 1\n",
            "predictions: [0.162 0.89  0.015 0.656]\n",
            "true_class: 0\n",
            "true_odd: 1.326\n",
            "[1, 0, 0, 0, 1.326, 5.346, 8.672]\n",
            "preds: [0.162 0.89  0.015 0.656], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.563 0.308 0.117 0.09 ]\n",
            "true_class: 1\n",
            "true_odd: 2.978\n",
            "[0, 1, 0, 0, 2.569, 2.978, 3.011]\n",
            "preds: [0.563 0.308 0.117 0.09 ], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.263]\n",
            "true_class: 1\n",
            "true_odd: 3.53\n",
            "[0, 1, 0, 0, 1.833, 3.53, 4.353]\n",
            "preds: [1.    0.    0.    0.263], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.879 0.041 0.013 0.812]\n",
            "true_class: 0\n",
            "true_odd: 1.86\n",
            "[1, 0, 0, 0, 1.86, 3.549, 4.218]\n",
            "preds: [0.879 0.041 0.013 0.812], pred_class: 0, true: 0, added 0.860\n",
            "predicted_class: 0\n",
            "predictions: [0.742 0.032 0.017 0.252]\n",
            "true_class: 2\n",
            "true_odd: 6.205\n",
            "[0, 0, 1, 0, 1.508, 4.219, 6.205]\n",
            "preds: [0.742 0.032 0.017 0.252], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.175 0.872 0.106 0.325]\n",
            "true_class: 1\n",
            "true_odd: 3.207\n",
            "[0, 1, 0, 0, 2.047, 3.207, 3.902]\n",
            "preds: [0.175 0.872 0.106 0.325], pred_class: 1, true: 1, added 2.207\n",
            "predicted_class: 0\n",
            "predictions: [0.959 0.01  0.011 0.128]\n",
            "true_class: 0\n",
            "true_odd: 1.835\n",
            "[1, 0, 0, 0, 1.835, 3.507, 4.251]\n",
            "preds: [0.959 0.01  0.011 0.128], pred_class: 0, true: 0, added 0.835\n",
            "predicted_class: 1\n",
            "predictions: [0.182 0.864 0.052 0.589]\n",
            "true_class: 0\n",
            "true_odd: 1.52\n",
            "[1, 0, 0, 0, 1.52, 3.749, 7.351]\n",
            "preds: [0.182 0.864 0.052 0.589], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.924 0.043 0.048 0.322]\n",
            "true_class: 1\n",
            "true_odd: 2.969\n",
            "[0, 1, 0, 0, 2.518, 2.969, 3.072]\n",
            "preds: [0.924 0.043 0.048 0.322], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.67  0.392 0.014 0.864]\n",
            "true_class: 0\n",
            "true_odd: 1.43\n",
            "[1, 0, 0, 0, 1.43, 4.623, 7.04]\n",
            "preds: [0.67  0.392 0.014 0.864], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.836 0.031 0.02  0.278]\n",
            "true_class: 1\n",
            "true_odd: 3.763\n",
            "[0, 1, 0, 0, 1.697, 3.763, 4.874]\n",
            "preds: [0.836 0.031 0.02  0.278], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.615\n",
            "[1, 0, 0, 0, 1.615, 4.194, 4.99]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.615\n",
            "predicted_class: 0\n",
            "predictions: [0.596 0.088 0.056 0.233]\n",
            "true_class: 0\n",
            "true_odd: 1.751\n",
            "[1, 0, 0, 0, 1.751, 3.555, 4.819]\n",
            "preds: [0.596 0.088 0.056 0.233], pred_class: 0, true: 0, added 0.751\n",
            "predicted_class: 1\n",
            "predictions: [0.306 0.907 0.004 0.812]\n",
            "true_class: 0\n",
            "true_odd: 1.891\n",
            "[1, 0, 0, 0, 1.891, 3.475, 4.073]\n",
            "preds: [0.306 0.907 0.004 0.812], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.22  0.758 0.229 0.157]\n",
            "true_class: 1\n",
            "true_odd: 2.985\n",
            "[0, 1, 0, 0, 2.195, 2.985, 3.71]\n",
            "preds: [0.22  0.758 0.229 0.157], pred_class: 1, true: 1, added 1.985\n",
            "predicted_class: 0\n",
            "predictions: [0.983 0.005 0.002 0.742]\n",
            "true_class: 0\n",
            "true_odd: 1.95\n",
            "[1, 0, 0, 0, 1.95, 3.355, 3.972]\n",
            "preds: [0.983 0.005 0.002 0.742], pred_class: 0, true: 0, added 0.950\n",
            "predicted_class: 0\n",
            "predictions: [0.758 0.314 0.017 0.211]\n",
            "true_class: 1\n",
            "true_odd: 3.584\n",
            "[0, 1, 0, 0, 1.737, 3.584, 4.885]\n",
            "preds: [0.758 0.314 0.017 0.211], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.872 0.013 0.003 0.606]\n",
            "true_class: 0\n",
            "true_odd: 1.333\n",
            "[1, 0, 0, 0, 1.333, 4.952, 9.54]\n",
            "preds: [0.872 0.013 0.003 0.606], pred_class: 0, true: 0, added 0.333\n",
            "predicted_class: 3\n",
            "predictions: [0.584 0.461 0.098 0.729]\n",
            "true_class: 0\n",
            "true_odd: 1.933\n",
            "[1, 0, 0, 0, 1.933, 3.257, 4.296]\n",
            "preds: [0.584 0.461 0.098 0.729], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 1\n",
            "predictions: [0.306 0.888 0.053 0.8  ]\n",
            "true_class: 1\n",
            "true_odd: 5.594\n",
            "[0, 1, 0, 0, 1.287, 5.594, 9.962]\n",
            "preds: [0.306 0.888 0.053 0.8  ], pred_class: 1, true: 1, added 4.594\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.829\n",
            "[1, 0, 0, 0, 1.829, 3.523, 4.36]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.829\n",
            "predicted_class: 0\n",
            "predictions: [0.97  0.002 0.001 0.057]\n",
            "true_class: 0\n",
            "true_odd: 1.598\n",
            "[1, 0, 0, 0, 1.598, 3.987, 5.423]\n",
            "preds: [0.97  0.002 0.001 0.057], pred_class: 0, true: 0, added 0.598\n",
            "predicted_class: 0\n",
            "predictions: [0.98  0.002 0.005 0.207]\n",
            "true_class: 0\n",
            "true_odd: 1.905\n",
            "[1, 0, 0, 0, 1.905, 3.155, 4.585]\n",
            "preds: [0.98  0.002 0.005 0.207], pred_class: 0, true: 0, added 0.905\n",
            "predicted_class: 1\n",
            "predictions: [0.507 0.717 0.009 0.383]\n",
            "true_class: 0\n",
            "true_odd: 1.571\n",
            "[1, 0, 0, 0, 1.571, 3.997, 5.774]\n",
            "preds: [0.507 0.717 0.009 0.383], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.892 0.053 0.019 0.202]\n",
            "true_class: 1\n",
            "true_odd: 3.439\n",
            "[0, 1, 0, 0, 1.816, 3.439, 4.618]\n",
            "preds: [0.892 0.053 0.019 0.202], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.987 0.001 0.01  0.124]\n",
            "true_class: 1\n",
            "true_odd: 3.027\n",
            "[0, 1, 0, 0, 2.48, 3.027, 3.04]\n",
            "preds: [0.987 0.001 0.01  0.124], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.247 0.724 0.018 0.624]\n",
            "true_class: 0\n",
            "true_odd: 1.38\n",
            "[1, 0, 0, 0, 1.38, 4.915, 7.729]\n",
            "preds: [0.247 0.724 0.018 0.624], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.001 0.511]\n",
            "true_class: 1\n",
            "true_odd: 3.468\n",
            "[0, 1, 0, 0, 1.956, 3.468, 3.854]\n",
            "preds: [1.    0.    0.001 0.511], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.365 0.249 0.003 0.753]\n",
            "true_class: 0\n",
            "true_odd: 1.221\n",
            "[1, 0, 0, 0, 1.221, 6.354, 12.352]\n",
            "preds: [0.365 0.249 0.003 0.753], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.917 0.01  0.005 0.384]\n",
            "true_class: 0\n",
            "true_odd: 1.556\n",
            "[1, 0, 0, 0, 1.556, 4.302, 5.42]\n",
            "preds: [0.917 0.01  0.005 0.384], pred_class: 0, true: 0, added 0.556\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.078]\n",
            "true_class: 0\n",
            "true_odd: 1.835\n",
            "[1, 0, 0, 0, 1.835, 3.502, 4.315]\n",
            "preds: [1.    0.    0.    0.078], pred_class: 0, true: 0, added 0.835\n",
            "predicted_class: 0\n",
            "predictions: [0.867 0.05  0.005 0.066]\n",
            "true_class: 1\n",
            "true_odd: 3.342\n",
            "[0, 1, 0, 0, 2.008, 3.342, 3.786]\n",
            "preds: [0.867 0.05  0.005 0.066], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.781\n",
            "[1, 0, 0, 0, 1.781, 3.543, 4.593]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.781\n",
            "predicted_class: 1\n",
            "predictions: [0.224 0.672 0.066 0.462]\n",
            "true_class: 0\n",
            "true_odd: 1.426\n",
            "[1, 0, 0, 0, 1.426, 4.345, 7.728]\n",
            "preds: [0.224 0.672 0.066 0.462], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.989 0.003 0.002 0.713]\n",
            "true_class: 0\n",
            "true_odd: 1.745\n",
            "[1, 0, 0, 0, 1.745, 3.624, 4.755]\n",
            "preds: [0.989 0.003 0.002 0.713], pred_class: 0, true: 0, added 0.745\n",
            "predicted_class: 0\n",
            "predictions: [0.994 0.002 0.001 0.64 ]\n",
            "true_class: 0\n",
            "true_odd: 1.812\n",
            "[1, 0, 0, 0, 1.812, 3.49, 4.47]\n",
            "preds: [0.994 0.002 0.001 0.64 ], pred_class: 0, true: 0, added 0.812\n",
            "predicted_class: 0\n",
            "predictions: [0.879 0.025 0.026 0.212]\n",
            "true_class: 0\n",
            "true_odd: 1.972\n",
            "[1, 0, 0, 0, 1.972, 3.535, 3.681]\n",
            "preds: [0.879 0.025 0.026 0.212], pred_class: 0, true: 0, added 0.972\n",
            "predicted_class: 0\n",
            "predictions: [0.521 0.132 0.187 0.271]\n",
            "true_class: 1\n",
            "true_odd: 3.282\n",
            "[0, 1, 0, 0, 1.821, 3.282, 4.907]\n",
            "preds: [0.521 0.132 0.187 0.271], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.922 0.016 0.055 0.099]\n",
            "true_class: 0\n",
            "true_odd: 2.47\n",
            "[1, 0, 0, 0, 2.47, 2.924, 3.123]\n",
            "preds: [0.922 0.016 0.055 0.099], pred_class: 0, true: 0, added 1.470\n",
            "predicted_class: 0\n",
            "predictions: [0.783 0.303 0.003 0.667]\n",
            "true_class: 0\n",
            "true_odd: 1.88\n",
            "[1, 0, 0, 0, 1.88, 3.581, 3.962]\n",
            "preds: [0.783 0.303 0.003 0.667], pred_class: 0, true: 0, added 0.880\n",
            "predicted_class: 0\n",
            "predictions: [0.991 0.006 0.003 0.228]\n",
            "true_class: 0\n",
            "true_odd: 1.645\n",
            "[1, 0, 0, 0, 1.645, 3.888, 5.025]\n",
            "preds: [0.991 0.006 0.003 0.228], pred_class: 0, true: 0, added 0.645\n",
            "predicted_class: 3\n",
            "predictions: [0.123 0.452 0.001 0.582]\n",
            "true_class: 0\n",
            "true_odd: 1.154\n",
            "[1, 0, 0, 0, 1.154, 7.59, 16.117]\n",
            "preds: [0.123 0.452 0.001 0.582], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.916 0.032 0.042 0.163]\n",
            "true_class: 1\n",
            "true_odd: 3.075\n",
            "[0, 1, 0, 0, 2.115, 3.075, 3.67]\n",
            "preds: [0.916 0.032 0.042 0.163], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.814 0.042 0.039 0.44 ]\n",
            "true_class: 1\n",
            "true_odd: 3.604\n",
            "[0, 1, 0, 0, 1.805, 3.604, 4.255]\n",
            "preds: [0.814 0.042 0.039 0.44 ], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.981 0.007 0.007 0.086]\n",
            "true_class: 0\n",
            "true_odd: 2.554\n",
            "[1, 0, 0, 0, 2.554, 2.907, 3.08]\n",
            "preds: [0.981 0.007 0.007 0.086], pred_class: 0, true: 0, added 1.554\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.001 0.104]\n",
            "true_class: 2\n",
            "true_odd: 4.414\n",
            "[0, 0, 1, 0, 1.904, 3.236, 4.414]\n",
            "preds: [0.999 0.    0.001 0.104], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.247\n",
            "[1, 0, 0, 0, 1.247, 6.244, 10.34]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.247\n",
            "predicted_class: 3\n",
            "predictions: [0.899 0.168 0.003 0.954]\n",
            "true_class: 2\n",
            "true_odd: 5.153\n",
            "[0, 0, 1, 0, 1.548, 4.502, 5.153]\n",
            "preds: [0.899 0.168 0.003 0.954], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.997 0.    0.003 0.126]\n",
            "true_class: 0\n",
            "true_odd: 2.0\n",
            "[1, 0, 0, 0, 2.0, 3.277, 3.855]\n",
            "preds: [0.997 0.    0.003 0.126], pred_class: 0, true: 0, added 1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.001 0.207]\n",
            "true_class: 2\n",
            "true_odd: 5.264\n",
            "[0, 0, 1, 0, 1.674, 3.649, 5.264]\n",
            "preds: [1.    0.    0.001 0.207], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.984 0.003 0.001 0.356]\n",
            "true_class: 0\n",
            "true_odd: 1.565\n",
            "[1, 0, 0, 0, 1.565, 4.201, 5.308]\n",
            "preds: [0.984 0.003 0.001 0.356], pred_class: 0, true: 0, added 0.565\n",
            "predicted_class: 3\n",
            "predictions: [0.849 0.159 0.012 0.931]\n",
            "true_class: 1\n",
            "true_odd: 3.721\n",
            "[0, 1, 0, 0, 1.719, 3.721, 4.703]\n",
            "preds: [0.849 0.159 0.012 0.931], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.977 0.001 0.014 0.096]\n",
            "true_class: 1\n",
            "true_odd: 3.3\n",
            "[0, 1, 0, 0, 1.89, 3.3, 4.294]\n",
            "preds: [0.977 0.001 0.014 0.096], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.346 0.474 0.006 0.799]\n",
            "true_class: 0\n",
            "true_odd: 1.29\n",
            "[1, 0, 0, 0, 1.29, 5.845, 8.576]\n",
            "preds: [0.346 0.474 0.006 0.799], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.625 0.475 0.004 0.83 ]\n",
            "true_class: 0\n",
            "true_odd: 1.598\n",
            "[1, 0, 0, 0, 1.598, 3.86, 5.648]\n",
            "preds: [0.625 0.475 0.004 0.83 ], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.317 0.615 0.05  0.653]\n",
            "true_class: 1\n",
            "true_odd: 4.905\n",
            "[0, 1, 0, 0, 1.325, 4.905, 9.712]\n",
            "preds: [0.317 0.615 0.05  0.653], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.136\n",
            "[1, 0, 0, 0, 1.136, 8.783, 15.391]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.136\n",
            "predicted_class: 0\n",
            "predictions: [0.881 0.091 0.009 0.295]\n",
            "true_class: 0\n",
            "true_odd: 1.382\n",
            "[1, 0, 0, 0, 1.382, 4.738, 7.835]\n",
            "preds: [0.881 0.091 0.009 0.295], pred_class: 0, true: 0, added 0.382\n",
            "predicted_class: 1\n",
            "predictions: [0.408 0.482 0.148 0.166]\n",
            "true_class: 0\n",
            "true_odd: 2.247\n",
            "[1, 0, 0, 0, 2.247, 3.003, 3.508]\n",
            "preds: [0.408 0.482 0.148 0.166], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.996 0.001 0.001 0.405]\n",
            "true_class: 0\n",
            "true_odd: 1.568\n",
            "[1, 0, 0, 0, 1.568, 4.127, 5.611]\n",
            "preds: [0.996 0.001 0.001 0.405], pred_class: 0, true: 0, added 0.568\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.098]\n",
            "true_class: 2\n",
            "true_odd: 3.41\n",
            "[0, 0, 1, 0, 2.246, 3.058, 3.41]\n",
            "preds: [0.999 0.    0.    0.098], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.493]\n",
            "true_class: 1\n",
            "true_odd: 3.785\n",
            "[0, 1, 0, 0, 1.552, 3.785, 6.345]\n",
            "preds: [0.998 0.    0.    0.493], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.001 0.142]\n",
            "true_class: 0\n",
            "true_odd: 2.077\n",
            "[1, 0, 0, 0, 2.077, 3.372, 3.516]\n",
            "preds: [0.998 0.    0.001 0.142], pred_class: 0, true: 0, added 1.077\n",
            "predicted_class: 1\n",
            "predictions: [0.023 0.987 0.032 0.54 ]\n",
            "true_class: 0\n",
            "true_odd: 1.217\n",
            "[1, 0, 0, 0, 1.217, 6.204, 12.512]\n",
            "preds: [0.023 0.987 0.032 0.54 ], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.66\n",
            "[1, 0, 0, 0, 1.66, 3.9, 4.905]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.660\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.078]\n",
            "true_class: 2\n",
            "true_odd: 4.597\n",
            "[0, 0, 1, 0, 1.782, 3.504, 4.597]\n",
            "preds: [1.    0.    0.    0.078], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 1\n",
            "predictions: [0.185 0.802 0.192 0.2  ]\n",
            "true_class: 1\n",
            "true_odd: 2.993\n",
            "[0, 1, 0, 0, 2.476, 2.993, 3.06]\n",
            "preds: [0.185 0.802 0.192 0.2  ], pred_class: 1, true: 1, added 1.993\n",
            "predicted_class: 0\n",
            "predictions: [0.828 0.21  0.02  0.536]\n",
            "true_class: 0\n",
            "true_odd: 2.127\n",
            "[1, 0, 0, 0, 2.127, 3.27, 3.472]\n",
            "preds: [0.828 0.21  0.02  0.536], pred_class: 0, true: 0, added 1.127\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.522]\n",
            "true_class: 0\n",
            "true_odd: 1.576\n",
            "[1, 0, 0, 0, 1.576, 4.166, 5.291]\n",
            "preds: [0.999 0.    0.    0.522], pred_class: 0, true: 0, added 0.576\n",
            "predicted_class: 0\n",
            "predictions: [0.99  0.    0.004 0.277]\n",
            "true_class: 0\n",
            "true_odd: 1.742\n",
            "[1, 0, 0, 0, 1.742, 3.42, 5.146]\n",
            "preds: [0.99  0.    0.004 0.277], pred_class: 0, true: 0, added 0.742\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.039]\n",
            "true_class: 2\n",
            "true_odd: 4.326\n",
            "[0, 0, 1, 0, 1.896, 3.297, 4.326]\n",
            "preds: [1.    0.    0.    0.039], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.71  0.185 0.058 0.212]\n",
            "true_class: 0\n",
            "true_odd: 2.154\n",
            "[1, 0, 0, 0, 2.154, 3.031, 3.665]\n",
            "preds: [0.71  0.185 0.058 0.212], pred_class: 0, true: 0, added 1.154\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.146\n",
            "[1, 0, 0, 0, 1.146, 8.485, 14.971]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.146\n",
            "predicted_class: 0\n",
            "predictions: [0.975 0.05  0.    0.758]\n",
            "true_class: 0\n",
            "true_odd: 1.661\n",
            "[1, 0, 0, 0, 1.661, 4.012, 4.707]\n",
            "preds: [0.975 0.05  0.    0.758], pred_class: 0, true: 0, added 0.661\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.421]\n",
            "true_class: 1\n",
            "true_odd: 3.831\n",
            "[0, 1, 0, 0, 1.602, 3.831, 5.73]\n",
            "preds: [1.    0.    0.    0.421], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.599 0.076 0.003 0.81 ]\n",
            "true_class: 2\n",
            "true_odd: 8.71\n",
            "[0, 0, 1, 0, 1.301, 5.687, 8.71]\n",
            "preds: [0.599 0.076 0.003 0.81 ], pred_class: 3, true: 2, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.144]\n",
            "true_class: 1\n",
            "true_odd: 3.333\n",
            "[0, 1, 0, 0, 2.069, 3.333, 3.61]\n",
            "preds: [1.    0.    0.    0.144], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.973 0.003 0.002 0.431]\n",
            "true_class: 0\n",
            "true_odd: 1.499\n",
            "[1, 0, 0, 0, 1.499, 4.301, 6.2]\n",
            "preds: [0.973 0.003 0.002 0.431], pred_class: 0, true: 0, added 0.499\n",
            "predicted_class: 0\n",
            "predictions: [0.992 0.001 0.001 0.109]\n",
            "true_class: 0\n",
            "true_odd: 1.823\n",
            "[1, 0, 0, 0, 1.823, 3.451, 4.519]\n",
            "preds: [0.992 0.001 0.001 0.109], pred_class: 0, true: 0, added 0.823\n",
            "predicted_class: 3\n",
            "predictions: [0.434 0.237 0.003 0.81 ]\n",
            "true_class: 0\n",
            "true_odd: 1.265\n",
            "[1, 0, 0, 0, 1.265, 5.727, 10.819]\n",
            "preds: [0.434 0.237 0.003 0.81 ], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.369]\n",
            "true_class: 0\n",
            "true_odd: 1.354\n",
            "[1, 0, 0, 0, 1.354, 5.201, 8.016]\n",
            "preds: [0.998 0.    0.    0.369], pred_class: 0, true: 0, added 0.354\n",
            "predicted_class: 1\n",
            "predictions: [0.21  0.862 0.049 0.374]\n",
            "true_class: 0\n",
            "true_odd: 1.557\n",
            "[1, 0, 0, 0, 1.557, 3.893, 6.27]\n",
            "preds: [0.21  0.862 0.049 0.374], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.645\n",
            "[1, 0, 0, 0, 1.645, 3.876, 5.121]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.645\n",
            "predicted_class: 3\n",
            "predictions: [0.838 0.159 0.01  0.859]\n",
            "true_class: 1\n",
            "true_odd: 3.844\n",
            "[0, 1, 0, 0, 1.749, 3.844, 4.371]\n",
            "preds: [0.838 0.159 0.01  0.859], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.905 0.057 0.013 0.843]\n",
            "true_class: 1\n",
            "true_odd: 3.419\n",
            "[0, 1, 0, 0, 1.826, 3.419, 4.509]\n",
            "preds: [0.905 0.057 0.013 0.843], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.526 0.071 0.101 0.405]\n",
            "true_class: 1\n",
            "true_odd: 3.766\n",
            "[0, 1, 0, 0, 1.716, 3.766, 4.674]\n",
            "preds: [0.526 0.071 0.101 0.405], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.487]\n",
            "true_class: 2\n",
            "true_odd: 4.893\n",
            "[0, 0, 1, 0, 1.765, 3.46, 4.893]\n",
            "preds: [0.998 0.    0.    0.487], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.556 0.66  0.016 0.9  ]\n",
            "true_class: 0\n",
            "true_odd: 1.556\n",
            "[1, 0, 0, 0, 1.556, 4.282, 5.399]\n",
            "preds: [0.556 0.66  0.016 0.9  ], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.945 0.045 0.012 0.221]\n",
            "true_class: 0\n",
            "true_odd: 2.285\n",
            "[1, 0, 0, 0, 2.285, 3.179, 3.234]\n",
            "preds: [0.945 0.045 0.012 0.221], pred_class: 0, true: 0, added 1.285\n",
            "predicted_class: 0\n",
            "predictions: [0.923 0.019 0.05  0.158]\n",
            "true_class: 0\n",
            "true_odd: 2.271\n",
            "[1, 0, 0, 0, 2.271, 3.012, 3.446]\n",
            "preds: [0.923 0.019 0.05  0.158], pred_class: 0, true: 0, added 1.271\n",
            "predicted_class: 0\n",
            "predictions: [0.868 0.007 0.    0.644]\n",
            "true_class: 1\n",
            "true_odd: 6.69\n",
            "[0, 1, 0, 0, 1.218, 6.69, 11.28]\n",
            "preds: [0.868 0.007 0.    0.644], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.837 0.02  0.024 0.311]\n",
            "true_class: 0\n",
            "true_odd: 1.696\n",
            "[1, 0, 0, 0, 1.696, 3.492, 5.34]\n",
            "preds: [0.837 0.02  0.024 0.311], pred_class: 0, true: 0, added 0.696\n",
            "predicted_class: 0\n",
            "predictions: [0.997 0.001 0.001 0.09 ]\n",
            "true_class: 1\n",
            "true_odd: 3.343\n",
            "[0, 1, 0, 0, 2.064, 3.343, 3.569]\n",
            "preds: [0.997 0.001 0.001 0.09 ], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.984 0.001 0.001 0.383]\n",
            "true_class: 0\n",
            "true_odd: 1.329\n",
            "[1, 0, 0, 0, 1.329, 5.034, 9.004]\n",
            "preds: [0.984 0.001 0.001 0.383], pred_class: 0, true: 0, added 0.329\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 1\n",
            "true_odd: 3.593\n",
            "[0, 1, 0, 0, 1.936, 3.593, 3.697]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.733]\n",
            "true_class: 1\n",
            "true_odd: 3.444\n",
            "[0, 1, 0, 0, 1.959, 3.444, 3.769]\n",
            "preds: [0.998 0.    0.    0.733], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.989 0.    0.    0.563]\n",
            "true_class: 2\n",
            "true_odd: 4.838\n",
            "[0, 0, 1, 0, 1.705, 3.685, 4.838]\n",
            "preds: [0.989 0.    0.    0.563], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.964 0.005 0.013 0.265]\n",
            "true_class: 1\n",
            "true_odd: 3.055\n",
            "[0, 1, 0, 0, 1.971, 3.055, 4.329]\n",
            "preds: [0.964 0.005 0.013 0.265], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.425 0.487 0.014 0.848]\n",
            "true_class: 0\n",
            "true_odd: 1.351\n",
            "[1, 0, 0, 0, 1.351, 5.0, 8.022]\n",
            "preds: [0.425 0.487 0.014 0.848], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.997 0.    0.001 0.051]\n",
            "true_class: 1\n",
            "true_odd: 3.01\n",
            "[0, 1, 0, 0, 2.412, 3.01, 3.118]\n",
            "preds: [0.997 0.    0.001 0.051], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.544 0.391 0.003 0.863]\n",
            "true_class: 0\n",
            "true_odd: 1.28\n",
            "[1, 0, 0, 0, 1.28, 5.528, 9.598]\n",
            "preds: [0.544 0.391 0.003 0.863], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.996 0.004 0.    0.756]\n",
            "true_class: 0\n",
            "true_odd: 1.58\n",
            "[1, 0, 0, 0, 1.58, 4.14, 5.265]\n",
            "preds: [0.996 0.004 0.    0.756], pred_class: 0, true: 0, added 0.580\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.731\n",
            "[1, 0, 0, 0, 1.731, 3.74, 4.492]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.731\n",
            "predicted_class: 0\n",
            "predictions: [1.   0.   0.   0.39]\n",
            "true_class: 0\n",
            "true_odd: 2.498\n",
            "[1, 0, 0, 0, 2.498, 3.0, 3.03]\n",
            "preds: [1.   0.   0.   0.39], pred_class: 0, true: 0, added 1.498\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.106]\n",
            "true_class: 1\n",
            "true_odd: 3.377\n",
            "[0, 1, 0, 0, 1.73, 3.377, 5.232]\n",
            "preds: [1.    0.    0.    0.106], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.979 0.005 0.007 0.14 ]\n",
            "true_class: 1\n",
            "true_odd: 3.245\n",
            "[0, 1, 0, 0, 1.925, 3.245, 4.271]\n",
            "preds: [0.979 0.005 0.007 0.14 ], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.916 0.021 0.005 0.895]\n",
            "true_class: 0\n",
            "true_odd: 1.535\n",
            "[1, 0, 0, 0, 1.535, 4.264, 5.509]\n",
            "preds: [0.916 0.021 0.005 0.895], pred_class: 0, true: 0, added 0.535\n",
            "predicted_class: 0\n",
            "predictions: [0.992 0.    0.001 0.147]\n",
            "true_class: 0\n",
            "true_odd: 1.697\n",
            "[1, 0, 0, 0, 1.697, 3.974, 4.445]\n",
            "preds: [0.992 0.    0.001 0.147], pred_class: 0, true: 0, added 0.697\n",
            "predicted_class: 0\n",
            "predictions: [0.993 0.001 0.003 0.147]\n",
            "true_class: 0\n",
            "true_odd: 2.303\n",
            "[1, 0, 0, 0, 2.303, 3.07, 3.28]\n",
            "preds: [0.993 0.001 0.003 0.147], pred_class: 0, true: 0, added 1.303\n",
            "predicted_class: 1\n",
            "predictions: [0.121 0.74  0.019 0.719]\n",
            "true_class: 0\n",
            "true_odd: 1.306\n",
            "[1, 0, 0, 0, 1.306, 5.286, 9.359]\n",
            "preds: [0.121 0.74  0.019 0.719], pred_class: 1, true: 0, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.937 0.028 0.01  0.119]\n",
            "true_class: 0\n",
            "true_odd: 2.147\n",
            "[1, 0, 0, 0, 2.147, 3.076, 3.639]\n",
            "preds: [0.937 0.028 0.01  0.119], pred_class: 0, true: 0, added 1.147\n",
            "predicted_class: 0\n",
            "predictions: [0.9   0.136 0.001 0.728]\n",
            "true_class: 0\n",
            "true_odd: 1.622\n",
            "[1, 0, 0, 0, 1.622, 4.11, 4.931]\n",
            "preds: [0.9   0.136 0.001 0.728], pred_class: 0, true: 0, added 0.622\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.088]\n",
            "true_class: 0\n",
            "true_odd: 2.109\n",
            "[1, 0, 0, 0, 2.109, 3.065, 3.725]\n",
            "preds: [1.    0.    0.    0.088], pred_class: 0, true: 0, added 1.109\n",
            "predicted_class: 3\n",
            "predictions: [0.198 0.769 0.002 0.836]\n",
            "true_class: 0\n",
            "true_odd: 1.24\n",
            "[1, 0, 0, 0, 1.24, 6.1, 10.71]\n",
            "preds: [0.198 0.769 0.002 0.836], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.895 0.007 0.002 0.82 ]\n",
            "true_class: 0\n",
            "true_odd: 1.424\n",
            "[1, 0, 0, 0, 1.424, 4.163, 8.323]\n",
            "preds: [0.895 0.007 0.002 0.82 ], pred_class: 0, true: 0, added 0.424\n",
            "predicted_class: 0\n",
            "predictions: [0.958 0.023 0.003 0.401]\n",
            "true_class: 0\n",
            "true_odd: 1.563\n",
            "[1, 0, 0, 0, 1.563, 3.793, 6.237]\n",
            "preds: [0.958 0.023 0.003 0.401], pred_class: 0, true: 0, added 0.563\n",
            "predicted_class: 0\n",
            "predictions: [0.927 0.007 0.01  0.227]\n",
            "true_class: 0\n",
            "true_odd: 1.848\n",
            "[1, 0, 0, 0, 1.848, 3.307, 4.483]\n",
            "preds: [0.927 0.007 0.01  0.227], pred_class: 0, true: 0, added 0.848\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 2\n",
            "true_odd: 3.865\n",
            "[0, 0, 1, 0, 1.931, 3.5, 3.865]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.897 0.016 0.018 0.197]\n",
            "true_class: 0\n",
            "true_odd: 2.016\n",
            "[1, 0, 0, 0, 2.016, 3.473, 3.514]\n",
            "preds: [0.897 0.016 0.018 0.197], pred_class: 0, true: 0, added 1.016\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.224]\n",
            "true_class: 2\n",
            "true_odd: 3.735\n",
            "[0, 0, 1, 0, 2.006, 3.359, 3.735]\n",
            "preds: [1.    0.    0.    0.224], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.269]\n",
            "true_class: 0\n",
            "true_odd: 2.172\n",
            "[1, 0, 0, 0, 2.172, 3.232, 3.361]\n",
            "preds: [1.    0.    0.    0.269], pred_class: 0, true: 0, added 1.172\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.118]\n",
            "true_class: 0\n",
            "true_odd: 2.058\n",
            "[1, 0, 0, 0, 2.058, 3.31, 3.591]\n",
            "preds: [1.    0.    0.    0.118], pred_class: 0, true: 0, added 1.058\n",
            "predicted_class: 1\n",
            "predictions: [0.358 0.437 0.068 0.154]\n",
            "true_class: 1\n",
            "true_odd: 3.122\n",
            "[0, 1, 0, 0, 1.938, 3.122, 4.398]\n",
            "preds: [0.358 0.437 0.068 0.154], pred_class: 1, true: 1, added 2.122\n",
            "predicted_class: 0\n",
            "predictions: [0.953 0.006 0.001 0.719]\n",
            "true_class: 0\n",
            "true_odd: 1.27\n",
            "[1, 0, 0, 0, 1.27, 5.815, 9.497]\n",
            "preds: [0.953 0.006 0.001 0.719], pred_class: 0, true: 0, added 0.270\n",
            "predicted_class: 3\n",
            "predictions: [0.64  0.531 0.017 0.849]\n",
            "true_class: 0\n",
            "true_odd: 1.538\n",
            "[1, 0, 0, 0, 1.538, 4.218, 5.625]\n",
            "preds: [0.64  0.531 0.017 0.849], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.825 0.275 0.003 0.91 ]\n",
            "true_class: 0\n",
            "true_odd: 1.648\n",
            "[1, 0, 0, 0, 1.648, 4.11, 4.615]\n",
            "preds: [0.825 0.275 0.003 0.91 ], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.001 0.001 0.421]\n",
            "true_class: 1\n",
            "true_odd: 3.286\n",
            "[0, 1, 0, 0, 2.111, 3.286, 3.48]\n",
            "preds: [0.999 0.001 0.001 0.421], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.968 0.018 0.003 0.853]\n",
            "true_class: 0\n",
            "true_odd: 2.067\n",
            "[1, 0, 0, 0, 2.067, 3.41, 3.477]\n",
            "preds: [0.968 0.018 0.003 0.853], pred_class: 0, true: 0, added 1.067\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.101]\n",
            "true_class: 1\n",
            "true_odd: 3.152\n",
            "[0, 1, 0, 0, 2.08, 3.152, 3.813]\n",
            "preds: [1.    0.    0.    0.101], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 1\n",
            "true_odd: 4.85\n",
            "[0, 1, 0, 0, 1.35, 4.85, 8.441]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.923 0.074 0.008 0.321]\n",
            "true_class: 1\n",
            "true_odd: 4.121\n",
            "[0, 1, 0, 0, 1.594, 4.121, 5.001]\n",
            "preds: [0.923 0.074 0.008 0.321], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.94  0.015 0.009 0.179]\n",
            "true_class: 2\n",
            "true_odd: 3.207\n",
            "[0, 0, 1, 0, 2.36, 3.03, 3.207]\n",
            "preds: [0.94  0.015 0.009 0.179], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.944 0.005 0.    0.324]\n",
            "true_class: 1\n",
            "true_odd: 5.598\n",
            "[0, 1, 0, 0, 1.264, 5.598, 10.455]\n",
            "preds: [0.944 0.005 0.    0.324], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.959 0.012 0.004 0.388]\n",
            "true_class: 0\n",
            "true_odd: 1.87\n",
            "[1, 0, 0, 0, 1.87, 3.483, 4.046]\n",
            "preds: [0.959 0.012 0.004 0.388], pred_class: 0, true: 0, added 0.870\n",
            "predicted_class: 0\n",
            "predictions: [1.   0.   0.   0.06]\n",
            "true_class: 0\n",
            "true_odd: 2.102\n",
            "[1, 0, 0, 0, 2.102, 3.156, 3.669]\n",
            "preds: [1.   0.   0.   0.06], pred_class: 0, true: 0, added 1.102\n",
            "predicted_class: 0\n",
            "predictions: [0.969 0.011 0.007 0.317]\n",
            "true_class: 2\n",
            "true_odd: 3.239\n",
            "[0, 0, 1, 0, 2.236, 3.175, 3.239]\n",
            "preds: [0.969 0.011 0.007 0.317], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 3\n",
            "predictions: [0.674 0.221 0.003 0.919]\n",
            "true_class: 0\n",
            "true_odd: 1.374\n",
            "[1, 0, 0, 0, 1.374, 4.848, 7.469]\n",
            "preds: [0.674 0.221 0.003 0.919], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.791 0.295 0.01  0.934]\n",
            "true_class: 0\n",
            "true_odd: 1.743\n",
            "[1, 0, 0, 0, 1.743, 3.968, 4.155]\n",
            "preds: [0.791 0.295 0.01  0.934], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.994 0.003 0.003 0.259]\n",
            "true_class: 0\n",
            "true_odd: 1.875\n",
            "[1, 0, 0, 0, 1.875, 3.25, 4.395]\n",
            "preds: [0.994 0.003 0.003 0.259], pred_class: 0, true: 0, added 0.875\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.001 0.265]\n",
            "true_class: 0\n",
            "true_odd: 2.244\n",
            "[1, 0, 0, 0, 2.244, 3.069, 3.384]\n",
            "preds: [0.998 0.    0.001 0.265], pred_class: 0, true: 0, added 1.244\n",
            "predicted_class: 0\n",
            "predictions: [0.99  0.002 0.001 0.627]\n",
            "true_class: 0\n",
            "true_odd: 1.895\n",
            "[1, 0, 0, 0, 1.895, 3.452, 3.963]\n",
            "preds: [0.99  0.002 0.001 0.627], pred_class: 0, true: 0, added 0.895\n",
            "predicted_class: 0\n",
            "predictions: [0.962 0.001 0.011 0.257]\n",
            "true_class: 1\n",
            "true_odd: 2.892\n",
            "[0, 1, 0, 0, 2.484, 2.892, 3.138]\n",
            "preds: [0.962 0.001 0.011 0.257], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.997 0.    0.001 0.178]\n",
            "true_class: 0\n",
            "true_odd: 1.764\n",
            "[1, 0, 0, 0, 1.764, 3.684, 4.391]\n",
            "preds: [0.997 0.    0.001 0.178], pred_class: 0, true: 0, added 0.764\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.827]\n",
            "true_class: 1\n",
            "true_odd: 3.244\n",
            "[0, 1, 0, 0, 2.164, 3.244, 3.32]\n",
            "preds: [0.998 0.    0.    0.827], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.866 0.031 0.001 0.814]\n",
            "true_class: 0\n",
            "true_odd: 1.383\n",
            "[1, 0, 0, 0, 1.383, 4.788, 7.395]\n",
            "preds: [0.866 0.031 0.001 0.814], pred_class: 0, true: 0, added 0.383\n",
            "predicted_class: 3\n",
            "predictions: [0.274 0.323 0.013 0.828]\n",
            "true_class: 0\n",
            "true_odd: 1.262\n",
            "[1, 0, 0, 0, 1.262, 5.793, 10.324]\n",
            "preds: [0.274 0.323 0.013 0.828], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.453]\n",
            "true_class: 0\n",
            "true_odd: 1.371\n",
            "[1, 0, 0, 0, 1.371, 4.587, 8.257]\n",
            "preds: [0.998 0.    0.    0.453], pred_class: 0, true: 0, added 0.371\n",
            "predicted_class: 0\n",
            "predictions: [0.996 0.    0.    0.148]\n",
            "true_class: 2\n",
            "true_odd: 4.217\n",
            "[0, 0, 1, 0, 1.975, 3.112, 4.217]\n",
            "preds: [0.996 0.    0.    0.148], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.122]\n",
            "true_class: 0\n",
            "true_odd: 1.506\n",
            "[1, 0, 0, 0, 1.506, 4.278, 5.884]\n",
            "preds: [1.    0.    0.    0.122], pred_class: 0, true: 0, added 0.506\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 2\n",
            "true_odd: 5.279\n",
            "[0, 0, 1, 0, 1.594, 4.014, 5.279]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.929 0.055 0.001 0.527]\n",
            "true_class: 1\n",
            "true_odd: 4.527\n",
            "[0, 1, 0, 0, 1.385, 4.527, 8.191]\n",
            "preds: [0.929 0.055 0.001 0.527], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.65  0.1   0.03  0.319]\n",
            "true_class: 0\n",
            "true_odd: 1.763\n",
            "[1, 0, 0, 0, 1.763, 3.345, 5.011]\n",
            "preds: [0.65  0.1   0.03  0.319], pred_class: 0, true: 0, added 0.763\n",
            "predicted_class: 0\n",
            "predictions: [0.994 0.    0.001 0.269]\n",
            "true_class: 0\n",
            "true_odd: 2.21\n",
            "[1, 0, 0, 0, 2.21, 3.054, 3.532]\n",
            "preds: [0.994 0.    0.001 0.269], pred_class: 0, true: 0, added 1.210\n",
            "predicted_class: 0\n",
            "predictions: [0.985 0.002 0.    0.635]\n",
            "true_class: 0\n",
            "true_odd: 1.425\n",
            "[1, 0, 0, 0, 1.425, 4.66, 6.611]\n",
            "preds: [0.985 0.002 0.    0.635], pred_class: 0, true: 0, added 0.425\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.    0.    0.114]\n",
            "true_class: 1\n",
            "true_odd: 3.108\n",
            "[0, 1, 0, 0, 2.099, 3.108, 3.701]\n",
            "preds: [0.999 0.    0.    0.114], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 0\n",
            "true_odd: 1.405\n",
            "[1, 0, 0, 0, 1.405, 4.762, 6.83]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 0, added 0.405\n",
            "predicted_class: 3\n",
            "predictions: [0.917 0.038 0.002 0.929]\n",
            "true_class: 0\n",
            "true_odd: 1.741\n",
            "[1, 0, 0, 0, 1.741, 3.713, 4.548]\n",
            "preds: [0.917 0.038 0.002 0.929], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 3\n",
            "predictions: [0.547 0.179 0.003 0.847]\n",
            "true_class: 0\n",
            "true_odd: 1.301\n",
            "[1, 0, 0, 0, 1.301, 5.367, 9.027]\n",
            "preds: [0.547 0.179 0.003 0.847], pred_class: 3, true: 0, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [1.   0.   0.   0.03]\n",
            "true_class: 0\n",
            "true_odd: 1.737\n",
            "[1, 0, 0, 0, 1.737, 3.582, 4.747]\n",
            "preds: [1.   0.   0.   0.03], pred_class: 0, true: 0, added 0.737\n",
            "predicted_class: 0\n",
            "predictions: [1.    0.    0.    0.261]\n",
            "true_class: 2\n",
            "true_odd: 4.328\n",
            "[0, 0, 1, 0, 1.814, 3.518, 4.328]\n",
            "preds: [1.    0.    0.    0.261], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.991 0.001 0.    0.671]\n",
            "true_class: 0\n",
            "true_odd: 1.557\n",
            "[1, 0, 0, 0, 1.557, 3.808, 6.21]\n",
            "preds: [0.991 0.001 0.    0.671], pred_class: 0, true: 0, added 0.557\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.001 0.251]\n",
            "true_class: 0\n",
            "true_odd: 2.14\n",
            "[1, 0, 0, 0, 2.14, 3.039, 3.764]\n",
            "preds: [0.998 0.    0.001 0.251], pred_class: 0, true: 0, added 1.140\n",
            "predicted_class: 0\n",
            "predictions: [0.999 0.001 0.    0.356]\n",
            "true_class: 0\n",
            "true_odd: 1.676\n",
            "[1, 0, 0, 0, 1.676, 3.923, 4.775]\n",
            "preds: [0.999 0.001 0.    0.356], pred_class: 0, true: 0, added 0.676\n",
            "predicted_class: 0\n",
            "predictions: [0.995 0.    0.    0.476]\n",
            "true_class: 2\n",
            "true_odd: 8.142\n",
            "[0, 0, 1, 0, 1.349, 5.13, 8.142]\n",
            "preds: [0.995 0.    0.    0.476], pred_class: 0, true: 2, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.997 0.001 0.    0.865]\n",
            "true_class: 0\n",
            "true_odd: 1.3\n",
            "[1, 0, 0, 0, 1.3, 5.589, 8.975]\n",
            "preds: [0.997 0.001 0.    0.865], pred_class: 0, true: 0, added 0.300\n",
            "predicted_class: 0\n",
            "predictions: [1. 0. 0. 0.]\n",
            "true_class: 1\n",
            "true_odd: 3.705\n",
            "[0, 1, 0, 0, 1.641, 3.705, 5.39]\n",
            "preds: [1. 0. 0. 0.], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.998 0.    0.    0.177]\n",
            "true_class: 1\n",
            "true_odd: 3.316\n",
            "[0, 1, 0, 0, 1.91, 3.316, 4.213]\n",
            "preds: [0.998 0.    0.    0.177], pred_class: 0, true: 1, added -1.000\n",
            "predicted_class: 0\n",
            "predictions: [0.938 0.014 0.    0.911]\n",
            "true_class: 0\n",
            "true_odd: 1.241\n",
            "[1, 0, 0, 0, 1.241, 6.417, 9.689]\n",
            "preds: [0.938 0.014 0.    0.911], pred_class: 0, true: 0, added 0.241\n",
            "predicted_class: 3\n",
            "predictions: [0.712 0.344 0.005 0.961]\n",
            "true_class: 1\n",
            "true_odd: 5.714\n",
            "[0, 1, 0, 0, 1.314, 5.714, 7.809]\n",
            "preds: [0.712 0.344 0.005 0.961], pred_class: 3, true: 1, added 0.000\n",
            "predicted_class: 0\n",
            "predictions: [0.94  0.032 0.002 0.432]\n",
            "true_class: 1\n",
            "true_odd: 3.684\n",
            "[0, 1, 0, 0, 1.861, 3.684, 3.929]\n",
            "preds: [0.94  0.032 0.002 0.432], pred_class: 0, true: 1, added -1.000\n",
            "loss: -0.0045\n",
            "bet: 81.522%      300.000/368\n",
            "home true: 61.685%      227.000/368\n",
            "draw true: 24.457%      90.000/368\n",
            "away true: 13.859%      51.000/368\n",
            "pred bet accuracy: 53.333%      160.000/300\n",
            "home correct: 60.744%      147.000/242\n",
            "draw correct: 22.414%      13.000/58\n",
            "away correct: invalid%      0/0\n",
            "nb correct: 0.000%      0.000/68\n",
            "home ev: 6.914%      16.733/242\n",
            "draw ev: -14.753%      -8.557/58\n",
            "away ev: invalid%      0/0\n",
            "ev: 2.725%      8.176/300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"BNBD_DAH_37A_7p7EV_1.keras\"\n",
        "model_path = f\"{model_save_pwd}/{model_name}\"\n",
        "model_12.save(f\"{model_path}\")\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79M-jlfYrE-O",
        "outputId": "4be8e8c3-92ec-4343-c834-de36ddc7be57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/JSIP Final Project/models/BNBD_DAH_37A_7p7EV_1.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bottom\n"
      ],
      "metadata": {
        "id": "ZBoEZMTcEkZ1"
      }
    }
  ]
}